{'R_grad_norm': 0.8027688139677047, 'training_loss': 3.637546281814575}
{'R_grad_norm': 0.7819469806551933, 'training_loss': 3.467550171613693}
{'R_grad_norm': 0.7859990951418877, 'training_loss': 3.379333702325821}
{'R_grad_norm': 0.7894311514496803, 'training_loss': 3.2849481177330015}
{'R_grad_norm': 0.7940750324726105, 'training_loss': 3.235658119916916}
{'R_grad_norm': 0.7973246642947197, 'training_loss': 3.195988733768463}
{'R_grad_norm': 0.7968414890766143, 'training_loss': 3.13967604637146}
{'R_grad_norm': 0.7977609491348266, 'training_loss': 3.1085676980018615}
{'R_grad_norm': 0.7998445338010788, 'training_loss': 3.085613880157471}
{'R_grad_norm': 0.8005700409412384, 'training_loss': 3.0532439136505127}
{'R_grad_norm': 0.8012907233834267, 'training_loss': 3.0266589748859407}
{'R_grad_norm': 0.8019519278407097, 'training_loss': 3.0110858476161955}
{'R_grad_norm': 0.8011398127675057, 'training_loss': 2.983056594133377}
{'R_grad_norm': 0.8025065895915031, 'training_loss': 2.969971189498901}
{'R_grad_norm': 0.79962950527668, 'training_loss': 2.9480301201343537}
{'R_grad_norm': 0.8021152347326279, 'training_loss': 2.9332223463058473}
{'R_grad_norm': 0.8026139429211616, 'training_loss': 2.9360848915576936}
{'R_grad_norm': 0.8010538843274116, 'training_loss': 2.9062946212291716}
{'R_grad_norm': 0.7980792748928071, 'training_loss': 2.8815259981155394}
{'R_grad_norm': 0.8003069251775742, 'training_loss': 2.885331680774689}
{'R_grad_norm': 0.7990138906240464, 'training_loss': 2.866252416372299}
{'R_grad_norm': 0.8013216251134873, 'training_loss': 2.872793198823929}
{'R_grad_norm': 0.7995208045840263, 'training_loss': 2.8550551569461824}
{'R_grad_norm': 0.7990778547525406, 'training_loss': 2.841804141998291}
{'R_grad_norm': 0.8016597002744674, 'training_loss': 2.848326859474182}
{'R_grad_norm': 0.7997323742508888, 'training_loss': 2.8373963916301728}
{'R_grad_norm': 0.7997906279563903, 'training_loss': 2.8353616058826447}
{'R_grad_norm': 0.7986732247471809, 'training_loss': 2.82356871843338}
{'R_grad_norm': 0.7979691645503044, 'training_loss': 2.8255861139297487}
{'R_grad_norm': 0.7984071144461632, 'training_loss': 2.8262282371520997}
{'R_grad_norm': 0.797651293873787, 'training_loss': 2.807049345970154}
{'R_grad_norm': 0.7967919817566872, 'training_loss': 2.806025985479355}
{'R_grad_norm': 0.7993129312992096, 'training_loss': 2.819337919950485}
{'R_grad_norm': 0.7976523342728615, 'training_loss': 2.804640072584152}
{'R_grad_norm': 0.7957814964652061, 'training_loss': 2.7992773163318634}
{'R_grad_norm': 0.7956458321213722, 'training_loss': 2.7897520589828493}
{'R_grad_norm': 0.7941062358021737, 'training_loss': 2.7847508347034453}
{'R_grad_norm': 0.7922933518886566, 'training_loss': 2.7632583796978}
{'R_grad_norm': 0.7949994298815727, 'training_loss': 2.7823043131828307}
{'R_grad_norm': 0.7918543103337288, 'training_loss': 2.757252278327942}
{'R_grad_norm': 0.7931817933917046, 'training_loss': 2.7725314927101135}
{'R_grad_norm': 0.7938695651292801, 'training_loss': 2.770715413093567}
{'R_grad_norm': 0.7900250911712646, 'training_loss': 2.7468769371509554}
{'R_grad_norm': 0.7953395366668701, 'training_loss': 2.7754471373558043}
{'R_grad_norm': 0.7954145866632462, 'training_loss': 2.76245796918869}
{'R_grad_norm': 0.795459860265255, 'training_loss': 2.7713194417953493}
{'R_grad_norm': 0.793943589925766, 'training_loss': 2.7571677565574646}
{'R_grad_norm': 0.7924833336472511, 'training_loss': 2.7586813485622406}
{'R_grad_norm': 0.7906477746367454, 'training_loss': 2.7541345489025115}
{'R_grad_norm': 0.7914021670818329, 'training_loss': 2.739223450422287}
{'R_grad_norm': 0.7923258709907531, 'training_loss': 2.762184203863144}
{'R_grad_norm': 0.7929583746194839, 'training_loss': 2.755647755861282}
{'R_grad_norm': 0.7952723672986031, 'training_loss': 2.767926412820816}
{'R_grad_norm': 0.7897815671563149, 'training_loss': 2.7415178430080416}
{'R_grad_norm': 0.7884975358843803, 'training_loss': 2.734282751083374}
{'R_grad_norm': 0.7884532341361046, 'training_loss': 2.743636646270752}
{'R_grad_norm': 0.7881569880247116, 'training_loss': 2.7377538311481477}
{'R_grad_norm': 0.7901339912414551, 'training_loss': 2.75036763548851}
{'R_grad_norm': 0.7873095965385437, 'training_loss': 2.720873034000397}
{'R_grad_norm': 0.7883316811919212, 'training_loss': 2.740744971036911}
{'R_grad_norm': 0.7849450531601906, 'training_loss': 2.7270725739002226}
{'R_grad_norm': 0.7859327891469001, 'training_loss': 2.7174543952941894}
{'R_grad_norm': 0.7871572905778885, 'training_loss': 2.7245872724056244}
{'R_grad_norm': 0.786738982796669, 'training_loss': 2.7344620990753175}
{'R_grad_norm': 0.7858193522691727, 'training_loss': 2.7275258612632753}
{'R_grad_norm': 0.7837792757153511, 'training_loss': 2.709509555101395}
{'R_grad_norm': 0.7890239134430885, 'training_loss': 2.7396893990039826}
{'R_grad_norm': 0.7829327127337455, 'training_loss': 2.710070630311966}
{'R_grad_norm': 0.7870967239141464, 'training_loss': 2.72054980635643}
{'R_grad_norm': 0.7865770530700683, 'training_loss': 2.7152643835544588}
{'R_grad_norm': 0.7839715641736984, 'training_loss': 2.7055033683776855}
{'R_grad_norm': 0.7856463274359703, 'training_loss': 2.7194622468948366}
{'R_grad_norm': 0.7843882182240486, 'training_loss': 2.7164600467681885}
{'R_grad_norm': 0.7817776635289192, 'training_loss': 2.7154600918293}
{'R_grad_norm': 0.7816877713799477, 'training_loss': 2.7063606798648836}
{'R_grad_norm': 0.7826937344670296, 'training_loss': 2.7079782629013063}
{'R_grad_norm': 0.7828844571113587, 'training_loss': 2.701702146530151}
{'R_grad_norm': 0.7849368155002594, 'training_loss': 2.7155879616737364}
{'R_grad_norm': 0.7816606229543686, 'training_loss': 2.7028298592567443}
{'R_grad_norm': 0.786066299378872, 'training_loss': 2.705853340625763}
{'R_grad_norm': 0.782073692381382, 'training_loss': 2.70226789355278}
{'R_grad_norm': 0.7827547615766526, 'training_loss': 2.69983655333519}
{'R_grad_norm': 0.7821596419811249, 'training_loss': 2.7085609924793244}
{'R_grad_norm': 0.7824816289544105, 'training_loss': 2.7012481009960174}
{'R_grad_norm': 0.7823734179139137, 'training_loss': 2.6973621261119844}
{'R_grad_norm': 0.7818276140093804, 'training_loss': 2.703391568660736}
{'R_grad_norm': 0.7835717448592185, 'training_loss': 2.698716105222702}
{'R_grad_norm': 0.7808604842424393, 'training_loss': 2.6859366202354433}
{'R_grad_norm': 0.7792529618740082, 'training_loss': 2.684232409000397}
{'R_grad_norm': 0.7825274270772934, 'training_loss': 2.699150779247284}
{'R_grad_norm': 0.7806253781914712, 'training_loss': 2.692193262577057}
{'R_grad_norm': 0.784255608022213, 'training_loss': 2.703007515668869}
{'R_grad_norm': 0.7822713822126388, 'training_loss': 2.692751524448395}
{'R_grad_norm': 0.7790650352835655, 'training_loss': 2.6849536645412444}
{'R_grad_norm': 0.7797011315822602, 'training_loss': 2.682729380130768}
{'R_grad_norm': 0.7820706653594971, 'training_loss': 2.704228616952896}
{'R_grad_norm': 0.7785717615485191, 'training_loss': 2.6868861269950868}
{'R_grad_norm': 0.7776616317033768, 'training_loss': 2.6795286345481872}
{'R_grad_norm': 0.7813900211453437, 'training_loss': 2.6796560299396517}
{'R_grad_norm': 0.7800267416238785, 'training_loss': 2.6859132969379425}
eval result tensor([2.54784, 2.34619, 3.20622, 2.93486, 2.21047, 2.25384, 2.57239, 2.78240,
        2.56102, 2.33538, 2.59597, 2.43454, 2.78736, 3.20485, 2.69733, 3.34690,
        2.34308, 2.72423, 2.68222, 2.64602, 2.90205, 3.30479, 2.45309, 2.36942],
       device='cuda:0')
computing merge metric
normed mi [((5, 9), 0.14142802357673645), ((1, 9), 0.14050576090812683), ((1, 5), 0.1402604877948761), ((1, 22), 0.13839703798294067), ((9, 22), 0.13816875219345093), ((5, 22), 0.13753914833068848), ((0, 9), 0.1368378847837448), ((6, 23), 0.1367759257555008), ((22, 23), 0.13654130697250366), ((0, 5), 0.13604344427585602), ((6, 22), 0.13577458262443542), ((0, 1), 0.1357172429561615), ((7, 23), 0.13439330458641052), ((7, 22), 0.13437463343143463), ((6, 7), 0.1340402066707611), ((0, 22), 0.13342341780662537), ((1, 23), 0.13267281651496887), ((9, 23), 0.1320381760597229), ((1, 6), 0.13182450830936432), ((6, 9), 0.13104058802127838), ((5, 23), 0.13046635687351227), ((1, 7), 0.1304459571838379), ((7, 9), 0.1299416720867157), ((16, 23), 0.12967318296432495), ((16, 22), 0.1293988972902298), ((5, 6), 0.12929674983024597), ((10, 23), 0.12895722687244415), ((9, 16), 0.12893900275230408), ((5, 7), 0.12840287387371063), ((11, 23), 0.1282227486371994), ((6, 10), 0.12798656523227692), ((0, 23), 0.12790632247924805), ((6, 16), 0.12788338959217072), ((7, 10), 0.12784722447395325), ((1, 16), 0.12764674425125122), ((0, 6), 0.1272958666086197), ((6, 11), 0.12707079946994781), ((0, 7), 0.12678828835487366), ((10, 22), 0.126299649477005), ((5, 16), 0.12610624730587006), ((7, 16), 0.12510472536087036), ((20, 23), 0.12462098151445389), ((10, 16), 0.12449946999549866), ((7, 20), 0.12427981197834015), ((7, 11), 0.12409251183271408), ((6, 20), 0.12390356510877609), ((11, 22), 0.12373074144124985), ((20, 22), 0.12368812412023544), ((10, 11), 0.12303278595209122), ((0, 16), 0.12303118407726288), ((1, 10), 0.12232714146375656), ((9, 10), 0.12227194756269455), ((1, 20), 0.12222351878881454), ((9, 20), 0.12213592231273651), ((11, 16), 0.12210720777511597), ((16, 20), 0.12135390937328339), ((10, 20), 0.1212356761097908), ((5, 10), 0.11978819221258163), ((5, 20), 0.11961819976568222), ((0, 10), 0.11911916732788086), ((1, 11), 0.11876259744167328), ((9, 11), 0.11843007802963257), ((0, 20), 0.1180965006351471), ((11, 20), 0.11726812273263931), ((5, 11), 0.11633283644914627), ((0, 11), 0.1162443608045578), ((16, 19), 0.11269216239452362), ((19, 23), 0.1084207147359848), ((6, 19), 0.10719139873981476), ((9, 12), 0.10678529739379883), ((10, 19), 0.10587266087532043), ((19, 22), 0.10543203353881836), ((18, 19), 0.10525590926408768), ((5, 12), 0.10512574017047882), ((11, 19), 0.10494068264961243), ((19, 20), 0.10425932705402374), ((1, 12), 0.10403326153755188), ((7, 19), 0.10346249490976334), ((9, 19), 0.10310518741607666), ((0, 12), 0.10213947296142578), ((1, 19), 0.10197660326957703), ((12, 22), 0.10190780460834503), ((12, 16), 0.10123968869447708), ((16, 18), 0.10082823783159256), ((5, 19), 0.09989112615585327), ((4, 5), 0.09843843430280685), ((4, 9), 0.09843263775110245), ((0, 19), 0.09840153157711029), ((12, 23), 0.09767197072505951), ((18, 20), 0.09711534529924393), ((12, 20), 0.09701590240001678), ((6, 12), 0.09659028053283691), ((18, 23), 0.09637322276830673), ((7, 12), 0.09606801718473434), ((10, 18), 0.09516307711601257), ((10, 12), 0.09510626643896103), ((0, 4), 0.09501280635595322), ((6, 18), 0.09465805441141129), ((11, 18), 0.09435836225748062), ((1, 4), 0.09350001811981201), ((18, 22), 0.09156787395477295), ((7, 18), 0.09132136404514313), ((10, 17), 0.09097044914960861), ((17, 23), 0.09020791947841644), ((11, 12), 0.09017849713563919), ((16, 17), 0.08979426324367523), ((9, 18), 0.089558906853199), ((12, 19), 0.08861204236745834), ((6, 17), 0.08858432620763779), ((1, 18), 0.08852141350507736), ((11, 17), 0.08810964971780777), ((7, 17), 0.08788637071847916), ((5, 18), 0.08642540127038956), ((17, 22), 0.08617517352104187), ((17, 20), 0.08599292486906052), ((4, 22), 0.08433757722377777), ((17, 19), 0.08340396732091904), ((9, 17), 0.08333291858434677), ((12, 18), 0.08323881030082703), ((0, 18), 0.08322814851999283), ((1, 17), 0.08309491723775864), ((0, 17), 0.08266150951385498), ((5, 17), 0.08133319020271301), ((3, 18), 0.08123169839382172), ((3, 19), 0.08068601787090302), ((18, 21), 0.08034322410821915), ((14, 23), 0.0790640115737915), ((3, 16), 0.07898421585559845), ((10, 14), 0.0787549540400505), ((11, 14), 0.07869479805231094), ((6, 14), 0.0777416080236435), ((14, 18), 0.07730454951524734), ((14, 16), 0.07615400850772858), ((14, 19), 0.07593268901109695), ((12, 17), 0.07568282634019852), ((4, 16), 0.07562734186649323), ((7, 14), 0.07550990581512451), ((3, 10), 0.07542505860328674), ((3, 11), 0.07466650754213333), ((17, 18), 0.07419756054878235), ((14, 20), 0.07415314018726349), ((19, 21), 0.07413242757320404), ((3, 23), 0.07403036952018738), ((4, 12), 0.07359708845615387), ((3, 20), 0.07297751307487488), ((4, 8), 0.07276075333356857), ((4, 23), 0.07267677038908005), ((14, 22), 0.07244624197483063), ((3, 6), 0.07234553247690201), ((4, 7), 0.07187153398990631), ((4, 6), 0.07180634140968323), ((3, 7), 0.07144389301538467), ((3, 22), 0.07065907120704651), ((14, 21), 0.07042466849088669), ((3, 9), 0.06970547884702682), ((1, 14), 0.0695347785949707), ((3, 12), 0.0690232515335083), ((9, 14), 0.06878063827753067), ((1, 3), 0.0683850347995758), ((3, 5), 0.06830063462257385), ((4, 20), 0.06827885657548904), ((5, 14), 0.06729206442832947), ((0, 3), 0.06717055290937424), ((5, 8), 0.06577388197183609), ((8, 9), 0.06571375578641891), ((0, 14), 0.0653076022863388), ((16, 21), 0.06474123150110245), ((4, 10), 0.0644327774643898), ((3, 17), 0.06407614797353745), ((0, 8), 0.0632166862487793), ((20, 21), 0.0627836138010025), ((21, 23), 0.062167830765247345), ((10, 21), 0.06174423173069954), ((6, 21), 0.06171150133013725), ((1, 8), 0.06150864437222481), ((14, 17), 0.06086407229304314), ((4, 11), 0.060173969715833664), ((7, 21), 0.06004146859049797), ((11, 21), 0.05975298583507538), ((21, 22), 0.05846256762742996), ((9, 21), 0.057801809161901474), ((1, 21), 0.056476399302482605), ((3, 14), 0.056245092302560806), ((3, 21), 0.05579950660467148), ((12, 14), 0.05556919798254967), ((5, 21), 0.05504009500145912), ((4, 19), 0.05474891513586044), ((0, 21), 0.05471295118331909), ((12, 21), 0.053365934640169144), ((8, 22), 0.05254950746893883), ((4, 13), 0.050773948431015015), ((17, 21), 0.05045176297426224), ((8, 12), 0.04882848635315895), ((8, 16), 0.04491191357374191), ((8, 20), 0.04471881315112114), ((4, 17), 0.04275854676961899), ((7, 8), 0.04270492494106293), ((4, 18), 0.04259875789284706), ((8, 23), 0.041901543736457825), ((6, 8), 0.04163597896695137), ((2, 15), 0.04111073911190033), ((8, 10), 0.03675008565187454), ((3, 4), 0.0352986715734005), ((8, 11), 0.03276198357343674), ((8, 19), 0.03230127692222595), ((4, 21), 0.02854727953672409), ((9, 15), 0.02802995592355728), ((8, 18), 0.027875255793333054), ((5, 15), 0.027777427807450294), ((12, 15), 0.027625322341918945), ((4, 14), 0.027478951960802078), ((1, 15), 0.027237143367528915), ((0, 15), 0.027011536061763763), ((15, 22), 0.026192542165517807), ((15, 16), 0.02532913163304329), ((15, 20), 0.025314755737781525), ((8, 15), 0.025202324613928795), ((6, 15), 0.02470499649643898), ((15, 23), 0.024463342502713203), ((2, 4), 0.0243061650544405), ((7, 15), 0.02390557900071144), ((11, 15), 0.022822165861725807), ((10, 15), 0.022798018530011177), ((8, 17), 0.022088084369897842), ((8, 13), 0.022078700363636017), ((3, 15), 0.022019099444150925), ((3, 8), 0.021686438471078873), ((15, 18), 0.021518375724554062), ((15, 19), 0.021214740350842476), ((2, 5), 0.020793266594409943), ((2, 8), 0.020762566477060318), ((2, 9), 0.02066820301115513), ((8, 21), 0.020557105541229248), ((0, 2), 0.02019544132053852), ((2, 12), 0.020096568390727043), ((1, 2), 0.01969817280769348), ((4, 15), 0.01952964812517166), ((15, 17), 0.01938258484005928), ((2, 22), 0.018158700317144394), ((5, 13), 0.016904257237911224), ((9, 13), 0.016709456220269203), ((2, 20), 0.016224544495344162), ((15, 21), 0.016111718490719795), ((2, 16), 0.01603817380964756), ((2, 6), 0.015927908942103386), ((2, 23), 0.015882208943367004), ((2, 7), 0.015826517716050148), ((1, 13), 0.015241360291838646), ((8, 14), 0.015056626871228218), ((0, 13), 0.014798619784414768), ((14, 15), 0.014293245039880276), ((2, 10), 0.014241274446249008), ((2, 11), 0.013546536676585674), ((2, 17), 0.013008905574679375), ((2, 18), 0.012446507811546326), ((2, 19), 0.012249688617885113), ((13, 22), 0.011995971202850342), ((12, 13), 0.011598105542361736), ((2, 3), 0.010539878159761429), ((2, 13), 0.010164491832256317), ((13, 20), 0.010154439136385918), ((13, 16), 0.00968889705836773), ((7, 13), 0.009287284687161446), ((2, 21), 0.00922638550400734), ((13, 23), 0.009066017344594002), ((2, 14), 0.008958681486546993), ((6, 13), 0.008788778446614742), ((10, 13), 0.007625441532582045), ((11, 13), 0.00677653169259429), ((13, 19), 0.006328895688056946), ((13, 18), 0.0062113734893500805), ((13, 15), 0.006047784350812435), ((13, 21), 0.004806270822882652), ((3, 13), 0.004066886380314827), ((13, 17), 0.003724317532032728), ((13, 14), 0.0035235430113971233)]
******* after merging (0.04): [((5, 9), 64), ((1, 22), 64), ((6, 23), 64), ((0,), 32), ((2,), 32), ((3,), 32), ((4,), 32), ((7,), 32), ((8,), 32), ((10,), 32), ((11,), 32), ((12,), 32), ((13,), 32), ((14,), 32), ((15,), 32), ((16,), 32), ((17,), 32), ((18,), 32), ((19,), 32), ((20,), 32), ((21,), 32)]
{'R_grad_norm': 0.9609333372116089, 'training_loss': 2.909432816505432}
{'R_grad_norm': 0.9554631716012955, 'training_loss': 2.8958404791355132}
{'R_grad_norm': 0.9580530393123626, 'training_loss': 2.899681670665741}
{'R_grad_norm': 0.9565915182232857, 'training_loss': 2.890408868789673}
{'R_grad_norm': 0.9575276598334312, 'training_loss': 2.902502328157425}
{'R_grad_norm': 0.9531801694631576, 'training_loss': 2.8793363535404204}
{'R_grad_norm': 0.9562308937311172, 'training_loss': 2.893961975574493}
{'R_grad_norm': 0.9557156944274903, 'training_loss': 2.884288333654404}
{'R_grad_norm': 0.9534714156389237, 'training_loss': 2.8738191747665405}
{'R_grad_norm': 0.9549073129892349, 'training_loss': 2.881628489494324}
{'R_grad_norm': 0.9556475257873536, 'training_loss': 2.882776474952698}
{'R_grad_norm': 0.9531133085489273, 'training_loss': 2.8828825998306273}
{'R_grad_norm': 0.9548605111241341, 'training_loss': 2.8756693279743195}
{'R_grad_norm': 0.9520201063156128, 'training_loss': 2.865244039297104}
{'R_grad_norm': 0.9508722877502441, 'training_loss': 2.859274568557739}
{'R_grad_norm': 0.9494412893056869, 'training_loss': 2.8633409440517426}
{'R_grad_norm': 0.9503965038061142, 'training_loss': 2.863925106525421}
{'R_grad_norm': 0.9498500746488571, 'training_loss': 2.861513293981552}
{'R_grad_norm': 0.9491522705554962, 'training_loss': 2.8570970940589904}
{'R_grad_norm': 0.9512048733234405, 'training_loss': 2.872642045021057}
{'R_grad_norm': 0.9484741857647896, 'training_loss': 2.860511882305145}
{'R_grad_norm': 0.9496568325161934, 'training_loss': 2.8584532701969145}
{'R_grad_norm': 0.945935340821743, 'training_loss': 2.848873690366745}
{'R_grad_norm': 0.9478833940625191, 'training_loss': 2.8618398833274843}
{'R_grad_norm': 0.9485843291878701, 'training_loss': 2.853376042842865}
{'R_grad_norm': 0.947138130068779, 'training_loss': 2.8637199079990387}
{'R_grad_norm': 0.9460302749276162, 'training_loss': 2.8484094631671906}
{'R_grad_norm': 0.9473531055450439, 'training_loss': 2.8631994462013246}
{'R_grad_norm': 0.9467774870991706, 'training_loss': 2.8585870933532713}
{'R_grad_norm': 0.9458977302908897, 'training_loss': 2.8501612043380735}
{'R_grad_norm': 0.944058877825737, 'training_loss': 2.8433667004108427}
{'R_grad_norm': 0.9471136829257012, 'training_loss': 2.8617116808891296}
{'R_grad_norm': 0.9432821118831635, 'training_loss': 2.8447214758396147}
{'R_grad_norm': 0.9412121248245239, 'training_loss': 2.846054733991623}
{'R_grad_norm': 0.9420527431368828, 'training_loss': 2.8512573421001433}
{'R_grad_norm': 0.9388657861948013, 'training_loss': 2.8402245354652407}
{'R_grad_norm': 0.9438824924826622, 'training_loss': 2.854737821817398}
{'R_grad_norm': 0.942470726966858, 'training_loss': 2.8604291129112243}
{'R_grad_norm': 0.9414400669932366, 'training_loss': 2.8532078886032104}
{'R_grad_norm': 0.9397982379794121, 'training_loss': 2.8369216763973237}
eval result tensor([3.68048, 3.92471, 4.49709, 2.21672, 3.08292, 2.95296, 1.96094, 2.45264,
        2.59234, 2.39403, 2.15743, 2.69641, 3.12776, 2.50611, 3.21814, 2.15418,
        2.66027, 2.63379, 2.50927, 2.68212, 3.25350], device='cuda:0')
computing merge metric
normed mi [((7, 9), 0.12149473279714584), ((7, 10), 0.12017364054918289), ((3, 7), 0.11999024450778961), ((7, 19), 0.11924507468938828), ((9, 10), 0.11838982254266739), ((3, 15), 0.11818848550319672), ((7, 15), 0.11763723939657211), ((9, 15), 0.11751940101385117), ((9, 19), 0.11577929556369781), ((10, 15), 0.1153007373213768), ((15, 19), 0.11528417468070984), ((10, 19), 0.11397501081228256), ((3, 9), 0.11175259947776794), ((3, 10), 0.11076237261295319), ((3, 19), 0.11046799272298813), ((15, 18), 0.11026345938444138), ((17, 18), 0.10463377088308334), ((9, 18), 0.10447517037391663), ((10, 18), 0.10409682244062424), ((18, 19), 0.10181182622909546), ((7, 18), 0.10177187621593475), ((15, 17), 0.10020945221185684), ((3, 11), 0.09938983619213104), ((17, 19), 0.09776964783668518), ((11, 15), 0.09651730954647064), ((3, 18), 0.09527022391557693), ((10, 17), 0.09371983259916306), ((9, 17), 0.09345318377017975), ((0, 3), 0.09157208601633708), ((2, 7), 0.09041447440783183), ((7, 17), 0.09006885439157486), ((1, 7), 0.08972127238909404), ((11, 19), 0.08957266807556152), ((7, 11), 0.08910414576530457), ((0, 7), 0.08838379383087158), ((1, 3), 0.08798137307167053), ((9, 11), 0.08751100301742554), ((0, 15), 0.08660398920377095), ((2, 10), 0.08600829044977824), ((9, 16), 0.08585532754659653), ((1, 15), 0.08551811178525288), ((2, 9), 0.08519570032755534), ((15, 16), 0.08462323248386383), ((2, 19), 0.08363393942515056), ((7, 16), 0.08308885991573334), ((1, 9), 0.08304867148399353), ((10, 11), 0.08283517509698868), ((10, 16), 0.08268024027347565), ((1, 19), 0.08243825038274129), ((1, 10), 0.08228976527849834), ((11, 18), 0.08208449184894562), ((16, 19), 0.08185839653015137), ((3, 17), 0.08178369700908661), ((0, 9), 0.08173402647177379), ((0, 19), 0.08164615432421367), ((3, 6), 0.0813065767288208), ((2, 15), 0.08092646797498067), ((0, 10), 0.08053695658842723), ((11, 17), 0.08038274943828583), ((2, 3), 0.08017297089099884), ((16, 18), 0.07990656793117523), ((17, 20), 0.07934847474098206), ((5, 17), 0.07886840403079987), ((10, 13), 0.07864969223737717), ((3, 16), 0.07831620424985886), ((5, 18), 0.07763361930847168), ((9, 13), 0.07726656645536423), ((13, 17), 0.07645058631896973), ((5, 15), 0.07580606639385223), ((7, 13), 0.07529779523611069), ((13, 18), 0.07496751844882965), ((13, 19), 0.07448773086071014), ((0, 1), 0.07383888214826584), ((2, 18), 0.0737539529800415), ((5, 9), 0.07300987839698792), ((13, 15), 0.07223765552043915), ((16, 17), 0.07166630029678345), ((1, 18), 0.07148358722527821), ((5, 10), 0.07062588632106781), ((0, 11), 0.07051161924997966), ((0, 18), 0.07047220567862193), ((1, 2), 0.06991459429264069), ((11, 16), 0.06990798562765121), ((3, 8), 0.06983566284179688), ((5, 19), 0.06972959637641907), ((18, 20), 0.06948911398649216), ((5, 7), 0.06750743091106415), ((2, 17), 0.06729421019554138), ((0, 2), 0.06706596165895462), ((1, 11), 0.0666511207818985), ((13, 20), 0.06642021238803864), ((6, 11), 0.06454432755708694), ((5, 11), 0.06418387591838837), ((3, 13), 0.06376578658819199), ((1, 17), 0.06349411606788635), ((0, 17), 0.06270070870717366), ((3, 5), 0.06260327994823456), ((5, 16), 0.06073475256562233), ((15, 20), 0.06023107469081879), ((6, 15), 0.05987429991364479), ((2, 11), 0.05970520277818044), ((2, 16), 0.05952669680118561), ((19, 20), 0.05914910510182381), ((6, 8), 0.0579056479036808), ((9, 20), 0.05740705505013466), ((1, 16), 0.057322452465693154), ((2, 13), 0.05681805809338888), ((13, 16), 0.056775256991386414), ((0, 16), 0.05603055159250895), ((10, 20), 0.05592179670929909), ((7, 20), 0.055810973048210144), ((8, 11), 0.05509626865386963), ((5, 13), 0.05485759302973747), ((8, 15), 0.05300632864236832), ((6, 12), 0.05234689638018608), ((5, 20), 0.0523027703166008), ((11, 13), 0.05166895315051079), ((6, 7), 0.05046531930565834), ((3, 20), 0.050136592239141464), ((1, 13), 0.04987151424090067), ((0, 6), 0.04971794784069061), ((2, 5), 0.04912710189819336), ((11, 20), 0.04896038770675659), ((0, 13), 0.04841314256191254), ((6, 19), 0.04775627329945564), ((1, 5), 0.04645212491353353), ((8, 19), 0.04638530686497688), ((0, 5), 0.046228110790252686), ((16, 20), 0.04610200226306915), ((6, 9), 0.04593968763947487), ((7, 8), 0.04583992063999176), ((4, 14), 0.04552038013935089), ((0, 8), 0.04414135217666626), ((6, 10), 0.042833201587200165), ((2, 20), 0.04275014499823252), ((1, 6), 0.04243773718674978), ((8, 9), 0.04109593853354454), ((6, 18), 0.03947388380765915), ((1, 20), 0.03875404347976049), ((1, 8), 0.038233945767084755), ((0, 20), 0.03776541352272034), ((8, 10), 0.03735706955194473), ((8, 18), 0.035984937101602554), ((8, 17), 0.03289733827114105), ((6, 17), 0.0325356125831604), ((6, 16), 0.031192345544695854), ((2, 6), 0.02981783201297124), ((8, 16), 0.02778998389840126), ((2, 8), 0.02683468411366145), ((8, 14), 0.026527952402830124), ((5, 8), 0.02518589235842228), ((3, 14), 0.024090325459837914), ((5, 6), 0.02406695857644081), ((11, 14), 0.02404569648206234), ((8, 20), 0.022834178060293198), ((4, 6), 0.021425895392894745), ((4, 11), 0.02137564681470394), ((6, 20), 0.020990286022424698), ((14, 15), 0.02053724229335785), ((3, 4), 0.01927897334098816), ((6, 13), 0.01899072341620922), ((14, 19), 0.01861155405640602), ((4, 8), 0.018490465357899666), ((8, 13), 0.018224148079752922), ((7, 14), 0.018188321962952614), ((6, 14), 0.0178679246455431), ((10, 14), 0.01659275032579899), ((9, 14), 0.016406428068876266), ((0, 14), 0.016355258723100025), ((14, 17), 0.015752604231238365), ((4, 15), 0.015236515551805496), ((14, 18), 0.015006848610937595), ((1, 14), 0.014683280140161514), ((4, 7), 0.01468240562826395), ((4, 19), 0.01438047830015421), ((5, 14), 0.01416573766618967), ((14, 16), 0.013619459234178066), ((8, 12), 0.013145195320248604), ((4, 9), 0.012726124376058578), ((0, 4), 0.012680259843667349), ((4, 10), 0.01256445050239563), ((4, 16), 0.012373900972306728), ((4, 17), 0.011972385458648205), ((2, 14), 0.01171241949001948), ((14, 20), 0.011553297750651836), ((1, 4), 0.01130667453010877), ((4, 18), 0.010967385955154896), ((3, 12), 0.010359641164541245), ((13, 14), 0.01010851375758648), ((4, 5), 0.009847589768469334), ((2, 4), 0.009293202931682268), ((11, 12), 0.008659964427351952), ((4, 20), 0.008503702469170094), ((4, 13), 0.008265307173132896), ((4, 12), 0.007322159130126238), ((12, 15), 0.0067670103162527084), ((12, 14), 0.00621817447245121), ((12, 19), 0.006044743116945028), ((0, 12), 0.005920364831884702), ((7, 12), 0.0058400374837219715), ((9, 12), 0.004746034275740385), ((1, 12), 0.004690377662579219), ((10, 12), 0.004343489184975624), ((12, 17), 0.004188679624348879), ((12, 18), 0.0037823980674147606), ((12, 20), 0.003002794925123453), ((2, 12), 0.002854708582162857), ((12, 13), 0.002601480111479759), ((5, 12), 0.00244150310754776), ((12, 16), 0.0023751743137836456)]
******* after merging (0.04): [((7, 9), 64), ((3, 15), 64), ((0,), 64), ((1,), 64), ((2,), 64), ((4,), 32), ((5,), 32), ((6,), 32), ((8,), 32), ((10,), 32), ((11,), 32), ((12,), 32), ((13,), 32), ((14,), 32), ((16,), 32), ((17,), 32), ((18,), 32), ((19,), 32), ((20,), 32)]
{'R_grad_norm': 1.0219745981693267, 'training_loss': 3.0292403900623324}
{'R_grad_norm': 1.0188899338245392, 'training_loss': 3.0365740859508517}
{'R_grad_norm': 1.0186116003990173, 'training_loss': 3.031144177913666}
{'R_grad_norm': 1.0207719054818154, 'training_loss': 3.028773888349533}
{'R_grad_norm': 1.0174231311678887, 'training_loss': 3.0215385150909424}
{'R_grad_norm': 1.018538966178894, 'training_loss': 3.025813276767731}
{'R_grad_norm': 1.021504849791527, 'training_loss': 3.0316865527629853}
{'R_grad_norm': 1.0204609125852584, 'training_loss': 3.0275013422966004}
{'R_grad_norm': 1.0252734589576722, 'training_loss': 3.056718657016754}
{'R_grad_norm': 1.0202235931158066, 'training_loss': 3.0351759016513826}
{'R_grad_norm': 1.025167782008648, 'training_loss': 3.0543090748786925}
{'R_grad_norm': 1.0318214747309684, 'training_loss': 3.0798332941532136}
{'R_grad_norm': 1.0317013496160508, 'training_loss': 3.083379416465759}
{'R_grad_norm': 1.0294997799396515, 'training_loss': 3.0831419694423676}
{'R_grad_norm': 1.0321345824003219, 'training_loss': 3.0871761870384216}
{'R_grad_norm': 1.039566201865673, 'training_loss': 3.12961070895195}
{'R_grad_norm': 1.0410737743973733, 'training_loss': 3.132851755619049}
{'R_grad_norm': 1.0384802731871605, 'training_loss': 3.1177005898952483}
{'R_grad_norm': 1.0424529492855072, 'training_loss': 3.148393681049347}
{'R_grad_norm': 1.0514400935173034, 'training_loss': 3.1836860036849974}
{'R_grad_norm': 1.0555201971530914, 'training_loss': 3.217643007040024}
{'R_grad_norm': 1.0585682094097137, 'training_loss': 3.233967159986496}
{'R_grad_norm': 1.0341894519329071, 'training_loss': 3.1158187878131867}
{'R_grad_norm': 1.015171418786049, 'training_loss': 3.0319562327861784}
{'R_grad_norm': 1.0138511362671851, 'training_loss': 3.0141675102710725}
{'R_grad_norm': 1.0149795496463776, 'training_loss': 3.0179228615760803}
{'R_grad_norm': 1.018419468998909, 'training_loss': 3.03835240483284}
{'R_grad_norm': 1.0150975534319877, 'training_loss': 3.016902542114258}
{'R_grad_norm': 1.0121717831492425, 'training_loss': 3.0089383864402772}
{'R_grad_norm': 1.0130587342381476, 'training_loss': 3.016676725149155}
{'R_grad_norm': 1.01043548732996, 'training_loss': 3.008342704772949}
{'R_grad_norm': 1.0103532546758651, 'training_loss': 3.0097464084625245}
{'R_grad_norm': 1.013488907814026, 'training_loss': 3.0147908723354337}
{'R_grad_norm': 1.0113882610201836, 'training_loss': 3.010776165723801}
{'R_grad_norm': 1.0109754085540772, 'training_loss': 3.016243281364441}
{'R_grad_norm': 1.0132099458575248, 'training_loss': 3.02009036898613}
{'R_grad_norm': 1.007136207818985, 'training_loss': 2.998578429222107}
{'R_grad_norm': 1.0109452667832375, 'training_loss': 3.0156219828128816}
{'R_grad_norm': 1.0052597534656524, 'training_loss': 2.9905547523498535}
{'R_grad_norm': 1.0085740616917611, 'training_loss': 3.0150054705142977}
eval result tensor([4.12470, 3.62837, 3.70288, 3.93538, 4.84444, 3.01741, 3.01522, 1.93921,
        2.66230, 2.03611, 2.67012, 3.09564, 2.47749, 3.18516, 2.59938, 2.66937,
        2.45446, 2.51829, 3.23970], device='cuda:0')
computing merge metric
normed mi [((9, 17), 0.11250560730695724), ((15, 16), 0.10321319103240967), ((16, 17), 0.10115894675254822), ((9, 16), 0.10104724764823914), ((15, 17), 0.09814759343862534), ((9, 15), 0.08944826573133469), ((10, 17), 0.0850600004196167), ((1, 9), 0.08326263229052226), ((4, 17), 0.0824148456255595), ((4, 9), 0.08236378928025563), ((1, 17), 0.0815022091070811), ((0, 9), 0.08095586796601613), ((3, 9), 0.08077215154965718), ((15, 18), 0.08071170747280121), ((0, 17), 0.08058033386866252), ((2, 9), 0.07996319234371185), ((3, 17), 0.07975480457146962), ((9, 10), 0.07938487827777863), ((2, 17), 0.0792558987935384), ((10, 15), 0.0784272775053978), ((9, 14), 0.07827376574277878), ((10, 16), 0.07778094708919525), ((14, 17), 0.07735219597816467), ((8, 17), 0.07698696851730347), ((6, 15), 0.07674352824687958), ((14, 16), 0.07639779150485992), ((6, 16), 0.0752132460474968), ((2, 3), 0.0739787295460701), ((8, 9), 0.07387058436870575), ((1, 16), 0.07383778691291809), ((9, 12), 0.07330329716205597), ((12, 16), 0.07254672050476074), ((12, 15), 0.07244038581848145), ((12, 17), 0.07243794202804565), ((4, 16), 0.07205047210057576), ((0, 16), 0.07196260492006938), ((0, 4), 0.06978031992912292), ((2, 10), 0.06907759110132854), ((16, 18), 0.06902899593114853), ((1, 2), 0.06895001977682114), ((1, 3), 0.06892374157905579), ((3, 16), 0.06805439293384552), ((2, 16), 0.067796324690183), ((14, 15), 0.06765448302030563), ((6, 17), 0.06740152835845947), ((3, 4), 0.0665363222360611), ((4, 15), 0.06623600920041402), ((1, 4), 0.06613004207611084), ((8, 16), 0.06598076969385147), ((1, 15), 0.06591834127902985), ((3, 10), 0.06584826608498891), ((12, 18), 0.06551525741815567), ((6, 9), 0.0652012974023819), ((7, 10), 0.06505758315324783), ((0, 15), 0.06481081744035085), ((2, 4), 0.06463103741407394), ((0, 1), 0.0646195113658905), ((10, 14), 0.06354741007089615), ((1, 10), 0.06303202609221141), ((0, 3), 0.062353648245334625), ((2, 15), 0.06110001107056936), ((6, 10), 0.061072204262018204), ((0, 2), 0.061062466353178024), ((8, 15), 0.06093288213014603), ((3, 15), 0.06083842615286509), ((17, 18), 0.058902766555547714), ((8, 14), 0.058263879269361496), ((1, 14), 0.05689772963523865), ((0, 14), 0.056539297103881836), ((4, 14), 0.05647135774294535), ((4, 10), 0.056220218539237976), ((6, 14), 0.05612759292125702), ((4, 12), 0.05571627120176951), ((0, 12), 0.055659313996632896), ((0, 10), 0.05436276396115621), ((9, 18), 0.054313015192747116), ((0, 8), 0.053852190574010216), ((3, 14), 0.053232247630755104), ((4, 8), 0.052977209289868675), ((8, 10), 0.05242134630680084), ((12, 14), 0.052287738770246506), ((2, 14), 0.052208478252092995), ((6, 18), 0.05178477242588997), ((1, 8), 0.05168836315472921), ((8, 12), 0.05136309191584587), ((6, 8), 0.051170483231544495), ((7, 11), 0.05092272162437439), ((2, 7), 0.05040989319483439), ((6, 12), 0.05023987218737602), ((1, 12), 0.050064836939175926), ((0, 6), 0.04902674754460653), ((1, 6), 0.048970172802607216), ((3, 8), 0.048391252756118774), ((2, 8), 0.04746787746747335), ((4, 6), 0.04692536095778147), ((10, 12), 0.046726491302251816), ((10, 18), 0.04658673703670502), ((7, 9), 0.04628795012831688), ((3, 12), 0.04608559111754099), ((2, 12), 0.045844982067743935), ((7, 17), 0.045540452003479004), ((3, 7), 0.04484317203362783), ((5, 13), 0.04475406929850578), ((14, 18), 0.04435328394174576), ((2, 6), 0.04402299225330353), ((3, 6), 0.04343574742476145), ((4, 18), 0.04335598647594452), ((8, 18), 0.04259376600384712), ((0, 18), 0.04186838368574778), ((1, 18), 0.04019468277692795), ((1, 7), 0.03966605414946874), ((7, 16), 0.03811568021774292), ((3, 18), 0.03689652929703394), ((2, 18), 0.03667129327853521), ((7, 15), 0.03280158340930939), ((7, 14), 0.029444916173815727), ((7, 8), 0.028635121881961823), ((4, 7), 0.028401754796504974), ((0, 7), 0.02550808588663737), ((6, 7), 0.023184532299637794), ((10, 13), 0.022564636543393135), ((5, 7), 0.020766308531165123), ((5, 10), 0.02056838385760784), ((7, 18), 0.01969478279352188), ((7, 12), 0.01843339204788208), ((7, 13), 0.018236594274640083), ((13, 17), 0.016086993739008904), ((2, 13), 0.015288090954224268), ((9, 13), 0.015172264538705349), ((3, 13), 0.014075164993604025), ((13, 15), 0.014034541323781013), ((6, 13), 0.013084313832223415), ((5, 17), 0.012808597646653652), ((13, 16), 0.012731283903121948), ((8, 13), 0.012559627182781696), ((1, 13), 0.012310327341159185), ((5, 9), 0.01192166656255722), ((2, 5), 0.011891935020685196), ((13, 14), 0.011888478882610798), ((5, 14), 0.011518940329551697), ((3, 5), 0.010939236730337143), ((5, 15), 0.010411622002720833), ((5, 8), 0.010408369824290276), ((4, 13), 0.009907053783535957), ((13, 18), 0.009604796767234802), ((5, 16), 0.009510663338005543), ((5, 6), 0.00949095655232668), ((1, 5), 0.009377999852101008), ((10, 11), 0.009107994846999645), ((0, 13), 0.008817204584678015), ((12, 13), 0.008392322808504105), ((4, 5), 0.008227127293745676), ((0, 5), 0.0073536355048418045), ((5, 12), 0.0073114242404699326), ((5, 18), 0.007075919769704342), ((5, 11), 0.006989756133407354), ((11, 13), 0.006515750661492348), ((2, 11), 0.005982264255483945), ((11, 17), 0.005369098857045174), ((3, 11), 0.004969499694804351), ((9, 11), 0.004549082834273577), ((11, 15), 0.0039052355568856), ((1, 11), 0.0036263676981131234), ((8, 11), 0.003486114554107189), ((11, 16), 0.003435912076383829), ((11, 18), 0.002762004965916276), ((4, 11), 0.0025139624873797097), ((6, 11), 0.0023857562337070704), ((0, 11), 0.0023851697333157063), ((11, 12), 0.0023129708133637905), ((11, 14), 0.002220303285866976)]
******* after merging (0.04): [((9, 17), 64), ((15, 16), 64), ((0,), 64), ((1,), 64), ((2,), 64), ((3,), 64), ((4,), 64), ((5,), 32), ((6,), 32), ((7,), 32), ((8,), 32), ((10,), 32), ((11,), 32), ((12,), 32), ((13,), 32), ((14,), 32), ((18,), 32)]
{'R_grad_norm': 1.0857153099775314, 'training_loss': 3.263527853488922}
{'R_grad_norm': 1.084405529499054, 'training_loss': 3.2391812801361084}
{'R_grad_norm': 1.0846413797140122, 'training_loss': 3.244216115474701}
{'R_grad_norm': 1.0782927888631821, 'training_loss': 3.2398630011081697}
{'R_grad_norm': 1.0823463654518128, 'training_loss': 3.242834689617157}
{'R_grad_norm': 1.0790639042854309, 'training_loss': 3.2290273118019104}
{'R_grad_norm': 1.0785662037134172, 'training_loss': 3.221266793012619}
{'R_grad_norm': 1.0773471653461457, 'training_loss': 3.2296844899654387}
{'R_grad_norm': 1.0822861075401307, 'training_loss': 3.2423821103572847}
{'R_grad_norm': 1.0796462041139603, 'training_loss': 3.2367447412014005}
{'R_grad_norm': 1.0775585383176804, 'training_loss': 3.2157735419273377}
{'R_grad_norm': 1.0782667297124862, 'training_loss': 3.2280812680721285}
{'R_grad_norm': 1.082621962428093, 'training_loss': 3.242793402671814}
{'R_grad_norm': 1.0784366887807846, 'training_loss': 3.2231879460811617}
{'R_grad_norm': 1.082848454117775, 'training_loss': 3.235052111148834}
{'R_grad_norm': 1.075491780936718, 'training_loss': 3.226467049121857}
{'R_grad_norm': 1.0779635995626449, 'training_loss': 3.2269152438640596}
{'R_grad_norm': 1.0793520665168763, 'training_loss': 3.2445997726917266}
{'R_grad_norm': 1.0808979511260985, 'training_loss': 3.2402636110782623}
{'R_grad_norm': 1.0737248307466507, 'training_loss': 3.2103228986263277}
{'R_grad_norm': 1.078657727241516, 'training_loss': 3.23203151345253}
{'R_grad_norm': 1.0774993631243706, 'training_loss': 3.2268716776371003}
{'R_grad_norm': 1.0756705141067504, 'training_loss': 3.2251361382007597}
{'R_grad_norm': 1.0793113434314727, 'training_loss': 3.2282336258888247}
{'R_grad_norm': 1.0764781320095063, 'training_loss': 3.217739589214325}
{'R_grad_norm': 1.0778710782527923, 'training_loss': 3.230148296356201}
{'R_grad_norm': 1.0768948292732239, 'training_loss': 3.2333581900596617}
{'R_grad_norm': 1.0750252747535705, 'training_loss': 3.2258958649635314}
{'R_grad_norm': 1.074866492152214, 'training_loss': 3.2212118554115294}
{'R_grad_norm': 1.0748856252431869, 'training_loss': 3.2286737954616544}
{'R_grad_norm': 1.071859655380249, 'training_loss': 3.2089962482452394}
{'R_grad_norm': 1.0723322486877442, 'training_loss': 3.2180349683761595}
{'R_grad_norm': 1.072030058503151, 'training_loss': 3.219441750049591}
{'R_grad_norm': 1.0736589640378953, 'training_loss': 3.228349620103836}
{'R_grad_norm': 1.0762550288438797, 'training_loss': 3.2396334743499757}
{'R_grad_norm': 1.072531706094742, 'training_loss': 3.2108153200149534}
{'R_grad_norm': 1.071807114481926, 'training_loss': 3.226210025548935}
{'R_grad_norm': 1.0702083438634873, 'training_loss': 3.208865860700607}
{'R_grad_norm': 1.0739846104383468, 'training_loss': 3.232039121389389}
{'R_grad_norm': 1.0687252160906793, 'training_loss': 3.2127157759666445}
eval result tensor([3.53619, 4.40624, 4.05941, 3.48025, 3.53359, 3.77328, 4.74898, 2.94421,
        2.99013, 1.82899, 2.67029, 2.54881, 2.98376, 2.34391, 3.07391, 2.44922,
        3.20309], device='cuda:0')
computing merge metric
normed mi [((4, 5), 0.07389041036367416), ((4, 11), 0.06896511713663737), ((2, 6), 0.06844610720872879), ((3, 5), 0.06765111535787582), ((0, 6), 0.06739488989114761), ((3, 4), 0.06735283881425858), ((9, 11), 0.06687886267900467), ((0, 2), 0.06644588708877563), ((5, 11), 0.06535183886686961), ((3, 6), 0.06500152498483658), ((5, 6), 0.06465177237987518), ((2, 3), 0.06426084041595459), ((0, 3), 0.06403226405382156), ((13, 16), 0.06385812908411026), ((4, 6), 0.06272077560424805), ((3, 11), 0.06146577497323354), ((2, 5), 0.060361817479133606), ((11, 15), 0.06014029309153557), ((0, 5), 0.059700869023799896), ((2, 4), 0.0591757632791996), ((10, 13), 0.05909164249897003), ((0, 4), 0.05905776470899582), ((3, 15), 0.05768020451068878), ((2, 15), 0.05754246314366659), ((0, 1), 0.05693664774298668), ((6, 15), 0.056667973597844444), ((8, 11), 0.056455597281455994), ((0, 13), 0.05644649267196655), ((2, 13), 0.0560502161582311), ((6, 13), 0.05604487160841624), ((1, 16), 0.055948843558629356), ((0, 15), 0.05574096739292145), ((1, 3), 0.0552683100104332), ((1, 6), 0.05498974025249481), ((1, 2), 0.05488027632236481), ((1, 8), 0.054575646917025246), ((6, 11), 0.054206584890683494), ((13, 15), 0.054169539362192154), ((8, 15), 0.053627703338861465), ((2, 10), 0.05355392396450043), ((1, 13), 0.05331417918205261), ((0, 11), 0.05303291976451874), ((10, 15), 0.05263226851820946), ((2, 11), 0.0523908386627833), ((4, 9), 0.05228991309801737), ((5, 15), 0.0522475391626358), ((1, 11), 0.052169352769851685), ((0, 10), 0.05172538757324219), ((4, 15), 0.051095396280288696), ((1, 15), 0.05068619052569071), ((6, 10), 0.05051058530807495), ((3, 13), 0.05040033161640167), ((9, 12), 0.050370387732982635), ((8, 16), 0.04980206862092018), ((8, 13), 0.0487758070230484), ((8, 10), 0.04854732006788254), ((1, 5), 0.04826672375202179), ((2, 8), 0.04818268120288849), ((1, 4), 0.04816725105047226), ((3, 8), 0.047728036840756737), ((0, 8), 0.04690943161646525), ((5, 9), 0.046487520138422646), ((5, 13), 0.04585787157217661), ((7, 14), 0.04571252316236496), ((6, 8), 0.04524456957976023), ((4, 13), 0.045121461153030396), ((11, 13), 0.045095108449459076), ((3, 10), 0.044874414801597595), ((10, 16), 0.04404337331652641), ((15, 16), 0.04360819607973099), ((11, 16), 0.043461237102746964), ((1, 10), 0.04338269432385763), ((6, 16), 0.04324394464492798), ((2, 16), 0.041837722063064575), ((0, 16), 0.04153939584891001), ((10, 11), 0.04120501130819321), ((4, 8), 0.04120106250047684), ((5, 8), 0.040796505908171334), ((5, 10), 0.04074367135763168), ((3, 16), 0.0405619740486145), ((3, 9), 0.039935323099295296), ((4, 10), 0.03984735161066055), ((5, 16), 0.03605362524588903), ((4, 16), 0.03564877808094025), ((9, 15), 0.029047701507806778), ((6, 9), 0.028483154873053234), ((0, 9), 0.027820676565170288), ((2, 9), 0.026277830203374226), ((11, 14), 0.023187274113297462), ((1, 9), 0.022928441564242046), ((7, 9), 0.02183358371257782), ((8, 9), 0.02157614938914776), ((7, 11), 0.021080590784549713), ((9, 16), 0.019691526889801025), ((9, 13), 0.019157493487000465), ((9, 14), 0.01870957762002945), ((9, 10), 0.016453690826892853), ((4, 14), 0.015922531485557556), ((5, 14), 0.014486455669005712), ((4, 7), 0.012803029268980026), ((8, 14), 0.012114969082176685), ((3, 14), 0.012107963363329569), ((5, 7), 0.011595897376537323), ((7, 15), 0.011074349284172058), ((14, 15), 0.010808260180056095), ((11, 12), 0.01074246410280466), ((6, 14), 0.009716539333264032), ((3, 7), 0.009657766049106916), ((0, 14), 0.009618964667121569), ((14, 16), 0.009071811102330685), ((7, 8), 0.008960605598986149), ((7, 10), 0.008810080587863922), ((2, 14), 0.008689402292172113), ((1, 14), 0.008637472366293272), ((13, 14), 0.008530846796929836), ((6, 7), 0.008367287615935007), ((10, 14), 0.008334229700267315), ((0, 7), 0.008184493829806646), ((7, 13), 0.007745183538645506), ((7, 12), 0.00771018723025918), ((2, 7), 0.007554670795798302), ((4, 12), 0.007145651305715243), ((1, 7), 0.006892352054516475), ((7, 16), 0.006855501793324947), ((12, 14), 0.006827046629041433), ((5, 12), 0.0058488429834445315), ((3, 12), 0.003829193922380606), ((0, 12), 0.003017265039185683), ((12, 16), 0.0027260668575763702), ((6, 12), 0.002666580801208814), ((12, 13), 0.002533672144636512), ((2, 12), 0.0024712433417638144), ((8, 12), 0.0024061284493654966), ((1, 12), 0.002306985047956308), ((10, 12), 0.002288874238729477), ((12, 15), 0.0022383048199117184)]
******* after merging (0.04): [((4, 5), 128), ((2, 6), 128), ((0,), 64), ((1,), 64), ((3,), 64), ((7,), 32), ((8,), 32), ((9,), 32), ((10,), 32), ((11,), 32), ((12,), 32), ((13,), 32), ((14,), 32), ((15,), 32), ((16,), 32)]
{'R_grad_norm': 1.1763808703422547, 'training_loss': 3.3616432929039}
{'R_grad_norm': 1.1746383583545685, 'training_loss': 3.3465833175182342}
{'R_grad_norm': 1.1742055594921113, 'training_loss': 3.3557326650619506}
{'R_grad_norm': 1.1738585901260377, 'training_loss': 3.35517573595047}
{'R_grad_norm': 1.1744652247428895, 'training_loss': 3.3577008235454557}
{'R_grad_norm': 1.1720123559236526, 'training_loss': 3.352047756910324}
{'R_grad_norm': 1.1757001626491546, 'training_loss': 3.3516705548763275}
{'R_grad_norm': 1.173227561712265, 'training_loss': 3.3449652874469757}
{'R_grad_norm': 1.1747942131757736, 'training_loss': 3.3613015031814575}
{'R_grad_norm': 1.172046982049942, 'training_loss': 3.3345733916759492}
{'R_grad_norm': 1.175031436085701, 'training_loss': 3.3598272156715394}
{'R_grad_norm': 1.1717113906145096, 'training_loss': 3.354695427417755}
{'R_grad_norm': 1.171519249677658, 'training_loss': 3.3449303889274598}
{'R_grad_norm': 1.1687104558944703, 'training_loss': 3.3351251280307768}
{'R_grad_norm': 1.1707166957855224, 'training_loss': 3.349620169401169}
{'R_grad_norm': 1.1703425830602645, 'training_loss': 3.353160091638565}
{'R_grad_norm': 1.169426817893982, 'training_loss': 3.336770297288895}
{'R_grad_norm': 1.1659495913982392, 'training_loss': 3.3339137279987336}
{'R_grad_norm': 1.1659124147892, 'training_loss': 3.3348953032493593}
{'R_grad_norm': 1.167262652516365, 'training_loss': 3.3528204107284547}
{'R_grad_norm': 1.1693349879980088, 'training_loss': 3.3473671865463257}
{'R_grad_norm': 1.1649266737699508, 'training_loss': 3.328914588689804}
{'R_grad_norm': 1.1678557419776916, 'training_loss': 3.3437381100654604}
{'R_grad_norm': 1.1672141951322557, 'training_loss': 3.3254941856861113}
{'R_grad_norm': 1.1661702799797058, 'training_loss': 3.3368095600605012}
{'R_grad_norm': 1.1678316462039948, 'training_loss': 3.3556372594833372}
{'R_grad_norm': 1.1635541850328446, 'training_loss': 3.332729687690735}
{'R_grad_norm': 1.1647386467456817, 'training_loss': 3.335720784664154}
{'R_grad_norm': 1.1633936619758607, 'training_loss': 3.3353816986083986}
{'R_grad_norm': 1.165289396047592, 'training_loss': 3.3267346620559692}
{'R_grad_norm': 1.1656605499982833, 'training_loss': 3.337029861211777}
{'R_grad_norm': 1.1668617743253709, 'training_loss': 3.352710473537445}
{'R_grad_norm': 1.1610911959409713, 'training_loss': 3.325288951396942}
{'R_grad_norm': 1.1598982089757919, 'training_loss': 3.327729642391205}
{'R_grad_norm': 1.1644888764619827, 'training_loss': 3.3420956909656523}
{'R_grad_norm': 1.1628686726093291, 'training_loss': 3.328215091228485}
{'R_grad_norm': 1.1622391599416733, 'training_loss': 3.335670006275177}
{'R_grad_norm': 1.1597900837659836, 'training_loss': 3.3337411141395568}
{'R_grad_norm': 1.1610300993919374, 'training_loss': 3.3343030965328215}
{'R_grad_norm': 1.1604159283638, 'training_loss': 3.3200164330005646}
eval result tensor([5.42888, 7.07446, 3.25935, 4.30163, 3.26271, 2.89626, 2.95028, 1.78623,
        2.65012, 2.41613, 2.92344, 2.27255, 2.97843, 2.32935, 3.08668],
       device='cuda:0')
computing merge metric
normed mi [((7, 9), 0.07061626017093658), ((2, 4), 0.06596384197473526), ((11, 14), 0.0645211935043335), ((4, 9), 0.0623988409837087), ((9, 13), 0.060382675379514694), ((8, 11), 0.05987010523676872), ((2, 13), 0.05868104100227356), ((2, 11), 0.05857024590174357), ((4, 13), 0.058175588647524513), ((2, 3), 0.05672162398695946), ((11, 13), 0.05659306421875954), ((8, 13), 0.05594027414917946), ((6, 9), 0.05578027293086052), ((3, 14), 0.05536775290966034), ((2, 9), 0.05476642648379008), ((3, 11), 0.05362620453039805), ((3, 6), 0.05361781517664591), ((3, 4), 0.05352598428726196), ((2, 8), 0.05312909185886383), ((3, 9), 0.05201274653275808), ((4, 11), 0.051738555232683815), ((6, 13), 0.05104285478591919), ((3, 13), 0.05059345563252767), ((7, 10), 0.050462644547224045), ((6, 8), 0.05008609592914581), ((6, 11), 0.04887962341308594), ((9, 11), 0.047418706119060516), ((0, 4), 0.04718250036239624), ((6, 14), 0.047021880745887756), ((4, 8), 0.046897108356157936), ((1, 2), 0.046692838271458946), ((8, 14), 0.04656161740422249), ((2, 6), 0.046107167998949684), ((4, 6), 0.04530419409275055), ((8, 9), 0.04523840919137001), ((4, 7), 0.0449556956688563), ((3, 8), 0.044886703292528786), ((5, 12), 0.043453771620988846), ((13, 14), 0.043188195675611496), ((0, 2), 0.04271252453327179), ((1, 4), 0.04238815108935038), ((9, 14), 0.0423097163438797), ((2, 14), 0.04094653328259786), ((0, 9), 0.0404957264661789), ((4, 14), 0.03885949899752935), ((1, 3), 0.03869482378164927), ((1, 11), 0.03691385090351105), ((1, 13), 0.03584662973880768), ((1, 8), 0.035015398263931276), ((0, 3), 0.03296796977519989), ((2, 7), 0.032785266637802124), ((0, 13), 0.032556363940238954), ((7, 13), 0.03249865397810936), ((1, 9), 0.03150725960731506), ((0, 1), 0.03084646351635456), ((0, 7), 0.030350244045257567), ((0, 11), 0.02948850691318512), ((1, 6), 0.029163739085197447), ((1, 14), 0.02701241672039032), ((0, 8), 0.02655281126499176), ((3, 7), 0.02515723059574763), ((0, 6), 0.024728576838970184), ((9, 12), 0.02356155589222908), ((6, 7), 0.02272169291973114), ((7, 11), 0.02232515439391136), ((5, 7), 0.022173278033733368), ((0, 14), 0.02176625430583954), ((7, 8), 0.02139386348426342), ((7, 14), 0.02049805037677288), ((5, 9), 0.02015819028019905), ((7, 12), 0.017974423244595528), ((1, 7), 0.016372309625148775), ((4, 12), 0.013981622954209646), ((6, 12), 0.01357539277523756), ((9, 10), 0.012469768524169922), ((12, 13), 0.012399895116686821), ((2, 12), 0.011342912912368774), ((5, 13), 0.010566256009042263), ((8, 12), 0.010538103058934212), ((4, 5), 0.010022558271884918), ((12, 14), 0.009999081492424011), ((11, 12), 0.009966682642698288), ((3, 12), 0.009619690477848053), ((0, 12), 0.009605973213911056), ((5, 8), 0.009418249130249023), ((5, 6), 0.008749994449317455), ((5, 10), 0.008652864955365658), ((2, 5), 0.008584621051947275), ((5, 11), 0.008104573003947735), ((5, 14), 0.007505304645746946), ((0, 5), 0.007213075459003448), ((10, 12), 0.006922153290361166), ((3, 5), 0.006593223661184311), ((1, 12), 0.005801444500684738), ((4, 10), 0.005193622472385566), ((1, 5), 0.004561524838209152), ((0, 10), 0.0042668160051107405), ((2, 10), 0.003871180427571138), ((10, 14), 0.0033475258387625217), ((10, 11), 0.0030628128442913294), ((8, 10), 0.0030540202278643847), ((6, 10), 0.0028027088847011328), ((10, 13), 0.0027790989261120558), ((3, 10), 0.0027012967815001807), ((1, 10), 0.0015151245519518853)]
******* after merging (0.04): [((0,), 128), ((1,), 128), ((7, 9), 64), ((2,), 64), ((3,), 64), ((4,), 64), ((5,), 32), ((6,), 32), ((8,), 32), ((10,), 32), ((11,), 32), ((12,), 32), ((13,), 32), ((14,), 32)]
{'R_grad_norm': 1.219005338549614, 'training_loss': 3.5311871147155762}
{'R_grad_norm': 1.2155058360099793, 'training_loss': 3.5333580684661867}
{'R_grad_norm': 1.2133592998981475, 'training_loss': 3.521264612674713}
{'R_grad_norm': 1.2168958842754365, 'training_loss': 3.5374338161945342}
{'R_grad_norm': 1.2164963108301163, 'training_loss': 3.5245094764232636}
{'R_grad_norm': 1.214341978430748, 'training_loss': 3.5172593820095064}
{'R_grad_norm': 1.213180163502693, 'training_loss': 3.5134360718727113}
{'R_grad_norm': 1.2144979935884477, 'training_loss': 3.5295249831676485}
{'R_grad_norm': 1.2103206843137742, 'training_loss': 3.518212225437164}
{'R_grad_norm': 1.2115099596977235, 'training_loss': 3.5118789362907408}
{'R_grad_norm': 1.2127108675241471, 'training_loss': 3.5171705722808837}
{'R_grad_norm': 1.2102841466665268, 'training_loss': 3.5219667863845827}
{'R_grad_norm': 1.2103080505132675, 'training_loss': 3.511701048612595}
{'R_grad_norm': 1.210601151585579, 'training_loss': 3.5179416143894198}
{'R_grad_norm': 1.2075031352043153, 'training_loss': 3.5000888991355894}
{'R_grad_norm': 1.2105578970909119, 'training_loss': 3.5188791608810424}
{'R_grad_norm': 1.2118021827936172, 'training_loss': 3.5318113422393798}
{'R_grad_norm': 1.207108725309372, 'training_loss': 3.489412056207657}
{'R_grad_norm': 1.2076265817880631, 'training_loss': 3.5015695869922636}
{'R_grad_norm': 1.20828034222126, 'training_loss': 3.516409660577774}
{'R_grad_norm': 1.2110023444890976, 'training_loss': 3.517099913358688}
{'R_grad_norm': 1.2080694407224655, 'training_loss': 3.5134841060638426}
{'R_grad_norm': 1.2052527999877929, 'training_loss': 3.516367666721344}
{'R_grad_norm': 1.2105934584140778, 'training_loss': 3.5153540813922883}
{'R_grad_norm': 1.2061219757795334, 'training_loss': 3.512177083492279}
{'R_grad_norm': 1.2059661781787872, 'training_loss': 3.503741819858551}
{'R_grad_norm': 1.2072274428606034, 'training_loss': 3.5066049683094023}
{'R_grad_norm': 1.2047073006629945, 'training_loss': 3.506604015827179}
{'R_grad_norm': 1.2108621072769166, 'training_loss': 3.538705940246582}
{'R_grad_norm': 1.2043926745653153, 'training_loss': 3.509549913406372}
{'R_grad_norm': 1.2049199879169463, 'training_loss': 3.5006148624420166}
{'R_grad_norm': 1.2029646164178849, 'training_loss': 3.494868392944336}
{'R_grad_norm': 1.2044709950685502, 'training_loss': 3.50058109998703}
{'R_grad_norm': 1.2020627224445344, 'training_loss': 3.501446577310562}
{'R_grad_norm': 1.2054177713394165, 'training_loss': 3.511369693279266}
{'R_grad_norm': 1.2058653610944747, 'training_loss': 3.5105549204349518}
{'R_grad_norm': 1.2022944015264512, 'training_loss': 3.4948944067955017}
{'R_grad_norm': 1.2008955734968185, 'training_loss': 3.497388701438904}
{'R_grad_norm': 1.2006857079267501, 'training_loss': 3.485512797832489}
{'R_grad_norm': 1.2005277848243714, 'training_loss': 3.4911124658584596}
eval result tensor([5.45290, 7.42347, 3.38886, 3.21944, 4.31430, 3.24896, 2.87369, 2.94490,
        2.64794, 2.92024, 2.24584, 2.94880, 2.28824, 3.09130], device='cuda:0')
computing merge metric
normed mi [((3, 5), 0.06580328941345215), ((10, 13), 0.06394501775503159), ((3, 10), 0.06113650401433309), ((8, 10), 0.05975332483649254), ((5, 12), 0.05833109219868978), ((3, 4), 0.05662907660007477), ((2, 5), 0.056269485503435135), ((4, 13), 0.05518698692321777), ((3, 12), 0.05508882304032644), ((4, 10), 0.05401932199796041), ((3, 8), 0.05325435598691305), ((4, 5), 0.05304493382573128), ((4, 7), 0.05283606549104055), ((5, 10), 0.052824373046557106), ((10, 12), 0.05217112600803375), ((8, 12), 0.05164290964603424), ((7, 8), 0.049771279096603394), ((2, 12), 0.049619014064470925), ((7, 12), 0.04921707883477211), ((7, 10), 0.048868559300899506), ((2, 3), 0.047706425189971924), ((5, 8), 0.04761142532030741), ((4, 12), 0.047499880194664), ((0, 5), 0.04734906554222107), ((8, 13), 0.047150325030088425), ((1, 3), 0.04699755211671194), ((7, 13), 0.04623481631278992), ((3, 7), 0.045910234252611794), ((5, 7), 0.0448971688747406), ((4, 8), 0.04466440280278524), ((0, 3), 0.04285442332426707), ((2, 4), 0.04277198389172554), ((1, 5), 0.04258021215597788), ((3, 13), 0.04141156623760859), ((6, 11), 0.04111591726541519), ((12, 13), 0.04043925181031227), ((0, 2), 0.040361536045869194), ((2, 7), 0.039078344901402794), ((1, 4), 0.03874098261197408), ((5, 13), 0.03838667025168737), ((1, 10), 0.03729555010795593), ((2, 10), 0.036484017968177795), ((1, 8), 0.035079196095466614), ((0, 12), 0.033941513299942015), ((2, 8), 0.033680650095144905), ((0, 4), 0.03286409626404444), ((1, 12), 0.032817670702934267), ((0, 1), 0.030538832768797874), ((2, 13), 0.030420238773028057), ((0, 10), 0.030046716332435608), ((1, 2), 0.029454121987024944), ((1, 7), 0.028916579484939576), ((1, 13), 0.02729974389076233), ((0, 8), 0.026960304379463194), ((0, 7), 0.024861864745616913), ((0, 13), 0.021683259308338164), ((2, 11), 0.016825444996356964), ((11, 12), 0.012937193736433983), ((7, 11), 0.012525364756584167), ((5, 11), 0.012203391641378403), ((2, 6), 0.012039287636677424), ((6, 12), 0.010306695476174355), ((8, 11), 0.00995336752384901), ((6, 9), 0.009881870821118355), ((3, 11), 0.009611676136652628), ((2, 9), 0.009183084592223167), ((10, 11), 0.008982932195067406), ((11, 13), 0.008872219361364841), ((6, 8), 0.008475320413708687), ((0, 11), 0.008456497639417648), ((4, 11), 0.008082613969842592), ((5, 6), 0.0077690910547971725), ((6, 7), 0.006982965394854546), ((6, 10), 0.006856835447251797), ((6, 13), 0.006789774168282747), ((3, 6), 0.0067060428361097974), ((9, 11), 0.006702053360641003), ((0, 6), 0.00559847205877304), ((4, 6), 0.0051056987916429835), ((1, 11), 0.004828495532274246), ((5, 9), 0.0042038119087616605), ((1, 6), 0.0035442642867565153), ((0, 9), 0.003382647782564163), ((9, 12), 0.003342660376802087), ((3, 9), 0.0031792251393198967), ((9, 13), 0.0031210114248096943), ((8, 9), 0.0029501491226255894), ((9, 10), 0.0028929049149155617), ((7, 9), 0.002634506206959486), ((4, 9), 0.002255191716055075), ((1, 9), 0.001234712079167366)]
******* after merging (0.04): [((3, 5), 128), ((0,), 128), ((1,), 128), ((2,), 64), ((4,), 64), ((6,), 32), ((7,), 32), ((8,), 32), ((9,), 32), ((10,), 32), ((11,), 32), ((12,), 32), ((13,), 32)]
{'R_grad_norm': 1.276679366827011, 'training_loss': 3.6417212092876436}
{'R_grad_norm': 1.274942227602005, 'training_loss': 3.636082912683487}
{'R_grad_norm': 1.2775493508577347, 'training_loss': 3.6407203137874604}
{'R_grad_norm': 1.2743246799707413, 'training_loss': 3.637611235380173}
{'R_grad_norm': 1.2745381385087966, 'training_loss': 3.63985756278038}
{'R_grad_norm': 1.271434126496315, 'training_loss': 3.6246838223934175}
{'R_grad_norm': 1.2682275038957596, 'training_loss': 3.6100795638561247}
{'R_grad_norm': 1.2732709705829621, 'training_loss': 3.6224323427677154}
{'R_grad_norm': 1.2767102336883545, 'training_loss': 3.6366587507724764}
{'R_grad_norm': 1.281976752281189, 'training_loss': 3.6723263657093046}
{'R_grad_norm': 1.2770058023929596, 'training_loss': 3.6527191162109376}
{'R_grad_norm': 1.2867050957679749, 'training_loss': 3.691287170648575}
{'R_grad_norm': 1.2835777634382248, 'training_loss': 3.6991724908351897}
{'R_grad_norm': 1.285220257639885, 'training_loss': 3.698593282699585}
{'R_grad_norm': 1.288883213996887, 'training_loss': 3.715601795911789}
{'R_grad_norm': 1.2914664405584335, 'training_loss': 3.7265253818035124}
{'R_grad_norm': 1.2929646044969558, 'training_loss': 3.7297744941711426}
{'R_grad_norm': 1.3011449337005616, 'training_loss': 3.78159215927124}
{'R_grad_norm': 1.3054043281078338, 'training_loss': 3.7891572451591493}
{'R_grad_norm': 1.307856502532959, 'training_loss': 3.809449713230133}
{'R_grad_norm': 1.3114464884996415, 'training_loss': 3.8269147443771363}
{'R_grad_norm': 1.3168720799684523, 'training_loss': 3.861284064054489}
{'R_grad_norm': 1.3238815873861314, 'training_loss': 3.910319985151291}
{'R_grad_norm': 1.2838423347473145, 'training_loss': 3.6864577770233153}
{'R_grad_norm': 1.2695175534486771, 'training_loss': 3.6422815680503846}
{'R_grad_norm': 1.2717166167497636, 'training_loss': 3.6507362294197083}
{'R_grad_norm': 1.26895498752594, 'training_loss': 3.6394640266895295}
{'R_grad_norm': 1.2687454807758332, 'training_loss': 3.640404558181763}
{'R_grad_norm': 1.2690368223190307, 'training_loss': 3.6324354827404024}
{'R_grad_norm': 1.2659229999780655, 'training_loss': 3.627070903778076}
{'R_grad_norm': 1.2674288243055343, 'training_loss': 3.6232463562488557}
{'R_grad_norm': 1.2710199010372163, 'training_loss': 3.645608092546463}
{'R_grad_norm': 1.2675603425502777, 'training_loss': 3.63697580575943}
{'R_grad_norm': 1.26716015458107, 'training_loss': 3.62566974401474}
{'R_grad_norm': 1.2674693495035172, 'training_loss': 3.6344338393211366}
{'R_grad_norm': 1.2671569031476975, 'training_loss': 3.6473560082912444}
{'R_grad_norm': 1.26300372838974, 'training_loss': 3.6287275874614715}
{'R_grad_norm': 1.267061602473259, 'training_loss': 3.6376595973968504}
{'R_grad_norm': 1.2667640137672425, 'training_loss': 3.6316928589344024}
{'R_grad_norm': 1.2686094987392424, 'training_loss': 3.6478789973258974}
eval result tensor([5.10644, 5.31090, 7.47091, 3.23333, 4.22793, 2.81628, 2.92605, 2.64158,
        2.86513, 2.19383, 2.90791, 2.20505, 3.04641], device='cuda:0')
computing merge metric
normed mi [((9, 12), 0.06245036423206329), ((7, 9), 0.05883124843239784), ((3, 11), 0.057524800300598145), ((4, 12), 0.054246172308921814), ((4, 9), 0.05315119028091431), ((9, 11), 0.051705196499824524), ((4, 6), 0.05149994293848673), ((7, 11), 0.048928990960121155), ((3, 4), 0.04802783951163292), ((6, 7), 0.047828711569309235), ((6, 9), 0.047686975449323654), ((6, 11), 0.04716535285115242), ((7, 12), 0.04651322588324547), ((6, 12), 0.04631228744983673), ((4, 11), 0.045256649454434715), ((3, 9), 0.044173464179039), ((1, 3), 0.04397240777810415), ((4, 7), 0.04278644919395447), ((3, 6), 0.0427163690328598), ((11, 12), 0.03936681151390076), ((0, 3), 0.038413241505622864), ((0, 4), 0.03832513093948364), ((3, 7), 0.03826702882846197), ((2, 4), 0.03815131137768427), ((2, 9), 0.03714624047279358), ((0, 9), 0.03654647469520569), ((5, 10), 0.03613083437085152), ((0, 2), 0.03552817925810814), ((2, 3), 0.035163442293802895), ((0, 11), 0.034735488891601565), ((2, 7), 0.034627577662467955), ((3, 12), 0.034544527530670166), ((1, 11), 0.03380966484546662), ((2, 11), 0.03229673206806183), ((0, 1), 0.03200797364115715), ((0, 7), 0.0310831755399704), ((1, 4), 0.030996290345986683), ((1, 9), 0.029335013031959532), ((1, 2), 0.02933156117796898), ((2, 6), 0.028531846404075623), ((0, 6), 0.027919596433639525), ((2, 12), 0.027269622683525084), ((1, 7), 0.02566452920436859), ((0, 12), 0.02544507384300232), ((1, 6), 0.02397235780954361), ((1, 12), 0.020927993953227995), ((6, 10), 0.01545700989663601), ((10, 11), 0.015381700359284878), ((3, 10), 0.015018392354249954), ((5, 8), 0.01148269884288311), ((7, 10), 0.01094133872538805), ((9, 10), 0.010479293763637543), ((10, 12), 0.010057398118078709), ((5, 11), 0.009690296836197376), ((1, 10), 0.009598864614963532), ((4, 10), 0.009078878288467726), ((3, 5), 0.008985841025908789), ((5, 7), 0.007892558351159096), ((5, 6), 0.006982294376939535), ((0, 10), 0.006780212372541427), ((5, 9), 0.006723267491906881), ((8, 10), 0.006460887845605612), ((5, 12), 0.006340704392641783), ((3, 8), 0.006099263827006022), ((1, 5), 0.005779904872179031), ((2, 10), 0.005513616278767586), ((4, 5), 0.004761223370830218), ((1, 8), 0.004222630709409714), ((8, 11), 0.0038983295671641827), ((0, 5), 0.003870930150151253), ((8, 12), 0.003472434589639306), ((2, 5), 0.003460913896560669), ((6, 8), 0.0033764138352125883), ((8, 9), 0.003220616141334176), ((7, 8), 0.0029376207385212183), ((4, 8), 0.002524823881685734), ((0, 8), 0.0020530804991722106), ((2, 8), 0.0013518471270799637)]
******* after merging (0.04): [((0,), 128), ((1,), 128), ((2,), 128), ((9, 12), 64), ((3,), 64), ((4,), 64), ((5,), 32), ((6,), 32), ((7,), 32), ((8,), 32), ((10,), 32), ((11,), 32)]
{'R_grad_norm': 1.3216824859380722, 'training_loss': 3.8631726193428038}
{'R_grad_norm': 1.3209377121925354, 'training_loss': 3.87705229640007}
{'R_grad_norm': 1.3181425255537034, 'training_loss': 3.863887232542038}
{'R_grad_norm': 1.3170203298330307, 'training_loss': 3.856281781196594}
{'R_grad_norm': 1.3188152772188186, 'training_loss': 3.8633588373661043}
{'R_grad_norm': 1.3189483451843262, 'training_loss': 3.8659718942642214}
{'R_grad_norm': 1.3159362471103668, 'training_loss': 3.854515745639801}
{'R_grad_norm': 1.310439603328705, 'training_loss': 3.83824476480484}
{'R_grad_norm': 1.318334533572197, 'training_loss': 3.8688254046440123}
{'R_grad_norm': 1.3176010811328889, 'training_loss': 3.8760534644126894}
{'R_grad_norm': 1.3132515001296996, 'training_loss': 3.8566948878765106}
{'R_grad_norm': 1.3156792938709259, 'training_loss': 3.8638186395168304}
{'R_grad_norm': 1.3134220838546753, 'training_loss': 3.8611231446266174}
{'R_grad_norm': 1.3132264536619187, 'training_loss': 3.852968462705612}
{'R_grad_norm': 1.3078301453590393, 'training_loss': 3.8311495041847228}
{'R_grad_norm': 1.3081371206045151, 'training_loss': 3.8319811630249023}
{'R_grad_norm': 1.3121561652421951, 'training_loss': 3.8486557590961454}
{'R_grad_norm': 1.3081659895181657, 'training_loss': 3.8408795058727265}
{'R_grad_norm': 1.3088487553596497, 'training_loss': 3.843081682920456}
{'R_grad_norm': 1.3123323094844819, 'training_loss': 3.855612576007843}
{'R_grad_norm': 1.3105055063962936, 'training_loss': 3.858677875995636}
{'R_grad_norm': 1.311342986226082, 'training_loss': 3.8612184607982636}
{'R_grad_norm': 1.3127171576023102, 'training_loss': 3.8604244565963746}
{'R_grad_norm': 1.3115915143489838, 'training_loss': 3.860522220134735}
{'R_grad_norm': 1.3109818363189698, 'training_loss': 3.8568244326114653}
{'R_grad_norm': 1.3097928375005723, 'training_loss': 3.847340816259384}
{'R_grad_norm': 1.3093175929784775, 'training_loss': 3.837550543546677}
{'R_grad_norm': 1.304858449101448, 'training_loss': 3.83877126455307}
{'R_grad_norm': 1.307757605910301, 'training_loss': 3.843847018480301}
{'R_grad_norm': 1.309770330786705, 'training_loss': 3.848557368516922}
{'R_grad_norm': 1.3092310428619385, 'training_loss': 3.8577943634986878}
{'R_grad_norm': 1.3116303580999373, 'training_loss': 3.872614734172821}
{'R_grad_norm': 1.3091741251945495, 'training_loss': 3.8313390862941743}
{'R_grad_norm': 1.3067560935020446, 'training_loss': 3.850083955526352}
{'R_grad_norm': 1.3036568033695222, 'training_loss': 3.82946049451828}
{'R_grad_norm': 1.3083195811510087, 'training_loss': 3.84902397274971}
{'R_grad_norm': 1.307534110546112, 'training_loss': 3.8642822980880736}
{'R_grad_norm': 1.3055808359384538, 'training_loss': 3.836726859807968}
{'R_grad_norm': 1.3046561092138291, 'training_loss': 3.845567080974579}
{'R_grad_norm': 1.305222647190094, 'training_loss': 3.8444745254516604}
eval result tensor([5.17115, 5.31997, 7.52537, 4.51095, 3.21527, 4.20896, 2.81593, 2.92003,
        2.61932, 2.84236, 2.86822, 2.17544], device='cuda:0')
computing merge metric
normed mi [((4, 11), 0.058775881926218666), ((5, 7), 0.05180664360523224), ((4, 5), 0.04913116991519928), ((8, 11), 0.047588929533958435), ((7, 8), 0.04680105671286583), ((5, 11), 0.045969431598981224), ((7, 11), 0.04553849250078201), ((1, 4), 0.044086565574010216), ((5, 8), 0.04265734056631724), ((4, 7), 0.042154873410860695), ((3, 5), 0.04085280001163483), ((0, 4), 0.039092364410559334), ((4, 8), 0.0385018785794576), ((0, 5), 0.03826416035493215), ((2, 5), 0.03748302161693573), ((3, 8), 0.036783985793590546), ((6, 10), 0.03567194938659668), ((0, 2), 0.03548373281955719), ((0, 11), 0.035284629464149474), ((2, 4), 0.03497116764386495), ((1, 11), 0.034748098254203795), ((2, 8), 0.03469099700450897), ((0, 1), 0.03226100653409958), ((2, 11), 0.03208306431770325), ((1, 5), 0.03135881324609121), ((0, 8), 0.031186872720718385), ((3, 7), 0.03006810446580251), ((3, 11), 0.02936587979396184), ((1, 2), 0.0291610024869442), ((2, 7), 0.02803557813167572), ((0, 7), 0.027531915903091432), ((3, 4), 0.027222219854593277), ((2, 3), 0.02681087205807368), ((1, 8), 0.02576987147331238), ((0, 3), 0.024900153279304504), ((1, 7), 0.023663470149040224), ((1, 3), 0.019621272881825764), ((10, 11), 0.015368287451565266), ((7, 10), 0.015168054960668087), ((4, 10), 0.014715531220038732), ((6, 9), 0.010811666958034039), ((8, 10), 0.010583571158349514), ((6, 11), 0.009416252374649048), ((1, 10), 0.009389074146747589), ((5, 10), 0.009359625478585562), ((4, 6), 0.008978148301442465), ((6, 8), 0.007559528574347496), ((4, 9), 0.0074243806302547455), ((9, 10), 0.007300292607396841), ((6, 7), 0.006929473951458931), ((0, 10), 0.006697308272123337), ((1, 6), 0.005700859799981117), ((3, 10), 0.005605258668462436), ((2, 10), 0.005253846198320389), ((1, 9), 0.005245010554790497), ((9, 11), 0.005043711978942156), ((5, 6), 0.004680360356966655), ((7, 9), 0.004120752215385437), ((0, 6), 0.003909371793270111), ((3, 6), 0.003878043033182621), ((8, 9), 0.0033755574841052294), ((5, 9), 0.0032625962048768997), ((2, 6), 0.003218923509120941), ((0, 9), 0.0024512197822332384), ((3, 9), 0.0020746691152453423), ((2, 9), 0.0015067114494740964)]
******* after merging (0.04): [((0,), 128), ((1,), 128), ((2,), 128), ((4, 11), 96), ((3,), 64), ((5,), 64), ((6,), 32), ((7,), 32), ((8,), 32), ((9,), 32), ((10,), 32)]
{'R_grad_norm': 1.3727374625205995, 'training_loss': 4.09606968998909}
{'R_grad_norm': 1.3734061616659163, 'training_loss': 4.101277520656586}
{'R_grad_norm': 1.3762800645828248, 'training_loss': 4.11889899969101}
{'R_grad_norm': 1.3655651146173478, 'training_loss': 4.08319855928421}
{'R_grad_norm': 1.3700608348846435, 'training_loss': 4.099602949619293}
{'R_grad_norm': 1.371526153087616, 'training_loss': 4.0967157161235805}
{'R_grad_norm': 1.3689761424064637, 'training_loss': 4.096963042020798}
{'R_grad_norm': 1.370368612408638, 'training_loss': 4.087902334928512}
{'R_grad_norm': 1.3710586661100388, 'training_loss': 4.101964747905731}
{'R_grad_norm': 1.3678633975982666, 'training_loss': 4.085633058547973}
{'R_grad_norm': 1.3658078002929688, 'training_loss': 4.09778859615326}
{'R_grad_norm': 1.3641680002212524, 'training_loss': 4.079676941633225}
{'R_grad_norm': 1.371565603017807, 'training_loss': 4.103248339891434}
{'R_grad_norm': 1.366955736875534, 'training_loss': 4.097224105596542}
{'R_grad_norm': 1.3656122863292695, 'training_loss': 4.084217846393585}
{'R_grad_norm': 1.3657718443870543, 'training_loss': 4.087475570440293}
{'R_grad_norm': 1.3691783809661866, 'training_loss': 4.112183223962784}
{'R_grad_norm': 1.3662180280685425, 'training_loss': 4.094817487001419}
{'R_grad_norm': 1.3700530004501343, 'training_loss': 4.112725367546082}
{'R_grad_norm': 1.3683950293064118, 'training_loss': 4.094610067605973}
{'R_grad_norm': 1.366437367796898, 'training_loss': 4.0830302023887635}
{'R_grad_norm': 1.3642998820543288, 'training_loss': 4.085619167089463}
{'R_grad_norm': 1.3627557939291, 'training_loss': 4.0862144231796265}
{'R_grad_norm': 1.3671500968933106, 'training_loss': 4.104576400518417}
{'R_grad_norm': 1.3669876915216446, 'training_loss': 4.10834860920906}
{'R_grad_norm': 1.3677922469377517, 'training_loss': 4.1025325965881345}
{'R_grad_norm': 1.3646590226888657, 'training_loss': 4.095011084079743}
{'R_grad_norm': 1.3669337236881256, 'training_loss': 4.107723889350891}
{'R_grad_norm': 1.3659118282794953, 'training_loss': 4.099841597080231}
{'R_grad_norm': 1.3663608253002166, 'training_loss': 4.097864227294922}
{'R_grad_norm': 1.363379601240158, 'training_loss': 4.103212795257568}
{'R_grad_norm': 1.3627065283060074, 'training_loss': 4.07962620139122}
{'R_grad_norm': 1.3620895195007323, 'training_loss': 4.0881375205516814}
{'R_grad_norm': 1.3642282485961914, 'training_loss': 4.093345745801925}
{'R_grad_norm': 1.3607285046577453, 'training_loss': 4.082733812332154}
{'R_grad_norm': 1.3625156193971635, 'training_loss': 4.087545419931412}
{'R_grad_norm': 1.3613980185985566, 'training_loss': 4.078858485221863}
{'R_grad_norm': 1.3630176025629044, 'training_loss': 4.09855890750885}
{'R_grad_norm': 1.3630415242910385, 'training_loss': 4.089358460903168}
{'R_grad_norm': 1.3623046654462814, 'training_loss': 4.096120994091034}
eval result tensor([5.14262, 5.26751, 7.50256, 4.47111, 4.49333, 4.13153, 2.79334, 2.90173,
        2.58739, 2.80969, 2.84987], device='cuda:0')
computing merge metric
normed mi [((5, 7), 0.05074253181616465), ((7, 8), 0.04679177701473236), ((5, 8), 0.042922904094060264), ((3, 5), 0.04099148809909821), ((4, 5), 0.03947356715798378), ((0, 5), 0.038028823832670845), ((2, 5), 0.03777912010749181), ((0, 2), 0.03587755188345909), ((4, 8), 0.03574287394682566), ((6, 10), 0.0356857068836689), ((2, 8), 0.0348200261592865), ((1, 3), 0.03467231776033129), ((0, 3), 0.03435045267854418), ((2, 3), 0.03296300555978503), ((3, 8), 0.03238162025809288), ((3, 7), 0.0322282649576664), ((0, 1), 0.03219010308384895), ((0, 8), 0.03205481767654419), ((1, 5), 0.03199291229248047), ((1, 2), 0.029690321534872055), ((4, 7), 0.028903397421042126), ((2, 7), 0.028027015924453735), ((0, 7), 0.027035295963287354), ((1, 8), 0.02661731541156769), ((2, 4), 0.025467810531457264), ((0, 4), 0.024309953053792317), ((1, 7), 0.024276627600193022), ((3, 4), 0.022475120425224305), ((1, 4), 0.01910268763701121), ((7, 10), 0.014364482834935188), ((8, 10), 0.010130861774086952), ((6, 9), 0.009648905135691166), ((1, 10), 0.0087084099650383), ((3, 10), 0.008477667346596718), ((5, 10), 0.008452475691835085), ((6, 8), 0.007479687687009573), ((6, 7), 0.006604391615837812), ((9, 10), 0.006086066830903292), ((0, 10), 0.0059075519442558285), ((3, 6), 0.005612797103822231), ((4, 10), 0.005506909141937892), ((1, 6), 0.005197810009121895), ((2, 10), 0.0049834012985229496), ((5, 6), 0.004676576082905133), ((4, 6), 0.0038237093637386956), ((0, 6), 0.0035631194710731505), ((2, 6), 0.0031189870089292525), ((1, 9), 0.0031031534075737), ((7, 9), 0.0027277241460978985), ((8, 9), 0.0025354446843266487), ((5, 9), 0.002044414170086384), ((3, 9), 0.0019664112478494644), ((0, 9), 0.0014814081601798534), ((4, 9), 0.0014166072942316532), ((2, 9), 0.0010395456105470658)]
******* after merging (0.04): [((0,), 128), ((1,), 128), ((2,), 128), ((5, 7), 96), ((3,), 96), ((4,), 64), ((6,), 32), ((8,), 32), ((9,), 32), ((10,), 32)]
{'R_grad_norm': 1.4290709978342055, 'training_loss': 4.388864725828171}
{'R_grad_norm': 1.426551256775856, 'training_loss': 4.390657258033753}
{'R_grad_norm': 1.4238508421182632, 'training_loss': 4.383763463497162}
{'R_grad_norm': 1.4227898305654525, 'training_loss': 4.385553534030914}
{'R_grad_norm': 1.4267898142337798, 'training_loss': 4.401680154800415}
{'R_grad_norm': 1.4215236169099807, 'training_loss': 4.383632193803788}
{'R_grad_norm': 1.4272938561439514, 'training_loss': 4.395563629865646}
{'R_grad_norm': 1.4188390827178956, 'training_loss': 4.372146872282028}
{'R_grad_norm': 1.4217419052124023, 'training_loss': 4.389441142082214}
{'R_grad_norm': 1.4205239981412887, 'training_loss': 4.367510262727738}
{'R_grad_norm': 1.4195808762311934, 'training_loss': 4.385420942306519}
{'R_grad_norm': 1.422797102332115, 'training_loss': 4.380836255550385}
{'R_grad_norm': 1.4164829385280608, 'training_loss': 4.360280966758728}
{'R_grad_norm': 1.4212892580032348, 'training_loss': 4.380634642839432}
{'R_grad_norm': 1.4195509672164917, 'training_loss': 4.391163325309753}
{'R_grad_norm': 1.4202158230543136, 'training_loss': 4.368767778873444}
{'R_grad_norm': 1.4167082345485686, 'training_loss': 4.373534386157989}
{'R_grad_norm': 1.4210504388809204, 'training_loss': 4.393948543071747}
{'R_grad_norm': 1.4201302707195282, 'training_loss': 4.393776729106903}
{'R_grad_norm': 1.415308591723442, 'training_loss': 4.363509179353714}
{'R_grad_norm': 1.4202724415063859, 'training_loss': 4.376735167503357}
{'R_grad_norm': 1.4161355310678483, 'training_loss': 4.373058853149414}
{'R_grad_norm': 1.4130946731567382, 'training_loss': 4.371847997903824}
{'R_grad_norm': 1.4153724431991577, 'training_loss': 4.380132462978363}
{'R_grad_norm': 1.4192218321561814, 'training_loss': 4.386510148048401}
{'R_grad_norm': 1.4114854097366334, 'training_loss': 4.365437389612198}
{'R_grad_norm': 1.4124645376205445, 'training_loss': 4.363772443532944}
{'R_grad_norm': 1.4122825038433076, 'training_loss': 4.37186096906662}
{'R_grad_norm': 1.41089006960392, 'training_loss': 4.357977497577667}
{'R_grad_norm': 1.415855003595352, 'training_loss': 4.3946900308132175}
{'R_grad_norm': 1.411340578198433, 'training_loss': 4.382565143108368}
{'R_grad_norm': 1.4151975798606873, 'training_loss': 4.3985662376880645}
{'R_grad_norm': 1.416263342499733, 'training_loss': 4.3914503002166745}
{'R_grad_norm': 1.4112091290950775, 'training_loss': 4.378521171808242}
{'R_grad_norm': 1.4080957996845245, 'training_loss': 4.359053512811661}
{'R_grad_norm': 1.413598086833954, 'training_loss': 4.379792029857636}
{'R_grad_norm': 1.40910047352314, 'training_loss': 4.37645268201828}
{'R_grad_norm': 1.4100000703334807, 'training_loss': 4.368816504478454}
{'R_grad_norm': 1.4147354972362518, 'training_loss': 4.380504457950592}
{'R_grad_norm': 1.4084806793928146, 'training_loss': 4.37429404258728}
eval result tensor([5.14055, 5.27464, 7.44608, 6.09895, 4.43052, 4.45257, 2.79862, 2.56929,
        2.68314, 2.82051], device='cuda:0')
computing merge metric
normed mi [((0, 2), 0.03587856516242027), ((2, 7), 0.034745851159095766), ((1, 4), 0.03467854005949838), ((5, 7), 0.034412309527397156), ((2, 4), 0.03332693023341043), ((0, 4), 0.033210775681904385), ((3, 4), 0.03225521743297577), ((0, 1), 0.032046034932136536), ((0, 7), 0.031935054063797), ((3, 7), 0.03175458312034607), ((4, 7), 0.03151402249932289), ((2, 3), 0.030840982283864702), ((0, 3), 0.030506270272391185), ((1, 2), 0.030450962483882904), ((3, 5), 0.028529328107833863), ((6, 9), 0.0283042062073946), ((1, 7), 0.026454252004623414), ((1, 3), 0.025323627250535146), ((0, 5), 0.023971555133660633), ((2, 5), 0.023846052587032318), ((4, 5), 0.021427640318870546), ((1, 5), 0.018550287932157516), ((7, 9), 0.017018098384141922), ((4, 9), 0.01302070077508688), ((3, 9), 0.012443475425243378), ((1, 9), 0.01082896962761879), ((6, 8), 0.010273905470967293), ((0, 9), 0.00942617803812027), ((2, 9), 0.00936110019683838), ((5, 9), 0.00901696210106214), ((6, 7), 0.008056728169322014), ((4, 6), 0.006115779280662537), ((1, 6), 0.005497011542320252), ((1, 8), 0.004889396205544472), ((8, 9), 0.004231475293636322), ((5, 6), 0.0037952040632565818), ((0, 6), 0.003719376027584076), ((2, 6), 0.0036666922271251677), ((4, 8), 0.0034284486901015043), ((3, 6), 0.0034164765384048223), ((7, 8), 0.0032937927171587944), ((0, 8), 0.0022832224145531653), ((3, 8), 0.002073760377243161), ((2, 8), 0.001892578974366188), ((5, 8), 0.001825260619322459)]
finish training (92000)
evaluating (25 steps)...
 ******* eval result *******
mean (weighted) 5.107263565063477
mean (unweighted) 4.3666863441467285
tensor([5.12788, 5.28415, 7.37719, 6.11454, 4.42792, 4.45486, 2.80374, 2.57099,
        2.69210, 2.81348], device='cuda:0')
