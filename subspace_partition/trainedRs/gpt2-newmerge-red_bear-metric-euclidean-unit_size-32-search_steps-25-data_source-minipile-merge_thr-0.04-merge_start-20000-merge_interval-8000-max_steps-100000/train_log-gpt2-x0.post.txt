{'R_grad_norm': 0.6631411951780319, 'training_loss': 1.4017206013202668}
{'R_grad_norm': 0.6985000014305115, 'training_loss': 1.2350192511081695}
{'R_grad_norm': 0.7086795842647553, 'training_loss': 1.163966230750084}
{'R_grad_norm': 0.707871016561985, 'training_loss': 1.1305717223882674}
{'R_grad_norm': 0.709896844625473, 'training_loss': 1.1189606979489326}
{'R_grad_norm': 0.7088394540548325, 'training_loss': 1.0935449755191804}
{'R_grad_norm': 0.7060404887795448, 'training_loss': 1.0809629899263382}
{'R_grad_norm': 0.7090769141912461, 'training_loss': 1.0701321840286255}
{'R_grad_norm': 0.7068445357680321, 'training_loss': 1.0624696093797683}
{'R_grad_norm': 0.7050563511252403, 'training_loss': 1.0485502898693084}
{'R_grad_norm': 0.7045873391628266, 'training_loss': 1.0382626828551293}
{'R_grad_norm': 0.700870986878872, 'training_loss': 1.044189575612545}
{'R_grad_norm': 0.7011757934093475, 'training_loss': 1.0377442586421965}
{'R_grad_norm': 0.7015935134887695, 'training_loss': 1.0225238662958145}
{'R_grad_norm': 0.7001502865552902, 'training_loss': 1.0186140009760856}
{'R_grad_norm': 0.6999096435308456, 'training_loss': 1.005814452767372}
{'R_grad_norm': 0.6972094571590424, 'training_loss': 1.0046963196992875}
{'R_grad_norm': 0.6999499979615211, 'training_loss': 1.0129146924614907}
{'R_grad_norm': 0.6981235793232918, 'training_loss': 0.9983107912540435}
{'R_grad_norm': 0.6954665485024453, 'training_loss': 0.9968634533882141}
{'R_grad_norm': 0.6931807789206504, 'training_loss': 1.001782736182213}
{'R_grad_norm': 0.6933326160907746, 'training_loss': 0.9925800225138665}
{'R_grad_norm': 0.6950315991044045, 'training_loss': 0.9942311719059944}
{'R_grad_norm': 0.6927949741482735, 'training_loss': 0.9898005524277687}
{'R_grad_norm': 0.6892683890461921, 'training_loss': 0.9853415024280548}
{'R_grad_norm': 0.6918341740965843, 'training_loss': 0.9851181790232658}
{'R_grad_norm': 0.6904640391469001, 'training_loss': 0.9862341782450676}
{'R_grad_norm': 0.6921166494488716, 'training_loss': 0.9819540816545487}
{'R_grad_norm': 0.6923321375250816, 'training_loss': 0.9815866658091545}
{'R_grad_norm': 0.6903996419906616, 'training_loss': 0.9800831416249275}
{'R_grad_norm': 0.6899921882152558, 'training_loss': 0.9805316370725632}
{'R_grad_norm': 0.6834876689314843, 'training_loss': 0.9724594384431839}
{'R_grad_norm': 0.6873278120160102, 'training_loss': 0.9786257821321488}
{'R_grad_norm': 0.6853104665875435, 'training_loss': 0.9710487136244774}
{'R_grad_norm': 0.6862911480665207, 'training_loss': 0.9667536541819572}
{'R_grad_norm': 0.6844745555520058, 'training_loss': 0.9621260142326356}
{'R_grad_norm': 0.6836511620879173, 'training_loss': 0.9672694003582001}
{'R_grad_norm': 0.6842918682098389, 'training_loss': 0.9667123508453369}
{'R_grad_norm': 0.6839662414789199, 'training_loss': 0.9620715123414993}
{'R_grad_norm': 0.682091777920723, 'training_loss': 0.9600212392210961}
{'R_grad_norm': 0.6842017346620559, 'training_loss': 0.9573417463898659}
{'R_grad_norm': 0.6812383925914764, 'training_loss': 0.9559383746981621}
{'R_grad_norm': 0.6822098103165627, 'training_loss': 0.9563841536641121}
{'R_grad_norm': 0.6796494254469871, 'training_loss': 0.9466248714923858}
{'R_grad_norm': 0.6802764201164245, 'training_loss': 0.9571329820156097}
{'R_grad_norm': 0.6802547556161881, 'training_loss': 0.9514865738153457}
{'R_grad_norm': 0.6771687772870064, 'training_loss': 0.9487153521180153}
{'R_grad_norm': 0.6786770424246789, 'training_loss': 0.9492922878265381}
{'R_grad_norm': 0.6762956205010414, 'training_loss': 0.9483368876576423}
{'R_grad_norm': 0.6781103712320328, 'training_loss': 0.9443176537752151}
{'R_grad_norm': 0.6772075608372689, 'training_loss': 0.9505468136072159}
{'R_grad_norm': 0.6768017718195916, 'training_loss': 0.9485696199536323}
{'R_grad_norm': 0.6761993509531021, 'training_loss': 0.941281832754612}
{'R_grad_norm': 0.6745607361197472, 'training_loss': 0.9420509988069534}
{'R_grad_norm': 0.6745606589317322, 'training_loss': 0.950342226922512}
{'R_grad_norm': 0.6741614595055581, 'training_loss': 0.9445004162192344}
{'R_grad_norm': 0.6722313037514687, 'training_loss': 0.9397189930081368}
{'R_grad_norm': 0.673174312710762, 'training_loss': 0.9496846348047256}
{'R_grad_norm': 0.6743739461898803, 'training_loss': 0.9456510043144226}
{'R_grad_norm': 0.6754355615377426, 'training_loss': 0.9507190307974815}
{'R_grad_norm': 0.6720936924219132, 'training_loss': 0.9396144127845765}
{'R_grad_norm': 0.6712396851181984, 'training_loss': 0.9442408338189126}
{'R_grad_norm': 0.6710728281736373, 'training_loss': 0.9371160185337066}
{'R_grad_norm': 0.6682499435544014, 'training_loss': 0.9333185681700706}
{'R_grad_norm': 0.6704941663146019, 'training_loss': 0.9362298780679703}
{'R_grad_norm': 0.671229011118412, 'training_loss': 0.9452011182904243}
{'R_grad_norm': 0.6707576483488082, 'training_loss': 0.9395812723040581}
{'R_grad_norm': 0.6687230914831161, 'training_loss': 0.9328972339630127}
{'R_grad_norm': 0.6681881406903267, 'training_loss': 0.9346134182810784}
{'R_grad_norm': 0.6688561859726906, 'training_loss': 0.9362264209985733}
{'R_grad_norm': 0.6709075048565865, 'training_loss': 0.9406187748908996}
{'R_grad_norm': 0.6680397382378578, 'training_loss': 0.9382068455219269}
{'R_grad_norm': 0.6707481199502945, 'training_loss': 0.9335443687438965}
{'R_grad_norm': 0.6678732812404633, 'training_loss': 0.930168169438839}
{'R_grad_norm': 0.6703028598427773, 'training_loss': 0.9291252535581589}
{'R_grad_norm': 0.6704533159732818, 'training_loss': 0.9331185090541839}
{'R_grad_norm': 0.6685616850852967, 'training_loss': 0.9344302242994309}
{'R_grad_norm': 0.6674257129430771, 'training_loss': 0.9345784372091294}
{'R_grad_norm': 0.6650765699148178, 'training_loss': 0.9261322003602982}
{'R_grad_norm': 0.6682848304510116, 'training_loss': 0.934007672071457}
{'R_grad_norm': 0.6664894297719002, 'training_loss': 0.9277707603573799}
{'R_grad_norm': 0.6669238388538361, 'training_loss': 0.9298698088526726}
{'R_grad_norm': 0.6645634540915489, 'training_loss': 0.9224112322926521}
{'R_grad_norm': 0.6664198815822602, 'training_loss': 0.9247156125307083}
{'R_grad_norm': 0.6679013082385064, 'training_loss': 0.9308811974525452}
{'R_grad_norm': 0.666351757645607, 'training_loss': 0.9330760416388512}
{'R_grad_norm': 0.6643641746044159, 'training_loss': 0.9327293422818184}
{'R_grad_norm': 0.6656035768985749, 'training_loss': 0.9253924626111985}
{'R_grad_norm': 0.6652411684393883, 'training_loss': 0.927672461271286}
{'R_grad_norm': 0.6649023607373238, 'training_loss': 0.92838718354702}
{'R_grad_norm': 0.6629012304544449, 'training_loss': 0.9224197900295258}
{'R_grad_norm': 0.6647232550382615, 'training_loss': 0.9299591344594955}
{'R_grad_norm': 0.6604618331789971, 'training_loss': 0.9205069226026535}
{'R_grad_norm': 0.6629760357737541, 'training_loss': 0.9264506289362907}
{'R_grad_norm': 0.6637075251340866, 'training_loss': 0.9286864936351776}
{'R_grad_norm': 0.6637668597698212, 'training_loss': 0.9331806036829948}
{'R_grad_norm': 0.6642699363827705, 'training_loss': 0.9243983697891235}
{'R_grad_norm': 0.6628980419039726, 'training_loss': 0.9197104582190514}
{'R_grad_norm': 0.6635671588778496, 'training_loss': 0.9334505423903465}
{'R_grad_norm': 0.6615714338421822, 'training_loss': 0.9264794453978539}
eval result tensor([1.29927, 1.21414, 1.14275, 0.85277, 0.99776, 0.94144, 0.67775, 0.97294,
        0.53728, 1.00050, 0.85985, 1.13178, 0.95854, 0.76688, 0.64239, 0.74940,
        1.09666, 0.95539, 0.69871, 0.96562, 1.19543, 0.75098, 1.28473, 0.75004],
       device='cuda:0')
computing merge metric
normed mi [((6, 14), 0.1279778778553009), ((11, 16), 0.12680688500404358), ((3, 6), 0.12648776173591614), ((11, 20), 0.1262805014848709), ((3, 17), 0.12627729773521423), ((4, 17), 0.1258598268032074), ((3, 14), 0.1256720870733261), ((3, 4), 0.12566246092319489), ((10, 17), 0.12554705142974854), ((3, 23), 0.12535154819488525), ((11, 17), 0.12532015144824982), ((3, 10), 0.12514875829219818), ((6, 17), 0.1251239776611328), ((6, 9), 0.12507019937038422), ((14, 17), 0.12498246878385544), ((17, 20), 0.1248791292309761), ((17, 23), 0.12481679022312164), ((6, 23), 0.1246085911989212), ((4, 23), 0.12448562681674957), ((4, 6), 0.1244787871837616), ((5, 17), 0.124429851770401), ((4, 10), 0.12425737828016281), ((4, 11), 0.12419440597295761), ((10, 23), 0.12419343739748001), ((10, 11), 0.12419019639492035), ((14, 23), 0.12413299083709717), ((9, 14), 0.12412577122449875), ((3, 11), 0.12409690767526627), ((4, 14), 0.12397781759500504), ((11, 22), 0.12394295632839203), ((10, 14), 0.12387055903673172), ((6, 10), 0.12386594712734222), ((10, 20), 0.12384869158267975), ((9, 17), 0.12366250902414322), ((17, 19), 0.12352824956178665), ((3, 5), 0.12339561432600021), ((16, 20), 0.12331071496009827), ((20, 22), 0.12330060452222824), ((11, 23), 0.12329178303480148), ((16, 17), 0.12326952815055847), ((3, 9), 0.12319952994585037), ((4, 20), 0.12307543307542801), ((20, 23), 0.12302456796169281), ((8, 14), 0.12296070903539658), ((5, 20), 0.12295778840780258), ((6, 8), 0.12288986146450043), ((6, 7), 0.12284374982118607), ((0, 11), 0.12282664328813553), ((19, 20), 0.12274687737226486), ((3, 16), 0.12273918092250824), ((4, 9), 0.12272811681032181), ((4, 16), 0.12270621210336685), ((10, 16), 0.1226259171962738), ((4, 5), 0.12246961146593094), ((5, 10), 0.12243791669607162), ((3, 20), 0.12235727906227112), ((5, 6), 0.12234487384557724), ((7, 14), 0.12212129682302475), ((4, 19), 0.12203768640756607), ((5, 23), 0.12191794067621231), ((5, 14), 0.12191202491521835), ((3, 8), 0.12187767773866653), ((9, 10), 0.12177319079637527), ((17, 21), 0.12173032760620117), ((7, 17), 0.1217125803232193), ((5, 11), 0.12169249355792999), ((9, 23), 0.12162450700998306), ((5, 9), 0.12160982936620712), ((3, 19), 0.121583953499794), ((7, 9), 0.12155251950025558), ((6, 21), 0.12155047059059143), ((3, 21), 0.12152120471000671), ((3, 7), 0.12149633467197418), ((11, 19), 0.12140365689992905), ((16, 23), 0.12125755846500397), ((8, 17), 0.12124238908290863), ((5, 19), 0.12114809453487396), ((0, 22), 0.12111269682645798), ((4, 21), 0.12111132591962814), ((4, 8), 0.12103993445634842), ((4, 7), 0.12099385261535645), ((14, 21), 0.12093522399663925), ((10, 19), 0.12088509649038315), ((19, 23), 0.1208532303571701), ((8, 9), 0.12081807851791382), ((8, 23), 0.1206822544336319), ((0, 20), 0.1206187903881073), ((9, 19), 0.12060730904340744), ((8, 10), 0.12035776674747467), ((5, 16), 0.12028319388628006), ((6, 19), 0.12028071284294128), ((16, 19), 0.12025899440050125), ((10, 21), 0.12021082639694214), ((7, 23), 0.1201728954911232), ((14, 19), 0.1201484426856041), ((5, 21), 0.12014448642730713), ((0, 17), 0.12009447813034058), ((16, 22), 0.1200847402215004), ((9, 21), 0.12007933109998703), ((7, 8), 0.12004856020212173), ((11, 14), 0.11989595741033554), ((21, 23), 0.11984188854694366), ((0, 16), 0.11981374770402908), ((7, 10), 0.11977049708366394), ((11, 21), 0.1197129413485527), ((9, 20), 0.11966461688280106), ((0, 4), 0.11957298964262009), ((14, 20), 0.1195533350110054), ((14, 16), 0.11939124763011932), ((20, 21), 0.11924660205841064), ((6, 11), 0.11921396851539612), ((5, 8), 0.1190895214676857), ((6, 16), 0.11898893117904663), ((8, 21), 0.11869094520807266), ((9, 11), 0.11868247389793396), ((0, 10), 0.11865038424730301), ((6, 20), 0.11864662170410156), ((7, 11), 0.11863788217306137), ((5, 7), 0.11862101405858994), ((19, 21), 0.11852254718542099), ((8, 11), 0.1183868870139122), ((0, 19), 0.11832908540964127), ((9, 16), 0.11819060146808624), ((0, 3), 0.1181415244936943), ((0, 5), 0.1180863156914711), ((7, 19), 0.11807435005903244), ((16, 21), 0.11799999326467514), ((17, 22), 0.11791791021823883), ((7, 16), 0.1178654357790947), ((7, 21), 0.11783577501773834), ((8, 19), 0.11778933554887772), ((0, 23), 0.11757993698120117), ((4, 22), 0.11746358871459961), ((7, 20), 0.11726237088441849), ((6, 13), 0.11718416959047318), ((8, 20), 0.11716829985380173), ((10, 22), 0.11716475337743759), ((13, 14), 0.11695192754268646), ((8, 16), 0.11686629801988602), ((19, 22), 0.11680320650339127), ((3, 22), 0.11650495231151581), ((8, 13), 0.11641500145196915), ((0, 7), 0.11639540642499924), ((22, 23), 0.11637531965970993), ((5, 22), 0.11604991555213928), ((3, 13), 0.11561955511569977), ((0, 21), 0.11532410979270935), ((13, 17), 0.11519911140203476), ((0, 14), 0.11519529670476913), ((4, 13), 0.1148981899023056), ((9, 13), 0.11482790857553482), ((0, 6), 0.11475346982479095), ((0, 9), 0.11474988609552383), ((7, 13), 0.11463393270969391), ((13, 23), 0.11409968882799149), ((10, 13), 0.1140759065747261), ((0, 8), 0.11393967270851135), ((21, 22), 0.11379190534353256), ((7, 12), 0.11356469243764877), ((13, 21), 0.11299930512905121), ((5, 13), 0.1128382459282875), ((11, 13), 0.11199741810560226), ((13, 19), 0.11187251657247543), ((7, 22), 0.11177442222833633), ((8, 12), 0.11160886287689209), ((13, 20), 0.11143187433481216), ((14, 22), 0.11134754866361618), ((9, 22), 0.11110136657953262), ((8, 18), 0.11105667799711227), ((12, 14), 0.11103569716215134), ((6, 12), 0.11102885007858276), ((14, 18), 0.11085668951272964), ((13, 16), 0.11083963513374329), ((6, 22), 0.11082084476947784), ((9, 12), 0.11079581826925278), ((6, 18), 0.11064538359642029), ((12, 17), 0.11027449369430542), ((3, 12), 0.11022544652223587), ((8, 22), 0.10986001044511795), ((7, 18), 0.10958358645439148), ((4, 12), 0.10942576825618744), ((9, 18), 0.10909663885831833), ((12, 23), 0.10897000879049301), ((10, 12), 0.10893307626247406), ((3, 18), 0.1083923950791359), ((0, 13), 0.10834116488695145), ((5, 12), 0.10833818465471268), ((17, 18), 0.10821960121393204), ((18, 23), 0.10820681601762772), ((4, 18), 0.10814710706472397), ((12, 21), 0.10790210217237473), ((12, 19), 0.10754982382059097), ((11, 12), 0.10745203495025635), ((10, 18), 0.10716787725687027), ((5, 18), 0.10703173279762268), ((12, 20), 0.10652270168066025), ((18, 21), 0.10639134049415588), ((12, 16), 0.10623200982809067), ((12, 18), 0.10619810223579407), ((0, 12), 0.10593228042125702), ((12, 13), 0.10582761466503143), ((11, 18), 0.1056622788310051), ((18, 19), 0.105286605656147), ((13, 22), 0.10518572479486465), ((13, 18), 0.10517203062772751), ((18, 20), 0.10515976697206497), ((16, 18), 0.10382731258869171), ((0, 18), 0.1035614013671875), ((12, 22), 0.10061471909284592), ((18, 22), 0.09901729226112366), ((1, 11), 0.09876204282045364), ((1, 20), 0.098731629550457), ((0, 1), 0.09819287061691284), ((1, 22), 0.09725946187973022), ((1, 17), 0.09634695202112198), ((1, 8), 0.09610912948846817), ((1, 19), 0.0955154299736023), ((1, 5), 0.09545634686946869), ((1, 4), 0.09544406831264496), ((1, 16), 0.09543538093566895), ((1, 23), 0.0952037125825882), ((1, 7), 0.09503723680973053), ((1, 10), 0.09493961185216904), ((1, 21), 0.09420222789049149), ((1, 3), 0.09408266097307205), ((1, 9), 0.09343916922807693), ((1, 14), 0.09282568097114563), ((1, 13), 0.09154946357011795), ((1, 6), 0.09153731912374496), ((1, 18), 0.09101702272891998), ((1, 12), 0.09088248759508133), ((2, 15), 0.0614372156560421), ((6, 15), 0.03885381296277046), ((14, 15), 0.036597467958927155), ((7, 15), 0.03457733616232872), ((8, 15), 0.034166786819696426), ((9, 15), 0.03336954116821289), ((13, 15), 0.03199394792318344), ((3, 15), 0.029879478737711906), ((15, 18), 0.02898424118757248), ((15, 21), 0.02894335426390171), ((15, 23), 0.028813136741518974), ((12, 15), 0.02854158543050289), ((4, 15), 0.028504328802227974), ((10, 15), 0.028189780190587044), ((15, 17), 0.028175346553325653), ((5, 15), 0.027019210159778595), ((15, 19), 0.025920147076249123), ((2, 8), 0.02522072196006775), ((15, 16), 0.024241115897893906), ((11, 15), 0.022400638088583946), ((2, 6), 0.020915640518069267), ((15, 20), 0.020907729864120483), ((0, 15), 0.020447375252842903), ((2, 14), 0.020193595439195633), ((2, 13), 0.019849717617034912), ((2, 9), 0.018070822581648827), ((2, 3), 0.017662538215517998), ((2, 7), 0.01760917715728283), ((2, 18), 0.017193127423524857), ((15, 22), 0.01662934198975563), ((2, 10), 0.016514597460627556), ((2, 17), 0.016353528946638107), ((2, 23), 0.016336733475327492), ((2, 4), 0.016190238296985626), ((2, 21), 0.016070926561951637), ((2, 5), 0.015448497608304024), ((2, 12), 0.015271005220711231), ((2, 19), 0.015183155424892902), ((2, 16), 0.01464196015149355), ((2, 11), 0.014145013876259327), ((2, 20), 0.013800485990941525), ((1, 15), 0.013397209346294403), ((1, 2), 0.011679677292704582), ((0, 2), 0.011350042186677456), ((2, 22), 0.011063209734857082)]
******* after merging (0.04): [((6, 14), 64), ((11, 16), 64), ((3, 17), 64), ((0,), 32), ((1,), 32), ((2,), 32), ((4,), 32), ((5,), 32), ((7,), 32), ((8,), 32), ((9,), 32), ((10,), 32), ((12,), 32), ((13,), 32), ((15,), 32), ((18,), 32), ((19,), 32), ((20,), 32), ((21,), 32), ((22,), 32), ((23,), 32)]
{'R_grad_norm': 0.7754706728458405, 'training_loss': 0.9967439535260201}
{'R_grad_norm': 0.7668977624177933, 'training_loss': 0.9850655549764633}
{'R_grad_norm': 0.7677773821353913, 'training_loss': 1.0072458377480507}
{'R_grad_norm': 0.7658194369077682, 'training_loss': 0.9986380463838578}
{'R_grad_norm': 0.7652875599265099, 'training_loss': 0.995071724653244}
{'R_grad_norm': 0.7662384140491486, 'training_loss': 0.9878653836250305}
{'R_grad_norm': 0.7636264660954475, 'training_loss': 0.9904156735539437}
{'R_grad_norm': 0.766127679347992, 'training_loss': 0.9969106978178024}
{'R_grad_norm': 0.7628260660171509, 'training_loss': 0.9893764799833298}
{'R_grad_norm': 0.7624080988764763, 'training_loss': 0.9821230337023735}
{'R_grad_norm': 0.7624758407473564, 'training_loss': 0.993276692032814}
{'R_grad_norm': 0.7615390422940255, 'training_loss': 0.98525799959898}
{'R_grad_norm': 0.7597793617844582, 'training_loss': 0.9768391534686088}
{'R_grad_norm': 0.7605069231987, 'training_loss': 0.9868055790662765}
{'R_grad_norm': 0.7597080206871033, 'training_loss': 0.9873699423670769}
{'R_grad_norm': 0.7603227451443673, 'training_loss': 0.9740921944379807}
{'R_grad_norm': 0.759854374229908, 'training_loss': 0.9794961550831794}
{'R_grad_norm': 0.7586197471618652, 'training_loss': 0.9790494853258133}
{'R_grad_norm': 0.758144325017929, 'training_loss': 0.9790455704927444}
{'R_grad_norm': 0.7582562881708145, 'training_loss': 0.9850512012839318}
{'R_grad_norm': 0.7576388570666314, 'training_loss': 0.9807321473956108}
{'R_grad_norm': 0.7601895841956139, 'training_loss': 0.9888768962025642}
{'R_grad_norm': 0.7553747934103012, 'training_loss': 0.9693409883975983}
{'R_grad_norm': 0.7565092888474464, 'training_loss': 0.9820649746060371}
{'R_grad_norm': 0.7577883172035217, 'training_loss': 0.9879843488335609}
{'R_grad_norm': 0.7532892474532127, 'training_loss': 0.9717478197813034}
{'R_grad_norm': 0.7560778069496155, 'training_loss': 0.981821081340313}
{'R_grad_norm': 0.7555945247411728, 'training_loss': 0.9850527775287629}
{'R_grad_norm': 0.7548490780591964, 'training_loss': 0.976091091632843}
{'R_grad_norm': 0.7544825011491776, 'training_loss': 0.9768187239766121}
{'R_grad_norm': 0.7533122861385345, 'training_loss': 0.9735166701674461}
{'R_grad_norm': 0.7524719884991646, 'training_loss': 0.9779861423373223}
{'R_grad_norm': 0.7532219097018242, 'training_loss': 0.9698762342333793}
{'R_grad_norm': 0.7531232276558876, 'training_loss': 0.9762306508421897}
{'R_grad_norm': 0.754542981684208, 'training_loss': 0.9816945365071297}
{'R_grad_norm': 0.7524936005473137, 'training_loss': 0.978759800195694}
{'R_grad_norm': 0.7505759990215302, 'training_loss': 0.9793956995010376}
{'R_grad_norm': 0.7512735414505005, 'training_loss': 0.9753326126933097}
{'R_grad_norm': 0.7485230609774589, 'training_loss': 0.9788092795014381}
{'R_grad_norm': 0.751639552116394, 'training_loss': 0.9646435379981995}
eval result tensor([1.21775, 2.20273, 1.61853, 1.14957, 1.12904, 1.10032, 0.87677, 0.85950,
        0.86061, 0.49525, 0.89964, 0.76669, 0.88561, 0.69259, 0.70025, 0.65248,
        0.88902, 1.08995, 0.70320, 1.13243, 0.67735], device='cuda:0')
computing merge metric
normed mi [((6, 20), 0.12360032647848129), ((11, 20), 0.12349487841129303), ((6, 11), 0.12335430830717087), ((9, 20), 0.12234018743038177), ((9, 10), 0.12191009521484375), ((17, 19), 0.12176164239645004), ((6, 17), 0.12165064364671707), ((9, 11), 0.12151969969272614), ((6, 7), 0.12132002413272858), ((7, 11), 0.12112241238355637), ((6, 9), 0.1206933781504631), ((7, 20), 0.12067611515522003), ((10, 20), 0.12033624202013016), ((10, 11), 0.12027507275342941), ((7, 17), 0.12001454830169678), ((6, 18), 0.11984992027282715), ((18, 20), 0.11983112245798111), ((6, 16), 0.11979252845048904), ((11, 17), 0.11971869319677353), ((8, 9), 0.11962252110242844), ((11, 18), 0.11959788203239441), ((8, 10), 0.11958988755941391), ((6, 10), 0.11948837339878082), ((7, 10), 0.11948195844888687), ((17, 20), 0.11912339925765991), ((3, 6), 0.1190640926361084), ((7, 16), 0.11903614550828934), ((7, 18), 0.1188947930932045), ((11, 16), 0.11886823177337646), ((8, 20), 0.11886744946241379), ((16, 20), 0.11885358393192291), ((9, 18), 0.1188044399023056), ((16, 17), 0.11856747418642044), ((6, 8), 0.11853276938199997), ((10, 18), 0.118504598736763), ((7, 9), 0.1185012236237526), ((10, 16), 0.11840033531188965), ((8, 11), 0.11828591674566269), ((3, 19), 0.11828393489122391), ((9, 16), 0.11811379343271255), ((6, 19), 0.11798708885908127), ((3, 17), 0.1171252429485321), ((16, 18), 0.11700359731912613), ((17, 18), 0.11681684851646423), ((3, 7), 0.11663087457418442), ((3, 11), 0.11653479933738708), ((7, 8), 0.11642338335514069), ((3, 20), 0.11603307723999023), ((8, 18), 0.11588195711374283), ((8, 16), 0.11580689996480942), ((9, 13), 0.1156521886587143), ((3, 16), 0.11535850167274475), ((19, 20), 0.11486950516700745), ((11, 19), 0.11485526710748672), ((9, 17), 0.11483734101057053), ((7, 19), 0.1145695298910141), ((3, 18), 0.11452383548021317), ((10, 17), 0.1143059954047203), ((3, 8), 0.11420834064483643), ((10, 13), 0.11371075361967087), ((16, 19), 0.11370684951543808), ((8, 17), 0.11331072449684143), ((18, 19), 0.11319191753864288), ((3, 9), 0.11290326714515686), ((13, 20), 0.11272986978292465), ((3, 10), 0.11212974041700363), ((11, 13), 0.11206106841564178), ((8, 13), 0.11191117018461227), ((6, 13), 0.11146298050880432), ((8, 12), 0.1106419563293457), ((13, 18), 0.1105228140950203), ((7, 13), 0.11003797501325607), ((9, 15), 0.10994408279657364), ((8, 19), 0.10966754704713821), ((9, 12), 0.10952189564704895), ((9, 19), 0.10940184444189072), ((13, 16), 0.10908239334821701), ((10, 12), 0.10894003510475159), ((10, 19), 0.10879527777433395), ((12, 20), 0.10821115970611572), ((10, 15), 0.10786359757184982), ((11, 12), 0.10747797042131424), ((8, 15), 0.10735920816659927), ((6, 12), 0.10733960568904877), ((15, 20), 0.10657501220703125), ((12, 18), 0.10643120855093002), ((7, 12), 0.10629652440547943), ((13, 17), 0.10623445361852646), ((11, 15), 0.10596808791160583), ((12, 16), 0.10561514645814896), ((6, 15), 0.10524297505617142), ((3, 13), 0.1050516664981842), ((3, 12), 0.10484801977872849), ((12, 15), 0.10427603125572205), ((15, 18), 0.10426291823387146), ((7, 15), 0.10411828756332397), ((15, 16), 0.1034531369805336), ((13, 15), 0.1031707227230072), ((12, 13), 0.1031162217259407), ((12, 17), 0.10276198387145996), ((13, 19), 0.1015499159693718), ((3, 15), 0.1007850170135498), ((15, 17), 0.10071778297424316), ((12, 19), 0.09906306117773056), ((15, 19), 0.0958670899271965), ((4, 17), 0.09566815197467804), ((3, 4), 0.09560547769069672), ((4, 6), 0.0947202742099762), ((4, 9), 0.09395620226860046), ((4, 7), 0.09383489191532135), ((4, 19), 0.093784861266613), ((4, 20), 0.09361688047647476), ((4, 8), 0.09345117211341858), ((4, 11), 0.09322353452444077), ((4, 16), 0.09308143705129623), ((4, 18), 0.09277524054050446), ((4, 10), 0.09188015758991241), ((4, 12), 0.09027568250894547), ((4, 15), 0.08896414190530777), ((4, 13), 0.08770128339529037), ((1, 19), 0.08701173464457194), ((2, 6), 0.08693174521128337), ((0, 20), 0.0868281622727712), ((1, 17), 0.08665222922960918), ((0, 11), 0.0865849753220876), ((0, 6), 0.08647658427556355), ((0, 9), 0.08601433038711548), ((2, 11), 0.08588056763013203), ((2, 20), 0.08573472499847412), ((2, 7), 0.084860364596049), ((0, 7), 0.08480355143547058), ((2, 17), 0.08455918232599895), ((1, 6), 0.08447664976119995), ((1, 3), 0.08432638645172119), ((0, 10), 0.08426704009373982), ((0, 18), 0.08356858293215434), ((2, 16), 0.08340037862459819), ((0, 8), 0.08312046031157176), ((0, 16), 0.08310991525650024), ((2, 18), 0.08299303551514943), ((2, 9), 0.08282005786895752), ((2, 3), 0.08232022325197856), ((2, 10), 0.08203611771265666), ((1, 11), 0.08195198078950246), ((2, 8), 0.0818636417388916), ((1, 20), 0.08152967194716136), ((2, 19), 0.08139915764331818), ((1, 7), 0.08120442926883698), ((0, 17), 0.08089910944302876), ((1, 16), 0.08074006934960683), ((1, 18), 0.08011652529239655), ((0, 3), 0.08011102676391602), ((0, 13), 0.07863256335258484), ((1, 8), 0.0781273643175761), ((1, 9), 0.07759810984134674), ((0, 19), 0.0770941972732544), ((1, 10), 0.07681988676389058), ((2, 13), 0.07623453438282013), ((0, 12), 0.07539884249369304), ((0, 15), 0.07454505562782288), ((2, 12), 0.07440578440825145), ((2, 15), 0.07222509384155273), ((1, 13), 0.07221250236034393), ((1, 12), 0.07126690944035848), ((1, 15), 0.06842632095019023), ((0, 2), 0.06826012581586838), ((1, 4), 0.06757196287314098), ((1, 2), 0.06575627624988556), ((2, 4), 0.06521713236967723), ((0, 4), 0.06245038906733195), ((0, 1), 0.06145278364419937), ((5, 14), 0.059695541858673096), ((10, 14), 0.03319743275642395), ((9, 14), 0.0330062173306942), ((8, 14), 0.032674070447683334), ((13, 14), 0.0316186286509037), ((14, 15), 0.028409183025360107), ((14, 20), 0.027213286608457565), ((11, 14), 0.02691727876663208), ((14, 18), 0.025759421288967133), ((12, 14), 0.02506834641098976), ((7, 14), 0.02439814805984497), ((14, 16), 0.024374086409807205), ((5, 9), 0.02412053570151329), ((6, 14), 0.0238982941955328), ((5, 13), 0.02123205177485943), ((0, 14), 0.020657875885566074), ((5, 10), 0.019368529319763184), ((5, 15), 0.01884576678276062), ((3, 14), 0.01854066178202629), ((5, 8), 0.01799357682466507), ((5, 11), 0.017637135460972786), ((5, 20), 0.017550094053149223), ((5, 18), 0.016654549166560173), ((5, 6), 0.016336269676685333), ((14, 17), 0.01611611619591713), ((2, 14), 0.015988260507583618), ((5, 16), 0.015829753130674362), ((5, 7), 0.015826266258955002), ((5, 12), 0.015323574654757977), ((14, 19), 0.014332981780171394), ((0, 5), 0.013505461315313974), ((5, 17), 0.013288608752191067), ((4, 14), 0.012862985953688622), ((4, 5), 0.012671922333538532), ((5, 19), 0.011690566316246986), ((3, 5), 0.01147649995982647), ((2, 5), 0.011439789086580276), ((1, 14), 0.0110584224263827), ((1, 5), 0.008956967542568842)]
******* after merging (0.04): [((6, 20), 64), ((9, 10), 64), ((0,), 64), ((1,), 64), ((2,), 64), ((3,), 32), ((4,), 32), ((5,), 32), ((7,), 32), ((8,), 32), ((11,), 32), ((12,), 32), ((13,), 32), ((14,), 32), ((15,), 32), ((16,), 32), ((17,), 32), ((18,), 32), ((19,), 32)]
{'R_grad_norm': 0.8196994471549988, 'training_loss': 1.046429619193077}
{'R_grad_norm': 0.8112041211128235, 'training_loss': 1.0341488736867905}
{'R_grad_norm': 0.8117120030522347, 'training_loss': 1.0373505395650864}
{'R_grad_norm': 0.8120803678035736, 'training_loss': 1.0494937795400618}
{'R_grad_norm': 0.8078193175792694, 'training_loss': 1.0411971312761308}
{'R_grad_norm': 0.8057513412833214, 'training_loss': 1.0314957848191262}
{'R_grad_norm': 0.8083363798260689, 'training_loss': 1.038375136256218}
{'R_grad_norm': 0.8078197020292283, 'training_loss': 1.0364922416210174}
{'R_grad_norm': 0.8090021723508835, 'training_loss': 1.0434368750452996}
{'R_grad_norm': 0.8081634950637817, 'training_loss': 1.0427905356884002}
{'R_grad_norm': 0.8110000857710838, 'training_loss': 1.0464073729515075}
{'R_grad_norm': 0.8127247577905655, 'training_loss': 1.0570277771353722}
{'R_grad_norm': 0.812786435186863, 'training_loss': 1.0539391505718232}
{'R_grad_norm': 0.8148512858152389, 'training_loss': 1.056113995015621}
{'R_grad_norm': 0.8125817295908928, 'training_loss': 1.072163667678833}
{'R_grad_norm': 0.816598984003067, 'training_loss': 1.0707243359088898}
{'R_grad_norm': 0.8196368098258973, 'training_loss': 1.0790449267625808}
{'R_grad_norm': 0.8197482180595398, 'training_loss': 1.0864976170659064}
{'R_grad_norm': 0.8226919692754745, 'training_loss': 1.1027934700250626}
{'R_grad_norm': 0.8236117142438889, 'training_loss': 1.1183055648207665}
{'R_grad_norm': 0.8257573148608208, 'training_loss': 1.1155812960863114}
{'R_grad_norm': 0.8261999580264091, 'training_loss': 1.1335373440384864}
{'R_grad_norm': 0.8083263397216797, 'training_loss': 1.0699037528038025}
{'R_grad_norm': 0.7990287944674492, 'training_loss': 1.0219617754220962}
{'R_grad_norm': 0.7983716621994972, 'training_loss': 1.0343617457151413}
{'R_grad_norm': 0.8003685310482979, 'training_loss': 1.0311843705177308}
{'R_grad_norm': 0.7991656258702278, 'training_loss': 1.0250031313300132}
{'R_grad_norm': 0.7978262451291084, 'training_loss': 1.0296592912077904}
{'R_grad_norm': 0.7970527178049087, 'training_loss': 1.0192717084288596}
{'R_grad_norm': 0.7961990976333618, 'training_loss': 1.0278354665637017}
{'R_grad_norm': 0.796704366505146, 'training_loss': 1.022644243836403}
{'R_grad_norm': 0.7966471582651138, 'training_loss': 1.0218403053283691}
{'R_grad_norm': 0.795169403553009, 'training_loss': 1.0245454585552216}
{'R_grad_norm': 0.7951553675532341, 'training_loss': 1.0280015486478806}
{'R_grad_norm': 0.7956109547615051, 'training_loss': 1.0195492160320283}
{'R_grad_norm': 0.7950233721733093, 'training_loss': 1.0160338640213014}
{'R_grad_norm': 0.7942182043194771, 'training_loss': 1.0177917894721031}
{'R_grad_norm': 0.7913303661346436, 'training_loss': 1.0104563790559768}
{'R_grad_norm': 0.7957386860251426, 'training_loss': 1.039218789935112}
{'R_grad_norm': 0.7961237752437591, 'training_loss': 1.0321776798367501}
eval result tensor([1.28619, 1.19348, 1.24482, 2.39017, 1.62048, 1.02453, 1.05024, 1.07704,
        0.75507, 0.72863, 0.65830, 0.80745, 0.60438, 0.68329, 0.60656, 0.78275,
        0.93232, 0.63911, 0.97034], device='cuda:0')
computing merge metric
normed mi [((8, 10), 0.1203172579407692), ((16, 18), 0.11973205953836441), ((10, 17), 0.11916203051805496), ((8, 16), 0.11909361928701401), ((10, 16), 0.11836932599544525), ((9, 10), 0.11821520328521729), ((10, 15), 0.11807598173618317), ((8, 17), 0.11789363622665405), ((8, 15), 0.1177850291132927), ((15, 16), 0.11709005385637283), ((16, 17), 0.11611045897006989), ((15, 17), 0.11587851494550705), ((8, 9), 0.11578938364982605), ((9, 17), 0.11562349647283554), ((5, 8), 0.11535253375768661), ((9, 15), 0.11533507704734802), ((5, 16), 0.11525958776473999), ((5, 18), 0.11522192507982254), ((5, 10), 0.11501950025558472), ((10, 18), 0.11463063955307007), ((8, 18), 0.11431516706943512), ((5, 15), 0.11393088102340698), ((5, 17), 0.11371766030788422), ((5, 9), 0.11370339244604111), ((17, 18), 0.11296546459197998), ((9, 16), 0.11295071244239807), ((15, 18), 0.11285153776407242), ((9, 12), 0.11160609871149063), ((10, 12), 0.1112838163971901), ((9, 11), 0.10972752422094345), ((9, 18), 0.10941776633262634), ((12, 17), 0.10846465826034546), ((8, 12), 0.10825119912624359), ((9, 14), 0.10714415460824966), ((12, 15), 0.10697833448648453), ((10, 11), 0.10680259764194489), ((8, 11), 0.10529933869838715), ((11, 17), 0.10517860949039459), ((10, 14), 0.10478659719228745), ((11, 15), 0.1042327880859375), ((12, 16), 0.10411209613084793), ((11, 14), 0.10392028838396072), ((5, 11), 0.10376010835170746), ((12, 14), 0.10279187560081482), ((5, 12), 0.1027219146490097), ((14, 17), 0.10267649590969086), ((8, 14), 0.10233821719884872), ((11, 16), 0.10203613340854645), ((14, 15), 0.10174968838691711), ((11, 12), 0.10158571600914001), ((12, 18), 0.09936892986297607), ((5, 14), 0.09931551665067673), ((14, 16), 0.09868061542510986), ((11, 18), 0.09793354570865631), ((14, 18), 0.09409380704164505), ((6, 9), 0.09381622821092606), ((6, 16), 0.09373320639133453), ((5, 6), 0.09359703212976456), ((6, 8), 0.09316147863864899), ((6, 10), 0.09231969714164734), ((6, 17), 0.09161002933979034), ((6, 15), 0.09155973047018051), ((6, 18), 0.09026695787906647), ((6, 11), 0.08966389298439026), ((6, 14), 0.08824604004621506), ((2, 10), 0.0867311954498291), ((6, 12), 0.0863509550690651), ((4, 16), 0.08536211649576823), ((4, 10), 0.085052490234375), ((3, 18), 0.08505219221115112), ((0, 10), 0.08445701996485393), ((3, 16), 0.08434454600016277), ((2, 8), 0.0843105415503184), ((4, 8), 0.08414773146311443), ((1, 10), 0.08391368389129639), ((0, 16), 0.08330459396044414), ((2, 9), 0.08302556971708934), ((1, 8), 0.08292173345883687), ((2, 17), 0.08282787601153056), ((4, 17), 0.08269353707631429), ((4, 15), 0.08259719610214233), ((2, 15), 0.08251956105232239), ((4, 18), 0.08246472477912903), ((3, 5), 0.08238525191942851), ((0, 8), 0.08234552045663197), ((4, 5), 0.08189883331457774), ((1, 9), 0.08183017373085022), ((1, 15), 0.08174461126327515), ((0, 18), 0.08153004944324493), ((1, 17), 0.08146533866723378), ((0, 17), 0.08137255410353343), ((0, 15), 0.0810577670733134), ((4, 9), 0.08099223176638286), ((0, 5), 0.08083526293436687), ((2, 16), 0.08078292508920033), ((1, 16), 0.08037002881368001), ((0, 9), 0.07997846603393555), ((2, 5), 0.07970701158046722), ((1, 5), 0.07885258396466573), ((3, 8), 0.0787657896677653), ((3, 17), 0.07832187910874684), ((3, 10), 0.0782119482755661), ((3, 15), 0.07821115851402283), ((2, 18), 0.07773450016975403), ((2, 12), 0.07744140426317851), ((1, 18), 0.07717107733090718), ((1, 12), 0.07661658525466919), ((3, 9), 0.07545346021652222), ((2, 11), 0.0747557133436203), ((4, 12), 0.07451687256495158), ((1, 11), 0.0737861692905426), ((4, 11), 0.07355199257532756), ((0, 12), 0.07348486284414928), ((2, 14), 0.07345217963059743), ((1, 14), 0.07272874812285106), ((0, 11), 0.07204378147919972), ((4, 14), 0.07055404285589854), ((0, 14), 0.0696558157602946), ((3, 12), 0.06838985780874889), ((3, 11), 0.06828410426775615), ((0, 4), 0.068144291639328), ((2, 4), 0.06768770515918732), ((1, 2), 0.06706662476062775), ((0, 2), 0.06672076135873795), ((4, 6), 0.06545432408650716), ((1, 4), 0.06503073871135712), ((3, 14), 0.06477202475070953), ((3, 6), 0.06443476180235545), ((0, 1), 0.06395947188138962), ((0, 6), 0.06395493447780609), ((1, 6), 0.0636504739522934), ((3, 4), 0.06293585151433945), ((2, 6), 0.06248037020365397), ((0, 3), 0.062351178377866745), ((1, 3), 0.058745015412569046), ((2, 3), 0.05825478583574295), ((7, 13), 0.057711705565452576), ((9, 13), 0.034731145948171616), ((12, 13), 0.034216418862342834), ((13, 14), 0.030030889436602592), ((10, 13), 0.028574569150805473), ((13, 17), 0.025600185617804527), ((8, 13), 0.02517666667699814), ((13, 15), 0.024820556864142418), ((11, 13), 0.024730341508984566), ((2, 13), 0.02168753743171692), ((7, 12), 0.020976414903998375), ((1, 13), 0.01966654633482297), ((5, 13), 0.019255565479397774), ((7, 14), 0.018188288435339928), ((7, 9), 0.0172108244150877), ((13, 16), 0.01716122403740883), ((7, 10), 0.0169252697378397), ((0, 13), 0.015583738684654236), ((4, 13), 0.015572567780812582), ((13, 18), 0.015269914641976357), ((7, 17), 0.015186302363872528), ((7, 8), 0.01497145276516676), ((7, 11), 0.014661730267107487), ((7, 15), 0.014298799447715282), ((6, 13), 0.014016029424965382), ((2, 7), 0.01298497368892034), ((1, 7), 0.01292059694727262), ((7, 16), 0.012403232976794243), ((6, 7), 0.012265603058040142), ((7, 18), 0.011211775243282318), ((5, 7), 0.010993782430887222), ((4, 7), 0.010512632628281912), ((0, 7), 0.010184551899631819), ((3, 13), 0.00863568422695001), ((3, 7), 0.006899211555719376)]
******* after merging (0.04): [((8, 10), 64), ((16, 18), 64), ((0,), 64), ((1,), 64), ((2,), 64), ((3,), 64), ((4,), 64), ((5,), 32), ((6,), 32), ((7,), 32), ((9,), 32), ((11,), 32), ((12,), 32), ((13,), 32), ((14,), 32), ((15,), 32), ((17,), 32)]
{'R_grad_norm': 0.8691306394338608, 'training_loss': 1.0997118863463402}
{'R_grad_norm': 0.862351031601429, 'training_loss': 1.1007781636714935}
{'R_grad_norm': 0.8560430207848548, 'training_loss': 1.0951924902200698}
{'R_grad_norm': 0.8571363505721092, 'training_loss': 1.1056553596258163}
{'R_grad_norm': 0.859218253493309, 'training_loss': 1.1044468185305596}
{'R_grad_norm': 0.8527036529779434, 'training_loss': 1.0934437865018845}
{'R_grad_norm': 0.8531015554070472, 'training_loss': 1.0958961942791938}
{'R_grad_norm': 0.8516962692141533, 'training_loss': 1.0915303480625154}
{'R_grad_norm': 0.8529944801330567, 'training_loss': 1.0912170442938804}
{'R_grad_norm': 0.8524165424704552, 'training_loss': 1.0902639245986938}
{'R_grad_norm': 0.8525133857131004, 'training_loss': 1.0908071425557138}
{'R_grad_norm': 0.8493397882580758, 'training_loss': 1.0898360604047774}
{'R_grad_norm': 0.8501053938269615, 'training_loss': 1.0963224244117737}
{'R_grad_norm': 0.848755724132061, 'training_loss': 1.0961816012859344}
{'R_grad_norm': 0.8488708344101906, 'training_loss': 1.1000224855542182}
{'R_grad_norm': 0.8488573199510574, 'training_loss': 1.1027257344126702}
{'R_grad_norm': 0.84765141248703, 'training_loss': 1.0925172013044357}
{'R_grad_norm': 0.8454400098323822, 'training_loss': 1.0940585523843764}
{'R_grad_norm': 0.8500530391931533, 'training_loss': 1.0938778230547905}
{'R_grad_norm': 0.8477920871973038, 'training_loss': 1.096542717218399}
{'R_grad_norm': 0.8481406486034393, 'training_loss': 1.0926924848556518}
{'R_grad_norm': 0.8486353051662445, 'training_loss': 1.0920274367928504}
{'R_grad_norm': 0.848019355237484, 'training_loss': 1.0944771519303322}
{'R_grad_norm': 0.8470583185553551, 'training_loss': 1.094088459610939}
{'R_grad_norm': 0.8462834030389785, 'training_loss': 1.0851816675066948}
{'R_grad_norm': 0.8467344614863396, 'training_loss': 1.0935201385617257}
{'R_grad_norm': 0.8438383963704109, 'training_loss': 1.093642355799675}
{'R_grad_norm': 0.8460809692740441, 'training_loss': 1.0902775293588638}
{'R_grad_norm': 0.8432542684674263, 'training_loss': 1.0973790886998176}
{'R_grad_norm': 0.8438121891021728, 'training_loss': 1.08720370054245}
{'R_grad_norm': 0.845233291387558, 'training_loss': 1.0908867612481117}
{'R_grad_norm': 0.841444790661335, 'training_loss': 1.0963375943899154}
{'R_grad_norm': 0.8411999699473381, 'training_loss': 1.082246619462967}
{'R_grad_norm': 0.8373721733689308, 'training_loss': 1.0833983644843102}
{'R_grad_norm': 0.8416099807620049, 'training_loss': 1.0890568339824676}
{'R_grad_norm': 0.8428783735632897, 'training_loss': 1.0907503205537796}
{'R_grad_norm': 0.8416312053799629, 'training_loss': 1.0869081684947013}
{'R_grad_norm': 0.8382370686531067, 'training_loss': 1.0851318782567978}
{'R_grad_norm': 0.8442977532744408, 'training_loss': 1.0915025395154954}
{'R_grad_norm': 0.8421045124530793, 'training_loss': 1.1001512944698333}
eval result tensor([1.15673, 1.66599, 1.28506, 1.21246, 1.23652, 2.56289, 1.64030, 0.94586,
        1.00951, 1.07971, 0.65555, 0.80990, 0.59519, 0.69184, 0.61038, 0.72931,
        0.61534], device='cuda:0')
computing merge metric
normed mi [((15, 16), 0.11560380458831787), ((10, 16), 0.11559988558292389), ((10, 15), 0.1148623377084732), ((7, 16), 0.11312506347894669), ((7, 15), 0.11265158653259277), ((7, 10), 0.11259660124778748), ((10, 12), 0.11120697855949402), ((10, 11), 0.10806071758270264), ((12, 16), 0.10739772766828537), ((10, 14), 0.10678831487894058), ((12, 15), 0.10638400167226791), ((11, 16), 0.10308182239532471), ((11, 15), 0.10250042378902435), ((7, 11), 0.10213366150856018), ((11, 14), 0.10207908600568771), ((7, 12), 0.1012410968542099), ((12, 14), 0.10120491683483124), ((14, 16), 0.101018987596035), ((14, 15), 0.10090038925409317), ((11, 12), 0.09938335418701172), ((7, 14), 0.0980236828327179), ((8, 10), 0.09311652928590775), ((7, 8), 0.0921705812215805), ((8, 16), 0.09089483320713043), ((8, 15), 0.09051766246557236), ((8, 11), 0.08863972127437592), ((8, 14), 0.0875672698020935), ((8, 12), 0.0852685272693634), ((4, 10), 0.08345203598340352), ((4, 16), 0.08263790607452393), ((6, 16), 0.08226315180460612), ((3, 16), 0.08212687571843465), ((3, 10), 0.08210367461045583), ((3, 15), 0.08201074600219727), ((6, 15), 0.08183407783508301), ((4, 15), 0.08179689447085063), ((6, 7), 0.08139192561308543), ((2, 16), 0.08133686582247417), ((0, 16), 0.08106594781080882), ((6, 10), 0.08032016456127167), ((2, 15), 0.08023470143477122), ((2, 7), 0.08005607624848683), ((5, 7), 0.0800379862387975), ((0, 15), 0.08001543084780376), ((2, 10), 0.07978445291519165), ((0, 7), 0.07867065072059631), ((0, 10), 0.0785842090845108), ((3, 7), 0.0785146951675415), ((1, 7), 0.07805205881595612), ((4, 7), 0.07786223789056142), ((4, 12), 0.07761292656262715), ((1, 16), 0.07694839437802632), ((1, 15), 0.07626727720101674), ((5, 16), 0.07615614434083302), ((3, 12), 0.07591772576173146), ((5, 15), 0.07527361810207367), ((4, 11), 0.0732748160759608), ((6, 12), 0.07320486009120941), ((2, 12), 0.07307055095831554), ((3, 11), 0.07295320431391399), ((4, 14), 0.07295038302739461), ((1, 10), 0.07287357747554779), ((0, 12), 0.0725335677464803), ((6, 11), 0.07250418265660603), ((5, 10), 0.07222514847914378), ((3, 14), 0.07190856337547302), ((2, 11), 0.07112663984298706), ((0, 11), 0.07088355720043182), ((6, 14), 0.06941083073616028), ((2, 14), 0.0689605971177419), ((0, 14), 0.06861730416615804), ((2, 6), 0.0676748976111412), ((3, 4), 0.06695102900266647), ((1, 12), 0.06639053920904796), ((0, 6), 0.06623180210590363), ((1, 11), 0.06583733856678009), ((2, 4), 0.0658196210861206), ((1, 5), 0.06570859998464584), ((6, 8), 0.06567451854546864), ((5, 11), 0.0654444694519043), ((4, 6), 0.06536803394556046), ((5, 12), 0.06527424355347951), ((0, 2), 0.06500673294067383), ((3, 6), 0.06495878100395203), ((0, 4), 0.06451523303985596), ((2, 3), 0.06443401426076889), ((0, 3), 0.06432745605707169), ((3, 8), 0.06359346210956573), ((2, 8), 0.06358303129673004), ((0, 8), 0.06342490514119466), ((1, 6), 0.06340846419334412), ((1, 14), 0.062436903516451515), ((1, 8), 0.062142391999562584), ((1, 2), 0.061683300882577896), ((4, 8), 0.06154139836629232), ((5, 14), 0.06120393673578898), ((5, 8), 0.061141004165013633), ((0, 1), 0.06092575564980507), ((5, 6), 0.06042155250906944), ((2, 5), 0.059239137917757034), ((0, 5), 0.05854925885796547), ((1, 3), 0.058361392468214035), ((1, 4), 0.0574599951505661), ((9, 13), 0.05731864646077156), ((3, 5), 0.05689847841858864), ((4, 5), 0.05585642531514168), ((10, 13), 0.037035875022411346), ((12, 13), 0.03546326979994774), ((13, 14), 0.03136582672595978), ((13, 15), 0.02606404945254326), ((13, 16), 0.025858113542199135), ((4, 13), 0.024335165818532307), ((11, 13), 0.02386372722685337), ((9, 12), 0.021862339228391647), ((3, 13), 0.02027874564131101), ((7, 13), 0.019698621705174446), ((9, 14), 0.01901652291417122), ((9, 10), 0.018451081588864326), ((2, 13), 0.01676854242881139), ((0, 13), 0.016039635986089706), ((9, 16), 0.015592913143336773), ((6, 13), 0.015358557303746542), ((9, 15), 0.015080145560204983), ((8, 13), 0.014405499212443829), ((4, 9), 0.013850043217341105), ((9, 11), 0.013788680545985699), ((3, 9), 0.013343226164579391), ((8, 9), 0.012626743875443935), ((7, 9), 0.010876602493226528), ((2, 9), 0.010851265241702398), ((0, 9), 0.010581068694591522), ((6, 9), 0.01017757939795653), ((1, 13), 0.009136912102500597), ((1, 9), 0.007453041772047679), ((5, 13), 0.00693153589963913), ((5, 9), 0.006176396583517392)]
******* after merging (0.04): [((15, 16), 64), ((7, 10), 64), ((0,), 64), ((1,), 64), ((2,), 64), ((3,), 64), ((4,), 64), ((5,), 64), ((6,), 64), ((8,), 32), ((9,), 32), ((11,), 32), ((12,), 32), ((13,), 32), ((14,), 32)]
{'R_grad_norm': 0.9235422950983048, 'training_loss': 1.1910479402542113}
{'R_grad_norm': 0.9183368071913719, 'training_loss': 1.2069812867045402}
{'R_grad_norm': 0.9095804318785667, 'training_loss': 1.1960889840126037}
{'R_grad_norm': 0.9098667749762535, 'training_loss': 1.2014995402097701}
{'R_grad_norm': 0.905005002617836, 'training_loss': 1.1931282466650008}
{'R_grad_norm': 0.9018292436003685, 'training_loss': 1.1887455350160598}
{'R_grad_norm': 0.9069876515865326, 'training_loss': 1.2012754249572755}
{'R_grad_norm': 0.9044792625308037, 'training_loss': 1.200731742978096}
{'R_grad_norm': 0.8999295157194137, 'training_loss': 1.1913329350948334}
{'R_grad_norm': 0.8989764711260796, 'training_loss': 1.189755579829216}
{'R_grad_norm': 0.9003457194566726, 'training_loss': 1.189528466463089}
{'R_grad_norm': 0.8990662789344788, 'training_loss': 1.1884980863332748}
{'R_grad_norm': 0.9009620001912118, 'training_loss': 1.1990068709850312}
{'R_grad_norm': 0.8977197793126106, 'training_loss': 1.1973159110546112}
{'R_grad_norm': 0.8986112675070763, 'training_loss': 1.2042733150720597}
{'R_grad_norm': 0.8941712367534638, 'training_loss': 1.193864495754242}
{'R_grad_norm': 0.8972843313217163, 'training_loss': 1.1957096236944198}
{'R_grad_norm': 0.8940808779001236, 'training_loss': 1.195397233068943}
{'R_grad_norm': 0.8945583665370941, 'training_loss': 1.1893088406324386}
{'R_grad_norm': 0.8961036285758018, 'training_loss': 1.1921431583166122}
{'R_grad_norm': 0.8956308114528656, 'training_loss': 1.1938739123940467}
{'R_grad_norm': 0.8905862009525299, 'training_loss': 1.1775620126724242}
{'R_grad_norm': 0.8948598834872246, 'training_loss': 1.1895112478733063}
{'R_grad_norm': 0.8923392397165298, 'training_loss': 1.2031381380558015}
{'R_grad_norm': 0.8926706731319427, 'training_loss': 1.1802965036034585}
{'R_grad_norm': 0.8939490818977356, 'training_loss': 1.1935156205296515}
{'R_grad_norm': 0.895143632888794, 'training_loss': 1.1927089828252793}
{'R_grad_norm': 0.8911178037524223, 'training_loss': 1.1882012334465981}
{'R_grad_norm': 0.8890469664335251, 'training_loss': 1.1845311349630356}
{'R_grad_norm': 0.8923570257425308, 'training_loss': 1.1906509310007096}
{'R_grad_norm': 0.8930841270089149, 'training_loss': 1.2024563264846801}
{'R_grad_norm': 0.8957546806335449, 'training_loss': 1.1915004369616509}
{'R_grad_norm': 0.8935397124290466, 'training_loss': 1.1896865266561507}
{'R_grad_norm': 0.8952332106232643, 'training_loss': 1.195728422999382}
{'R_grad_norm': 0.8902528765797615, 'training_loss': 1.1836459547281266}
{'R_grad_norm': 0.8908774697780609, 'training_loss': 1.1705729734897614}
{'R_grad_norm': 0.8962748703360558, 'training_loss': 1.193587002456188}
{'R_grad_norm': 0.8961750024557114, 'training_loss': 1.1905856195092201}
{'R_grad_norm': 0.8955996876955032, 'training_loss': 1.187246708869934}
{'R_grad_norm': 0.8934950888156891, 'training_loss': 1.1892952668666839}
eval result tensor([1.10243, 1.37889, 1.13196, 1.70602, 1.27970, 1.18047, 1.22961, 2.65014,
        1.65547, 0.96329, 1.04283, 0.78448, 0.58107, 0.61286, 0.61045],
       device='cuda:0')
computing merge metric
normed mi [((11, 14), 0.09943551570177078), ((12, 14), 0.09922873973846436), ((11, 12), 0.09607873857021332), ((9, 11), 0.08671098202466965), ((9, 14), 0.08631918579339981), ((9, 12), 0.08372921496629715), ((6, 12), 0.07731050252914429), ((12, 13), 0.07517803460359573), ((5, 12), 0.07504371305306752), ((6, 14), 0.07201656699180603), ((4, 12), 0.0719797561566035), ((5, 11), 0.07191500067710876), ((8, 12), 0.07173986236254375), ((2, 12), 0.07125828663508098), ((5, 14), 0.0712422529856364), ((6, 11), 0.07120816906293233), ((8, 11), 0.0706786960363388), ((13, 14), 0.0704987421631813), ((0, 12), 0.07039963205655415), ((1, 11), 0.06995607415835063), ((2, 11), 0.06956283251444499), ((4, 11), 0.06947936117649078), ((1, 12), 0.06905809044837952), ((0, 11), 0.06830129524072011), ((8, 14), 0.06819249192873637), ((4, 14), 0.06812301278114319), ((2, 14), 0.06740927696228027), ((1, 14), 0.06711037953694661), ((4, 8), 0.06633402407169342), ((0, 14), 0.06631944080193837), ((5, 6), 0.0657518282532692), ((11, 13), 0.06516062468290329), ((3, 12), 0.06511575480302174), ((3, 11), 0.06501183907190959), ((2, 8), 0.06491884589195251), ((3, 7), 0.06473514437675476), ((8, 9), 0.06438639263312022), ((2, 4), 0.0642622783780098), ((7, 11), 0.06404674549897511), ((2, 5), 0.06393220275640488), ((5, 8), 0.06390847265720367), ((4, 5), 0.06387244910001755), ((4, 6), 0.06384849548339844), ((7, 12), 0.0636955052614212), ((3, 8), 0.06307762861251831), ((1, 8), 0.06302295625209808), ((0, 8), 0.06302285194396973), ((5, 9), 0.06301868458588918), ((2, 6), 0.06282765418291092), ((6, 8), 0.06254491955041885), ((1, 9), 0.06230250497659048), ((4, 9), 0.062198251485824585), ((0, 5), 0.062031909823417664), ((2, 9), 0.06199882924556732), ((3, 14), 0.06174564858277639), ((1, 4), 0.061745304614305496), ((0, 4), 0.06152283400297165), ((0, 2), 0.06151823326945305), ((0, 9), 0.06120571494102478), ((1, 5), 0.060917120426893234), ((1, 2), 0.06089022010564804), ((3, 4), 0.06032870337367058), ((6, 9), 0.060150603453318276), ((1, 7), 0.060046080499887466), ((0, 6), 0.05993254482746124), ((3, 9), 0.0598694384098053), ((0, 1), 0.05982556194067001), ((7, 14), 0.059687912464141846), ((2, 3), 0.05961388349533081), ((1, 3), 0.05953195318579674), ((0, 3), 0.05932408198714256), ((7, 8), 0.059270571917295456), ((1, 6), 0.05911342427134514), ((0, 7), 0.058085788041353226), ((7, 9), 0.05755793551603953), ((3, 5), 0.0575353167951107), ((4, 7), 0.057442888617515564), ((2, 7), 0.05711802467703819), ((5, 7), 0.05591844022274017), ((6, 13), 0.05568538109461466), ((3, 6), 0.05563763529062271), ((6, 7), 0.05415751039981842), ((9, 13), 0.05232108384370804), ((5, 13), 0.052233219146728516), ((4, 13), 0.048284709453582764), ((8, 13), 0.04794739683469137), ((2, 13), 0.047503297527631126), ((0, 13), 0.04484062890211741), ((1, 13), 0.043376147747039795), ((10, 13), 0.041006434708833694), ((3, 13), 0.035224693516890206), ((7, 13), 0.029114996393521626), ((10, 12), 0.019835762679576874), ((10, 14), 0.01610567420721054), ((6, 10), 0.012462077041467031), ((10, 11), 0.01199946366250515), ((5, 10), 0.011755450318257013), ((9, 10), 0.011660311371088028), ((4, 10), 0.009164859851201376), ((2, 10), 0.009091452384988466), ((8, 10), 0.008915438627203306), ((0, 10), 0.008365882560610771), ((1, 10), 0.006720847760637601), ((3, 10), 0.006388135254383087), ((7, 10), 0.0054485853761434555)]
******* after merging (0.04): [((11, 14), 64), ((0,), 64), ((1,), 64), ((2,), 64), ((3,), 64), ((4,), 64), ((5,), 64), ((6,), 64), ((7,), 64), ((8,), 64), ((9,), 32), ((10,), 32), ((12,), 32), ((13,), 32)]
{'R_grad_norm': 0.973160735964775, 'training_loss': 1.2520207560062409}
{'R_grad_norm': 0.9655308428406716, 'training_loss': 1.2466967082023621}
{'R_grad_norm': 0.9679618847370147, 'training_loss': 1.2570425033569337}
{'R_grad_norm': 0.9624209091067314, 'training_loss': 1.258222943544388}
{'R_grad_norm': 0.9564886313676834, 'training_loss': 1.2478065818548203}
{'R_grad_norm': 0.954847748875618, 'training_loss': 1.2502189373970032}
{'R_grad_norm': 0.953941622376442, 'training_loss': 1.2666569405794144}
{'R_grad_norm': 0.9475180190801621, 'training_loss': 1.2388922929763795}
{'R_grad_norm': 0.9466451415419579, 'training_loss': 1.2548052090406419}
{'R_grad_norm': 0.9447628164291382, 'training_loss': 1.252080087661743}
{'R_grad_norm': 0.9394765058159829, 'training_loss': 1.2467411264777184}
{'R_grad_norm': 0.9397775357961655, 'training_loss': 1.2427900171279906}
{'R_grad_norm': 0.9360086715221405, 'training_loss': 1.2391319590806962}
{'R_grad_norm': 0.9336824035644531, 'training_loss': 1.242317521572113}
{'R_grad_norm': 0.9308616840839385, 'training_loss': 1.2472881525754929}
{'R_grad_norm': 0.9295570111274719, 'training_loss': 1.2434867191314698}
{'R_grad_norm': 0.9266534632444382, 'training_loss': 1.2445533800125121}
{'R_grad_norm': 0.9295257613062858, 'training_loss': 1.2496918857097625}
{'R_grad_norm': 0.9267501467466355, 'training_loss': 1.24912433385849}
{'R_grad_norm': 0.9195723366737366, 'training_loss': 1.2478258121013641}
{'R_grad_norm': 0.9221717578172683, 'training_loss': 1.2499991327524185}
{'R_grad_norm': 0.9182527273893356, 'training_loss': 1.2364218145608903}
{'R_grad_norm': 0.9176270291209221, 'training_loss': 1.2504275393486024}
{'R_grad_norm': 0.9188378158211709, 'training_loss': 1.2469120025634766}
{'R_grad_norm': 0.9149215683341027, 'training_loss': 1.2512806510925294}
{'R_grad_norm': 0.9137920346856118, 'training_loss': 1.2409914875030517}
{'R_grad_norm': 0.9144750410318374, 'training_loss': 1.2413333567976952}
{'R_grad_norm': 0.9096331804990768, 'training_loss': 1.227098087668419}
{'R_grad_norm': 0.9090688496828079, 'training_loss': 1.2305769628286363}
{'R_grad_norm': 0.9118685141205788, 'training_loss': 1.246685998439789}
{'R_grad_norm': 0.9085829111933709, 'training_loss': 1.2534611785411836}
{'R_grad_norm': 0.9071778810024261, 'training_loss': 1.2312826466560365}
{'R_grad_norm': 0.9073477077484131, 'training_loss': 1.250454565882683}
{'R_grad_norm': 0.9066793483495712, 'training_loss': 1.255471072793007}
{'R_grad_norm': 0.9061159220337868, 'training_loss': 1.2511747032403946}
{'R_grad_norm': 0.9018984690308571, 'training_loss': 1.2408517402410508}
{'R_grad_norm': 0.9010642084479332, 'training_loss': 1.2463878017663956}
{'R_grad_norm': 0.8995968508720398, 'training_loss': 1.23797180891037}
{'R_grad_norm': 0.9006192460656166, 'training_loss': 1.2356475108861924}
{'R_grad_norm': 0.8980022969841958, 'training_loss': 1.2448580324649812}
eval result tensor([1.22359, 1.05503, 1.39565, 1.08467, 1.71721, 1.23916, 1.14943, 1.19451,
        2.71407, 1.63842, 0.91947, 1.03312, 0.57414, 0.47406], device='cuda:0')
computing merge metric
normed mi [((12, 13), 0.10003653168678284), ((10, 12), 0.08054421097040176), ((10, 13), 0.08046058565378189), ((6, 13), 0.07758491237958272), ((7, 12), 0.07715154687563579), ((9, 13), 0.07614220182100932), ((3, 13), 0.07586720585823059), ((5, 13), 0.07585709790388744), ((7, 13), 0.07524833083152771), ((1, 13), 0.07424849271774292), ((2, 13), 0.0740561733643214), ((6, 12), 0.07397574683030446), ((3, 12), 0.07149682442347209), ((5, 12), 0.07131119072437286), ((9, 12), 0.07091934482256572), ((1, 12), 0.07001179953416188), ((4, 13), 0.06973741451899211), ((2, 12), 0.06899627546469371), ((8, 13), 0.06844347715377808), ((0, 13), 0.06722427904605865), ((5, 9), 0.0658893957734108), ((4, 12), 0.06514506538709004), ((4, 8), 0.06500142067670822), ((3, 9), 0.06460142135620117), ((3, 5), 0.06455668061971664), ((6, 7), 0.06450343132019043), ((3, 6), 0.06449328362941742), ((0, 12), 0.06414863467216492), ((6, 9), 0.06394510716199875), ((5, 6), 0.06386543065309525), ((8, 12), 0.06364962955315907), ((4, 9), 0.06322669237852097), ((2, 9), 0.0630129724740982), ((5, 7), 0.06300082802772522), ((1, 9), 0.06294067949056625), ((3, 7), 0.062535859644413), ((1, 6), 0.062226321548223495), ((9, 10), 0.06215030451615652), ((1, 5), 0.06185920536518097), ((2, 5), 0.06183195114135742), ((1, 3), 0.06174642592668533), ((2, 3), 0.06127990409731865), ((2, 6), 0.06126737967133522), ((7, 9), 0.061166465282440186), ((6, 10), 0.061030805110931396), ((2, 8), 0.06044561788439751), ((1, 2), 0.06030074879527092), ((4, 5), 0.060253288596868515), ((3, 10), 0.06018166244029999), ((2, 4), 0.05995597690343857), ((5, 10), 0.059889018535614014), ((2, 10), 0.0597590704758962), ((8, 9), 0.0596940740942955), ((1, 7), 0.05938021093606949), ((3, 4), 0.05934184044599533), ((1, 4), 0.05916190147399902), ((1, 10), 0.058864196141560875), ((0, 10), 0.058671181400616966), ((2, 7), 0.05840320885181427), ((4, 6), 0.058266423642635345), ((7, 10), 0.05823346475760142), ((1, 8), 0.05789828300476074), ((5, 8), 0.057342953979969025), ((3, 8), 0.056835465133190155), ((6, 8), 0.05671142041683197), ((4, 10), 0.05636258920033773), ((4, 7), 0.05535009875893593), ((0, 6), 0.0548013299703598), ((0, 2), 0.054518990218639374), ((0, 9), 0.05444340035319328), ((7, 8), 0.05390181392431259), ((8, 10), 0.05377583205699921), ((0, 3), 0.05324931815266609), ((0, 5), 0.053205456584692), ((0, 1), 0.052560895681381226), ((0, 7), 0.05255499854683876), ((0, 4), 0.05105559155344963), ((0, 8), 0.05069448798894882), ((11, 12), 0.018780997022986412), ((11, 13), 0.015544875524938107), ((7, 11), 0.011969449619452158), ((10, 11), 0.011792768724262714), ((6, 11), 0.010731827467679977), ((3, 11), 0.008862506598234177), ((5, 11), 0.008615530406435331), ((9, 11), 0.008288211499651274), ((0, 11), 0.007746237019697825), ((1, 11), 0.00765091987947623), ((2, 11), 0.006546893467505773), ((4, 11), 0.005979575837651889), ((8, 11), 0.005215377236406009)]
******* after merging (0.04): [((12, 13), 64), ((0,), 64), ((1,), 64), ((2,), 64), ((3,), 64), ((4,), 64), ((5,), 64), ((6,), 64), ((7,), 64), ((8,), 64), ((9,), 64), ((10,), 32), ((11,), 32)]
{'R_grad_norm': 1.010092143714428, 'training_loss': 1.3179254055023193}
{'R_grad_norm': 0.9927227401733398, 'training_loss': 1.3190923845767974}
{'R_grad_norm': 0.9852023887634277, 'training_loss': 1.320664697289467}
{'R_grad_norm': 0.9778531330823899, 'training_loss': 1.3153322738409043}
{'R_grad_norm': 0.9712343129515648, 'training_loss': 1.3225911009311675}
{'R_grad_norm': 0.9619208326935769, 'training_loss': 1.3044139814376832}
{'R_grad_norm': 0.9620885223150253, 'training_loss': 1.3337313932180406}
{'R_grad_norm': 0.9538832229375839, 'training_loss': 1.3189131730794907}
{'R_grad_norm': 0.954901485145092, 'training_loss': 1.340275474190712}
{'R_grad_norm': 0.9478374668955802, 'training_loss': 1.327824370265007}
{'R_grad_norm': 0.9486339166760445, 'training_loss': 1.344686518907547}
{'R_grad_norm': 0.9419671094417572, 'training_loss': 1.3362648969888686}
{'R_grad_norm': 0.9408763197064399, 'training_loss': 1.3445670175552369}
{'R_grad_norm': 0.9392185261845589, 'training_loss': 1.36202099442482}
{'R_grad_norm': 0.940334170460701, 'training_loss': 1.361309067606926}
{'R_grad_norm': 0.9411725056171417, 'training_loss': 1.3773014152050018}
{'R_grad_norm': 0.9363773739337922, 'training_loss': 1.3743302464485168}
{'R_grad_norm': 0.9394162228703499, 'training_loss': 1.3948451298475266}
{'R_grad_norm': 0.9375275549292564, 'training_loss': 1.3868238759040832}
{'R_grad_norm': 0.9372687050700188, 'training_loss': 1.4052428907155992}
{'R_grad_norm': 0.9374354353547096, 'training_loss': 1.4211643987894058}
{'R_grad_norm': 0.939269198179245, 'training_loss': 1.4263075470924378}
{'R_grad_norm': 0.940645190179348, 'training_loss': 1.4532894843816757}
{'R_grad_norm': 0.9139127466082573, 'training_loss': 1.350652341246605}
{'R_grad_norm': 0.9088779479265213, 'training_loss': 1.338458612561226}
{'R_grad_norm': 0.9031393092870712, 'training_loss': 1.3264459955692292}
{'R_grad_norm': 0.9023864459991455, 'training_loss': 1.3234814178943635}
{'R_grad_norm': 0.9052790510654449, 'training_loss': 1.3193501871824265}
{'R_grad_norm': 0.899790096282959, 'training_loss': 1.3091334736347198}
{'R_grad_norm': 0.9026155921816826, 'training_loss': 1.312079336643219}
{'R_grad_norm': 0.9014634853601455, 'training_loss': 1.3106234753131867}
{'R_grad_norm': 0.8985239034891128, 'training_loss': 1.3005578428506852}
{'R_grad_norm': 0.9006539168953895, 'training_loss': 1.3173625928163528}
{'R_grad_norm': 0.8996897473931312, 'training_loss': 1.3219054806232453}
{'R_grad_norm': 0.9023017409443855, 'training_loss': 1.3265777468681335}
{'R_grad_norm': 0.8958663126826286, 'training_loss': 1.3228422373533248}
{'R_grad_norm': 0.8975476863980293, 'training_loss': 1.3093410474061966}
{'R_grad_norm': 0.8982549402117729, 'training_loss': 1.3180370384454727}
{'R_grad_norm': 0.898309885263443, 'training_loss': 1.3146765875816344}
{'R_grad_norm': 0.8989664742350578, 'training_loss': 1.3116671687364578}
eval result tensor([0.89204, 1.23352, 0.98409, 1.43259, 1.04849, 1.70943, 1.21763, 1.13171,
        1.16157, 2.77876, 1.59982, 0.85705, 1.03252], device='cuda:0')
computing merge metric
normed mi [((6, 10), 0.06577654182910919), ((5, 9), 0.06530812382698059), ((4, 7), 0.06500804424285889), ((4, 6), 0.06500247120857239), ((7, 10), 0.06484667956829071), ((4, 10), 0.06448295712471008), ((6, 7), 0.06439833343029022), ((5, 10), 0.06389787048101425), ((2, 7), 0.06339331716299057), ((3, 10), 0.06315924227237701), ((7, 8), 0.06312978267669678), ((2, 10), 0.06312012672424316), ((2, 4), 0.06275362521409988), ((4, 8), 0.06272050738334656), ((2, 6), 0.06256193667650223), ((6, 8), 0.062430448830127716), ((3, 6), 0.06196523830294609), ((3, 7), 0.06185850501060486), ((3, 4), 0.06125311553478241), ((3, 9), 0.06119348853826523), ((8, 10), 0.06074526160955429), ((5, 6), 0.06064430996775627), ((2, 3), 0.060553643852472305), ((3, 5), 0.06047988310456276), ((9, 10), 0.06020363047719002), ((5, 7), 0.05984199419617653), ((2, 8), 0.05980167165398598), ((4, 5), 0.05941230058670044), ((10, 11), 0.05913684765497843), ((7, 11), 0.05889541904131571), ((2, 5), 0.058678969740867615), ((0, 7), 0.05848115682601929), ((7, 9), 0.058085184544324875), ((6, 9), 0.05793214961886406), ((3, 8), 0.057898011058568954), ((4, 11), 0.057750736673672996), ((2, 9), 0.05740700289607048), ((6, 11), 0.05737511316935221), ((3, 11), 0.05726258456707001), ((0, 8), 0.05720002204179764), ((0, 10), 0.05718890577554703), ((0, 4), 0.05704250559210777), ((0, 6), 0.05693131685256958), ((4, 9), 0.0568714402616024), ((2, 11), 0.05676041046778361), ((0, 2), 0.05633325129747391), ((1, 11), 0.05628952383995056), ((8, 11), 0.05617512762546539), ((0, 3), 0.05574403330683708), ((5, 8), 0.055399250239133835), ((1, 7), 0.054501280188560486), ((1, 10), 0.05442311242222786), ((1, 3), 0.05420055612921715), ((8, 9), 0.05411860719323158), ((0, 5), 0.05367489159107208), ((0, 9), 0.053661420941352844), ((5, 11), 0.05361599723498026), ((1, 4), 0.0533590205013752), ((1, 6), 0.05318034440279007), ((1, 2), 0.05275604501366615), ((9, 11), 0.05218551059563955), ((1, 8), 0.05209580808877945), ((0, 11), 0.051530689001083374), ((1, 9), 0.0509270504117012), ((1, 5), 0.05066220462322235), ((0, 1), 0.049891646951436996), ((8, 12), 0.012050079802672068), ((11, 12), 0.011663923971354961), ((7, 12), 0.010417614132165909), ((0, 12), 0.009992398942510286), ((4, 12), 0.008844422797362009), ((6, 12), 0.00862741470336914), ((2, 12), 0.008281152074535688), ((1, 12), 0.008091933404405912), ((10, 12), 0.007894027978181839), ((3, 12), 0.0065046437084674835), ((5, 12), 0.0057081424941619234), ((9, 12), 0.005221623306473096)]
******* after merging (0.04): [((6, 10), 128), ((0,), 64), ((1,), 64), ((2,), 64), ((3,), 64), ((4,), 64), ((5,), 64), ((7,), 64), ((8,), 64), ((9,), 64), ((11,), 32), ((12,), 32)]
{'R_grad_norm': 1.0406533312797546, 'training_loss': 1.3544848847389221}
{'R_grad_norm': 1.0346400263905524, 'training_loss': 1.3792478704452515}
{'R_grad_norm': 1.0292238935828208, 'training_loss': 1.379535079598427}
{'R_grad_norm': 1.0246106901764869, 'training_loss': 1.3743610203266143}
{'R_grad_norm': 1.018994245827198, 'training_loss': 1.3720666718482972}
{'R_grad_norm': 1.0126349195837974, 'training_loss': 1.3623490303754806}
{'R_grad_norm': 1.0072359469532968, 'training_loss': 1.3649936801195144}
{'R_grad_norm': 1.0031050023436547, 'training_loss': 1.3597297406196593}
{'R_grad_norm': 1.0024522152543067, 'training_loss': 1.3778352987766267}
{'R_grad_norm': 0.9961134657263756, 'training_loss': 1.3705597937107086}
{'R_grad_norm': 0.989338928759098, 'training_loss': 1.3627412438392639}
{'R_grad_norm': 0.9832596045732498, 'training_loss': 1.3696421265602112}
{'R_grad_norm': 0.98325853317976, 'training_loss': 1.370712207555771}
{'R_grad_norm': 0.9731232494115829, 'training_loss': 1.3530509984493255}
{'R_grad_norm': 0.9732117170095443, 'training_loss': 1.3547591304779052}
{'R_grad_norm': 0.9675809559226036, 'training_loss': 1.348606026172638}
{'R_grad_norm': 0.9681166458129883, 'training_loss': 1.3661063253879546}
{'R_grad_norm': 0.9645433336496353, 'training_loss': 1.3625130379199981}
{'R_grad_norm': 0.9583314418792724, 'training_loss': 1.3572007405757904}
{'R_grad_norm': 0.9580768436193466, 'training_loss': 1.370077399611473}
{'R_grad_norm': 0.9552098613977432, 'training_loss': 1.3631644588708878}
{'R_grad_norm': 0.9572773942351341, 'training_loss': 1.3704436630010606}
{'R_grad_norm': 0.9547151923179626, 'training_loss': 1.3630956119298936}
{'R_grad_norm': 0.9495936596393585, 'training_loss': 1.3628659319877625}
{'R_grad_norm': 0.9500891658663749, 'training_loss': 1.3565550184249877}
{'R_grad_norm': 0.9482202535867691, 'training_loss': 1.364100728034973}
{'R_grad_norm': 0.9439339655637741, 'training_loss': 1.3610655564069747}
{'R_grad_norm': 0.9428810307383537, 'training_loss': 1.3595804673433305}
{'R_grad_norm': 0.9393870630860328, 'training_loss': 1.357454350590706}
{'R_grad_norm': 0.93782103151083, 'training_loss': 1.363669108748436}
{'R_grad_norm': 0.9377029013633728, 'training_loss': 1.3638977593183517}
{'R_grad_norm': 0.9344163942337036, 'training_loss': 1.35679093003273}
{'R_grad_norm': 0.9337707194685936, 'training_loss': 1.3498477107286453}
{'R_grad_norm': 0.9317338389158248, 'training_loss': 1.3454935497045517}
{'R_grad_norm': 0.9320076382160187, 'training_loss': 1.3579767847061157}
{'R_grad_norm': 0.9248541855812072, 'training_loss': 1.344336947798729}
{'R_grad_norm': 0.9259670779109002, 'training_loss': 1.3469653713703156}
{'R_grad_norm': 0.9261811169981956, 'training_loss': 1.3554240703582763}
{'R_grad_norm': 0.927348580956459, 'training_loss': 1.3599806207418441}
{'R_grad_norm': 0.9299844905734063, 'training_loss': 1.35787737429142}
eval result tensor([2.61427, 0.88587, 1.21167, 0.94548, 1.34436, 1.02175, 1.51461, 1.10059,
        1.13670, 2.77049, 0.80636, 1.01217], device='cuda:0')
computing merge metric
normed mi [((5, 7), 0.06467525660991669), ((3, 7), 0.06373059749603271), ((3, 5), 0.06342386454343796), ((5, 8), 0.06279151886701584), ((6, 9), 0.06251108646392822), ((4, 7), 0.06167755648493767), ((7, 8), 0.06142053380608559), ((4, 5), 0.06137090548872948), ((6, 7), 0.06127201393246651), ((3, 4), 0.06081641465425491), ((3, 8), 0.0606936551630497), ((4, 6), 0.06047553941607475), ((4, 9), 0.05987241119146347), ((5, 6), 0.059430330991744995), ((3, 6), 0.05880696326494217), ((1, 7), 0.058390263468027115), ((4, 8), 0.05788904428482056), ((1, 5), 0.05751796439290047), ((7, 9), 0.05746046453714371), ((1, 3), 0.056969814002513885), ((1, 8), 0.05695159733295441), ((7, 10), 0.05642946561177572), ((5, 10), 0.055954188108444214), ((1, 4), 0.055932410061359406), ((3, 10), 0.055812070767084755), ((4, 10), 0.055784290035565696), ((3, 9), 0.05561991408467293), ((6, 8), 0.05557120591402054), ((5, 9), 0.05538053438067436), ((8, 10), 0.05446809530258179), ((2, 10), 0.054375022649765015), ((1, 6), 0.05431129038333893), ((2, 7), 0.054150503128767014), ((2, 4), 0.05401049554347992), ((2, 3), 0.0532538965344429), ((1, 9), 0.053217608481645584), ((2, 5), 0.05304760858416557), ((8, 9), 0.05275069922208786), ((6, 10), 0.05227317909399668), ((2, 8), 0.05156752094626427), ((1, 10), 0.05072517693042755), ((2, 9), 0.05072096362709999), ((2, 6), 0.05062631145119667), ((9, 10), 0.05051529407501221), ((1, 2), 0.04969579726457596), ((0, 6), 0.045046220223108925), ((0, 7), 0.043215855956077576), ((0, 4), 0.042919511596361794), ((0, 5), 0.04218032956123352), ((0, 3), 0.04181582729021708), ((0, 9), 0.04094121605157852), ((0, 8), 0.039478023846944175), ((0, 1), 0.038321291406949363), ((0, 2), 0.036139500637849174), ((0, 10), 0.03471544682979584), ((8, 11), 0.012136453141768774), ((10, 11), 0.011329332366585732), ((7, 11), 0.00991026684641838), ((1, 11), 0.009781861677765846), ((5, 11), 0.009135299051801363), ((3, 11), 0.008787420267860094), ((2, 11), 0.008038281152645746), ((4, 11), 0.006551677361130714), ((6, 11), 0.006019546339909236), ((9, 11), 0.005078110533456008), ((0, 11), 0.00450480505824089)]
******* after merging (0.04): [((5, 7), 128), ((0,), 128), ((1,), 64), ((2,), 64), ((3,), 64), ((4,), 64), ((6,), 64), ((8,), 64), ((9,), 64), ((10,), 32), ((11,), 32)]
{'R_grad_norm': 1.088059179186821, 'training_loss': 1.4234652400016785}
{'R_grad_norm': 1.074809204041958, 'training_loss': 1.4252482944726943}
{'R_grad_norm': 1.0718807205557823, 'training_loss': 1.4394403541088103}
{'R_grad_norm': 1.069431672692299, 'training_loss': 1.4303653460741044}
{'R_grad_norm': 1.0633674228191377, 'training_loss': 1.435190789103508}
{'R_grad_norm': 1.0574238353967667, 'training_loss': 1.4427818262577057}
{'R_grad_norm': 1.0546244049072266, 'training_loss': 1.430817169547081}
{'R_grad_norm': 1.0510713148117066, 'training_loss': 1.428639310002327}
{'R_grad_norm': 1.047769710123539, 'training_loss': 1.4251655668020249}
{'R_grad_norm': 1.044501043856144, 'training_loss': 1.4250910490751267}
{'R_grad_norm': 1.0361940506100655, 'training_loss': 1.4177188849449158}
{'R_grad_norm': 1.0425510776042939, 'training_loss': 1.4425405699014664}
{'R_grad_norm': 1.0376594808697701, 'training_loss': 1.4271429890394212}
{'R_grad_norm': 1.0291704699397086, 'training_loss': 1.417574815750122}
{'R_grad_norm': 1.0312304151058198, 'training_loss': 1.4282117545604707}
{'R_grad_norm': 1.0242145538330079, 'training_loss': 1.4201983839273453}
{'R_grad_norm': 1.0245511150360107, 'training_loss': 1.4283942598104478}
{'R_grad_norm': 1.0180082499980927, 'training_loss': 1.431708265542984}
{'R_grad_norm': 1.0180014964938164, 'training_loss': 1.427849017381668}
{'R_grad_norm': 1.015858706831932, 'training_loss': 1.4168166714906691}
{'R_grad_norm': 1.0152713510394096, 'training_loss': 1.4229874122142792}
{'R_grad_norm': 1.0084480726718903, 'training_loss': 1.4242220455408097}
{'R_grad_norm': 1.004002581834793, 'training_loss': 1.431488919854164}
{'R_grad_norm': 1.004729636311531, 'training_loss': 1.4250139331817626}
{'R_grad_norm': 0.9970351231098175, 'training_loss': 1.4240203088521957}
{'R_grad_norm': 0.997862554192543, 'training_loss': 1.4296413213014603}
{'R_grad_norm': 0.9927817204594612, 'training_loss': 1.427984476685524}
{'R_grad_norm': 0.9943050390481949, 'training_loss': 1.4213576316833496}
{'R_grad_norm': 0.9897979426383973, 'training_loss': 1.4264985007047652}
{'R_grad_norm': 0.985926718711853, 'training_loss': 1.4189069736003876}
{'R_grad_norm': 0.9832647624611854, 'training_loss': 1.4184656625986098}
{'R_grad_norm': 0.9777265375852585, 'training_loss': 1.4218258088827134}
{'R_grad_norm': 0.9764835235476493, 'training_loss': 1.4226618111133575}
{'R_grad_norm': 0.9801406693458558, 'training_loss': 1.4189241141080857}
{'R_grad_norm': 0.9764357271790505, 'training_loss': 1.41695478618145}
{'R_grad_norm': 0.9743591895699502, 'training_loss': 1.4191347759962083}
{'R_grad_norm': 0.9725383317470551, 'training_loss': 1.4207047146558762}
{'R_grad_norm': 0.9677417773008347, 'training_loss': 1.430058509707451}
{'R_grad_norm': 0.9640687105059623, 'training_loss': 1.4110497558116912}
{'R_grad_norm': 0.9655095592141152, 'training_loss': 1.4094239068031311}
eval result tensor([1.83051, 2.72581, 0.80958, 1.16596, 0.86860, 1.16939, 1.27654, 1.01838,
        2.73605, 0.77266, 0.99492], device='cuda:0')
computing merge metric
normed mi [((4, 5), 0.0611688494682312), ((4, 7), 0.06072143092751503), ((5, 6), 0.060531508177518845), ((6, 8), 0.05980093777179718), ((4, 6), 0.05953293293714523), ((2, 4), 0.05847427248954773), ((5, 7), 0.05829238146543503), ((5, 8), 0.058194756507873535), ((2, 7), 0.05799439176917076), ((2, 5), 0.057402852922677994), ((6, 7), 0.05621252954006195), ((2, 6), 0.05588943883776665), ((5, 9), 0.05563044548034668), ((4, 9), 0.055092960596084595), ((3, 9), 0.05454494555791219), ((7, 9), 0.05421386162439982), ((4, 8), 0.05420437827706337), ((3, 5), 0.054171305149793625), ((3, 4), 0.053154751658439636), ((6, 9), 0.052861680587132774), ((2, 8), 0.05280309170484543), ((7, 8), 0.05181067809462547), ((2, 9), 0.05173052350680033), ((3, 6), 0.05163523554801941), ((3, 7), 0.051252126693725586), ((2, 3), 0.05074944347143173), ((3, 8), 0.05056919902563095), ((8, 9), 0.04993704458077749), ((1, 6), 0.045350849628448486), ((0, 6), 0.04274605214595795), ((0, 4), 0.04259410003821055), ((0, 5), 0.04202601810296377), ((1, 8), 0.0419052392244339), ((1, 5), 0.04187950988610586), ((1, 4), 0.040113975604375206), ((0, 7), 0.03966036687294642), ((0, 2), 0.03936202824115753), ((1, 2), 0.038274556398391724), ((1, 7), 0.038273448745409645), ((0, 8), 0.03723277896642685), ((0, 3), 0.036411695182323456), ((1, 3), 0.03575553745031357), ((0, 9), 0.034777399897575376), ((1, 9), 0.0337870180606842), ((0, 1), 0.032541655004024506), ((7, 10), 0.013239758710066477), ((9, 10), 0.012356451712548733), ((2, 10), 0.010588515549898148), ((4, 10), 0.009743872409065565), ((3, 10), 0.00880420207977295), ((6, 10), 0.007183882097403209), ((5, 10), 0.00715893196562926), ((0, 10), 0.005842569097876549), ((8, 10), 0.0051130518938104315), ((1, 10), 0.0044320404529571535)]
******* after merging (0.04): [((4, 5), 128), ((0,), 128), ((1,), 128), ((2,), 64), ((3,), 64), ((6,), 64), ((7,), 64), ((8,), 64), ((9,), 32), ((10,), 32)]
{'R_grad_norm': 1.1348643100261688, 'training_loss': 1.5139600157737731}
{'R_grad_norm': 1.1254197651147841, 'training_loss': 1.5146513044834138}
{'R_grad_norm': 1.1201105135679246, 'training_loss': 1.508907400369644}
{'R_grad_norm': 1.1220180255174637, 'training_loss': 1.508943510055542}
{'R_grad_norm': 1.1164320772886276, 'training_loss': 1.5168931359052658}
{'R_grad_norm': 1.110534737110138, 'training_loss': 1.5150607240200042}
{'R_grad_norm': 1.1068921154737472, 'training_loss': 1.5120324033498764}
{'R_grad_norm': 1.1057062017917634, 'training_loss': 1.5055667233467103}
{'R_grad_norm': 1.1040068703889847, 'training_loss': 1.5024894571304321}
{'R_grad_norm': 1.1011345428228378, 'training_loss': 1.5074832302331924}
{'R_grad_norm': 1.101102215051651, 'training_loss': 1.5126087087392808}
{'R_grad_norm': 1.09757565677166, 'training_loss': 1.505662772655487}
{'R_grad_norm': 1.095184301137924, 'training_loss': 1.5063376212120057}
{'R_grad_norm': 1.0944102609157562, 'training_loss': 1.5055420434474944}
{'R_grad_norm': 1.0908383017778396, 'training_loss': 1.5150541722774507}
{'R_grad_norm': 1.0951790595054627, 'training_loss': 1.5070858478546143}
{'R_grad_norm': 1.0938555020093919, 'training_loss': 1.5239158779382707}
{'R_grad_norm': 1.0842711558938027, 'training_loss': 1.4956532502174378}
{'R_grad_norm': 1.0860591009259224, 'training_loss': 1.5014504557847976}
{'R_grad_norm': 1.0900314062833787, 'training_loss': 1.5059283262491225}
{'R_grad_norm': 1.0843764275312424, 'training_loss': 1.5057720398902894}
{'R_grad_norm': 1.0825063860416413, 'training_loss': 1.502377707362175}
{'R_grad_norm': 1.0751014214754104, 'training_loss': 1.5051137018203735}
{'R_grad_norm': 1.0759676167368888, 'training_loss': 1.4903161329030992}
{'R_grad_norm': 1.0732326018810272, 'training_loss': 1.4861781358718873}
{'R_grad_norm': 1.0694521555304528, 'training_loss': 1.4994602066278457}
{'R_grad_norm': 1.0655468431115152, 'training_loss': 1.4922511208057403}
{'R_grad_norm': 1.0635435286164283, 'training_loss': 1.4932457560300827}
{'R_grad_norm': 1.0616529446840286, 'training_loss': 1.5013585925102233}
{'R_grad_norm': 1.0571938335895539, 'training_loss': 1.4896257680654525}
{'R_grad_norm': 1.0558749505877494, 'training_loss': 1.5011007815599442}
{'R_grad_norm': 1.0509986940026284, 'training_loss': 1.4932245707511902}
{'R_grad_norm': 1.049732781648636, 'training_loss': 1.5020561993122101}
{'R_grad_norm': 1.0460392388701438, 'training_loss': 1.495404336452484}
{'R_grad_norm': 1.0416530787944793, 'training_loss': 1.4998732751607895}
{'R_grad_norm': 1.03657608628273, 'training_loss': 1.4980312490463257}
{'R_grad_norm': 1.038253181874752, 'training_loss': 1.501003959774971}
{'R_grad_norm': 1.0335953560471536, 'training_loss': 1.5008649587631226}
{'R_grad_norm': 1.0232954344153404, 'training_loss': 1.4933406108617782}
{'R_grad_norm': 1.0191664439439774, 'training_loss': 1.4886333620548249}
eval result tensor([1.75326, 1.95958, 2.87419, 0.79642, 1.15308, 1.00734, 0.93905, 2.71677,
        0.73974, 1.00603], device='cuda:0')
computing merge metric
normed mi [((3, 6), 0.059919510036706924), ((5, 6), 0.05776141211390495), ((5, 7), 0.057277269661426544), ((3, 5), 0.05720685049891472), ((4, 8), 0.056224510073661804), ((6, 8), 0.05587712426980337), ((5, 8), 0.0555905153354009), ((3, 8), 0.0541367381811142), ((4, 5), 0.05257174372673035), ((4, 6), 0.05170479044318199), ((3, 7), 0.05139334872364998), ((3, 4), 0.05139031261205673), ((6, 7), 0.051056332886219025), ((7, 8), 0.050388882557551064), ((4, 7), 0.049523089081048965), ((2, 5), 0.04352885981400808), ((1, 5), 0.04336881637573242), ((2, 7), 0.042575900753339134), ((0, 5), 0.04256041347980499), ((1, 6), 0.04108601560195287), ((1, 3), 0.03995857387781143), ((0, 6), 0.03841245174407959), ((0, 3), 0.038129558165868126), ((0, 7), 0.03792291631301244), ((2, 6), 0.03789038956165314), ((2, 3), 0.03749669591585795), ((1, 4), 0.03657996157805125), ((1, 7), 0.03635823726654053), ((1, 8), 0.035911157727241516), ((0, 4), 0.035659621159235634), ((2, 4), 0.03519212702910105), ((0, 8), 0.03450317978858948), ((2, 8), 0.033280035853385924), ((0, 1), 0.03263961151242256), ((0, 2), 0.03187543898820877), ((1, 2), 0.031309548765420914), ((6, 9), 0.012860791136821112), ((8, 9), 0.012502508237957954), ((3, 9), 0.010736494014660517), ((4, 9), 0.00834272988140583), ((5, 9), 0.007479524239897728), ((1, 9), 0.005881114304065705), ((7, 9), 0.005035069150229295), ((0, 9), 0.004330189526081085), ((2, 9), 0.004012341052293778)]
******* after merging (0.04): [((3, 6), 128), ((0,), 128), ((1,), 128), ((2,), 128), ((4,), 64), ((5,), 64), ((7,), 64), ((8,), 32), ((9,), 32)]
{'R_grad_norm': 1.19624598801136, 'training_loss': 1.6187927716970443}
{'R_grad_norm': 1.175006098151207, 'training_loss': 1.6205483216047287}
{'R_grad_norm': 1.1728268319368362, 'training_loss': 1.6071586853265762}
{'R_grad_norm': 1.169294810295105, 'training_loss': 1.599015914797783}
{'R_grad_norm': 1.1673611634969712, 'training_loss': 1.6112172812223435}
{'R_grad_norm': 1.164045388698578, 'training_loss': 1.6225148671865464}
{'R_grad_norm': 1.1586330038309098, 'training_loss': 1.618249192237854}
{'R_grad_norm': 1.154811982512474, 'training_loss': 1.6218228369951249}
{'R_grad_norm': 1.1518851202726363, 'training_loss': 1.6103725242614746}
{'R_grad_norm': 1.1514961040019989, 'training_loss': 1.6246358841657638}
{'R_grad_norm': 1.1530239325761795, 'training_loss': 1.6288174927234649}
{'R_grad_norm': 1.1541729718446732, 'training_loss': 1.6332986986637115}
{'R_grad_norm': 1.1499408197402954, 'training_loss': 1.6410561513900757}
{'R_grad_norm': 1.1519347697496414, 'training_loss': 1.642101261615753}
{'R_grad_norm': 1.1548371362686156, 'training_loss': 1.658765280842781}
{'R_grad_norm': 1.1558768117427827, 'training_loss': 1.6698815202713013}
{'R_grad_norm': 1.150671164393425, 'training_loss': 1.666549218893051}
{'R_grad_norm': 1.1516146630048751, 'training_loss': 1.6704756498336792}
{'R_grad_norm': 1.150985164642334, 'training_loss': 1.6876288402080535}
{'R_grad_norm': 1.1594763064384461, 'training_loss': 1.7129843086004257}
{'R_grad_norm': 1.159033413529396, 'training_loss': 1.713302111029625}
{'R_grad_norm': 1.1597947800159454, 'training_loss': 1.7407886344194412}
{'R_grad_norm': 1.160854686498642, 'training_loss': 1.7638856106996537}
{'R_grad_norm': 1.1607418608665467, 'training_loss': 1.8155268836021423}
{'R_grad_norm': 1.1210311967134476, 'training_loss': 1.604768762588501}
{'R_grad_norm': 1.115582303404808, 'training_loss': 1.60668785572052}
{'R_grad_norm': 1.1177168947458267, 'training_loss': 1.605873612165451}
{'R_grad_norm': 1.1155616515874862, 'training_loss': 1.5905962127447129}
{'R_grad_norm': 1.1158397352695466, 'training_loss': 1.6017654967308044}
{'R_grad_norm': 1.1116087418794631, 'training_loss': 1.5993737453222274}
{'R_grad_norm': 1.1115453618764877, 'training_loss': 1.5992689257860184}
{'R_grad_norm': 1.1129155993461608, 'training_loss': 1.5874078983068467}
{'R_grad_norm': 1.111225214600563, 'training_loss': 1.5998494255542755}
{'R_grad_norm': 1.1111603128910064, 'training_loss': 1.6156106102466583}
{'R_grad_norm': 1.1078700184822083, 'training_loss': 1.5890578013658523}
{'R_grad_norm': 1.1054478973150252, 'training_loss': 1.5951400476694106}
{'R_grad_norm': 1.1058926504850388, 'training_loss': 1.6066674649715424}
{'R_grad_norm': 1.103632029891014, 'training_loss': 1.5946644455194474}
{'R_grad_norm': 1.1006036949157716, 'training_loss': 1.5940305751562118}
{'R_grad_norm': 1.1045293301343917, 'training_loss': 1.589577864408493}
finish training (100000)
evaluating (25 steps)...
 ******* eval result *******
mean (weighted) 1.8120039304097493
mean (unweighted) 1.6005327701568604
tensor([1.44422, 1.77762, 1.98176, 3.00396, 1.08805, 0.81154, 2.56101, 0.71308,
        1.02354], device='cuda:0')
