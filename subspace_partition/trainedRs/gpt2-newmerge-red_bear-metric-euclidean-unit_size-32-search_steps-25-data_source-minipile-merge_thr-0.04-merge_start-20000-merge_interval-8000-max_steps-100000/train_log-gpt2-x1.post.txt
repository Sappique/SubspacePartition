{'R_grad_norm': 0.7093528971076012, 'training_loss': 1.890427017211914}
{'R_grad_norm': 0.7298275524377823, 'training_loss': 1.6800788116455079}
{'R_grad_norm': 0.7347116842865944, 'training_loss': 1.6030629205703735}
{'R_grad_norm': 0.7343525660037994, 'training_loss': 1.5722633695602417}
{'R_grad_norm': 0.7345446297526359, 'training_loss': 1.523637773990631}
{'R_grad_norm': 0.7337887197732925, 'training_loss': 1.5121988582611083}
{'R_grad_norm': 0.7339791136980057, 'training_loss': 1.4931016927957534}
{'R_grad_norm': 0.7353117284178734, 'training_loss': 1.4798303765058518}
{'R_grad_norm': 0.7358185631036759, 'training_loss': 1.4689416235685349}
{'R_grad_norm': 0.7330012404918671, 'training_loss': 1.463757273554802}
{'R_grad_norm': 0.7333249968290328, 'training_loss': 1.443461337685585}
{'R_grad_norm': 0.7331878715753555, 'training_loss': 1.433464053273201}
{'R_grad_norm': 0.7317064818739891, 'training_loss': 1.4211694145202636}
{'R_grad_norm': 0.7322187897562981, 'training_loss': 1.4169065922498703}
{'R_grad_norm': 0.7328676447272301, 'training_loss': 1.4102892941236496}
{'R_grad_norm': 0.7313660290837288, 'training_loss': 1.4081154727935792}
{'R_grad_norm': 0.7298714265227317, 'training_loss': 1.4072025525569916}
{'R_grad_norm': 0.7283711194992065, 'training_loss': 1.38618643283844}
{'R_grad_norm': 0.7293335127830506, 'training_loss': 1.3892319810390472}
{'R_grad_norm': 0.7255137258768082, 'training_loss': 1.3802175211906433}
{'R_grad_norm': 0.7290430292487144, 'training_loss': 1.3794993937015534}
{'R_grad_norm': 0.7277364414930344, 'training_loss': 1.3784405082464217}
{'R_grad_norm': 0.7259261989593506, 'training_loss': 1.3801670801639556}
{'R_grad_norm': 0.7253613567352295, 'training_loss': 1.364910084605217}
{'R_grad_norm': 0.7257801485061646, 'training_loss': 1.3669818204641342}
{'R_grad_norm': 0.7273014423251152, 'training_loss': 1.3615438890457154}
{'R_grad_norm': 0.7246040803194046, 'training_loss': 1.3609787440299987}
{'R_grad_norm': 0.7229579830169678, 'training_loss': 1.3599954134225845}
{'R_grad_norm': 0.7233805879950523, 'training_loss': 1.3473091995716096}
{'R_grad_norm': 0.722177441418171, 'training_loss': 1.3477683794498443}
{'R_grad_norm': 0.7245758661627769, 'training_loss': 1.3468278223276138}
{'R_grad_norm': 0.7238282161951065, 'training_loss': 1.3531758254766464}
{'R_grad_norm': 0.721962853372097, 'training_loss': 1.3492032808065415}
{'R_grad_norm': 0.7215286263823509, 'training_loss': 1.3356896233558655}
{'R_grad_norm': 0.7207650557160378, 'training_loss': 1.3417439621686935}
{'R_grad_norm': 0.7203947624564171, 'training_loss': 1.3433312165737152}
{'R_grad_norm': 0.7190506505966187, 'training_loss': 1.3298442435264588}
{'R_grad_norm': 0.7170703878998756, 'training_loss': 1.3341275548934937}
{'R_grad_norm': 0.7182892143726349, 'training_loss': 1.3275412565469742}
{'R_grad_norm': 0.7165548515319824, 'training_loss': 1.3291656798124314}
{'R_grad_norm': 0.7177513214945793, 'training_loss': 1.3289695531129837}
{'R_grad_norm': 0.7176862639188767, 'training_loss': 1.325784062743187}
{'R_grad_norm': 0.7178705126047135, 'training_loss': 1.3331432628631592}
{'R_grad_norm': 0.7170906659960746, 'training_loss': 1.3201634061336518}
{'R_grad_norm': 0.7175617671012878, 'training_loss': 1.3240405011177063}
{'R_grad_norm': 0.7146986967325211, 'training_loss': 1.3120423299074173}
{'R_grad_norm': 0.7141922563314438, 'training_loss': 1.3049324822425843}
{'R_grad_norm': 0.7123177760839462, 'training_loss': 1.3078155618906022}
{'R_grad_norm': 0.7136544048786163, 'training_loss': 1.3087376880645751}
{'R_grad_norm': 0.7140347623825073, 'training_loss': 1.3078435909748078}
{'R_grad_norm': 0.7121675875782967, 'training_loss': 1.3106344801187515}
{'R_grad_norm': 0.7145812928676605, 'training_loss': 1.3118833965063095}
{'R_grad_norm': 0.7135222586989403, 'training_loss': 1.3121195584535599}
{'R_grad_norm': 0.7149773266911507, 'training_loss': 1.315762819647789}
{'R_grad_norm': 0.7146853005886078, 'training_loss': 1.3026960408687591}
{'R_grad_norm': 0.7118866458535195, 'training_loss': 1.2977529925107956}
{'R_grad_norm': 0.711745771765709, 'training_loss': 1.303825924396515}
{'R_grad_norm': 0.7087640243768693, 'training_loss': 1.2929879927635193}
{'R_grad_norm': 0.7118757483363152, 'training_loss': 1.3116296619176864}
{'R_grad_norm': 0.7137325525283813, 'training_loss': 1.308524363040924}
{'R_grad_norm': 0.7083482873439789, 'training_loss': 1.296408639550209}
{'R_grad_norm': 0.709568367600441, 'training_loss': 1.295673434138298}
{'R_grad_norm': 0.7126708117127418, 'training_loss': 1.300397573709488}
{'R_grad_norm': 0.7078382366895676, 'training_loss': 1.2878501284122468}
{'R_grad_norm': 0.7126093843579292, 'training_loss': 1.292094625234604}
{'R_grad_norm': 0.7096743357181549, 'training_loss': 1.2982647556066513}
{'R_grad_norm': 0.7076822277903557, 'training_loss': 1.282763022184372}
{'R_grad_norm': 0.7117090350389481, 'training_loss': 1.290460342168808}
{'R_grad_norm': 0.7076853859424591, 'training_loss': 1.2902719968557357}
{'R_grad_norm': 0.7078046572208404, 'training_loss': 1.295691539645195}
{'R_grad_norm': 0.7081550773978234, 'training_loss': 1.2881230354309081}
{'R_grad_norm': 0.710221735239029, 'training_loss': 1.2962739354372024}
{'R_grad_norm': 0.7062463653087616, 'training_loss': 1.2900995260477066}
{'R_grad_norm': 0.7081052732467651, 'training_loss': 1.294335213303566}
{'R_grad_norm': 0.7089325466752052, 'training_loss': 1.2905614644289016}
{'R_grad_norm': 0.7058149680495263, 'training_loss': 1.2755672091245651}
{'R_grad_norm': 0.7068736201524735, 'training_loss': 1.2893795692920684}
{'R_grad_norm': 0.7066753250360489, 'training_loss': 1.2853808480501174}
{'R_grad_norm': 0.7073678070306778, 'training_loss': 1.2911327069997787}
{'R_grad_norm': 0.70804658472538, 'training_loss': 1.2855814385414124}
{'R_grad_norm': 0.7081928050518036, 'training_loss': 1.2919504374265671}
{'R_grad_norm': 0.7055241513252258, 'training_loss': 1.2824735939502716}
{'R_grad_norm': 0.706251817047596, 'training_loss': 1.2849739122390746}
{'R_grad_norm': 0.704896157681942, 'training_loss': 1.274433821439743}
{'R_grad_norm': 0.704010880291462, 'training_loss': 1.2862489521503448}
{'R_grad_norm': 0.7051792258024215, 'training_loss': 1.283149597644806}
{'R_grad_norm': 0.7027813023328782, 'training_loss': 1.2764850276708604}
{'R_grad_norm': 0.7061674010753631, 'training_loss': 1.282784376144409}
{'R_grad_norm': 0.7040746435523033, 'training_loss': 1.2746584010124207}
{'R_grad_norm': 0.7069416388869285, 'training_loss': 1.2875720846652985}
{'R_grad_norm': 0.7041870766878128, 'training_loss': 1.273242553472519}
{'R_grad_norm': 0.7046841695904732, 'training_loss': 1.278198927640915}
{'R_grad_norm': 0.70386339366436, 'training_loss': 1.2851582372188568}
{'R_grad_norm': 0.7017617136240005, 'training_loss': 1.2754783993959427}
{'R_grad_norm': 0.7024308627843857, 'training_loss': 1.2731280720233917}
{'R_grad_norm': 0.7052595189213753, 'training_loss': 1.283336102962494}
{'R_grad_norm': 0.7029358381032944, 'training_loss': 1.2764663445949553}
{'R_grad_norm': 0.7014902639389038, 'training_loss': 1.2676384073495865}
{'R_grad_norm': 0.7039447042346001, 'training_loss': 1.2772141021490098}
{'R_grad_norm': 0.7024671646952629, 'training_loss': 1.2805776238441466}
eval result tensor([1.56502, 1.37699, 1.48069, 1.20161, 1.50233, 1.24206, 1.01401, 1.33523,
        0.82000, 1.26020, 1.09351, 1.14229, 1.46141, 0.96503, 0.94449, 1.49279,
        1.18833, 1.36345, 1.21348, 1.77758, 1.39868, 1.32799, 1.50705, 0.95772],
       device='cuda:0')
computing merge metric
normed mi [((6, 23), 0.1357620656490326), ((6, 14), 0.13575156033039093), ((6, 10), 0.13567334413528442), ((14, 23), 0.13560712337493896), ((10, 14), 0.13486555218696594), ((10, 23), 0.1346263438463211), ((6, 11), 0.13273583352565765), ((11, 14), 0.13205420970916748), ((11, 23), 0.13196471333503723), ((10, 11), 0.13169577717781067), ((3, 14), 0.13105256855487823), ((3, 23), 0.1306702345609665), ((3, 6), 0.13056835532188416), ((9, 14), 0.1304604858160019), ((6, 9), 0.13041120767593384), ((3, 10), 0.13037891685962677), ((9, 23), 0.13012568652629852), ((9, 10), 0.12958815693855286), ((16, 23), 0.12953068315982819), ((14, 16), 0.12931352853775024), ((1, 5), 0.1292031854391098), ((3, 5), 0.12918633222579956), ((5, 23), 0.1291777342557907), ((5, 14), 0.12913961708545685), ((1, 23), 0.129095196723938), ((1, 16), 0.12905147671699524), ((6, 16), 0.12903910875320435), ((10, 16), 0.1290193349123001), ((5, 10), 0.12897109985351562), ((5, 6), 0.12875130772590637), ((1, 14), 0.12860627472400665), ((1, 10), 0.12845845520496368), ((5, 16), 0.12843959033489227), ((0, 1), 0.12809030711650848), ((5, 20), 0.12805140018463135), ((5, 9), 0.1280229687690735), ((3, 16), 0.12788984179496765), ((3, 9), 0.12786918878555298), ((9, 16), 0.12786884605884552), ((16, 20), 0.12779924273490906), ((1, 6), 0.12776227295398712), ((1, 3), 0.1277436763048172), ((1, 20), 0.12763094902038574), ((14, 20), 0.12749329209327698), ((3, 11), 0.12746842205524445), ((3, 20), 0.12745614349842072), ((20, 23), 0.12725773453712463), ((9, 11), 0.12722907960414886), ((1, 4), 0.12713199853897095), ((9, 20), 0.1269252598285675), ((1, 9), 0.12680602073669434), ((0, 22), 0.12643851339817047), ((10, 20), 0.12643663585186005), ((1, 21), 0.12639394402503967), ((1, 11), 0.12634706497192383), ((20, 21), 0.12623360753059387), ((11, 16), 0.12621895968914032), ((6, 20), 0.1261492371559143), ((5, 11), 0.1261117160320282), ((0, 4), 0.12543238699436188), ((0, 5), 0.12473965436220169), ((1, 22), 0.12464820593595505), ((4, 21), 0.1244221180677414), ((0, 16), 0.12436767667531967), ((0, 21), 0.12413554638624191), ((5, 21), 0.12399771064519882), ((8, 14), 0.12395685166120529), ((16, 21), 0.12379191070795059), ((8, 23), 0.12373337149620056), ((6, 8), 0.12368860840797424), ((0, 20), 0.12352075427770615), ((11, 20), 0.12339197844266891), ((4, 20), 0.12304701656103134), ((0, 3), 0.12286336719989777), ((8, 10), 0.12254995107650757), ((4, 16), 0.12247151881456375), ((9, 21), 0.12245509028434753), ((4, 5), 0.1224164143204689), ((18, 20), 0.12239351123571396), ((5, 18), 0.12234017997980118), ((16, 22), 0.12230994552373886), ((21, 22), 0.12203349173069), ((20, 22), 0.12200727313756943), ((3, 21), 0.1219659224152565), ((5, 22), 0.12195717543363571), ((4, 22), 0.12194153666496277), ((14, 21), 0.12178973853588104), ((21, 23), 0.12169363349676132), ((0, 23), 0.12158152461051941), ((0, 10), 0.12148046493530273), ((1, 18), 0.12141288816928864), ((0, 9), 0.12136619538068771), ((9, 22), 0.12128739058971405), ((10, 21), 0.12120329588651657), ((0, 14), 0.12119371443986893), ((16, 18), 0.12086515873670578), ((8, 9), 0.12072534114122391), ((9, 18), 0.12043095380067825), ((3, 4), 0.12040466070175171), ((3, 18), 0.12038866430521011), ((0, 6), 0.12038572132587433), ((7, 14), 0.12033560127019882), ((7, 23), 0.12024802714586258), ((6, 21), 0.12023164331912994), ((4, 23), 0.12018895894289017), ((18, 21), 0.11998037248849869), ((8, 11), 0.11991880089044571), ((4, 14), 0.11987863481044769), ((0, 18), 0.11981851607561111), ((0, 11), 0.11981350928544998), ((7, 10), 0.11972908675670624), ((1, 7), 0.11970482766628265), ((4, 9), 0.11970043927431107), ((4, 10), 0.11968980729579926), ((6, 7), 0.11960583180189133), ((7, 9), 0.11960557848215103), ((3, 22), 0.11956703662872314), ((18, 22), 0.11950048059225082), ((7, 16), 0.11927905678749084), ((5, 7), 0.1190236359834671), ((8, 16), 0.11902051419019699), ((3, 8), 0.11896611750125885), ((11, 21), 0.11881688982248306), ((3, 7), 0.11871001124382019), ((4, 6), 0.11866088956594467), ((22, 23), 0.11865789443254471), ((14, 22), 0.11854007095098495), ((10, 22), 0.11853709816932678), ((4, 11), 0.11797959357500076), ((14, 18), 0.117958664894104), ((7, 20), 0.11786611378192902), ((7, 11), 0.11786480993032455), ((5, 8), 0.11780340224504471), ((18, 23), 0.11774762719869614), ((10, 18), 0.11731769144535065), ((6, 22), 0.1173168271780014), ((11, 22), 0.11729353666305542), ((4, 18), 0.11722441762685776), ((8, 20), 0.11678840219974518), ((1, 8), 0.11673203855752945), ((6, 18), 0.11662273108959198), ((7, 22), 0.11638008803129196), ((7, 21), 0.1161646693944931), ((11, 18), 0.11598189175128937), ((0, 7), 0.11536920070648193), ((7, 18), 0.11370151489973068), ((4, 7), 0.11286719888448715), ((7, 8), 0.11196078360080719), ((8, 21), 0.11125528067350388), ((8, 18), 0.1098412573337555), ((0, 8), 0.10928366333246231), ((8, 22), 0.10918675363063812), ((6, 13), 0.10698959976434708), ((4, 8), 0.10669075697660446), ((13, 14), 0.10600632429122925), ((13, 23), 0.10573980212211609), ((10, 13), 0.10531654953956604), ((11, 13), 0.1036553904414177), ((9, 13), 0.10340411961078644), ((1, 17), 0.102765291929245), ((17, 22), 0.10239091515541077), ((0, 17), 0.10229893773794174), ((9, 12), 0.10210350155830383), ((8, 13), 0.1018010601401329), ((17, 21), 0.1015724241733551), ((12, 14), 0.10151425749063492), ((12, 23), 0.10136864334344864), ((7, 12), 0.10102413594722748), ((5, 17), 0.10087461024522781), ((6, 12), 0.10071472823619843), ((12, 16), 0.10070164501667023), ((10, 12), 0.10061901062726974), ((4, 17), 0.10056541115045547), ((16, 17), 0.10038811713457108), ((3, 13), 0.10031622648239136), ((17, 20), 0.10017014294862747), ((17, 18), 0.10016081482172012), ((13, 16), 0.09975556284189224), ((5, 12), 0.09971202909946442), ((9, 17), 0.09965915232896805), ((11, 12), 0.09943161904811859), ((3, 12), 0.0987607091665268), ((1, 12), 0.09871334582567215), ((3, 17), 0.098577581346035), ((12, 20), 0.09801419824361801), ((5, 13), 0.09770079702138901), ((12, 22), 0.0973140150308609), ((13, 20), 0.09703254699707031), ((14, 17), 0.09697478264570236), ((11, 17), 0.09696473181247711), ((10, 17), 0.09688597172498703), ((17, 23), 0.0968719869852066), ((6, 17), 0.0961846336722374), ((8, 12), 0.09614896774291992), ((7, 17), 0.09612581133842468), ((1, 13), 0.09603296965360641), ((0, 12), 0.09590604901313782), ((7, 13), 0.09527209401130676), ((12, 21), 0.09511855244636536), ((12, 18), 0.09292368590831757), ((4, 12), 0.09223351627588272), ((13, 21), 0.09157498925924301), ((13, 18), 0.09093517810106277), ((8, 17), 0.09082270413637161), ((13, 22), 0.09057818353176117), ((0, 13), 0.0896853432059288), ((4, 13), 0.08798453956842422), ((12, 13), 0.08640885353088379), ((12, 17), 0.08574352413415909), ((18, 19), 0.08246656507253647), ((19, 22), 0.08172556757926941), ((0, 19), 0.07903879135847092), ((19, 21), 0.07765943557024002), ((13, 17), 0.07752977311611176), ((16, 19), 0.0769684761762619), ((19, 20), 0.07685688138008118), ((9, 19), 0.07656774669885635), ((5, 19), 0.07554700970649719), ((1, 19), 0.07522688060998917), ((4, 19), 0.07421164214611053), ((7, 19), 0.07326781004667282), ((3, 19), 0.07326342165470123), ((11, 19), 0.07211686670780182), ((10, 19), 0.07136622071266174), ((19, 23), 0.07122486084699631), ((14, 19), 0.0709678903222084), ((6, 19), 0.07042168825864792), ((17, 19), 0.06699489802122116), ((12, 19), 0.06663481891155243), ((8, 19), 0.06632734835147858), ((13, 19), 0.05652341619133949), ((2, 15), 0.05093493312597275), ((6, 15), 0.021953584626317024), ((14, 15), 0.02119430899620056), ((15, 23), 0.020627329126000404), ((10, 15), 0.020601505413651466), ((11, 15), 0.019978117197752), ((2, 6), 0.019304795190691948), ((2, 14), 0.01890658773481846), ((2, 11), 0.018738798797130585), ((2, 23), 0.01868261583149433), ((2, 10), 0.018456339836120605), ((2, 8), 0.01844516582787037), ((2, 13), 0.018370268866419792), ((13, 15), 0.018305189907550812), ((8, 15), 0.018270326778292656), ((9, 15), 0.01729576475918293), ((3, 15), 0.016738058999180794), ((15, 16), 0.016300013288855553), ((2, 9), 0.01613280549645424), ((2, 16), 0.015883903950452805), ((2, 3), 0.015578381717205048), ((2, 5), 0.015397406183183193), ((5, 15), 0.015167600475251675), ((2, 12), 0.014756368473172188), ((1, 2), 0.014652730897068977), ((2, 20), 0.014582311734557152), ((15, 20), 0.014493324793875217), ((1, 15), 0.014248190447688103), ((2, 17), 0.014064393937587738), ((2, 21), 0.013536330312490463), ((2, 7), 0.013384824618697166), ((2, 4), 0.013202079571783543), ((7, 15), 0.012734095565974712), ((12, 15), 0.012514418922364712), ((15, 21), 0.012473906390368938), ((2, 22), 0.012117833830416203), ((2, 18), 0.012079439125955105), ((0, 2), 0.011834193952381611), ((4, 15), 0.011447591707110405), ((15, 22), 0.011089290492236614), ((0, 15), 0.01055111549794674), ((15, 18), 0.00949777290225029), ((2, 19), 0.008321987465023994), ((15, 17), 0.008257643319666386), ((15, 19), 0.004963892512023449)]
******* after merging (0.04): [((6, 23), 64), ((10, 14), 64), ((1, 5), 64), ((0,), 32), ((2,), 32), ((3,), 32), ((4,), 32), ((7,), 32), ((8,), 32), ((9,), 32), ((11,), 32), ((12,), 32), ((13,), 32), ((15,), 32), ((16,), 32), ((17,), 32), ((18,), 32), ((19,), 32), ((20,), 32), ((21,), 32), ((22,), 32)]
{'R_grad_norm': 0.8380518993735313, 'training_loss': 1.384505781531334}
{'R_grad_norm': 0.8312485867738724, 'training_loss': 1.388384416103363}
{'R_grad_norm': 0.8274481305480004, 'training_loss': 1.373969966173172}
{'R_grad_norm': 0.8273400819301605, 'training_loss': 1.3784454250335694}
{'R_grad_norm': 0.8291596475243569, 'training_loss': 1.372417721748352}
{'R_grad_norm': 0.8275375533103942, 'training_loss': 1.3742114824056626}
{'R_grad_norm': 0.8228742092847824, 'training_loss': 1.3695305013656616}
{'R_grad_norm': 0.8244624871015549, 'training_loss': 1.3812778043746947}
{'R_grad_norm': 0.8258058789372444, 'training_loss': 1.3762295365333557}
{'R_grad_norm': 0.8263497799634933, 'training_loss': 1.3726852959394455}
{'R_grad_norm': 0.8287459769845009, 'training_loss': 1.37513549387455}
{'R_grad_norm': 0.8238967400789261, 'training_loss': 1.3686455756425857}
{'R_grad_norm': 0.8255849531292916, 'training_loss': 1.3559391617774963}
{'R_grad_norm': 0.8232951390743256, 'training_loss': 1.3606832885742188}
{'R_grad_norm': 0.8255925425887107, 'training_loss': 1.3635328483581544}
{'R_grad_norm': 0.8205058673024177, 'training_loss': 1.3578960251808168}
{'R_grad_norm': 0.8249366629123688, 'training_loss': 1.3626134538650512}
{'R_grad_norm': 0.8217108997702599, 'training_loss': 1.3684200984239578}
{'R_grad_norm': 0.8247894936800003, 'training_loss': 1.3662109833955765}
{'R_grad_norm': 0.8248320516943931, 'training_loss': 1.3666420239210129}
{'R_grad_norm': 0.8196526658535004, 'training_loss': 1.3599957793951034}
{'R_grad_norm': 0.8205703374743462, 'training_loss': 1.356674880385399}
{'R_grad_norm': 0.8199788549542427, 'training_loss': 1.3585258787870407}
{'R_grad_norm': 0.8194373121857643, 'training_loss': 1.3601157033443452}
{'R_grad_norm': 0.8186357605457306, 'training_loss': 1.356493847966194}
{'R_grad_norm': 0.8171878257393836, 'training_loss': 1.3525790393352508}
{'R_grad_norm': 0.8167689251899719, 'training_loss': 1.3469115936756133}
{'R_grad_norm': 0.8189988875389099, 'training_loss': 1.349457032084465}
{'R_grad_norm': 0.8162844654917717, 'training_loss': 1.3501197808980943}
{'R_grad_norm': 0.8168881976604462, 'training_loss': 1.3566000473499298}
{'R_grad_norm': 0.8195719346404076, 'training_loss': 1.355024010539055}
{'R_grad_norm': 0.8174922731518746, 'training_loss': 1.35906232714653}
{'R_grad_norm': 0.8156275770068169, 'training_loss': 1.3497906690835952}
{'R_grad_norm': 0.8149415215849877, 'training_loss': 1.3531527626514435}
{'R_grad_norm': 0.8148672524094581, 'training_loss': 1.349369728565216}
{'R_grad_norm': 0.8149309965968132, 'training_loss': 1.3447018724679947}
{'R_grad_norm': 0.8138838821649551, 'training_loss': 1.3356565982103348}
{'R_grad_norm': 0.8136743506789208, 'training_loss': 1.3477730447053908}
{'R_grad_norm': 0.8123240458965302, 'training_loss': 1.348495259284973}
{'R_grad_norm': 0.8103243327140808, 'training_loss': 1.3389473527669906}
eval result tensor([1.78396, 1.85929, 2.46220, 1.38164, 1.40995, 1.05208, 1.44350, 1.16408,
        0.78882, 1.08031, 1.00679, 1.39128, 0.91632, 1.50748, 1.00316, 1.29028,
        1.06386, 1.87817, 1.22328, 1.18315, 1.36628], device='cuda:0')
computing merge metric
normed mi [((9, 14), 0.12782692909240723), ((5, 14), 0.12708483636379242), ((9, 10), 0.12696470320224762), ((10, 14), 0.12676337361335754), ((5, 18), 0.1266956627368927), ((14, 18), 0.1258305460214615), ((5, 10), 0.12576641142368317), ((5, 9), 0.12526662647724152), ((9, 18), 0.12426434457302094), ((18, 19), 0.12420240789651871), ((8, 9), 0.12410484254360199), ((16, 18), 0.12362289428710938), ((14, 19), 0.1226520985364914), ((3, 5), 0.12262821942567825), ((3, 20), 0.12244894355535507), ((8, 10), 0.12243778258562088), ((8, 14), 0.12242461740970612), ((5, 16), 0.12228606641292572), ((3, 14), 0.12218085676431656), ((10, 18), 0.12216007709503174), ((14, 16), 0.12201350927352905), ((3, 19), 0.12191653996706009), ((3, 18), 0.12176907062530518), ((5, 19), 0.12070439755916595), ((9, 16), 0.12066911160945892), ((3, 6), 0.120411716401577), ((9, 19), 0.12017060071229935), ((6, 19), 0.12014070153236389), ((16, 19), 0.11964885145425797), ((19, 20), 0.11926781386137009), ((14, 20), 0.11906035989522934), ((5, 8), 0.1190369576215744), ((3, 10), 0.1189386174082756), ((18, 20), 0.1185809001326561), ((3, 16), 0.11850164085626602), ((7, 9), 0.11821267753839493), ((16, 20), 0.11812697350978851), ((10, 19), 0.1180894747376442), ((3, 9), 0.11808618903160095), ((10, 16), 0.1178537905216217), ((8, 18), 0.1177472472190857), ((7, 14), 0.1176760345697403), ((9, 20), 0.11748860031366348), ((6, 18), 0.11718200147151947), ((5, 20), 0.1168995350599289), ((7, 10), 0.11686926335096359), ((6, 20), 0.11663081496953964), ((6, 14), 0.11617035418748856), ((8, 16), 0.11583390086889267), ((5, 6), 0.11561625450849533), ((7, 8), 0.11547492444515228), ((5, 7), 0.11512500792741776), ((10, 20), 0.11468664556741714), ((7, 18), 0.11390441656112671), ((6, 16), 0.11316967755556107), ((7, 16), 0.11315831542015076), ((8, 19), 0.1130053773522377), ((6, 9), 0.11283743381500244), ((6, 10), 0.11270663142204285), ((7, 20), 0.11151501536369324), ((7, 19), 0.11141382157802582), ((3, 8), 0.11060485243797302), ((3, 7), 0.11047939211130142), ((8, 20), 0.11017303913831711), ((6, 8), 0.10401914268732071), ((6, 7), 0.10334046930074692), ((9, 12), 0.10164353251457214), ((8, 12), 0.10079223662614822), ((9, 11), 0.10023438185453415), ((7, 11), 0.09985191375017166), ((11, 14), 0.0994056835770607), ((10, 12), 0.0993277058005333), ((10, 11), 0.09756743907928467), ((8, 11), 0.09716211259365082), ((15, 20), 0.09651657938957214), ((3, 15), 0.09643995016813278), ((12, 14), 0.09621243923902512), ((15, 19), 0.09611006826162338), ((15, 16), 0.095789335668087), ((5, 11), 0.09547033905982971), ((11, 18), 0.09503833204507828), ((15, 18), 0.09486210346221924), ((14, 15), 0.09475307166576385), ((9, 15), 0.09384114295244217), ((5, 15), 0.0938277319073677), ((7, 12), 0.09373513609170914), ((11, 20), 0.09369061142206192), ((11, 16), 0.09362541884183884), ((6, 15), 0.09333696961402893), ((5, 12), 0.09317619353532791), ((11, 19), 0.0930422842502594), ((3, 11), 0.0927044153213501), ((10, 15), 0.09239236265420914), ((12, 18), 0.09091368317604065), ((0, 14), 0.09068415562311809), ((1, 14), 0.09045350551605225), ((0, 10), 0.0903486708799998), ((8, 15), 0.09031269699335098), ((12, 16), 0.08992863446474075), ((1, 10), 0.08981961011886597), ((7, 15), 0.08969230204820633), ((0, 5), 0.08963032563527425), ((1, 5), 0.08962868650754292), ((0, 9), 0.08920914928118388), ((1, 9), 0.0886223812898), ((2, 3), 0.08823558688163757), ((1, 18), 0.0874138077100118), ((0, 18), 0.08737486600875854), ((2, 18), 0.0870817502339681), ((6, 11), 0.08651905506849289), ((12, 19), 0.08637929707765579), ((2, 5), 0.08633294701576233), ((2, 19), 0.08625055352846782), ((2, 14), 0.0861100157101949), ((2, 6), 0.08539558450380962), ((0, 8), 0.08537741502126057), ((1, 3), 0.08523906270662944), ((2, 16), 0.0849373737970988), ((0, 3), 0.08486531178156535), ((12, 20), 0.08478321135044098), ((1, 8), 0.08475679159164429), ((2, 20), 0.08468520641326904), ((1, 19), 0.08458716670672099), ((0, 19), 0.08443259199460347), ((3, 12), 0.08433014899492264), ((1, 16), 0.0834822158018748), ((0, 16), 0.08304215470949809), ((2, 9), 0.08291906615098317), ((2, 10), 0.08271111051241557), ((11, 12), 0.08236545324325562), ((0, 7), 0.08202310403188069), ((1, 7), 0.08200865983963013), ((11, 15), 0.08154910057783127), ((1, 20), 0.08148703475793202), ((0, 20), 0.08089271187782288), ((1, 6), 0.08025874197483063), ((0, 6), 0.07959298292795818), ((6, 12), 0.07843826711177826), ((2, 7), 0.07726222276687622), ((2, 8), 0.07687090337276459), ((17, 20), 0.07431057840585709), ((0, 1), 0.07340226322412491), ((16, 17), 0.07211852073669434), ((12, 15), 0.07185248285531998), ((3, 17), 0.07129453122615814), ((17, 19), 0.06957820057868958), ((1, 11), 0.06934001048405965), ((0, 11), 0.06914795935153961), ((17, 18), 0.06865634024143219), ((2, 15), 0.06804539263248444), ((14, 17), 0.0677349865436554), ((0, 12), 0.06749455630779266), ((6, 17), 0.06733714789152145), ((1, 2), 0.06725543737411499), ((1, 12), 0.06719436248143514), ((9, 17), 0.06671886146068573), ((0, 2), 0.0663745328783989), ((5, 17), 0.06635908782482147), ((2, 11), 0.065044105052948), ((10, 17), 0.06415746361017227), ((1, 15), 0.06383406619230907), ((7, 17), 0.06335017085075378), ((0, 15), 0.06320742766062419), ((8, 17), 0.059902042150497437), ((15, 17), 0.05981413647532463), ((11, 17), 0.05945027247071266), ((2, 12), 0.05895857512950897), ((12, 17), 0.0490749217569828), ((2, 17), 0.0483086903889974), ((4, 13), 0.04741847515106201), ((1, 17), 0.043675512075424194), ((0, 17), 0.04315810898939768), ((4, 10), 0.017558516934514046), ((10, 13), 0.017381828278303146), ((4, 8), 0.017309600487351418), ((8, 13), 0.01677418127655983), ((4, 12), 0.016766928136348724), ((12, 13), 0.01645391248166561), ((9, 13), 0.016337161883711815), ((4, 9), 0.015284028835594654), ((4, 14), 0.014820747077465057), ((13, 14), 0.014551716856658459), ((4, 11), 0.014342338778078556), ((4, 5), 0.013804513029754162), ((5, 13), 0.013350648805499077), ((4, 18), 0.013339174911379814), ((4, 15), 0.012864291667938232), ((4, 7), 0.012739766389131546), ((13, 18), 0.012198337353765965), ((4, 19), 0.01198806893080473), ((7, 13), 0.011974574066698551), ((0, 13), 0.011587508022785187), ((4, 16), 0.011543053202331066), ((1, 13), 0.011328047762314478), ((1, 4), 0.011238242189089457), ((0, 4), 0.011100462327400843), ((11, 13), 0.010933107696473598), ((4, 6), 0.010842949151992798), ((13, 19), 0.010378059931099415), ((4, 20), 0.01030655950307846), ((13, 16), 0.01010824739933014), ((3, 4), 0.010078870691359043), ((13, 20), 0.0089190062135458), ((3, 13), 0.008652016520500183), ((6, 13), 0.00864632148295641), ((2, 4), 0.008049520974357923), ((13, 15), 0.007153633516281843), ((4, 17), 0.006960500497370958), ((2, 13), 0.006897670527299245), ((13, 17), 0.004241861868649721)]
******* after merging (0.04): [((9, 14), 64), ((5, 18), 64), ((0,), 64), ((1,), 64), ((2,), 64), ((3,), 32), ((4,), 32), ((6,), 32), ((7,), 32), ((8,), 32), ((10,), 32), ((11,), 32), ((12,), 32), ((13,), 32), ((15,), 32), ((16,), 32), ((17,), 32), ((19,), 32), ((20,), 32)]
{'R_grad_norm': 0.888774217069149, 'training_loss': 1.432635349035263}
{'R_grad_norm': 0.8848560282588005, 'training_loss': 1.441796755194664}
{'R_grad_norm': 0.883450608253479, 'training_loss': 1.4442478048801421}
{'R_grad_norm': 0.8831589722633362, 'training_loss': 1.4351739013195037}
{'R_grad_norm': 0.8772915241122246, 'training_loss': 1.4330420088768006}
{'R_grad_norm': 0.8788074442744255, 'training_loss': 1.428042347431183}
{'R_grad_norm': 0.8769826555252075, 'training_loss': 1.4241725450754166}
{'R_grad_norm': 0.8757335877418518, 'training_loss': 1.4285154354572296}
{'R_grad_norm': 0.8775568115711212, 'training_loss': 1.4306807398796082}
{'R_grad_norm': 0.8820847749710083, 'training_loss': 1.4460695779323578}
{'R_grad_norm': 0.8828981274366379, 'training_loss': 1.4422338658571243}
{'R_grad_norm': 0.8841474217176437, 'training_loss': 1.4513407856225968}
{'R_grad_norm': 0.8874590504169464, 'training_loss': 1.4611821115016936}
{'R_grad_norm': 0.8868485206365585, 'training_loss': 1.4633497452735902}
{'R_grad_norm': 0.8920060554146767, 'training_loss': 1.475938350558281}
{'R_grad_norm': 0.889184210896492, 'training_loss': 1.4738289445638657}
{'R_grad_norm': 0.8934290647506714, 'training_loss': 1.4880229949951171}
{'R_grad_norm': 0.8938548156619072, 'training_loss': 1.4901811707019805}
{'R_grad_norm': 0.9007418489456177, 'training_loss': 1.5100412142276765}
{'R_grad_norm': 0.8998406374454498, 'training_loss': 1.5332365626096724}
{'R_grad_norm': 0.9057861667871475, 'training_loss': 1.5392113202810287}
{'R_grad_norm': 0.9106019416451454, 'training_loss': 1.561629343032837}
{'R_grad_norm': 0.8820375171303749, 'training_loss': 1.4653711903095246}
{'R_grad_norm': 0.8636911627650261, 'training_loss': 1.3942778956890107}
{'R_grad_norm': 0.8635373085737228, 'training_loss': 1.4019449174404144}
{'R_grad_norm': 0.8641654643416404, 'training_loss': 1.39481299161911}
{'R_grad_norm': 0.8647612637281418, 'training_loss': 1.389309480190277}
{'R_grad_norm': 0.8603141212463379, 'training_loss': 1.4006430059671402}
{'R_grad_norm': 0.8673271209001541, 'training_loss': 1.3998013472557067}
{'R_grad_norm': 0.8634816190600395, 'training_loss': 1.402589702606201}
{'R_grad_norm': 0.8630275204777718, 'training_loss': 1.3935450714826585}
{'R_grad_norm': 0.864721671640873, 'training_loss': 1.402115779519081}
{'R_grad_norm': 0.8626858630776405, 'training_loss': 1.392647272348404}
{'R_grad_norm': 0.8632856622338295, 'training_loss': 1.403599928021431}
{'R_grad_norm': 0.8619472005963326, 'training_loss': 1.3939990615844726}
{'R_grad_norm': 0.8668472400307655, 'training_loss': 1.4015953838825226}
{'R_grad_norm': 0.8600436082482338, 'training_loss': 1.3976275062561034}
{'R_grad_norm': 0.859089457988739, 'training_loss': 1.3838222086429597}
{'R_grad_norm': 0.8610553067922592, 'training_loss': 1.3927794194221497}
{'R_grad_norm': 0.8599349594116211, 'training_loss': 1.3920686769485473}
eval result tensor([1.70053, 1.88008, 1.78178, 1.85610, 2.56597, 1.14030, 1.37147, 1.35157,
        1.07066, 0.76496, 0.90480, 1.35769, 0.88987, 1.47806, 1.24644, 0.96957,
        1.91851, 1.02838, 1.25334], device='cuda:0')
computing merge metric
normed mi [((9, 10), 0.12441731244325638), ((5, 17), 0.1229543685913086), ((10, 15), 0.12216874957084656), ((10, 17), 0.12198810279369354), ((5, 10), 0.1219770535826683), ((15, 17), 0.12087022513151169), ((9, 15), 0.12053816765546799), ((5, 18), 0.12047955393791199), ((17, 18), 0.11889977008104324), ((5, 15), 0.1187049075961113), ((7, 17), 0.1183178648352623), ((5, 7), 0.11762364953756332), ((8, 9), 0.11707112938165665), ((15, 18), 0.11689366400241852), ((9, 17), 0.11684068292379379), ((8, 10), 0.11631397157907486), ((10, 18), 0.11535374075174332), ((5, 9), 0.1148691326379776), ((7, 18), 0.11388688534498215), ((8, 15), 0.1137709841132164), ((7, 10), 0.11200674623250961), ((9, 18), 0.11181509494781494), ((8, 17), 0.11028507351875305), ((7, 15), 0.11020834743976593), ((5, 8), 0.10949962586164474), ((8, 18), 0.1080961525440216), ((7, 9), 0.10441473871469498), ((9, 12), 0.10118992626667023), ((8, 11), 0.09989994019269943), ((10, 12), 0.09869816899299622), ((7, 8), 0.09820786863565445), ((10, 11), 0.09741653501987457), ((9, 11), 0.09707143902778625), ((8, 12), 0.0958179384469986), ((11, 15), 0.09506269544363022), ((5, 14), 0.09481116384267807), ((14, 18), 0.0941377803683281), ((14, 17), 0.09396492689847946), ((12, 15), 0.0938262939453125), ((5, 11), 0.09375055879354477), ((11, 18), 0.09315117448568344), ((11, 17), 0.09275120496749878), ((14, 15), 0.09211369603872299), ((10, 14), 0.09133405238389969), ((2, 10), 0.09113648533821106), ((7, 14), 0.09100895375013351), ((3, 10), 0.09063487251599629), ((12, 17), 0.08803554624319077), ((9, 14), 0.08792407065629959), ((4, 5), 0.08775996168454488), ((0, 10), 0.08752552668253581), ((2, 9), 0.08674159646034241), ((5, 12), 0.08661777526140213), ((0, 17), 0.08641615509986877), ((0, 15), 0.08612221479415894), ((4, 17), 0.08611645301183064), ((3, 9), 0.08606270949045818), ((8, 14), 0.08589024096727371), ((1, 17), 0.08585450053215027), ((1, 5), 0.08560475707054138), ((4, 7), 0.08558587233225505), ((0, 5), 0.08537985881169637), ((3, 5), 0.0853364368279775), ((2, 5), 0.08520405491193135), ((12, 18), 0.08494672924280167), ((3, 17), 0.0848109523455302), ((0, 9), 0.08462317784627278), ((7, 11), 0.08458694070577621), ((2, 17), 0.08447436491648357), ((3, 15), 0.08431756496429443), ((2, 15), 0.08423656225204468), ((4, 18), 0.08400147159894307), ((1, 15), 0.08387371897697449), ((1, 10), 0.08270462354024251), ((0, 18), 0.08269069592158), ((11, 12), 0.08232825994491577), ((4, 10), 0.08166374266147614), ((1, 7), 0.08160772919654846), ((2, 8), 0.08137346307436626), ((3, 8), 0.08134588599205017), ((4, 15), 0.08128168682257335), ((1, 18), 0.08119497199853261), ((0, 8), 0.07985344529151917), ((3, 18), 0.07981548706690471), ((2, 18), 0.07950555781523387), ((0, 7), 0.07943908373514812), ((11, 14), 0.07919833809137344), ((1, 9), 0.07791784902413686), ((3, 7), 0.0775071233510971), ((7, 12), 0.07708659023046494), ((2, 7), 0.0767070899407069), ((4, 9), 0.07553677757581075), ((2, 3), 0.07375045120716095), ((16, 18), 0.07367869466543198), ((1, 8), 0.07361366351445515), ((4, 8), 0.07244850695133209), ((5, 16), 0.07074340432882309), ((0, 2), 0.0697040930390358), ((0, 3), 0.06970100104808807), ((12, 14), 0.06950455158948898), ((3, 11), 0.06908309956391652), ((0, 11), 0.06892522672812144), ((15, 16), 0.06888359040021896), ((2, 11), 0.06881252924601237), ((2, 12), 0.06873931487401326), ((1, 4), 0.06857224553823471), ((3, 12), 0.06840628882249196), ((4, 14), 0.06798404455184937), ((7, 16), 0.06769613921642303), ((16, 17), 0.0674186423420906), ((0, 12), 0.06659594178199768), ((0, 1), 0.06644756346940994), ((0, 4), 0.06515078246593475), ((1, 14), 0.06467995047569275), ((1, 3), 0.06431574374437332), ((10, 16), 0.06419304758310318), ((0, 14), 0.0640799750884374), ((1, 2), 0.0637621358036995), ((4, 11), 0.06321991483370464), ((3, 4), 0.06321617215871811), ((1, 11), 0.06273074448108673), ((2, 4), 0.06257937103509903), ((3, 14), 0.061176881194114685), ((8, 16), 0.06111352890729904), ((2, 14), 0.060682862997055054), ((14, 16), 0.05930149555206299), ((9, 16), 0.05892583727836609), ((1, 12), 0.05860800047715505), ((11, 16), 0.0582391731441021), ((4, 12), 0.056518723567326866), ((4, 16), 0.0502871572971344), ((1, 16), 0.048149640361467995), ((0, 16), 0.04764874776204427), ((12, 16), 0.04748614504933357), ((3, 16), 0.0425178607304891), ((2, 16), 0.04214182992776235), ((6, 13), 0.038533829152584076), ((9, 13), 0.022989582270383835), ((10, 13), 0.02185339853167534), ((12, 13), 0.021169019863009453), ((8, 13), 0.019025858491659164), ((13, 15), 0.017550036311149597), ((3, 13), 0.016926913211743038), ((2, 13), 0.01685180515050888), ((6, 12), 0.016242455691099167), ((13, 17), 0.015796106308698654), ((6, 10), 0.015492462553083897), ((11, 13), 0.01531137339770794), ((6, 9), 0.015237038023769855), ((5, 13), 0.013997113332152367), ((0, 13), 0.013670579840739569), ((6, 11), 0.013237097300589085), ((6, 14), 0.013041537255048752), ((13, 18), 0.012845154851675034), ((6, 8), 0.012498337775468826), ((6, 15), 0.012427304871380329), ((7, 13), 0.012051013298332691), ((6, 17), 0.011764280498027802), ((3, 6), 0.010547438015540441), ((2, 6), 0.010453421622514725), ((1, 13), 0.009985848640402159), ((6, 18), 0.009877892211079597), ((5, 6), 0.009778901934623718), ((13, 14), 0.009758428670465946), ((6, 7), 0.009702758863568306), ((0, 6), 0.008777950579921404), ((4, 13), 0.008542722711960474), ((1, 6), 0.00756109319627285), ((4, 6), 0.007167728617787361), ((6, 16), 0.0064329057931900024), ((13, 16), 0.005132552236318588)]
******* after merging (0.04): [((9, 10), 64), ((5, 17), 64), ((0,), 64), ((1,), 64), ((2,), 64), ((3,), 64), ((4,), 64), ((6,), 32), ((7,), 32), ((8,), 32), ((11,), 32), ((12,), 32), ((13,), 32), ((14,), 32), ((15,), 32), ((16,), 32), ((18,), 32)]
{'R_grad_norm': 0.9425169184803963, 'training_loss': 1.5113170450925828}
{'R_grad_norm': 0.939432170689106, 'training_loss': 1.5012075060606003}
{'R_grad_norm': 0.9355288133025169, 'training_loss': 1.5109290742874146}
{'R_grad_norm': 0.9326267471909523, 'training_loss': 1.498140445947647}
{'R_grad_norm': 0.9314481866359711, 'training_loss': 1.4939685153961182}
{'R_grad_norm': 0.9360401311516762, 'training_loss': 1.5112641632556916}
{'R_grad_norm': 0.93556844830513, 'training_loss': 1.4936062920093536}
{'R_grad_norm': 0.9339861389994621, 'training_loss': 1.4945249342918396}
{'R_grad_norm': 0.9305449008941651, 'training_loss': 1.4901997447013855}
{'R_grad_norm': 0.932403772175312, 'training_loss': 1.4894276762008667}
{'R_grad_norm': 0.9254852941632271, 'training_loss': 1.4779176014661788}
{'R_grad_norm': 0.9283398875594139, 'training_loss': 1.4797712332010269}
{'R_grad_norm': 0.9269702276587486, 'training_loss': 1.485603425502777}
{'R_grad_norm': 0.9287702271342277, 'training_loss': 1.487431032061577}
{'R_grad_norm': 0.9244732999801636, 'training_loss': 1.4823211687803268}
{'R_grad_norm': 0.923870661854744, 'training_loss': 1.4765736079216003}
{'R_grad_norm': 0.925871433019638, 'training_loss': 1.4890029680728913}
{'R_grad_norm': 0.9275897002220154, 'training_loss': 1.4914199817180633}
{'R_grad_norm': 0.9243466112017632, 'training_loss': 1.4781552588939666}
{'R_grad_norm': 0.9229753887653351, 'training_loss': 1.4826143300533294}
{'R_grad_norm': 0.9218480637669564, 'training_loss': 1.4865039640665054}
{'R_grad_norm': 0.923304235637188, 'training_loss': 1.4739402914047242}
{'R_grad_norm': 0.9197212508320809, 'training_loss': 1.494648357629776}
{'R_grad_norm': 0.9210415810346604, 'training_loss': 1.481386163830757}
{'R_grad_norm': 0.9210961988568306, 'training_loss': 1.4934455114603042}
{'R_grad_norm': 0.9205674758553505, 'training_loss': 1.4886476266384125}
{'R_grad_norm': 0.9219109094142914, 'training_loss': 1.4859996789693832}
{'R_grad_norm': 0.9190409380197525, 'training_loss': 1.4858175456523894}
{'R_grad_norm': 0.9168193596601486, 'training_loss': 1.4686869615316391}
{'R_grad_norm': 0.9195556819438935, 'training_loss': 1.482056337594986}
{'R_grad_norm': 0.9186571830511093, 'training_loss': 1.4834998697042465}
{'R_grad_norm': 0.9160926374793052, 'training_loss': 1.4766591912508011}
{'R_grad_norm': 0.9147433099150658, 'training_loss': 1.4670465975999831}
{'R_grad_norm': 0.9152022707462311, 'training_loss': 1.4833570641279221}
{'R_grad_norm': 0.9165848401188851, 'training_loss': 1.4814383107423783}
{'R_grad_norm': 0.9180848631262779, 'training_loss': 1.4808633321523665}
{'R_grad_norm': 0.9147180783748626, 'training_loss': 1.4707327425479888}
{'R_grad_norm': 0.9166965082287788, 'training_loss': 1.489858216047287}
{'R_grad_norm': 0.9151419660449028, 'training_loss': 1.4763754570484162}
{'R_grad_norm': 0.9185673144459724, 'training_loss': 1.4843706613779069}
eval result tensor([1.29575, 1.74165, 1.70885, 1.88561, 1.76204, 1.83182, 2.69887, 1.31391,
        1.22197, 0.99597, 1.29602, 0.85335, 1.31669, 1.20834, 0.87587, 1.91965,
        1.12849], device='cuda:0')
computing merge metric
normed mi [((14, 16), 0.11568645387887955), ((9, 14), 0.11421491950750351), ((8, 16), 0.11241597682237625), ((8, 14), 0.10751473158597946), ((9, 16), 0.10667140781879425), ((9, 10), 0.09731145948171616), ((8, 9), 0.09655337035655975), ((11, 14), 0.09643042087554932), ((9, 11), 0.09555719047784805), ((10, 14), 0.09467596560716629), ((10, 16), 0.0900222435593605), ((13, 16), 0.09001920372247696), ((2, 14), 0.08641383051872253), ((0, 14), 0.08627630273501079), ((8, 13), 0.08613605052232742), ((13, 14), 0.08587665110826492), ((11, 16), 0.08551564067602158), ((6, 8), 0.08444433410962422), ((5, 14), 0.0843486487865448), ((4, 14), 0.08371252814928691), ((6, 16), 0.08346132437388103), ((2, 16), 0.08277847866217296), ((8, 10), 0.08193866908550262), ((1, 16), 0.08182249466578166), ((10, 11), 0.0815596729516983), ((0, 16), 0.08152638375759125), ((3, 14), 0.08149995406468709), ((1, 8), 0.08142021795113881), ((3, 16), 0.0809424767891566), ((4, 9), 0.0808029721180598), ((5, 9), 0.08078613877296448), ((3, 8), 0.08047109345595042), ((9, 13), 0.08032234758138657), ((2, 9), 0.07993222276369731), ((0, 9), 0.07967985669771831), ((2, 8), 0.07847137252489726), ((5, 16), 0.0783846378326416), ((1, 14), 0.07814908027648926), ((0, 8), 0.07775827745596568), ((8, 11), 0.07752616703510284), ((4, 16), 0.07719070216019948), ((6, 14), 0.0766959289709727), ((5, 8), 0.07484627266724904), ((10, 13), 0.07402012497186661), ((4, 5), 0.07369421422481537), ((4, 8), 0.07358607649803162), ((3, 9), 0.07213752468427022), ((1, 9), 0.07190567255020142), ((4, 11), 0.06997380654017131), ((15, 16), 0.06964331120252609), ((6, 9), 0.06949167946974437), ((5, 11), 0.06942138075828552), ((0, 5), 0.06913019716739655), ((0, 2), 0.06882008910179138), ((0, 4), 0.06852710247039795), ((1, 6), 0.06835324317216873), ((2, 10), 0.06823199987411499), ((2, 5), 0.06822752207517624), ((3, 6), 0.0676586851477623), ((2, 4), 0.06764161586761475), ((5, 10), 0.06763713558514912), ((4, 10), 0.06694753468036652), ((2, 11), 0.066901296377182), ((0, 11), 0.06638496120770772), ((1, 3), 0.06630252301692963), ((11, 13), 0.0659501701593399), ((0, 10), 0.06590185562769572), ((12, 14), 0.06551472842693329), ((2, 3), 0.06527009606361389), ((6, 13), 0.06517305970191956), ((0, 3), 0.06423037499189377), ((8, 15), 0.06395447254180908), ((1, 2), 0.06392969191074371), ((14, 15), 0.06355048716068268), ((0, 1), 0.06335200369358063), ((2, 6), 0.06305372714996338), ((1, 13), 0.06261607507864635), ((3, 13), 0.062011500199635826), ((0, 6), 0.06193795055150986), ((3, 5), 0.06148693338036537), ((2, 13), 0.060931781927744545), ((3, 10), 0.06063867608706156), ((1, 5), 0.060611575841903687), ((3, 4), 0.06048949062824249), ((0, 13), 0.0603344589471817), ((1, 10), 0.06015746792157491), ((5, 6), 0.05986154079437256), ((6, 10), 0.0596924622853597), ((1, 4), 0.05937493219971657), ((9, 12), 0.05866825580596924), ((4, 6), 0.058665502816438675), ((12, 16), 0.05850459262728691), ((3, 11), 0.0580984503030777), ((9, 15), 0.05727940425276756), ((5, 13), 0.0570782075325648), ((1, 11), 0.05657788614432017), ((4, 13), 0.05600212514400482), ((13, 15), 0.05577850341796875), ((8, 12), 0.05535930395126343), ((10, 15), 0.054971493780612946), ((6, 11), 0.0544953445593516), ((6, 15), 0.05010827382405599), ((10, 12), 0.048557527363300323), ((11, 12), 0.04719718173146248), ((3, 15), 0.046995192766189575), ((3, 12), 0.046867236495018005), ((1, 15), 0.046743993957837425), ((2, 15), 0.0464325745900472), ((2, 12), 0.046308353543281555), ((11, 15), 0.04583368077874184), ((0, 12), 0.045343210299809776), ((5, 12), 0.0439939151207606), ((4, 12), 0.04330680270989736), ((0, 15), 0.04212495187918345), ((1, 12), 0.041659812132517494), ((12, 13), 0.04121171683073044), ((6, 12), 0.0409477228919665), ((5, 15), 0.0397618884841601), ((4, 15), 0.038997724652290344), ((12, 15), 0.034496940672397614), ((7, 11), 0.01498187705874443), ((7, 13), 0.013499114662408829), ((7, 10), 0.013499010354280472), ((7, 14), 0.012511934153735638), ((7, 9), 0.011877189390361309), ((5, 7), 0.010645513733228048), ((4, 7), 0.010478018472592035), ((7, 16), 0.010050743818283081), ((7, 8), 0.009852008894085884), ((0, 7), 0.00973484106361866), ((2, 7), 0.008670959000786146), ((7, 12), 0.007437359541654587), ((3, 7), 0.007334110637505849), ((6, 7), 0.006971217691898346), ((1, 7), 0.006617541735370954), ((7, 15), 0.0064116111025214195)]
******* after merging (0.04): [((14, 16), 64), ((9, 10), 64), ((0,), 64), ((1,), 64), ((2,), 64), ((3,), 64), ((4,), 64), ((5,), 64), ((6,), 64), ((7,), 32), ((8,), 32), ((11,), 32), ((12,), 32), ((13,), 32), ((15,), 32)]
{'R_grad_norm': 0.9949624735116959, 'training_loss': 1.6310423612594604}
{'R_grad_norm': 0.9912262588739396, 'training_loss': 1.623840019106865}
{'R_grad_norm': 0.986269933283329, 'training_loss': 1.6246393913030623}
{'R_grad_norm': 0.9849304914474487, 'training_loss': 1.6261969166994095}
{'R_grad_norm': 0.9809813487529755, 'training_loss': 1.6213032412528992}
{'R_grad_norm': 0.9814228895306587, 'training_loss': 1.6276384609937669}
{'R_grad_norm': 0.9800729367136956, 'training_loss': 1.6224393576383591}
{'R_grad_norm': 0.9768993976712227, 'training_loss': 1.610421174764633}
{'R_grad_norm': 0.9756990656256675, 'training_loss': 1.616848686337471}
{'R_grad_norm': 0.9770166090130806, 'training_loss': 1.6186465883255006}
{'R_grad_norm': 0.9753436034917832, 'training_loss': 1.6243416422605514}
{'R_grad_norm': 0.9713360181450844, 'training_loss': 1.6090803915262222}
{'R_grad_norm': 0.9755852934718132, 'training_loss': 1.6223758798837662}
{'R_grad_norm': 0.9700777590274811, 'training_loss': 1.609291387796402}
{'R_grad_norm': 0.9714606669545174, 'training_loss': 1.6186477881669998}
{'R_grad_norm': 0.9715574768185615, 'training_loss': 1.6184028166532516}
{'R_grad_norm': 0.9692890554666519, 'training_loss': 1.6145179605484008}
{'R_grad_norm': 0.9687665942311287, 'training_loss': 1.6155766266584397}
{'R_grad_norm': 0.9668351194262504, 'training_loss': 1.6151313799619675}
{'R_grad_norm': 0.966210073530674, 'training_loss': 1.6141292083263397}
{'R_grad_norm': 0.964940156340599, 'training_loss': 1.6061324679851532}
{'R_grad_norm': 0.9633360317349434, 'training_loss': 1.6098937833309173}
{'R_grad_norm': 0.9601934492588043, 'training_loss': 1.606977351307869}
{'R_grad_norm': 0.9594279855489731, 'training_loss': 1.6061962747573852}
{'R_grad_norm': 0.9577902099490165, 'training_loss': 1.6136141216754913}
{'R_grad_norm': 0.9571276617050171, 'training_loss': 1.619216320514679}
{'R_grad_norm': 0.9585233065485954, 'training_loss': 1.6110385078191758}
{'R_grad_norm': 0.9597848376631737, 'training_loss': 1.6115388613939285}
{'R_grad_norm': 0.9553229144215584, 'training_loss': 1.6067935436964036}
{'R_grad_norm': 0.9539376690983772, 'training_loss': 1.5975373595952989}
{'R_grad_norm': 0.9573568159341812, 'training_loss': 1.6079996848106384}
{'R_grad_norm': 0.952618011534214, 'training_loss': 1.616698330640793}
{'R_grad_norm': 0.9517160093784333, 'training_loss': 1.6077551603317262}
{'R_grad_norm': 0.9526148182153702, 'training_loss': 1.621399176120758}
{'R_grad_norm': 0.9502420741319656, 'training_loss': 1.6115695130825043}
{'R_grad_norm': 0.9565054839849472, 'training_loss': 1.622513917684555}
{'R_grad_norm': 0.9501250794529915, 'training_loss': 1.6110747534036636}
{'R_grad_norm': 0.9494470173120498, 'training_loss': 1.6049978017807007}
{'R_grad_norm': 0.9513148388266564, 'training_loss': 1.6166839438676834}
{'R_grad_norm': 0.9474036800861358, 'training_loss': 1.6110563504695892}
eval result tensor([1.69299, 2.01581, 1.23730, 1.73685, 1.70390, 1.85857, 1.76518, 1.84892,
        2.85242, 1.28391, 1.11332, 0.85087, 1.33523, 1.19154, 1.92899],
       device='cuda:0')
computing merge metric
normed mi [((8, 10), 0.08267018695672353), ((10, 13), 0.08022414147853851), ((3, 10), 0.08019881943861644), ((5, 10), 0.08008225758870442), ((4, 10), 0.07900962233543396), ((0, 10), 0.07823970417181651), ((2, 10), 0.07787562410036723), ((10, 11), 0.0765380710363388), ((7, 10), 0.07573042809963226), ((6, 10), 0.07369501392046611), ((6, 7), 0.07325943559408188), ((2, 7), 0.07040107250213623), ((2, 4), 0.06950637698173523), ((2, 6), 0.06925270706415176), ((6, 11), 0.06862547993659973), ((4, 7), 0.06808575242757797), ((7, 11), 0.06747318804264069), ((5, 8), 0.06667029857635498), ((4, 6), 0.06658699363470078), ((2, 11), 0.06598882377147675), ((3, 4), 0.06576254963874817), ((2, 3), 0.06574749201536179), ((3, 5), 0.06549781560897827), ((1, 10), 0.06528990467389424), ((4, 11), 0.06496621171633403), ((4, 5), 0.06485693156719208), ((3, 8), 0.06423098593950272), ((11, 13), 0.0641457587480545), ((0, 4), 0.06396237015724182), ((0, 8), 0.06395528465509415), ((0, 5), 0.06360682100057602), ((3, 7), 0.06352514773607254), ((0, 3), 0.06318207830190659), ((0, 2), 0.06282960623502731), ((2, 5), 0.06281815469264984), ((10, 12), 0.06170126423239708), ((3, 6), 0.06148042529821396), ((4, 8), 0.06146558001637459), ((10, 14), 0.061241310089826584), ((5, 7), 0.06079322099685669), ((5, 6), 0.05932195484638214), ((4, 13), 0.05929545064767202), ((8, 13), 0.0592650572458903), ((0, 7), 0.059222567826509476), ((3, 13), 0.05890419085820516), ((2, 8), 0.05869505926966667), ((0, 13), 0.05835231145222982), ((7, 8), 0.05825906619429588), ((1, 13), 0.0581355889638265), ((3, 11), 0.0580659011999766), ((1, 4), 0.05794459581375122), ((5, 13), 0.057902117570241295), ((2, 13), 0.05770244697729746), ((0, 6), 0.05754809081554413), ((1, 11), 0.05743753413359324), ((6, 8), 0.05688905715942383), ((1, 2), 0.056512121111154556), ((0, 11), 0.05596493681271871), ((1, 3), 0.05577288195490837), ((7, 13), 0.05553060273329417), ((5, 11), 0.05523570875326792), ((1, 7), 0.055014412850141525), ((0, 1), 0.05470241978764534), ((6, 13), 0.054276873668034874), ((12, 14), 0.054126985371112823), ((1, 5), 0.05382389575242996), ((1, 6), 0.05335557460784912), ((1, 8), 0.05291532725095749), ((8, 14), 0.050714775919914246), ((8, 11), 0.05059078832467397), ((13, 14), 0.05034497007727623), ((8, 12), 0.04841426511605581), ((0, 14), 0.04779476920763651), ((5, 14), 0.04662170012791952), ((5, 12), 0.046256432930628456), ((12, 13), 0.04590054228901863), ((4, 14), 0.045818716287612915), ((0, 12), 0.04438287019729614), ((3, 14), 0.043691674868265785), ((3, 12), 0.04338450233141581), ((4, 12), 0.042824904123942055), ((11, 14), 0.0423978716135025), ((1, 14), 0.0422272135814031), ((2, 12), 0.040645405650138855), ((2, 14), 0.03971190253893534), ((7, 12), 0.039676450192928314), ((6, 12), 0.03895473728577296), ((7, 14), 0.03895190358161926), ((11, 12), 0.038803502917289734), ((6, 14), 0.03832037498553594), ((1, 12), 0.0366146390636762), ((9, 11), 0.014609802514314651), ((9, 13), 0.013853157870471478), ((7, 9), 0.010173909366130829), ((6, 9), 0.009999551499883333), ((9, 10), 0.009672471322119236), ((2, 9), 0.009554715206225714), ((4, 9), 0.008007738118370375), ((1, 9), 0.007437040408452352), ((5, 9), 0.0070525674770275755), ((3, 9), 0.006604143728812535), ((0, 9), 0.006414979696273804), ((8, 9), 0.006338480239113172), ((9, 12), 0.006027849856764078), ((9, 14), 0.005916532129049301)]
******* after merging (0.04): [((8, 10), 96), ((0,), 64), ((1,), 64), ((2,), 64), ((3,), 64), ((4,), 64), ((5,), 64), ((6,), 64), ((7,), 64), ((9,), 32), ((11,), 32), ((12,), 32), ((13,), 32), ((14,), 32)]
{'R_grad_norm': 1.031746553182602, 'training_loss': 1.66956056535244}
{'R_grad_norm': 1.0237970638275147, 'training_loss': 1.6801195859909057}
{'R_grad_norm': 1.0187400424480437, 'training_loss': 1.6660131150484085}
{'R_grad_norm': 1.017929763197899, 'training_loss': 1.6682315230369569}
{'R_grad_norm': 1.0163472989201545, 'training_loss': 1.6662873488664627}
{'R_grad_norm': 1.0183629789948463, 'training_loss': 1.6654993641376494}
{'R_grad_norm': 1.014585661292076, 'training_loss': 1.6556799745559692}
{'R_grad_norm': 1.0150357255339622, 'training_loss': 1.662676529288292}
{'R_grad_norm': 1.0143149262666702, 'training_loss': 1.6613196283578873}
{'R_grad_norm': 1.0119036227464675, 'training_loss': 1.655753608942032}
{'R_grad_norm': 1.0137974628806115, 'training_loss': 1.6667092567682267}
{'R_grad_norm': 1.01402871966362, 'training_loss': 1.664494658112526}
{'R_grad_norm': 1.0115013936161994, 'training_loss': 1.6688264614343644}
{'R_grad_norm': 1.0111909717321397, 'training_loss': 1.6616714817285538}
{'R_grad_norm': 1.008128016591072, 'training_loss': 1.6542527121305466}
{'R_grad_norm': 1.005902601480484, 'training_loss': 1.6530827337503433}
{'R_grad_norm': 1.0073619306087493, 'training_loss': 1.6666795152425766}
{'R_grad_norm': 1.0034707525372506, 'training_loss': 1.6495442628860473}
{'R_grad_norm': 1.0022835192084312, 'training_loss': 1.6514230406284331}
{'R_grad_norm': 1.0016296669840812, 'training_loss': 1.646159101128578}
{'R_grad_norm': 1.0058601409196855, 'training_loss': 1.6665964174270629}
{'R_grad_norm': 1.0050996559858323, 'training_loss': 1.6574347430467606}
{'R_grad_norm': 1.0047989079356194, 'training_loss': 1.6590378820896148}
{'R_grad_norm': 1.001937946677208, 'training_loss': 1.6575708216428757}
{'R_grad_norm': 1.0055579021573067, 'training_loss': 1.662301973104477}
{'R_grad_norm': 0.9975645026564598, 'training_loss': 1.6573937386274338}
{'R_grad_norm': 0.9998807343840599, 'training_loss': 1.6551353871822356}
{'R_grad_norm': 0.9951161441206932, 'training_loss': 1.6458422255516052}
{'R_grad_norm': 0.9972318467497826, 'training_loss': 1.6611367899179459}
{'R_grad_norm': 0.9938289937376976, 'training_loss': 1.6545872712135314}
{'R_grad_norm': 0.994734815955162, 'training_loss': 1.6558479529619217}
{'R_grad_norm': 0.9932850682735443, 'training_loss': 1.6644958364963531}
{'R_grad_norm': 0.9945603251457215, 'training_loss': 1.6585830134153365}
{'R_grad_norm': 0.9890396842360496, 'training_loss': 1.6407504504919053}
{'R_grad_norm': 0.9933940240740776, 'training_loss': 1.6611720210313796}
{'R_grad_norm': 0.9902463960647583, 'training_loss': 1.6452069777250289}
{'R_grad_norm': 0.9864947319030761, 'training_loss': 1.6593126672506333}
{'R_grad_norm': 0.9867936378717422, 'training_loss': 1.6481586986780166}
{'R_grad_norm': 0.9849746266007423, 'training_loss': 1.647234554886818}
{'R_grad_norm': 0.987430445253849, 'training_loss': 1.6462547373771668}
eval result tensor([3.63538, 1.60021, 1.92528, 1.16880, 1.57573, 1.57873, 1.74379, 1.69138,
        1.76229, 1.26766, 0.83748, 1.31507, 1.13796, 1.83259], device='cuda:0')
computing merge metric
normed mi [((7, 8), 0.07269782572984695), ((3, 8), 0.07063154131174088), ((3, 5), 0.0695829838514328), ((5, 8), 0.06894144415855408), ((7, 10), 0.06873458127180736), ((3, 7), 0.06871753185987473), ((3, 4), 0.06828243285417557), ((4, 5), 0.0670042559504509), ((5, 7), 0.06670178472995758), ((4, 8), 0.06668560206890106), ((8, 10), 0.06649245321750641), ((3, 10), 0.06545044481754303), ((5, 6), 0.06484336405992508), ((5, 10), 0.06484063963095348), ((1, 6), 0.06426744908094406), ((4, 7), 0.06404417753219604), ((1, 5), 0.06398186832666397), ((4, 6), 0.06356695294380188), ((1, 3), 0.06321323662996292), ((3, 6), 0.06304764747619629), ((1, 4), 0.06263577193021774), ((10, 12), 0.06153551861643791), ((4, 10), 0.06136268377304077), ((6, 8), 0.06133003160357475), ((1, 8), 0.059799909591674805), ((6, 7), 0.05921395123004913), ((2, 5), 0.05787856504321098), ((1, 7), 0.05746476352214813), ((2, 10), 0.05678858359654745), ((5, 12), 0.05678081512451172), ((2, 12), 0.05613433321317037), ((1, 12), 0.05593595405419668), ((2, 4), 0.05589369311928749), ((1, 10), 0.055850336949030556), ((2, 3), 0.055771615356206894), ((4, 12), 0.05564276377360026), ((6, 12), 0.05543241401513418), ((3, 12), 0.05532103776931763), ((6, 10), 0.05530592302481333), ((2, 8), 0.05460138991475105), ((1, 2), 0.05441145598888397), ((11, 13), 0.054252736270427704), ((2, 6), 0.05423545837402344), ((8, 12), 0.05365149180094401), ((2, 7), 0.05248419940471649), ((7, 12), 0.052047585447629295), ((0, 6), 0.05160830020904541), ((0, 1), 0.04964945614337921), ((12, 13), 0.04853015020489693), ((0, 4), 0.04712623059749603), ((1, 13), 0.04699532687664032), ((0, 5), 0.046735253930091855), ((6, 13), 0.04610791802406311), ((0, 8), 0.04537467956542969), ((5, 13), 0.04523638387521108), ((0, 3), 0.0447764128446579), ((0, 7), 0.044201198220252993), ((10, 13), 0.04273535683751106), ((2, 13), 0.04235676924387614), ((6, 11), 0.04213233292102814), ((4, 13), 0.041558598478635154), ((1, 11), 0.04076357434193293), ((0, 2), 0.040613412857055664), ((0, 12), 0.040192198008298874), ((3, 13), 0.039302900433540344), ((11, 12), 0.03928886726498604), ((5, 11), 0.038854832450548805), ((0, 13), 0.03880691155791283), ((8, 13), 0.03876697023709615), ((4, 11), 0.038759020467599235), ((7, 13), 0.03789949913819631), ((3, 11), 0.037139842907587685), ((8, 11), 0.03677762299776077), ((0, 11), 0.0363844558596611), ((0, 10), 0.03595587983727455), ((7, 11), 0.035915193458398185), ((10, 11), 0.03265305981040001), ((2, 11), 0.031896211206912994), ((9, 10), 0.01480347104370594), ((9, 12), 0.01358645036816597), ((8, 9), 0.01042738805214564), ((7, 9), 0.010203418011466662), ((3, 9), 0.009557613482077917), ((5, 9), 0.008685864508152008), ((2, 9), 0.007737032448252042), ((4, 9), 0.007577999805410703), ((6, 9), 0.007379734267791112), ((1, 9), 0.006784025579690933), ((9, 13), 0.006127737462520599), ((9, 11), 0.005423576105386019), ((0, 9), 0.004510189406573772)]
******* after merging (0.04): [((7, 8), 128), ((0,), 96), ((1,), 64), ((2,), 64), ((3,), 64), ((4,), 64), ((5,), 64), ((6,), 64), ((9,), 32), ((10,), 32), ((11,), 32), ((12,), 32), ((13,), 32)]
{'R_grad_norm': 1.074765165746212, 'training_loss': 1.7121419268846512}
{'R_grad_norm': 1.065956239104271, 'training_loss': 1.6963782620429992}
{'R_grad_norm': 1.0643660035729408, 'training_loss': 1.7061947882175446}
{'R_grad_norm': 1.0618946635723114, 'training_loss': 1.6955889922380447}
{'R_grad_norm': 1.0616706356406211, 'training_loss': 1.7046936708688736}
{'R_grad_norm': 1.0618536946177484, 'training_loss': 1.6979309302568435}
{'R_grad_norm': 1.0547646728157998, 'training_loss': 1.6955530095100402}
{'R_grad_norm': 1.0548990362882613, 'training_loss': 1.7026300376653671}
{'R_grad_norm': 1.0586631351709366, 'training_loss': 1.7136422926187516}
{'R_grad_norm': 1.0601215410232543, 'training_loss': 1.722501803636551}
{'R_grad_norm': 1.0589276051521301, 'training_loss': 1.7124965178966522}
{'R_grad_norm': 1.063687403202057, 'training_loss': 1.734823716878891}
{'R_grad_norm': 1.0592163282632827, 'training_loss': 1.7180669128894805}
{'R_grad_norm': 1.065025980770588, 'training_loss': 1.7435807621479034}
{'R_grad_norm': 1.0648148754239082, 'training_loss': 1.7494250452518463}
{'R_grad_norm': 1.065929761528969, 'training_loss': 1.737555245757103}
{'R_grad_norm': 1.0706361377239226, 'training_loss': 1.7620685011148454}
{'R_grad_norm': 1.0754229998588563, 'training_loss': 1.7766322374343873}
{'R_grad_norm': 1.077800870537758, 'training_loss': 1.7906202727556229}
{'R_grad_norm': 1.0710610914230347, 'training_loss': 1.789107903242111}
{'R_grad_norm': 1.079396666586399, 'training_loss': 1.8244137316942215}
{'R_grad_norm': 1.0835117989778518, 'training_loss': 1.8354965651035309}
{'R_grad_norm': 1.0921143913269042, 'training_loss': 1.8883532732725143}
{'R_grad_norm': 1.05307293176651, 'training_loss': 1.7608276242017746}
{'R_grad_norm': 1.0461269235610962, 'training_loss': 1.7207494157552718}
{'R_grad_norm': 1.0459267953038216, 'training_loss': 1.7310719764232636}
{'R_grad_norm': 1.0433123657107353, 'training_loss': 1.7212893843650818}
{'R_grad_norm': 1.0437475484609604, 'training_loss': 1.7276103347539902}
{'R_grad_norm': 1.0370643231272698, 'training_loss': 1.7178907656669617}
{'R_grad_norm': 1.039931861758232, 'training_loss': 1.7304836016893388}
{'R_grad_norm': 1.0375377005338668, 'training_loss': 1.7161998969316483}
{'R_grad_norm': 1.0371036288142204, 'training_loss': 1.7163579493761063}
{'R_grad_norm': 1.037115450799465, 'training_loss': 1.7175552320480347}
{'R_grad_norm': 1.0352970704436302, 'training_loss': 1.7181085282564164}
{'R_grad_norm': 1.0381375080347062, 'training_loss': 1.7299386447668075}
{'R_grad_norm': 1.0353908509016037, 'training_loss': 1.7208880299329758}
{'R_grad_norm': 1.0336078023910522, 'training_loss': 1.714748619198799}
{'R_grad_norm': 1.0329623851180076, 'training_loss': 1.7097042834758758}
{'R_grad_norm': 1.0303033044934273, 'training_loss': 1.7098180705308914}
{'R_grad_norm': 1.0332314771413804, 'training_loss': 1.7200976675748825}
eval result tensor([2.78251, 3.75234, 1.49648, 1.90708, 1.17408, 1.53960, 1.53607, 1.70319,
        1.25903, 0.84380, 1.33468, 1.11824, 1.82742], device='cuda:0')
computing merge metric
normed mi [((4, 6), 0.06959458440542221), ((4, 5), 0.06826668232679367), ((5, 6), 0.06704304367303848), ((4, 9), 0.06543400386969249), ((2, 7), 0.06524138152599335), ((6, 9), 0.06495542327562968), ((2, 6), 0.06485473364591599), ((2, 4), 0.06431257724761963), ((6, 7), 0.06389281153678894), ((2, 5), 0.06325720250606537), ((5, 7), 0.06268014758825302), ((4, 7), 0.06245393678545952), ((5, 9), 0.0621915211280187), ((9, 11), 0.061867423355579376), ((3, 6), 0.057946715503931046), ((2, 9), 0.057137757539749146), ((3, 9), 0.057044804096221924), ((3, 4), 0.05601218715310097), ((3, 11), 0.05570044616858164), ((2, 3), 0.05564800277352333), ((2, 11), 0.055542945861816406), ((6, 11), 0.055538296699523926), ((3, 5), 0.0552775114774704), ((7, 9), 0.05514317750930786), ((4, 11), 0.054532185196876526), ((5, 11), 0.05422758559385935), ((3, 7), 0.053983062505722046), ((7, 11), 0.05337693293889364), ((10, 12), 0.05180246755480766), ((1, 7), 0.048141151666641235), ((0, 4), 0.04805062711238861), ((0, 6), 0.04765704274177551), ((0, 5), 0.046285723646481834), ((1, 2), 0.04625093042850494), ((2, 12), 0.04463474949200948), ((1, 5), 0.04416698217391968), ((11, 12), 0.04408448934555054), ((1, 6), 0.0440712034702301), ((7, 12), 0.04393186171849569), ((6, 12), 0.043201411763827004), ((1, 4), 0.04214945137500763), ((0, 2), 0.041810368498166404), ((0, 7), 0.04164143900076548), ((7, 10), 0.041426864763100944), ((9, 12), 0.04064587131142616), ((3, 12), 0.04057727505763372), ((2, 10), 0.039737833042939506), ((0, 9), 0.039456695318222046), ((5, 12), 0.03929234792788824), ((1, 3), 0.03851575255393982), ((6, 10), 0.03844222923119863), ((5, 10), 0.038016547759373985), ((1, 12), 0.03769712150096893), ((0, 3), 0.03754406919082006), ((4, 12), 0.03734783331553141), ((4, 10), 0.03674556314945221), ((1, 10), 0.036515239626169205), ((1, 11), 0.03604491055011749), ((10, 11), 0.03525504842400551), ((1, 9), 0.03385641425848007), ((0, 11), 0.03246365785598755), ((9, 10), 0.03177875652909279), ((0, 1), 0.031042852572032383), ((3, 10), 0.030824914574623108), ((0, 12), 0.022745381295681), ((0, 10), 0.022443109750747682), ((8, 9), 0.014336577616631985), ((8, 11), 0.012652122415602207), ((4, 8), 0.009098720426360766), ((6, 8), 0.008366340771317482), ((3, 8), 0.007538134232163429), ((5, 8), 0.0075134579092264175), ((7, 8), 0.006848786026239395), ((2, 8), 0.0065141165008147555), ((8, 12), 0.005913714412599802), ((0, 8), 0.005815406516194344), ((8, 10), 0.004209253471344709), ((1, 8), 0.0038604859728366137)]
******* after merging (0.04): [((4, 6), 128), ((0,), 128), ((1,), 96), ((2,), 64), ((3,), 64), ((5,), 64), ((7,), 64), ((8,), 32), ((9,), 32), ((10,), 32), ((11,), 32), ((12,), 32)]
{'R_grad_norm': 1.1304073655605316, 'training_loss': 1.79651600420475}
{'R_grad_norm': 1.1243369102478027, 'training_loss': 1.8136711066961289}
{'R_grad_norm': 1.120193337202072, 'training_loss': 1.8008534783124923}
{'R_grad_norm': 1.1172098243236541, 'training_loss': 1.7997842133045197}
{'R_grad_norm': 1.1173044461011887, 'training_loss': 1.8096828120946884}
{'R_grad_norm': 1.1119272965192795, 'training_loss': 1.8026671773195266}
{'R_grad_norm': 1.1166333788633347, 'training_loss': 1.806772407889366}
{'R_grad_norm': 1.1129251825809479, 'training_loss': 1.8053129863739015}
{'R_grad_norm': 1.1098306649923324, 'training_loss': 1.7884111469984054}
{'R_grad_norm': 1.106319665312767, 'training_loss': 1.7995935034751893}
{'R_grad_norm': 1.1073544758558274, 'training_loss': 1.8004590690135955}
{'R_grad_norm': 1.1059956187009812, 'training_loss': 1.8011260688304902}
{'R_grad_norm': 1.1044598466157913, 'training_loss': 1.79528539955616}
{'R_grad_norm': 1.1022131490707396, 'training_loss': 1.8057301485538482}
{'R_grad_norm': 1.1022112143039704, 'training_loss': 1.8012544375658035}
{'R_grad_norm': 1.1000073927640914, 'training_loss': 1.7871247690916061}
{'R_grad_norm': 1.103080752491951, 'training_loss': 1.7974960643053055}
{'R_grad_norm': 1.1029747289419174, 'training_loss': 1.803318532705307}
{'R_grad_norm': 1.096580879688263, 'training_loss': 1.7883515638113021}
{'R_grad_norm': 1.0969275945425034, 'training_loss': 1.7960861945152282}
{'R_grad_norm': 1.0974627417325973, 'training_loss': 1.7923119455575942}
{'R_grad_norm': 1.0972233060002328, 'training_loss': 1.8004903280735016}
{'R_grad_norm': 1.0927401459217072, 'training_loss': 1.79495352268219}
{'R_grad_norm': 1.0935458385944365, 'training_loss': 1.7988500308990478}
{'R_grad_norm': 1.0885476058721542, 'training_loss': 1.791380023956299}
{'R_grad_norm': 1.0875215226411818, 'training_loss': 1.7829243630170821}
{'R_grad_norm': 1.08704170525074, 'training_loss': 1.7816749733686448}
{'R_grad_norm': 1.086751314997673, 'training_loss': 1.8025633758306503}
{'R_grad_norm': 1.0857576781511307, 'training_loss': 1.7926607221364974}
{'R_grad_norm': 1.08688580930233, 'training_loss': 1.791191726922989}
{'R_grad_norm': 1.0824912884831428, 'training_loss': 1.7866449916362763}
{'R_grad_norm': 1.0787495166063308, 'training_loss': 1.7819756996631622}
{'R_grad_norm': 1.0818632179498673, 'training_loss': 1.7916143286228179}
{'R_grad_norm': 1.0771976083517074, 'training_loss': 1.7827357482910156}
{'R_grad_norm': 1.0756867903470992, 'training_loss': 1.78953193962574}
{'R_grad_norm': 1.0776892536878586, 'training_loss': 1.8014802241325378}
{'R_grad_norm': 1.0747043478488922, 'training_loss': 1.7954227739572526}
{'R_grad_norm': 1.0713535514473915, 'training_loss': 1.7888475608825685}
{'R_grad_norm': 1.0673788771033288, 'training_loss': 1.7677061104774474}
{'R_grad_norm': 1.066963443160057, 'training_loss': 1.7812072670459747}
eval result tensor([2.47923, 2.85448, 3.78321, 1.32349, 1.85455, 1.37930, 1.55459, 1.25737,
        0.84724, 1.32858, 1.10873, 1.79262], device='cuda:0')
computing merge metric
normed mi [((3, 6), 0.06573041528463364), ((3, 5), 0.06418727338314056), ((5, 8), 0.06412691374619801), ((8, 10), 0.062411464750766754), ((5, 6), 0.06205030158162117), ((3, 8), 0.05956051250298818), ((4, 8), 0.056700363755226135), ((6, 8), 0.05639889339605967), ((3, 4), 0.05568046122789383), ((4, 5), 0.05521024763584137), ((4, 10), 0.054885158936182656), ((3, 10), 0.054721047480901085), ((4, 6), 0.054334837943315506), ((5, 10), 0.05356884002685547), ((6, 10), 0.05274435877799988), ((9, 11), 0.0514971949160099), ((0, 3), 0.04684016605218252), ((1, 5), 0.04670853912830353), ((0, 6), 0.04631538192431132), ((2, 6), 0.045120233297348024), ((0, 5), 0.044237623612085976), ((1, 3), 0.04404244820276896), ((10, 11), 0.04277988523244858), ((6, 11), 0.04259255031744639), ((1, 6), 0.04257722198963165), ((2, 3), 0.04230952262878418), ((2, 5), 0.04149325489997864), ((3, 11), 0.04098683347304662), ((6, 9), 0.04094408949216207), ((4, 11), 0.04039191703001658), ((8, 11), 0.04011561721563339), ((0, 4), 0.03957382837931315), ((1, 8), 0.039198917150497434), ((5, 11), 0.03838993360598882), ((3, 9), 0.0381918673714002), ((1, 4), 0.03776045640309652), ((5, 9), 0.03754891951878866), ((2, 4), 0.03735015690326691), ((2, 11), 0.0373394675552845), ((0, 8), 0.0370079517364502), ((2, 9), 0.036709003150463104), ((0, 1), 0.03453681245446205), ((0, 10), 0.03447158634662628), ((9, 10), 0.033521685749292374), ((2, 10), 0.03308141976594925), ((0, 2), 0.033027659569467814), ((1, 10), 0.03261570632457733), ((2, 8), 0.03248811140656471), ((8, 9), 0.03195155784487724), ((4, 9), 0.03155220796664556), ((1, 2), 0.030206388660839627), ((0, 11), 0.026931187510490416), ((0, 9), 0.02556224763393402), ((1, 11), 0.022813375294208526), ((1, 9), 0.022763797640800477), ((7, 8), 0.014841395430266857), ((7, 10), 0.013725440949201584), ((5, 7), 0.008405751859148344), ((4, 7), 0.00791774628063043), ((3, 7), 0.007681082934141159), ((6, 7), 0.007499810929099719), ((1, 7), 0.0060420077294111255), ((7, 11), 0.005774360150098801), ((0, 7), 0.004856735095381736), ((7, 9), 0.004602388013154268), ((2, 7), 0.0038258216809481382)]
******* after merging (0.04): [((3, 6), 128), ((0,), 128), ((1,), 128), ((2,), 96), ((4,), 64), ((5,), 64), ((7,), 32), ((8,), 32), ((9,), 32), ((10,), 32), ((11,), 32)]
{'R_grad_norm': 1.185154139995575, 'training_loss': 1.8878587639331819}
{'R_grad_norm': 1.1769211655855178, 'training_loss': 1.883844836950302}
{'R_grad_norm': 1.1815725588798522, 'training_loss': 1.8985008275508881}
{'R_grad_norm': 1.1709045046567916, 'training_loss': 1.8868918150663376}
{'R_grad_norm': 1.1674760216474533, 'training_loss': 1.8895700293779374}
{'R_grad_norm': 1.1721215486526488, 'training_loss': 1.8732727599143981}
{'R_grad_norm': 1.1700256204605102, 'training_loss': 1.9076578772068025}
{'R_grad_norm': 1.1614781624078752, 'training_loss': 1.874309309720993}
{'R_grad_norm': 1.1625905328989028, 'training_loss': 1.875393015742302}
{'R_grad_norm': 1.1586349141597747, 'training_loss': 1.8789712876081466}
{'R_grad_norm': 1.1619653010368347, 'training_loss': 1.8900621140003204}
{'R_grad_norm': 1.1591112238168717, 'training_loss': 1.8713317680358887}
{'R_grad_norm': 1.1558508336544038, 'training_loss': 1.8648043256998061}
{'R_grad_norm': 1.1545559322834016, 'training_loss': 1.88856887280941}
{'R_grad_norm': 1.1587701225280762, 'training_loss': 1.8895893216133117}
{'R_grad_norm': 1.15477895796299, 'training_loss': 1.8712885904312133}
{'R_grad_norm': 1.1551892238855361, 'training_loss': 1.8926963639259338}
{'R_grad_norm': 1.1509388536214828, 'training_loss': 1.8750283640623093}
{'R_grad_norm': 1.151114004254341, 'training_loss': 1.8733213639259338}
{'R_grad_norm': 1.146011888384819, 'training_loss': 1.8646009027957917}
{'R_grad_norm': 1.1474700558185578, 'training_loss': 1.8623048043251038}
{'R_grad_norm': 1.1540715837478637, 'training_loss': 1.8856189048290253}
{'R_grad_norm': 1.1449762123823166, 'training_loss': 1.8724887418746947}
{'R_grad_norm': 1.1447253358364105, 'training_loss': 1.8756107538938522}
{'R_grad_norm': 1.1458571124076844, 'training_loss': 1.8846268725395203}
{'R_grad_norm': 1.1427122843265534, 'training_loss': 1.873997227549553}
{'R_grad_norm': 1.1454997152090072, 'training_loss': 1.8831427109241485}
{'R_grad_norm': 1.1436274594068527, 'training_loss': 1.8703186774253846}
{'R_grad_norm': 1.1372590965032578, 'training_loss': 1.8825856059789658}
{'R_grad_norm': 1.141346265077591, 'training_loss': 1.874774955511093}
{'R_grad_norm': 1.1406249564886093, 'training_loss': 1.8777503615617752}
{'R_grad_norm': 1.1417117619514465, 'training_loss': 1.8749243026971818}
{'R_grad_norm': 1.1359447222948074, 'training_loss': 1.8746672612428665}
{'R_grad_norm': 1.1360625225305556, 'training_loss': 1.8799373304843903}
{'R_grad_norm': 1.131318216919899, 'training_loss': 1.8850605368614197}
{'R_grad_norm': 1.1331019121408463, 'training_loss': 1.8860486823320388}
{'R_grad_norm': 1.1320572453737259, 'training_loss': 1.8810127222537993}
{'R_grad_norm': 1.1301157301664353, 'training_loss': 1.8711663329601287}
{'R_grad_norm': 1.1265834259986878, 'training_loss': 1.8658137315511703}
{'R_grad_norm': 1.1282643562555312, 'training_loss': 1.872894653081894}
eval result tensor([2.34472, 2.52282, 2.77019, 3.73547, 1.76259, 1.23271, 1.25743, 0.84843,
        1.30325, 1.08470, 1.74064], device='cuda:0')
computing merge metric
normed mi [((5, 7), 0.06555851300557454), ((7, 9), 0.0612911581993103), ((4, 7), 0.05692532658576965), ((4, 5), 0.05525655671954155), ((4, 9), 0.0543303390343984), ((5, 9), 0.05354176958401998), ((8, 10), 0.05043856054544449), ((2, 5), 0.04619663953781128), ((1, 5), 0.04316150645414988), ((9, 10), 0.041515570133924484), ((0, 5), 0.03998968998591105), ((1, 4), 0.039652228355407715), ((2, 7), 0.039603999257087706), ((3, 5), 0.03904322683811188), ((4, 10), 0.03878551969925562), ((7, 10), 0.03798405081033707), ((2, 4), 0.03762204945087433), ((1, 7), 0.037022712826728824), ((5, 8), 0.03677512456973394), ((0, 4), 0.03629914174477259), ((5, 10), 0.03628023713827133), ((3, 10), 0.03612804412841797), ((3, 4), 0.03602170944213867), ((3, 8), 0.03597960248589516), ((0, 1), 0.034953489899635315), ((1, 9), 0.034463852643966675), ((1, 2), 0.033905889838933945), ((0, 7), 0.033250349760055545), ((8, 9), 0.03312262147665024), ((0, 3), 0.03227477201393673), ((1, 3), 0.032247109072549004), ((2, 9), 0.03220928013324738), ((3, 9), 0.031978413462638855), ((7, 8), 0.03195999190211296), ((0, 9), 0.03189712166786194), ((3, 7), 0.03141258284449577), ((4, 8), 0.03109092762072881), ((0, 2), 0.030504077672958374), ((2, 3), 0.029252465282167708), ((0, 10), 0.026536062359809875), ((1, 10), 0.02635638415813446), ((1, 8), 0.025604990124702454), ((0, 8), 0.025368461012840272), ((2, 8), 0.022513887286186217), ((2, 10), 0.021959137916564942), ((6, 7), 0.013159200549125671), ((6, 9), 0.012629430741071701), ((5, 6), 0.008336933329701424), ((4, 6), 0.007238871728380521), ((2, 6), 0.005789248272776604), ((6, 10), 0.0056100995279848576), ((6, 8), 0.004721890203654766), ((1, 6), 0.004490620642900467), ((0, 6), 0.0038882501423358916), ((3, 6), 0.003653676016256213)]
******* after merging (0.04): [((0,), 128), ((1,), 128), ((2,), 128), ((5, 7), 96), ((3,), 96), ((4,), 64), ((6,), 32), ((8,), 32), ((9,), 32), ((10,), 32)]
{'R_grad_norm': 1.241806202530861, 'training_loss': 2.034990246295929}
{'R_grad_norm': 1.2349564743041992, 'training_loss': 2.019257931113243}
{'R_grad_norm': 1.2285315483808517, 'training_loss': 2.0302929174900055}
{'R_grad_norm': 1.2290298652648926, 'training_loss': 2.022029523849487}
{'R_grad_norm': 1.2259865033626556, 'training_loss': 2.02365236222744}
{'R_grad_norm': 1.2203093361854553, 'training_loss': 2.009709628224373}
{'R_grad_norm': 1.2201790010929108, 'training_loss': 2.0103927886486055}
{'R_grad_norm': 1.2200156795978545, 'training_loss': 2.032070918679237}
{'R_grad_norm': 1.2196787703037262, 'training_loss': 2.0198680394887925}
{'R_grad_norm': 1.2185350275039672, 'training_loss': 2.020698667168617}
{'R_grad_norm': 1.2127833139896393, 'training_loss': 2.0238669645786285}
{'R_grad_norm': 1.2127691721916198, 'training_loss': 2.027740954756737}
{'R_grad_norm': 1.21178053855896, 'training_loss': 2.0332233095169068}
{'R_grad_norm': 1.2093019622564316, 'training_loss': 2.0210059410333634}
{'R_grad_norm': 1.20770556807518, 'training_loss': 2.0273353546857833}
{'R_grad_norm': 1.2107489424943925, 'training_loss': 2.0322712188959122}
{'R_grad_norm': 1.210377073287964, 'training_loss': 2.037579148411751}
{'R_grad_norm': 1.2032478606700898, 'training_loss': 2.0295214116573335}
{'R_grad_norm': 1.2059809213876724, 'training_loss': 2.0254509943723678}
{'R_grad_norm': 1.2038790053129196, 'training_loss': 2.033756224513054}
{'R_grad_norm': 1.1964960116147996, 'training_loss': 2.0187558513879775}
{'R_grad_norm': 1.202216511964798, 'training_loss': 2.0331381911039355}
{'R_grad_norm': 1.2017472469806671, 'training_loss': 2.0256615293025972}
{'R_grad_norm': 1.199594025015831, 'training_loss': 2.0182924550771713}
{'R_grad_norm': 1.193631385564804, 'training_loss': 2.016437164545059}
{'R_grad_norm': 1.1948152947425843, 'training_loss': 2.023572880625725}
{'R_grad_norm': 1.1950908839702605, 'training_loss': 2.0375522381067275}
{'R_grad_norm': 1.1898338878154755, 'training_loss': 2.022375699877739}
{'R_grad_norm': 1.194727765917778, 'training_loss': 2.0380653500556947}
{'R_grad_norm': 1.1962462395429612, 'training_loss': 2.024432765841484}
{'R_grad_norm': 1.1876556211709977, 'training_loss': 2.023279720544815}
{'R_grad_norm': 1.1912118190526961, 'training_loss': 2.042953887581825}
{'R_grad_norm': 1.1867821449041367, 'training_loss': 2.020456513166428}
{'R_grad_norm': 1.1852064794301986, 'training_loss': 2.0266708087921144}
{'R_grad_norm': 1.1855724048614502, 'training_loss': 2.017016857266426}
{'R_grad_norm': 1.1853936970233918, 'training_loss': 2.017970148921013}
{'R_grad_norm': 1.185129114985466, 'training_loss': 2.0275578933954237}
{'R_grad_norm': 1.1818457269668579, 'training_loss': 2.0203513783216476}
{'R_grad_norm': 1.1852452236413955, 'training_loss': 2.032262114286423}
{'R_grad_norm': 1.181042937040329, 'training_loss': 2.023900141119957}
eval result tensor([2.39781, 2.57376, 2.82025, 1.71689, 3.74669, 1.67501, 1.24402, 1.27802,
        1.05744, 1.72847], device='cuda:0')
computing merge metric
normed mi [((5, 8), 0.05463229616483053), ((7, 9), 0.050479043275117874), ((8, 9), 0.042312368750572205), ((3, 5), 0.0419209212064743), ((1, 5), 0.039195165038108826), ((5, 9), 0.03872293482224146), ((3, 8), 0.03798189386725426), ((2, 5), 0.03779474149147669), ((4, 7), 0.036346435546875), ((2, 3), 0.03615872349057879), ((4, 9), 0.03594374284148216), ((0, 5), 0.03563899795214335), ((1, 3), 0.03469031197684152), ((0, 1), 0.034570395946502686), ((4, 5), 0.03456836938858032), ((1, 8), 0.034259903430938723), ((1, 2), 0.033880457282066345), ((7, 8), 0.03367990255355835), ((0, 3), 0.03254493432385581), ((2, 8), 0.03222431540489197), ((0, 4), 0.03168892860412598), ((1, 4), 0.031678155064582825), ((0, 8), 0.031505617499351504), ((5, 7), 0.0312864159544309), ((4, 8), 0.03083042800426483), ((3, 4), 0.030731551349163055), ((0, 2), 0.030151400715112686), ((2, 4), 0.02868347934314183), ((0, 9), 0.027123573422431945), ((3, 7), 0.027076834812760353), ((1, 9), 0.026837417483329774), ((3, 9), 0.026323260739445686), ((1, 7), 0.025968673825263976), ((0, 7), 0.025963249802589416), ((2, 7), 0.022981373965740202), ((2, 9), 0.02228476107120514), ((6, 8), 0.013404017314314842), ((5, 6), 0.007970830425620079), ((3, 6), 0.0064609902910888195), ((6, 9), 0.006220662035048008), ((2, 6), 0.006154062598943711), ((1, 6), 0.0049016006290912625), ((6, 7), 0.004672736395150423), ((0, 6), 0.004370571672916412), ((4, 6), 0.0038647849578410387)]
******* after merging (0.04): [((0,), 128), ((1,), 128), ((2,), 128), ((5, 8), 96), ((3,), 96), ((4,), 96), ((6,), 32), ((7,), 32), ((9,), 32)]
{'R_grad_norm': 1.3034491956233978, 'training_loss': 2.2080131846666338}
{'R_grad_norm': 1.2941314190626145, 'training_loss': 2.2057661134004594}
{'R_grad_norm': 1.2881701970100403, 'training_loss': 2.188195760846138}
{'R_grad_norm': 1.2897939229011535, 'training_loss': 2.2087562024593352}
{'R_grad_norm': 1.2880305778980254, 'training_loss': 2.200021193623543}
{'R_grad_norm': 1.2838448548316956, 'training_loss': 2.2173536199331285}
{'R_grad_norm': 1.278755310177803, 'training_loss': 2.199091466665268}
{'R_grad_norm': 1.2765664499998093, 'training_loss': 2.1896528542041778}
{'R_grad_norm': 1.2756611621379852, 'training_loss': 2.204269827604294}
{'R_grad_norm': 1.2795134139060975, 'training_loss': 2.2124992376565933}
{'R_grad_norm': 1.2789204305410384, 'training_loss': 2.216462695002556}
{'R_grad_norm': 1.28191519677639, 'training_loss': 2.2326256048679354}
{'R_grad_norm': 1.2762115913629533, 'training_loss': 2.2235127389431}
{'R_grad_norm': 1.2831542307138444, 'training_loss': 2.243665680885315}
{'R_grad_norm': 1.2789748764038087, 'training_loss': 2.2547391402721404}
{'R_grad_norm': 1.2831619256734847, 'training_loss': 2.252779120206833}
{'R_grad_norm': 1.2825079947710036, 'training_loss': 2.2784107339382174}
{'R_grad_norm': 1.2820718371868134, 'training_loss': 2.272705970406532}
{'R_grad_norm': 1.289768431186676, 'training_loss': 2.3097543227672577}
{'R_grad_norm': 1.2865905755758285, 'training_loss': 2.3110230123996733}
{'R_grad_norm': 1.2889078456163405, 'training_loss': 2.334199764728546}
{'R_grad_norm': 1.2960916721820832, 'training_loss': 2.3564281964302065}
{'R_grad_norm': 1.3024007731676102, 'training_loss': 2.3922378504276276}
{'R_grad_norm': 1.3025047039985658, 'training_loss': 2.430464746952057}
{'R_grad_norm': 1.2447021424770355, 'training_loss': 2.2080120569467545}
{'R_grad_norm': 1.245721356868744, 'training_loss': 2.2010743540525435}
{'R_grad_norm': 1.2426323735713958, 'training_loss': 2.19380426466465}
{'R_grad_norm': 1.2426623451709746, 'training_loss': 2.1947806054353713}
{'R_grad_norm': 1.2448019462823867, 'training_loss': 2.2007285034656525}
{'R_grad_norm': 1.2353203290700911, 'training_loss': 2.1766296726465226}
{'R_grad_norm': 1.2362583297491074, 'training_loss': 2.182121439576149}
{'R_grad_norm': 1.2375927650928498, 'training_loss': 2.1870786702632903}
{'R_grad_norm': 1.2381691205501557, 'training_loss': 2.181709430813789}
{'R_grad_norm': 1.2350359630584717, 'training_loss': 2.195875804424286}
{'R_grad_norm': 1.234462930560112, 'training_loss': 2.186526073217392}
{'R_grad_norm': 1.2324347853660584, 'training_loss': 2.186702873110771}
{'R_grad_norm': 1.2331211411952971, 'training_loss': 2.2005627018213274}
{'R_grad_norm': 1.2364027887582778, 'training_loss': 2.2003200459480285}
{'R_grad_norm': 1.2314050608873368, 'training_loss': 2.1849040377140043}
{'R_grad_norm': 1.2309276533126832, 'training_loss': 2.1982691580057145}
finish training (100000)
evaluating (25 steps)...
 ******* eval result *******
mean (weighted) 2.440349578857422
mean (unweighted) 2.193685293197632
tensor([2.38729, 2.55976, 2.76502, 2.38351, 1.69505, 3.76596, 1.23922, 1.25414,
        1.69323], device='cuda:0')
