{'R_grad_norm': 1.7787193304300308, 'training_loss': 12.470222311019898}
{'R_grad_norm': 1.801694421172142, 'training_loss': 12.298128185272217}
{'R_grad_norm': 1.8228050780296325, 'training_loss': 12.1118993806839}
{'R_grad_norm': 1.8369665265083313, 'training_loss': 11.970182614326477}
{'R_grad_norm': 1.8540638047456741, 'training_loss': 11.875890469551086}
{'R_grad_norm': 1.8631834012269974, 'training_loss': 11.767138557434082}
{'R_grad_norm': 1.8689293187856675, 'training_loss': 11.683927240371704}
{'R_grad_norm': 1.8716635155677794, 'training_loss': 11.596301922798157}
{'R_grad_norm': 1.8749584919214248, 'training_loss': 11.52220371723175}
{'R_grad_norm': 1.875373830795288, 'training_loss': 11.453555717468262}
{'R_grad_norm': 1.872520123720169, 'training_loss': 11.346446709632874}
{'R_grad_norm': 1.8756398046016693, 'training_loss': 11.32591628551483}
{'R_grad_norm': 1.8845528489351273, 'training_loss': 11.323314318656921}
{'R_grad_norm': 1.8832353693246842, 'training_loss': 11.250960164070129}
{'R_grad_norm': 1.8824195700883866, 'training_loss': 11.202762761116027}
{'R_grad_norm': 1.8796221494674683, 'training_loss': 11.150968689918518}
{'R_grad_norm': 1.8773762142658235, 'training_loss': 11.082997136116028}
{'R_grad_norm': 1.879456905722618, 'training_loss': 11.058249778747559}
{'R_grad_norm': 1.8826911664009094, 'training_loss': 11.059637150764466}
{'R_grad_norm': 1.8782606726884843, 'training_loss': 10.983051180839539}
{'R_grad_norm': 1.8738739371299744, 'training_loss': 10.940141777992249}
{'R_grad_norm': 1.8729275661706923, 'training_loss': 10.920577211380005}
{'R_grad_norm': 1.865360248684883, 'training_loss': 10.872345504760743}
{'R_grad_norm': 1.8750746458768845, 'training_loss': 10.900750432014465}
{'R_grad_norm': 1.8654738783836364, 'training_loss': 10.808505606651305}
{'R_grad_norm': 1.869570580124855, 'training_loss': 10.833981628417968}
{'R_grad_norm': 1.861289649605751, 'training_loss': 10.777476854324341}
{'R_grad_norm': 1.8607555502653121, 'training_loss': 10.735171155929566}
{'R_grad_norm': 1.8566720169782638, 'training_loss': 10.713293132781983}
{'R_grad_norm': 1.8649365544319152, 'training_loss': 10.722762145996093}
{'R_grad_norm': 1.8634658366441728, 'training_loss': 10.720740551948547}
{'R_grad_norm': 1.8604499638080596, 'training_loss': 10.702910194396972}
{'R_grad_norm': 1.8597945922613144, 'training_loss': 10.66717634677887}
{'R_grad_norm': 1.8562380599975585, 'training_loss': 10.64182631969452}
{'R_grad_norm': 1.853939307332039, 'training_loss': 10.641290006637574}
{'R_grad_norm': 1.8500743466615677, 'training_loss': 10.579237389564515}
{'R_grad_norm': 1.8545364236831665, 'training_loss': 10.613636498451234}
{'R_grad_norm': 1.8552903878688811, 'training_loss': 10.59130428791046}
{'R_grad_norm': 1.8495297688245773, 'training_loss': 10.563499336242677}
{'R_grad_norm': 1.8471900629997253, 'training_loss': 10.54960319519043}
{'R_grad_norm': 1.8483950835466385, 'training_loss': 10.564499402046204}
{'R_grad_norm': 1.8494776636362076, 'training_loss': 10.543550715446472}
{'R_grad_norm': 1.8456121790409088, 'training_loss': 10.497916479110717}
{'R_grad_norm': 1.8443292462825776, 'training_loss': 10.521550388336182}
{'R_grad_norm': 1.8403556835651398, 'training_loss': 10.480784487724303}
{'R_grad_norm': 1.8399926710128784, 'training_loss': 10.45789535522461}
{'R_grad_norm': 1.8424588024616242, 'training_loss': 10.476000003814697}
{'R_grad_norm': 1.8421322494745254, 'training_loss': 10.466056318283082}
{'R_grad_norm': 1.8431091302633285, 'training_loss': 10.484547142982484}
{'R_grad_norm': 1.8381456142663957, 'training_loss': 10.432713313102722}
{'R_grad_norm': 1.8380538874864578, 'training_loss': 10.440657620429993}
{'R_grad_norm': 1.8317925894260407, 'training_loss': 10.38646746635437}
{'R_grad_norm': 1.8385295629501344, 'training_loss': 10.423453450202942}
{'R_grad_norm': 1.8352346235513688, 'training_loss': 10.399868955612183}
{'R_grad_norm': 1.8334150528907776, 'training_loss': 10.394522895812988}
{'R_grad_norm': 1.8353276735544204, 'training_loss': 10.408800511360168}
{'R_grad_norm': 1.8269954186677932, 'training_loss': 10.356992616653443}
{'R_grad_norm': 1.830217712521553, 'training_loss': 10.367168011665344}
{'R_grad_norm': 1.8306252950429915, 'training_loss': 10.366006622314453}
{'R_grad_norm': 1.8325413197278977, 'training_loss': 10.388182888031006}
{'R_grad_norm': 1.8307306963205336, 'training_loss': 10.344140591621398}
{'R_grad_norm': 1.823628135919571, 'training_loss': 10.322611756324768}
{'R_grad_norm': 1.8300498509407044, 'training_loss': 10.373282022476197}
{'R_grad_norm': 1.8260667943954467, 'training_loss': 10.329837279319763}
{'R_grad_norm': 1.8231895333528518, 'training_loss': 10.309048652648926}
{'R_grad_norm': 1.8250659877061843, 'training_loss': 10.320568652153016}
{'R_grad_norm': 1.8204839038848877, 'training_loss': 10.295277581214904}
{'R_grad_norm': 1.8233482098579408, 'training_loss': 10.294692378044129}
{'R_grad_norm': 1.823391973376274, 'training_loss': 10.308766770362855}
{'R_grad_norm': 1.8204662418365478, 'training_loss': 10.295003786087037}
{'R_grad_norm': 1.826878940463066, 'training_loss': 10.327494277954102}
{'R_grad_norm': 1.8224183464050292, 'training_loss': 10.311162185668945}
{'R_grad_norm': 1.8160631686449051, 'training_loss': 10.253500247001648}
{'R_grad_norm': 1.821724492907524, 'training_loss': 10.280319828987121}
{'R_grad_norm': 1.8191937398910523, 'training_loss': 10.286888275146485}
{'R_grad_norm': 1.8155839973688126, 'training_loss': 10.256589922904968}
{'R_grad_norm': 1.8173762381076812, 'training_loss': 10.264842963218689}
{'R_grad_norm': 1.8167550671100616, 'training_loss': 10.28866099357605}
{'R_grad_norm': 1.813789781332016, 'training_loss': 10.245300555229187}
{'R_grad_norm': 1.811364695429802, 'training_loss': 10.219180607795716}
{'R_grad_norm': 1.818168315887451, 'training_loss': 10.282627143859862}
{'R_grad_norm': 1.8148423862457275, 'training_loss': 10.254900913238526}
{'R_grad_norm': 1.8104089295864105, 'training_loss': 10.221499667167663}
{'R_grad_norm': 1.8104968446493148, 'training_loss': 10.213895063400269}
{'R_grad_norm': 1.8156008571386337, 'training_loss': 10.253713755607604}
{'R_grad_norm': 1.8146139395236969, 'training_loss': 10.249469518661499}
{'R_grad_norm': 1.8080422115325927, 'training_loss': 10.214364261627198}
{'R_grad_norm': 1.8086901223659515, 'training_loss': 10.220092477798461}
{'R_grad_norm': 1.8118366241455077, 'training_loss': 10.23139723777771}
{'R_grad_norm': 1.8050925099849702, 'training_loss': 10.192004461288452}
{'R_grad_norm': 1.804415819644928, 'training_loss': 10.200963468551636}
{'R_grad_norm': 1.808316730260849, 'training_loss': 10.221397271156311}
{'R_grad_norm': 1.808350558280945, 'training_loss': 10.21585000038147}
{'R_grad_norm': 1.8108632457256317, 'training_loss': 10.221969094276428}
{'R_grad_norm': 1.8027723747491837, 'training_loss': 10.17185929775238}
{'R_grad_norm': 1.8089173501729965, 'training_loss': 10.197463564872741}
{'R_grad_norm': 1.803275557756424, 'training_loss': 10.162195901870728}
{'R_grad_norm': 1.8028605031967162, 'training_loss': 10.176111416816711}
{'R_grad_norm': 1.802693892121315, 'training_loss': 10.18611976146698}
{'R_grad_norm': 1.7985684442520142, 'training_loss': 10.137840332984924}
eval result tensor([ 9.24287, 10.47673, 10.06148, 10.52944,  8.52239, 10.57987, 10.86500,
         9.98633, 10.48881,  9.33385,  9.20359, 10.28308, 10.64780, 11.24728,
        11.68428, 10.32094, 10.01303,  7.87050, 10.96842, 10.46113,  7.44909,
        12.18553, 10.14807, 11.24075], device='cuda:0')
computing merge metric
normed mi [((17, 20), 0.10813798010349274), ((9, 20), 0.09895976632833481), ((9, 12), 0.091107077896595), ((0, 20), 0.08965015411376953), ((9, 17), 0.08872676640748978), ((12, 20), 0.08716325461864471), ((0, 9), 0.08558473736047745), ((4, 20), 0.08307921141386032), ((0, 17), 0.08256470412015915), ((12, 22), 0.07906267046928406), ((9, 22), 0.07847334444522858), ((0, 12), 0.07568918913602829), ((12, 17), 0.07423482835292816), ((5, 22), 0.07379616051912308), ((3, 9), 0.0734245553612709), ((4, 17), 0.0724422037601471), ((4, 9), 0.07234939187765121), ((9, 19), 0.07182234525680542), ((20, 22), 0.07176079601049423), ((3, 12), 0.07175450772047043), ((10, 20), 0.0712914913892746), ((19, 22), 0.07066222280263901), ((12, 19), 0.06946689635515213), ((0, 22), 0.06916642189025879), ((4, 12), 0.06908894330263138), ((5, 12), 0.0690840631723404), ((0, 3), 0.06820465624332428), ((3, 22), 0.06789683550596237), ((5, 9), 0.06682748347520828), ((3, 20), 0.06607300788164139), ((10, 17), 0.06606332212686539), ((9, 10), 0.06544620543718338), ((19, 20), 0.06532738357782364), ((0, 10), 0.06496336311101913), ((17, 22), 0.0626545175909996), ((9, 16), 0.06248932331800461), ((5, 19), 0.062366340309381485), ((0, 16), 0.062284667044878006), ((0, 4), 0.06203548610210419), ((3, 5), 0.0619998574256897), ((0, 19), 0.06139931082725525), ((7, 10), 0.06131322309374809), ((7, 20), 0.060437530279159546), ((3, 17), 0.06007014960050583), ((16, 22), 0.060048386454582214), ((3, 19), 0.0598391555249691), ((12, 16), 0.059266429394483566), ((16, 21), 0.058676350861787796), ((10, 16), 0.058391544967889786), ((12, 21), 0.057942941784858704), ((3, 16), 0.0577114038169384), ((21, 23), 0.057658419013023376), ((17, 19), 0.057512953877449036), ((16, 20), 0.05735495314002037), ((0, 5), 0.05729137361049652), ((3, 10), 0.057039812207221985), ((7, 9), 0.056956272572278976), ((0, 7), 0.05695086717605591), ((10, 22), 0.05683451518416405), ((5, 20), 0.056584689766168594), ((5, 16), 0.05603329837322235), ((0, 21), 0.05578644946217537), ((16, 19), 0.05574746057391167), ((7, 16), 0.055299289524555206), ((10, 12), 0.05504468455910683), ((7, 17), 0.05488341674208641), ((10, 19), 0.05461897328495979), ((4, 22), 0.054217882454395294), ((9, 23), 0.0538017675280571), ((12, 23), 0.05364476516842842), ((9, 21), 0.05339396744966507), ((11, 22), 0.05336293578147888), ((9, 11), 0.05324053764343262), ((11, 19), 0.05320142209529877), ((1, 16), 0.05319011211395264), ((3, 23), 0.05315570533275604), ((3, 21), 0.05298767611384392), ((16, 17), 0.05293511226773262), ((1, 10), 0.05292887985706329), ((0, 23), 0.05271574854850769), ((10, 21), 0.0525955855846405), ((1, 7), 0.0524635836482048), ((7, 22), 0.05212604999542236), ((18, 21), 0.05133279040455818), ((20, 21), 0.051130276173353195), ((3, 11), 0.05106884241104126), ((3, 7), 0.05105605348944664), ((11, 16), 0.05075572058558464), ((10, 11), 0.05075389891862869), ((7, 19), 0.05046602711081505), ((5, 11), 0.05041125789284706), ((1, 22), 0.05037769302725792), ((6, 7), 0.05011846870183945), ((5, 17), 0.050117433071136475), ((5, 10), 0.05007081851363182), ((22, 23), 0.04979002848267555), ((19, 21), 0.04963017255067825), ((0, 11), 0.0495893619954586), ((1, 3), 0.049417369067668915), ((1, 19), 0.04931462183594704), ((7, 21), 0.04911203309893608), ((4, 19), 0.04910498857498169), ((7, 11), 0.049065668135881424), ((6, 18), 0.04898383095860481), ((21, 22), 0.04884660616517067), ((16, 23), 0.048796553164720535), ((1, 9), 0.04865621030330658), ((7, 18), 0.048381734639406204), ((11, 20), 0.048374127596616745), ((6, 14), 0.04836936295032501), ((7, 12), 0.048355549573898315), ((14, 21), 0.048207201063632965), ((14, 18), 0.04793613776564598), ((1, 11), 0.0478300042450428), ((20, 23), 0.0477936826646328), ((1, 5), 0.04766874387860298), ((11, 12), 0.047526683658361435), ((3, 4), 0.047270238399505615), ((6, 10), 0.0472114272415638), ((17, 21), 0.047013409435749054), ((7, 14), 0.046866390854120255), ((14, 16), 0.04678810387849808), ((19, 23), 0.04675864055752754), ((5, 21), 0.04665163531899452), ((5, 7), 0.046572912484407425), ((16, 18), 0.046445924788713455), ((3, 14), 0.04627997428178787), ((0, 1), 0.046165674924850464), ((1, 6), 0.046101439744234085), ((1, 14), 0.0460515171289444), ((10, 18), 0.04595724120736122), ((1, 8), 0.04583929479122162), ((8, 16), 0.04560719430446625), ((6, 16), 0.04549206793308258), ((10, 23), 0.04540419578552246), ((5, 23), 0.045373834669589996), ((14, 23), 0.045045699924230576), ((4, 5), 0.04504498466849327), ((8, 14), 0.04501166567206383), ((7, 23), 0.0448090024292469), ((10, 14), 0.04472998157143593), ((1, 18), 0.04459569975733757), ((7, 8), 0.04455320164561272), ((18, 23), 0.044505774974823), ((11, 17), 0.04443885385990143), ((17, 23), 0.044066790491342545), ((9, 14), 0.04405577480792999), ((14, 22), 0.043850988149642944), ((6, 8), 0.04371953383088112), ((8, 18), 0.0436357744038105), ((1, 20), 0.04341956973075867), ((12, 14), 0.043276455253362656), ((5, 14), 0.043228816241025925), ((6, 21), 0.043219856917858124), ((1, 21), 0.04319002106785774), ((8, 10), 0.042737238109111786), ((0, 14), 0.04244164377450943), ((1, 12), 0.04239537566900253), ((6, 9), 0.04225316271185875), ((4, 10), 0.04210695996880531), ((8, 21), 0.04210548475384712), ((11, 21), 0.04183248057961464), ((0, 6), 0.04176900163292885), ((3, 6), 0.04143775254487991), ((6, 23), 0.04136281833052635), ((3, 18), 0.041299447417259216), ((0, 18), 0.041250601410865784), ((9, 18), 0.04107436537742615), ((1, 23), 0.041065316647291183), ((1, 17), 0.040782298892736435), ((11, 23), 0.04059221222996712), ((6, 22), 0.040554650127887726), ((6, 20), 0.03998939320445061), ((6, 11), 0.039966192096471786), ((11, 14), 0.03957070782780647), ((14, 19), 0.039365775883197784), ((3, 8), 0.03925453498959541), ((4, 16), 0.03923613578081131), ((18, 22), 0.03920430317521095), ((11, 18), 0.03909730911254883), ((8, 22), 0.038851696997880936), ((5, 8), 0.038844380527734756), ((18, 20), 0.038826834410429), ((8, 11), 0.03860185667872429), ((6, 19), 0.03844309598207474), ((5, 6), 0.03840671852231026), ((12, 18), 0.0384061262011528), ((14, 20), 0.037883415818214417), ((18, 19), 0.03786817565560341), ((8, 23), 0.037850841879844666), ((12, 13), 0.03783676028251648), ((5, 18), 0.03739773482084274), ((6, 12), 0.03715754300355911), ((0, 8), 0.03701568767428398), ((8, 9), 0.03693150356411934), ((6, 17), 0.036813702434301376), ((8, 19), 0.036176085472106934), ((17, 18), 0.0360717847943306), ((8, 12), 0.035352397710084915), ((4, 7), 0.035040199756622314), ((4, 11), 0.03495055064558983), ((4, 21), 0.0348648838698864), ((14, 17), 0.034037236124277115), ((8, 20), 0.03319774940609932), ((4, 23), 0.03255506604909897), ((4, 13), 0.0321577750146389), ((13, 20), 0.03086383454501629), ((8, 17), 0.030531758442521095), ((13, 15), 0.02858927473425865), ((1, 4), 0.028294039890170097), ((9, 13), 0.028065131977200508), ((4, 15), 0.02635475993156433), ((13, 17), 0.02544480562210083), ((4, 14), 0.025051964446902275), ((4, 6), 0.024825671687722206), ((4, 18), 0.02421725168824196), ((13, 22), 0.022822124883532524), ((2, 12), 0.02259042300283909), ((0, 13), 0.022454390302300453), ((4, 8), 0.021698856726288795), ((13, 19), 0.021671682596206665), ((12, 15), 0.021211659535765648), ((2, 21), 0.02102627046406269), ((13, 21), 0.020826786756515503), ((15, 20), 0.020715536549687386), ((5, 13), 0.020458688959479332), ((2, 5), 0.02039453200995922), ((2, 19), 0.01971840299665928), ((3, 13), 0.019513960927724838), ((2, 22), 0.019004443660378456), ((2, 4), 0.018908504396677017), ((2, 17), 0.01883521117269993), ((2, 9), 0.01858173869550228), ((2, 20), 0.018161987885832787), ((0, 2), 0.01730107143521309), ((13, 23), 0.017180096358060837), ((15, 17), 0.016948355361819267), ((2, 16), 0.01665026694536209), ((9, 15), 0.016250303015112877), ((13, 16), 0.016176089644432068), ((2, 3), 0.01599893346428871), ((2, 11), 0.015358743257820606), ((2, 23), 0.015222749672830105), ((10, 13), 0.014751686714589596), ((2, 10), 0.014691145159304142), ((2, 7), 0.013798754662275314), ((11, 13), 0.013637295924127102), ((2, 13), 0.01358576025813818), ((2, 18), 0.013115131296217442), ((15, 19), 0.013111152686178684), ((7, 13), 0.013005675747990608), ((2, 14), 0.01288814190775156), ((15, 22), 0.01250852644443512), ((0, 15), 0.012310834601521492), ((1, 2), 0.01226114109158516), ((2, 8), 0.012040261179208755), ((2, 6), 0.011882764287292957), ((2, 15), 0.011697575449943542), ((5, 15), 0.011676670052111149), ((13, 14), 0.011651917360723019), ((13, 18), 0.011381749995052814), ((1, 13), 0.011339455842971802), ((15, 21), 0.010242623277008533), ((6, 13), 0.01018975954502821), ((8, 13), 0.009761716239154339), ((3, 15), 0.009371846914291382), ((15, 16), 0.008266658522188663), ((10, 15), 0.008015786297619343), ((11, 15), 0.0075528970919549465), ((15, 23), 0.007533067837357521), ((7, 15), 0.006423597224056721), ((1, 15), 0.005434470716863871), ((15, 18), 0.005159627180546522), ((14, 15), 0.004991360008716583), ((6, 15), 0.004711410962045193), ((8, 15), 0.004397118464112282)]
******* after merging (0.04): [((17, 20), 64), ((9, 12), 64), ((5, 22), 64), ((0,), 32), ((1,), 32), ((2,), 32), ((3,), 32), ((4,), 32), ((6,), 32), ((7,), 32), ((8,), 32), ((10,), 32), ((11,), 32), ((13,), 32), ((14,), 32), ((15,), 32), ((16,), 32), ((18,), 32), ((19,), 32), ((21,), 32), ((23,), 32)]
{'R_grad_norm': 2.2525051581859588, 'training_loss': 11.083521370887757}
{'R_grad_norm': 2.2492444455623626, 'training_loss': 11.062333402633667}
{'R_grad_norm': 2.254695290327072, 'training_loss': 11.06992908000946}
{'R_grad_norm': 2.2578460109233855, 'training_loss': 11.092650799751281}
{'R_grad_norm': 2.2548508536815643, 'training_loss': 11.052593574523925}
{'R_grad_norm': 2.257665852308273, 'training_loss': 11.056892390251159}
{'R_grad_norm': 2.2524432170391084, 'training_loss': 11.031840224266052}
{'R_grad_norm': 2.252069990634918, 'training_loss': 11.029399132728576}
{'R_grad_norm': 2.251578801870346, 'training_loss': 11.044875946044922}
{'R_grad_norm': 2.247255928516388, 'training_loss': 11.031607923507691}
{'R_grad_norm': 2.2487507593631744, 'training_loss': 11.040994701385499}
{'R_grad_norm': 2.246138849258423, 'training_loss': 11.004233379364013}
{'R_grad_norm': 2.24917125582695, 'training_loss': 11.023898782730102}
{'R_grad_norm': 2.24677419424057, 'training_loss': 11.020904259681702}
{'R_grad_norm': 2.245896544456482, 'training_loss': 11.032583966255189}
{'R_grad_norm': 2.2459980809688567, 'training_loss': 10.995789189338684}
{'R_grad_norm': 2.2384068393707275, 'training_loss': 10.984562263488769}
{'R_grad_norm': 2.243418357372284, 'training_loss': 11.0293341255188}
{'R_grad_norm': 2.2418908536434174, 'training_loss': 10.991331243515015}
{'R_grad_norm': 2.242562711238861, 'training_loss': 10.999525532722473}
{'R_grad_norm': 2.234824242591858, 'training_loss': 10.950192203521729}
{'R_grad_norm': 2.237334064245224, 'training_loss': 10.968303461074829}
{'R_grad_norm': 2.2337730073928834, 'training_loss': 10.965254878997802}
{'R_grad_norm': 2.2334792017936707, 'training_loss': 10.961272430419921}
{'R_grad_norm': 2.235663012266159, 'training_loss': 10.96817373752594}
{'R_grad_norm': 2.235366485118866, 'training_loss': 10.971977405548095}
{'R_grad_norm': 2.22899982213974, 'training_loss': 10.93924958229065}
{'R_grad_norm': 2.2281955003738405, 'training_loss': 10.939693765640259}
{'R_grad_norm': 2.225802947282791, 'training_loss': 10.936653656959534}
{'R_grad_norm': 2.2288111662864685, 'training_loss': 10.952522978782653}
{'R_grad_norm': 2.2170027446746827, 'training_loss': 10.87974416255951}
{'R_grad_norm': 2.227953679561615, 'training_loss': 10.935835304260253}
{'R_grad_norm': 2.2285826027393343, 'training_loss': 10.95646192073822}
{'R_grad_norm': 2.218767658472061, 'training_loss': 10.928447585105896}
{'R_grad_norm': 2.2178690993785857, 'training_loss': 10.895376000404358}
{'R_grad_norm': 2.218139698505402, 'training_loss': 10.918104286193847}
{'R_grad_norm': 2.220209140777588, 'training_loss': 10.924967498779298}
{'R_grad_norm': 2.2182939302921296, 'training_loss': 10.913659348487855}
{'R_grad_norm': 2.2198839354515076, 'training_loss': 10.917862401008605}
{'R_grad_norm': 2.214073704481125, 'training_loss': 10.899144477844239}
eval result tensor([11.52781, 17.24071, 18.29270,  8.54888, 10.12231,  9.88767, 10.00962,
         8.04856, 10.72935,  9.62777, 10.22557,  8.65009,  9.95012, 10.88404,
        11.40068, 10.14708,  9.74076, 10.72555, 10.26726, 11.80640, 11.00221],
       device='cuda:0')
computing merge metric
normed mi [((0, 3), 0.06796494126319885), ((3, 11), 0.06737060099840164), ((3, 6), 0.0660114660859108), ((3, 7), 0.0606578066945076), ((3, 16), 0.06024406477808952), ((1, 3), 0.059627532958984375), ((9, 11), 0.059304751455783844), ((3, 18), 0.05837719887495041), ((3, 9), 0.058222491294145584), ((16, 19), 0.05676693469285965), ((19, 20), 0.05471470206975937), ((0, 1), 0.05462335795164108), ((1, 6), 0.05435525874296824), ((6, 18), 0.05434393137693405), ((11, 16), 0.054180506616830826), ((6, 16), 0.05404055118560791), ((0, 7), 0.054016138116518654), ((3, 19), 0.05389966443181038), ((0, 11), 0.05372201402982076), ((6, 11), 0.053360793739557266), ((1, 18), 0.0526131788889567), ((16, 18), 0.05229324847459793), ((4, 11), 0.051761966198682785), ((11, 18), 0.05136001855134964), ((12, 18), 0.051162976771593094), ((9, 16), 0.05060165375471115), ((1, 2), 0.05012248456478119), ((3, 20), 0.050059594213962555), ((3, 12), 0.05002269521355629), ((4, 9), 0.04996875673532486), ((6, 20), 0.04990692064166069), ((2, 6), 0.04929585258165995), ((6, 19), 0.04928012192249298), ((4, 16), 0.049190323799848557), ((6, 9), 0.04917037859559059), ((18, 19), 0.04889380931854248), ((11, 19), 0.04865555092692375), ((2, 18), 0.04856919745604197), ((17, 19), 0.048472389578819275), ((9, 18), 0.04820087179541588), ((0, 6), 0.048197334011395775), ((1, 7), 0.0480818102757136), ((4, 18), 0.04799693450331688), ((6, 12), 0.047519054263830185), ((8, 9), 0.04747333377599716), ((11, 12), 0.04738341644406319), ((2, 3), 0.04734232028325399), ((4, 6), 0.04723428562283516), ((3, 4), 0.047231271862983704), ((12, 16), 0.047159839421510696), ((0, 18), 0.047026097774505615), ((8, 14), 0.04688867926597595), ((1, 16), 0.04676826298236847), ((8, 17), 0.04670900106430054), ((7, 18), 0.04649119824171066), ((14, 17), 0.046326227486133575), ((9, 17), 0.0457758754491806), ((9, 19), 0.0454535186290741), ((6, 14), 0.0454145222902298), ((8, 11), 0.04540378600358963), ((16, 20), 0.04504471272230148), ((14, 20), 0.04499557986855507), ((14, 19), 0.04498059302568436), ((0, 9), 0.04485719402631124), ((1, 19), 0.04481638967990875), ((2, 16), 0.044807215531667076), ((6, 7), 0.044774994254112244), ((9, 14), 0.04455099627375603), ((1, 11), 0.044259682297706604), ((9, 12), 0.04396707937121391), ((10, 16), 0.043829891830682755), ((4, 10), 0.043774474412202835), ((11, 17), 0.043694835156202316), ((14, 16), 0.04361352697014809), ((4, 12), 0.04354751482605934), ((16, 17), 0.04351671412587166), ((4, 8), 0.04309655725955963), ((18, 20), 0.04301290586590767), ((10, 11), 0.042928244918584824), ((1, 20), 0.042779227097829185), ((10, 14), 0.042766232043504715), ((11, 14), 0.04259687662124634), ((3, 14), 0.04251684993505478), ((8, 16), 0.042502354830503464), ((17, 20), 0.04236629232764244), ((9, 10), 0.042282141745090485), ((4, 14), 0.04224729910492897), ((9, 20), 0.04200168699026108), ((3, 8), 0.04197372496128082), ((0, 16), 0.04173184931278229), ((10, 17), 0.041277237236499786), ((11, 20), 0.04125162586569786), ((8, 10), 0.04122816026210785), ((7, 11), 0.0411987230181694), ((3, 17), 0.04103769361972809), ((2, 11), 0.04060343404610952), ((1, 9), 0.04040343562761942), ((6, 8), 0.04036179557442665), ((4, 17), 0.04029528424143791), ((8, 20), 0.04027646407485008), ((2, 12), 0.04001472642024358), ((1, 12), 0.0400060291091601), ((8, 19), 0.039965879172086716), ((0, 2), 0.03980695456266403), ((4, 19), 0.0397794134914875), ((10, 19), 0.039440594613552094), ((12, 19), 0.039388056844472885), ((2, 4), 0.03892322132984797), ((0, 19), 0.038781498869260154), ((6, 10), 0.038764506578445435), ((6, 17), 0.03873908519744873), ((2, 9), 0.0387242908279101), ((7, 16), 0.03844746947288513), ((14, 18), 0.03793029859662056), ((3, 10), 0.03792707249522209), ((0, 12), 0.037915890415509544), ((2, 19), 0.037823066115379333), ((8, 18), 0.037498269230127335), ((7, 12), 0.03736869990825653), ((7, 19), 0.037338774651288986), ((4, 20), 0.03730786591768265), ((1, 14), 0.03695815056562424), ((12, 20), 0.03682916983962059), ((8, 12), 0.03657282516360283), ((2, 14), 0.03639598687489828), ((2, 20), 0.036391024788220726), ((12, 14), 0.03596004843711853), ((10, 12), 0.03591316565871239), ((7, 9), 0.035694222897291183), ((17, 18), 0.035649750381708145), ((10, 18), 0.03564012050628662), ((10, 20), 0.03557879477739334), ((12, 17), 0.035569991916418076), ((0, 20), 0.035378205279509224), ((1, 4), 0.03490061312913895), ((0, 4), 0.03348626693089803), ((2, 7), 0.03301645815372467), ((2, 10), 0.03261051823695501), ((1, 8), 0.03239805748065313), ((2, 8), 0.032375949124495186), ((7, 20), 0.03205939382314682), ((1, 17), 0.03167899946371714), ((7, 13), 0.031581901013851166), ((2, 17), 0.03058583289384842), ((7, 15), 0.030250273644924164), ((1, 10), 0.02995692938566208), ((0, 8), 0.02993985762198766), ((0, 14), 0.02948414037624995), ((4, 7), 0.029228638857603073), ((13, 15), 0.029168684035539627), ((0, 17), 0.028357235093911488), ((7, 14), 0.02590242773294449), ((7, 8), 0.025846298784017563), ((0, 10), 0.02525351196527481), ((7, 17), 0.024897562339901924), ((13, 19), 0.022983970120549202), ((5, 19), 0.022536978125572205), ((7, 10), 0.022508816793560982), ((1, 13), 0.02168405055999756), ((3, 13), 0.02164122462272644), ((13, 18), 0.02120385318994522), ((6, 13), 0.019355734810233116), ((0, 13), 0.018817272037267685), ((13, 20), 0.01821570284664631), ((5, 7), 0.017006374895572662), ((5, 18), 0.016820546239614487), ((13, 16), 0.016571829095482826), ((5, 16), 0.016298403963446617), ((15, 18), 0.015907542780041695), ((3, 5), 0.01558875385671854), ((15, 19), 0.015175062231719494), ((5, 20), 0.015095788985490799), ((5, 13), 0.015087251551449299), ((5, 6), 0.015063428319990635), ((1, 5), 0.014854208876689276), ((2, 13), 0.014778637637694677), ((5, 15), 0.01469874382019043), ((11, 13), 0.014592926949262619), ((12, 13), 0.014582406729459763), ((0, 15), 0.01449709509809812), ((3, 15), 0.014406287111341953), ((5, 12), 0.01393883302807808), ((1, 15), 0.01371238629023234), ((9, 13), 0.013630200177431107), ((5, 11), 0.012952234596014023), ((13, 14), 0.012841790914535522), ((5, 9), 0.012663964182138443), ((5, 17), 0.012633332051336765), ((0, 5), 0.012553336719671885), ((5, 14), 0.012503701262176037), ((2, 5), 0.01249266043305397), ((4, 13), 0.011937322095036507), ((13, 17), 0.01186918094754219), ((5, 10), 0.011616219766438007), ((5, 8), 0.011588326655328274), ((4, 5), 0.011520523577928543), ((6, 15), 0.011174236424267292), ((8, 13), 0.011115496046841145), ((12, 15), 0.010946563445031643), ((15, 16), 0.010715367272496223), ((10, 13), 0.01039808802306652), ((15, 20), 0.009985647164285183), ((11, 15), 0.009588291868567467), ((2, 15), 0.008705023055275282), ((9, 15), 0.00838344357907772), ((4, 15), 0.00707171531394124), ((15, 17), 0.006615641992539167), ((14, 15), 0.00657559372484684), ((8, 15), 0.006069366354495287), ((10, 15), 0.005692728795111179)]
******* after merging (0.04): [((0, 3), 96), ((9, 11), 64), ((1,), 64), ((2,), 64), ((4,), 32), ((5,), 32), ((6,), 32), ((7,), 32), ((8,), 32), ((10,), 32), ((12,), 32), ((13,), 32), ((14,), 32), ((15,), 32), ((16,), 32), ((17,), 32), ((18,), 32), ((19,), 32), ((20,), 32)]
{'R_grad_norm': 2.382703102827072, 'training_loss': 11.632871279716491}
{'R_grad_norm': 2.381857479810715, 'training_loss': 11.624986734390259}
{'R_grad_norm': 2.3787085855007173, 'training_loss': 11.596131434440613}
{'R_grad_norm': 2.3815190052986144, 'training_loss': 11.624102759361268}
{'R_grad_norm': 2.380186755657196, 'training_loss': 11.623938446044923}
{'R_grad_norm': 2.3800799655914306, 'training_loss': 11.62460464000702}
{'R_grad_norm': 2.3789424979686737, 'training_loss': 11.603556056022644}
{'R_grad_norm': 2.385663424730301, 'training_loss': 11.623704681396484}
{'R_grad_norm': 2.385569919347763, 'training_loss': 11.620092158317567}
{'R_grad_norm': 2.4029273164272307, 'training_loss': 11.711932854652405}
{'R_grad_norm': 2.4022365486621857, 'training_loss': 11.686901507377625}
{'R_grad_norm': 2.4151417434215547, 'training_loss': 11.765415630340577}
{'R_grad_norm': 2.42213561296463, 'training_loss': 11.78231083393097}
{'R_grad_norm': 2.4256155467033387, 'training_loss': 11.792700810432434}
{'R_grad_norm': 2.43038192152977, 'training_loss': 11.8203533411026}
{'R_grad_norm': 2.4386070358753202, 'training_loss': 11.832802920341491}
{'R_grad_norm': 2.44808562040329, 'training_loss': 11.881927933692932}
{'R_grad_norm': 2.4573798298835756, 'training_loss': 11.91299774646759}
{'R_grad_norm': 2.4654707503318787, 'training_loss': 11.979714555740356}
{'R_grad_norm': 2.479780000448227, 'training_loss': 12.026256403923036}
{'R_grad_norm': 2.4885358035564424, 'training_loss': 12.084296026229858}
{'R_grad_norm': 2.5114105379581453, 'training_loss': 12.189698123931885}
{'R_grad_norm': 2.4072665929794312, 'training_loss': 11.713723583221435}
{'R_grad_norm': 2.343775485754013, 'training_loss': 11.398807001113891}
{'R_grad_norm': 2.342022202014923, 'training_loss': 11.408709473609925}
{'R_grad_norm': 2.340381146669388, 'training_loss': 11.40398051738739}
{'R_grad_norm': 2.342328315973282, 'training_loss': 11.426359310150147}
{'R_grad_norm': 2.34607447385788, 'training_loss': 11.421938705444337}
{'R_grad_norm': 2.342006596326828, 'training_loss': 11.426573600769043}
{'R_grad_norm': 2.34434326171875, 'training_loss': 11.432355904579163}
{'R_grad_norm': 2.3416848254203795, 'training_loss': 11.426259384155273}
{'R_grad_norm': 2.3430013918876647, 'training_loss': 11.433373136520386}
{'R_grad_norm': 2.336768243312836, 'training_loss': 11.410640358924866}
{'R_grad_norm': 2.341471050977707, 'training_loss': 11.429289808273316}
{'R_grad_norm': 2.3339802265167235, 'training_loss': 11.413121490478515}
{'R_grad_norm': 2.339565930366516, 'training_loss': 11.442262835502625}
{'R_grad_norm': 2.335439190864563, 'training_loss': 11.397967491149902}
{'R_grad_norm': 2.328019814491272, 'training_loss': 11.37039388179779}
{'R_grad_norm': 2.3398395454883576, 'training_loss': 11.433496785163879}
{'R_grad_norm': 2.338193484544754, 'training_loss': 11.457853846549988}
eval result tensor([15.71909, 15.20066, 17.31233, 18.31949,  9.68942,  9.64474,  9.49349,
         7.46615, 10.53168,  9.91797,  9.60101, 10.57783, 11.12493,  9.91633,
         9.44777, 10.36620,  9.79429, 11.35177, 10.62884], device='cuda:0')
computing merge metric
normed mi [((14, 17), 0.05771513655781746), ((17, 18), 0.05425367131829262), ((6, 14), 0.05420726165175438), ((14, 16), 0.0521155521273613), ((2, 16), 0.051067223151524864), ((6, 16), 0.051009852439165115), ((4, 6), 0.05052943900227547), ((2, 6), 0.0495270440975825), ((4, 14), 0.04951252415776253), ((10, 16), 0.04901726543903351), ((16, 17), 0.04896889626979828), ((8, 12), 0.048923950642347336), ((2, 3), 0.048920854926109314), ((8, 15), 0.048656098544597626), ((6, 18), 0.048446886241436005), ((3, 6), 0.048273866375287376), ((4, 16), 0.048184365034103394), ((12, 15), 0.047819025814533234), ((6, 17), 0.04780972748994827), ((3, 16), 0.047310054302215576), ((15, 17), 0.04644915834069252), ((6, 10), 0.04636676236987114), ((14, 18), 0.04635752737522125), ((6, 12), 0.0462915264070034), ((2, 14), 0.04627552628517151), ((10, 14), 0.0460779033601284), ((9, 14), 0.045192573219537735), ((3, 14), 0.045135512948036194), ((12, 18), 0.044928327202796936), ((2, 17), 0.04475997885068258), ((4, 9), 0.04455263167619705), ((2, 18), 0.043734028935432434), ((12, 17), 0.043538834899663925), ((16, 18), 0.04353101924061775), ((4, 10), 0.0432482585310936), ((12, 14), 0.043154146522283554), ((1, 4), 0.043118556340535484), ((0, 2), 0.043099284172058105), ((14, 15), 0.04298636317253113), ((6, 9), 0.042885083705186844), ((9, 12), 0.04287781938910484), ((6, 8), 0.04190332442522049), ((9, 15), 0.04186967760324478), ((8, 14), 0.04184421896934509), ((4, 8), 0.041640568524599075), ((15, 18), 0.04164033383131027), ((8, 9), 0.04144006595015526), ((4, 12), 0.04143249988555908), ((2, 7), 0.040980237225691475), ((1, 14), 0.040615888933340706), ((3, 4), 0.04055023938417435), ((8, 18), 0.04043760150671005), ((4, 15), 0.0403282530605793), ((6, 15), 0.040269460529088974), ((9, 17), 0.04015997797250748), ((1, 6), 0.04008811960617701), ((4, 17), 0.04008157551288605), ((8, 17), 0.03955385833978653), ((10, 17), 0.0395464263856411), ((3, 10), 0.03927654524644216), ((7, 16), 0.03926321119070053), ((2, 10), 0.03889345129330953), ((1, 8), 0.038824486235777535), ((0, 6), 0.03880474343895912), ((8, 16), 0.037978388369083405), ((1, 16), 0.037957899272441864), ((3, 17), 0.03780701011419296), ((1, 15), 0.037783230344454445), ((12, 16), 0.037757113575935364), ((9, 16), 0.037644531577825546), ((3, 12), 0.03749081492424011), ((0, 16), 0.037305790930986404), ((4, 18), 0.03729846701025963), ((9, 10), 0.03717948868870735), ((2, 12), 0.03717438876628876), ((8, 10), 0.037031300365924835), ((10, 18), 0.036921124905347824), ((0, 14), 0.03669307753443718), ((9, 18), 0.036596473306417465), ((1, 9), 0.03648427873849869), ((1, 17), 0.036455427606900535), ((3, 18), 0.03641015042861303), ((0, 1), 0.03627634644508362), ((1, 12), 0.03617875029643377), ((10, 12), 0.03590034320950508), ((0, 3), 0.035730060935020444), ((3, 9), 0.03554835170507431), ((1, 3), 0.03526466712355614), ((15, 16), 0.03518754243850708), ((1, 10), 0.03514431913693746), ((10, 15), 0.035071227699518204), ((2, 4), 0.03456997871398926), ((7, 17), 0.03437332436442375), ((7, 14), 0.03403087705373764), ((7, 11), 0.03340550884604454), ((3, 8), 0.03330051898956299), ((6, 7), 0.03290482237935066), ((2, 8), 0.032797363897164665), ((1, 2), 0.03256583213806152), ((0, 17), 0.03230585902929306), ((7, 10), 0.03176167234778404), ((0, 10), 0.031510286033153534), ((2, 15), 0.03136018166939417), ((3, 15), 0.031321197748184204), ((7, 13), 0.031178580597043037), ((2, 9), 0.031007337073485058), ((0, 4), 0.030847670510411263), ((1, 18), 0.030587201317151386), ((0, 18), 0.030364669859409332), ((11, 13), 0.029962221160531044), ((7, 18), 0.02949061244726181), ((0, 7), 0.02826020121574402), ((0, 8), 0.026653224602341652), ((0, 12), 0.026419438421726227), ((3, 7), 0.025959983468055725), ((4, 7), 0.025750504806637764), ((0, 15), 0.02512877620756626), ((0, 9), 0.0243205726146698), ((5, 17), 0.023302942514419556), ((7, 12), 0.02253861352801323), ((7, 8), 0.02213440090417862), ((11, 17), 0.021854393184185028), ((7, 9), 0.0208889152854681), ((7, 15), 0.02078196033835411), ((1, 7), 0.020174247523148853), ((2, 11), 0.020125204076369602), ((11, 16), 0.019364966079592705), ((11, 18), 0.01769498735666275), ((5, 14), 0.01748187281191349), ((5, 16), 0.017301388084888458), ((5, 7), 0.01688724383711815), ((11, 14), 0.016276301816105843), ((5, 18), 0.016183963045477867), ((2, 5), 0.015884815404812496), ((6, 11), 0.01576034538447857), ((5, 6), 0.014568413607776165), ((5, 10), 0.01438059750944376), ((5, 11), 0.01380813680589199), ((10, 11), 0.013508498668670654), ((5, 12), 0.013345648534595966), ((13, 17), 0.013265551999211311), ((13, 16), 0.013118628412485123), ((5, 15), 0.013116377405822277), ((3, 5), 0.013077124953269958), ((5, 9), 0.012987181544303894), ((3, 11), 0.012777191897233328), ((4, 5), 0.012666316702961922), ((5, 8), 0.012098095379769802), ((11, 12), 0.01201528962701559), ((4, 11), 0.01182450819760561), ((5, 13), 0.011605280451476574), ((0, 11), 0.01121504046022892), ((2, 13), 0.01119697093963623), ((11, 15), 0.01098904199898243), ((8, 11), 0.010836184024810791), ((9, 11), 0.010136433877050877), ((13, 14), 0.009643585421144962), ((0, 5), 0.009587764739990234), ((1, 5), 0.009163865198691687), ((10, 13), 0.00903746671974659), ((13, 18), 0.0085704755038023), ((1, 11), 0.008307723328471184), ((6, 13), 0.007522944826632738), ((3, 13), 0.006597996999820073), ((4, 13), 0.006445426028221846), ((0, 13), 0.006365468259900808), ((12, 13), 0.005388476885855198), ((13, 15), 0.005264014936983585), ((8, 13), 0.0051965853199362755), ((9, 13), 0.0051748198457062244), ((1, 13), 0.004339128732681274)]
******* after merging (0.04): [((2, 16), 96), ((0,), 96), ((14, 17), 64), ((1,), 64), ((3,), 64), ((4,), 32), ((5,), 32), ((6,), 32), ((7,), 32), ((8,), 32), ((9,), 32), ((10,), 32), ((11,), 32), ((12,), 32), ((13,), 32), ((15,), 32), ((18,), 32)]
{'R_grad_norm': 2.4995453643798826, 'training_loss': 12.226667771339416}
{'R_grad_norm': 2.498534747362137, 'training_loss': 12.219231123924255}
{'R_grad_norm': 2.5014877247810365, 'training_loss': 12.221276545524598}
{'R_grad_norm': 2.504969444274902, 'training_loss': 12.251460123062134}
{'R_grad_norm': 2.497438428401947, 'training_loss': 12.194202189445496}
{'R_grad_norm': 2.4940494883060453, 'training_loss': 12.163486046791077}
{'R_grad_norm': 2.48775403380394, 'training_loss': 12.140737419128419}
{'R_grad_norm': 2.489757843017578, 'training_loss': 12.153533897399903}
{'R_grad_norm': 2.4893926680088043, 'training_loss': 12.160753355026245}
{'R_grad_norm': 2.4932329154014585, 'training_loss': 12.167193121910095}
{'R_grad_norm': 2.491669603586197, 'training_loss': 12.155657358169556}
{'R_grad_norm': 2.495807546377182, 'training_loss': 12.188648309707641}
{'R_grad_norm': 2.492456783056259, 'training_loss': 12.157115020751952}
{'R_grad_norm': 2.49557665348053, 'training_loss': 12.190638556480408}
{'R_grad_norm': 2.4891811490058897, 'training_loss': 12.136691551208497}
{'R_grad_norm': 2.4895171797275544, 'training_loss': 12.163087720870971}
{'R_grad_norm': 2.4880386424064636, 'training_loss': 12.171002726554871}
{'R_grad_norm': 2.484979521036148, 'training_loss': 12.14751992225647}
{'R_grad_norm': 2.483988010883331, 'training_loss': 12.121728229522706}
{'R_grad_norm': 2.4874479711055755, 'training_loss': 12.13928364276886}
{'R_grad_norm': 2.486492558717728, 'training_loss': 12.14717752456665}
{'R_grad_norm': 2.485771623849869, 'training_loss': 12.130458998680115}
{'R_grad_norm': 2.4833940875530245, 'training_loss': 12.141749773025513}
{'R_grad_norm': 2.4853718972206114, 'training_loss': 12.12650020122528}
{'R_grad_norm': 2.4810519874095918, 'training_loss': 12.124464135169983}
{'R_grad_norm': 2.481796374320984, 'training_loss': 12.127976818084717}
{'R_grad_norm': 2.4824919438362123, 'training_loss': 12.109466676712037}
{'R_grad_norm': 2.483532197475433, 'training_loss': 12.131497278213502}
{'R_grad_norm': 2.4801837682723997, 'training_loss': 12.11400876045227}
{'R_grad_norm': 2.4743778347969054, 'training_loss': 12.104913611412048}
{'R_grad_norm': 2.47419175863266, 'training_loss': 12.104759283065796}
{'R_grad_norm': 2.4765466690063476, 'training_loss': 12.087508344650269}
{'R_grad_norm': 2.4731460225582125, 'training_loss': 12.102526659965514}
{'R_grad_norm': 2.4780707931518555, 'training_loss': 12.132576713562012}
{'R_grad_norm': 2.4777779400348665, 'training_loss': 12.120350847244262}
{'R_grad_norm': 2.4683441483974455, 'training_loss': 12.097780022621155}
{'R_grad_norm': 2.469714012145996, 'training_loss': 12.078695731163025}
{'R_grad_norm': 2.4698513209819795, 'training_loss': 12.09232497215271}
{'R_grad_norm': 2.471186282634735, 'training_loss': 12.110779185295105}
{'R_grad_norm': 2.46875461935997, 'training_loss': 12.100168976783753}
eval result tensor([24.47699, 15.27470, 18.71470, 14.53599, 17.51110,  9.18274,  9.46161,
         9.03990,  7.12943, 10.28217,  9.54146,  9.20654, 10.24800, 10.86320,
         9.65939,  9.96138, 10.17463], device='cuda:0')
computing merge metric
normed mi [((5, 7), 0.05300183966755867), ((9, 13), 0.048626869916915894), ((9, 15), 0.04812885820865631), ((7, 11), 0.04765471816062927), ((13, 15), 0.04683784395456314), ((4, 7), 0.04585424562295278), ((5, 11), 0.04567403718829155), ((7, 13), 0.04491409286856651), ((5, 10), 0.04436272010207176), ((3, 5), 0.04425852497418722), ((7, 10), 0.044207751750946045), ((13, 16), 0.044195011258125305), ((3, 7), 0.04419369498888651), ((7, 16), 0.042414259165525436), ((7, 9), 0.04238668456673622), ((0, 4), 0.04144873321056366), ((10, 13), 0.04091409221291542), ((4, 5), 0.040480936566988625), ((9, 16), 0.04031617194414139), ((5, 9), 0.04028023034334183), ((10, 15), 0.04023530334234238), ((9, 10), 0.040232591331005096), ((15, 16), 0.040229182690382004), ((7, 15), 0.04012063518166542), ((5, 13), 0.03986722230911255), ((2, 16), 0.03951141486565272), ((5, 15), 0.03857527673244476), ((3, 11), 0.03804247329632441), ((3, 9), 0.038026362657547), ((0, 7), 0.03801492974162102), ((5, 16), 0.03794369101524353), ((10, 11), 0.03782316669821739), ((0, 1), 0.03771441181500753), ((1, 3), 0.03771375715732574), ((2, 7), 0.03763719399770101), ((4, 11), 0.037516641120115914), ((9, 11), 0.037507180124521255), ((2, 15), 0.03724673887093862), ((3, 10), 0.03681103388468424), ((1, 7), 0.036388836801052094), ((3, 15), 0.03632106383641561), ((7, 8), 0.03608442842960358), ((11, 13), 0.03588585555553436), ((2, 5), 0.035765682657559715), ((10, 16), 0.035639531910419464), ((3, 4), 0.03558667004108429), ((11, 15), 0.03548295050859451), ((2, 3), 0.03527716174721718), ((3, 13), 0.03521469235420227), ((1, 8), 0.035211142152547836), ((11, 16), 0.035075023770332336), ((4, 13), 0.035055642326672874), ((1, 4), 0.03496734201908112), ((2, 10), 0.0349211518963178), ((2, 13), 0.03481730818748474), ((2, 4), 0.03445776551961899), ((8, 14), 0.034430693835020065), ((0, 16), 0.03428460657596588), ((4, 16), 0.0342580129702886), ((0, 2), 0.03407775163650513), ((4, 10), 0.033942125737667084), ((8, 12), 0.03341364860534668), ((0, 3), 0.03322552144527435), ((8, 11), 0.03313747048377991), ((2, 9), 0.03273898114760717), ((0, 11), 0.03240497410297394), ((5, 8), 0.03223758563399315), ((0, 5), 0.031987257301807404), ((2, 11), 0.03188617527484894), ((4, 9), 0.03169303387403488), ((1, 5), 0.031652696430683136), ((3, 16), 0.03160507728656133), ((0, 13), 0.031420495361089706), ((8, 16), 0.031354933977127075), ((1, 11), 0.031238919124007225), ((12, 14), 0.029700739309191704), ((1, 16), 0.029649240896105766), ((4, 15), 0.02951575567324956), ((1, 2), 0.02928233742713928), ((4, 8), 0.028947246571381886), ((0, 9), 0.028307000175118446), ((0, 8), 0.02762441523373127), ((0, 10), 0.026974298059940338), ((0, 15), 0.026673542335629463), ((3, 8), 0.02632623662551244), ((1, 9), 0.026003243401646614), ((8, 9), 0.02599220909178257), ((1, 13), 0.025668537244200706), ((8, 13), 0.025451602414250374), ((8, 15), 0.024498097598552704), ((2, 8), 0.024376004934310913), ((1, 15), 0.024144848808646202), ((1, 10), 0.023861760273575783), ((8, 10), 0.023494848981499672), ((12, 16), 0.01878363825380802), ((6, 8), 0.016755716875195503), ((7, 12), 0.016074353829026222), ((6, 14), 0.015932679176330566), ((2, 6), 0.0158867451051871), ((6, 12), 0.014822829514741898), ((4, 12), 0.014579365650812784), ((2, 12), 0.014542518804470697), ((6, 16), 0.014440049417316914), ((0, 12), 0.014189799316227436), ((11, 12), 0.014016947709023952), ((5, 12), 0.013811696320772171), ((6, 7), 0.013465785421431065), ((12, 13), 0.013329904526472092), ((1, 12), 0.01328091137111187), ((4, 6), 0.013111655910809835), ((6, 11), 0.012599525973200798), ((6, 13), 0.01259311381727457), ((5, 6), 0.012505589053034782), ((6, 15), 0.012305689975619316), ((12, 15), 0.01204872690141201), ((9, 12), 0.012028380297124386), ((6, 9), 0.011778746731579304), ((14, 16), 0.01163677778095007), ((6, 10), 0.01152739953249693), ((10, 12), 0.01122495997697115), ((11, 14), 0.011174963787198067), ((7, 14), 0.010652313008904457), ((0, 6), 0.010583534836769104), ((4, 14), 0.010410826653242111), ((5, 14), 0.01026410236954689), ((3, 12), 0.009975933159391085), ((1, 14), 0.009890281595289707), ((1, 6), 0.009690933860838413), ((2, 14), 0.009368333344658216), ((3, 6), 0.009094867234428724), ((0, 14), 0.008817898109555244), ((13, 14), 0.008025787770748138), ((9, 14), 0.007537558674812317), ((14, 15), 0.007468192372471094), ((10, 14), 0.007009919732809067), ((3, 14), 0.006632133076588313)]
******* after merging (0.04): [((0,), 96), ((1,), 96), ((5, 7), 64), ((9, 13), 64), ((2,), 64), ((3,), 64), ((4,), 64), ((6,), 32), ((8,), 32), ((10,), 32), ((11,), 32), ((12,), 32), ((14,), 32), ((15,), 32), ((16,), 32)]
{'R_grad_norm': 2.612578545808792, 'training_loss': 13.209955744743347}
{'R_grad_norm': 2.6097605383396147, 'training_loss': 13.200843968391418}
{'R_grad_norm': 2.608608024120331, 'training_loss': 13.186774988174438}
{'R_grad_norm': 2.609867413043976, 'training_loss': 13.221418490409851}
{'R_grad_norm': 2.613396998643875, 'training_loss': 13.233603496551513}
{'R_grad_norm': 2.6079766952991488, 'training_loss': 13.18729097366333}
{'R_grad_norm': 2.607174746990204, 'training_loss': 13.183602828979492}
{'R_grad_norm': 2.6073351562023164, 'training_loss': 13.216553316116332}
{'R_grad_norm': 2.600565792322159, 'training_loss': 13.167773938179016}
{'R_grad_norm': 2.600842161178589, 'training_loss': 13.145935893058777}
{'R_grad_norm': 2.6042736804485322, 'training_loss': 13.187396035194396}
{'R_grad_norm': 2.600126336812973, 'training_loss': 13.158200497627258}
{'R_grad_norm': 2.5990217053890228, 'training_loss': 13.153235778808593}
{'R_grad_norm': 2.604137947559357, 'training_loss': 13.17390998363495}
{'R_grad_norm': 2.596061352491379, 'training_loss': 13.13227400302887}
{'R_grad_norm': 2.594665858745575, 'training_loss': 13.125994391441345}
{'R_grad_norm': 2.592765017747879, 'training_loss': 13.114962887763976}
{'R_grad_norm': 2.594503583908081, 'training_loss': 13.106708240509032}
{'R_grad_norm': 2.595341156721115, 'training_loss': 13.149844727516175}
{'R_grad_norm': 2.5903279519081117, 'training_loss': 13.097982153892517}
{'R_grad_norm': 2.5902306628227234, 'training_loss': 13.134201927185059}
{'R_grad_norm': 2.590198415517807, 'training_loss': 13.124412660598756}
{'R_grad_norm': 2.5893104159832, 'training_loss': 13.108301720619203}
{'R_grad_norm': 2.5880703020095823, 'training_loss': 13.102793002128601}
{'R_grad_norm': 2.584620807170868, 'training_loss': 13.123652386665345}
{'R_grad_norm': 2.5787044954299927, 'training_loss': 13.070873918533325}
{'R_grad_norm': 2.5895226335525514, 'training_loss': 13.115710067749024}
{'R_grad_norm': 2.585102149248123, 'training_loss': 13.121016011238098}
{'R_grad_norm': 2.5861868488788606, 'training_loss': 13.12715784549713}
{'R_grad_norm': 2.5842755389213563, 'training_loss': 13.1465904712677}
{'R_grad_norm': 2.585435165166855, 'training_loss': 13.146475043296814}
{'R_grad_norm': 2.5828330767154695, 'training_loss': 13.129726138114929}
{'R_grad_norm': 2.5831008458137514, 'training_loss': 13.124508609771729}
{'R_grad_norm': 2.5758817172050477, 'training_loss': 13.099213705062866}
{'R_grad_norm': 2.5779780840873716, 'training_loss': 13.094023594856262}
{'R_grad_norm': 2.5816910529136656, 'training_loss': 13.119259400367737}
{'R_grad_norm': 2.5756939685344697, 'training_loss': 13.140635986328125}
{'R_grad_norm': 2.5790840458869932, 'training_loss': 13.123369374275207}
{'R_grad_norm': 2.5778359246253966, 'training_loss': 13.13612488269806}
{'R_grad_norm': 2.5726042664051056, 'training_loss': 13.089172902107238}
eval result tensor([25.16342, 14.94535, 15.33460, 18.35525, 18.86731, 13.48198, 16.65209,
         9.36171,  6.89889,  9.16204,  8.83090,  9.94988,  9.38292,  9.33668,
         9.53188], device='cuda:0')
computing merge metric
normed mi [((2, 5), 0.042358994483947754), ((9, 13), 0.040802180767059326), ((1, 5), 0.04071226119995117), ((0, 6), 0.04030281007289886), ((5, 10), 0.039407879114151), ((13, 14), 0.03855515271425247), ((4, 14), 0.038354491194089256), ((9, 10), 0.03806345537304878), ((3, 13), 0.03788613776365916), ((2, 9), 0.03760855893294016), ((2, 6), 0.03749160096049309), ((5, 9), 0.03697748730580012), ((0, 1), 0.03684340417385101), ((6, 10), 0.036580175161361694), ((5, 6), 0.036534883081912994), ((9, 14), 0.036259185522794724), ((1, 8), 0.03621143475174904), ((2, 10), 0.036166831851005554), ((10, 14), 0.03586571291089058), ((10, 13), 0.03576894477009773), ((5, 13), 0.03570063163836797), ((4, 13), 0.035555546482404075), ((4, 5), 0.03544088453054428), ((1, 6), 0.034923937916755673), ((0, 5), 0.03452524542808533), ((4, 9), 0.034281350672245026), ((0, 14), 0.034084904938936234), ((8, 12), 0.03405199572443962), ((6, 14), 0.03381070991357168), ((8, 11), 0.03334135189652443), ((8, 10), 0.03329242020845413), ((6, 9), 0.033180964489777885), ((5, 14), 0.033170320093631744), ((4, 6), 0.03315451741218567), ((0, 4), 0.03299027681350708), ((2, 13), 0.03273708621660868), ((2, 4), 0.032384373247623444), ((3, 9), 0.03216691563526789), ((0, 10), 0.03191475570201874), ((1, 10), 0.03160605952143669), ((0, 2), 0.031468096375465396), ((4, 10), 0.030829439560572307), ((3, 5), 0.03078741393983364), ((3, 14), 0.030541251103083294), ((8, 14), 0.030538517981767654), ((2, 3), 0.030392974615097046), ((1, 2), 0.03024580180644989), ((1, 14), 0.02988751418888569), ((2, 14), 0.02983374148607254), ((3, 10), 0.02923891693353653), ((3, 4), 0.029199298471212387), ((5, 8), 0.029147421320279438), ((11, 12), 0.02909550629556179), ((3, 6), 0.028977539390325546), ((6, 13), 0.028896125654379528), ((0, 3), 0.028544625639915465), ((1, 4), 0.02843039333820343), ((6, 8), 0.02828150490919749), ((0, 9), 0.02740197628736496), ((0, 13), 0.02626718021929264), ((0, 8), 0.025298897176980972), ((1, 3), 0.02438187152147293), ((1, 13), 0.024067511782050133), ((1, 9), 0.023970171809196472), ((8, 13), 0.02362966164946556), ((8, 9), 0.023505598306655884), ((4, 8), 0.023332777122656505), ((2, 8), 0.023106778661410015), ((3, 8), 0.019408824543158214), ((11, 14), 0.01717163249850273), ((7, 8), 0.01646612398326397), ((7, 12), 0.016387563198804855), ((4, 7), 0.01567587877313296), ((7, 11), 0.015018485486507416), ((6, 11), 0.014294595768054327), ((4, 11), 0.01423285280664762), ((10, 11), 0.01422145590186119), ((7, 14), 0.01367286778986454), ((1, 11), 0.013636822812259197), ((0, 11), 0.013402084819972515), ((7, 10), 0.012961788102984428), ((6, 7), 0.012960972885290781), ((7, 13), 0.011853929609060287), ((7, 9), 0.01183919794857502), ((11, 13), 0.011757503263652325), ((10, 12), 0.011178497225046158), ((9, 11), 0.011120902374386787), ((5, 11), 0.010982926934957504), ((12, 14), 0.010510631836950779), ((6, 12), 0.010401826972762743), ((1, 12), 0.01022650208324194), ((1, 7), 0.01007815357297659), ((0, 7), 0.009858365170657635), ((5, 7), 0.009670447558164597), ((2, 11), 0.009613610804080963), ((2, 7), 0.009276167179147402), ((4, 12), 0.009062677000959715), ((3, 7), 0.008136256908377012), ((0, 12), 0.007719927933067083), ((5, 12), 0.007459675893187523), ((9, 12), 0.007037757430225611), ((12, 13), 0.0069618127308785915), ((2, 12), 0.006447512035568555), ((3, 11), 0.006359968334436417), ((3, 12), 0.0047103166580200195)]
******* after merging (0.04): [((2, 5), 128), ((0,), 96), ((1,), 96), ((3,), 64), ((4,), 64), ((6,), 64), ((7,), 32), ((8,), 32), ((9,), 32), ((10,), 32), ((11,), 32), ((12,), 32), ((13,), 32), ((14,), 32)]
{'R_grad_norm': 2.7201745498180387, 'training_loss': 13.54446813583374}
{'R_grad_norm': 2.711544774770737, 'training_loss': 13.490708861351013}
{'R_grad_norm': 2.717602376937866, 'training_loss': 13.516616034507752}
{'R_grad_norm': 2.719268947839737, 'training_loss': 13.516321339607238}
{'R_grad_norm': 2.712554831504822, 'training_loss': 13.506273283958436}
{'R_grad_norm': 2.7124354684352876, 'training_loss': 13.49785647392273}
{'R_grad_norm': 2.71126550078392, 'training_loss': 13.511765751838684}
{'R_grad_norm': 2.7149077212810515, 'training_loss': 13.512411308288574}
{'R_grad_norm': 2.716473574638367, 'training_loss': 13.498356838226318}
{'R_grad_norm': 2.711571139097214, 'training_loss': 13.493098697662354}
{'R_grad_norm': 2.705116685628891, 'training_loss': 13.452916646003723}
{'R_grad_norm': 2.708117858171463, 'training_loss': 13.473122458457947}
{'R_grad_norm': 2.70831689953804, 'training_loss': 13.493623065948487}
{'R_grad_norm': 2.708091125488281, 'training_loss': 13.446734433174134}
{'R_grad_norm': 2.708435673713684, 'training_loss': 13.448201813697814}
{'R_grad_norm': 2.7066890943050383, 'training_loss': 13.482602033615112}
{'R_grad_norm': 2.7031823766231535, 'training_loss': 13.447354955673218}
{'R_grad_norm': 2.7074850857257844, 'training_loss': 13.483427419662476}
{'R_grad_norm': 2.7046541571617126, 'training_loss': 13.471545343399049}
{'R_grad_norm': 2.7062668764591216, 'training_loss': 13.483187808990479}
{'R_grad_norm': 2.709091053009033, 'training_loss': 13.512280325889588}
{'R_grad_norm': 2.6971986830234527, 'training_loss': 13.445026278495789}
{'R_grad_norm': 2.693461229801178, 'training_loss': 13.432486381530762}
{'R_grad_norm': 2.6985157537460327, 'training_loss': 13.448369846343994}
{'R_grad_norm': 2.699772049188614, 'training_loss': 13.474230470657348}
{'R_grad_norm': 2.6961042535305024, 'training_loss': 13.449263277053833}
{'R_grad_norm': 2.697525843381882, 'training_loss': 13.482080192565919}
{'R_grad_norm': 2.690700291395187, 'training_loss': 13.43531048297882}
{'R_grad_norm': 2.6974739956855776, 'training_loss': 13.45350504875183}
{'R_grad_norm': 2.6847286891937254, 'training_loss': 13.38843237876892}
{'R_grad_norm': 2.6984723234176635, 'training_loss': 13.459554038047791}
{'R_grad_norm': 2.6816308641433717, 'training_loss': 13.410035815238952}
{'R_grad_norm': 2.682143977880478, 'training_loss': 13.366535139083862}
{'R_grad_norm': 2.686618185043335, 'training_loss': 13.42647949695587}
{'R_grad_norm': 2.694634610414505, 'training_loss': 13.471416006088257}
{'R_grad_norm': 2.6851956462860107, 'training_loss': 13.41494972705841}
{'R_grad_norm': 2.686720846891403, 'training_loss': 13.446183185577393}
{'R_grad_norm': 2.6801209008693694, 'training_loss': 13.42511203765869}
{'R_grad_norm': 2.6842101776599883, 'training_loss': 13.443074169158935}
{'R_grad_norm': 2.679265115261078, 'training_loss': 13.411334500312805}
eval result tensor([25.03707, 24.95278, 14.63696, 18.30744, 18.66143, 16.04105,  9.28260,
         6.86603,  8.80231,  8.56825,  9.73013,  9.21766,  8.76222,  9.00952],
       device='cuda:0')
computing merge metric
normed mi [((8, 12), 0.04056110233068466), ((8, 9), 0.039426837116479874), ((1, 5), 0.03931135535240173), ((9, 13), 0.03745784983038902), ((8, 13), 0.03717680647969246), ((4, 13), 0.03691632300615311), ((1, 2), 0.0360783189535141), ((9, 12), 0.03602440655231476), ((2, 5), 0.03496142625808716), ((5, 9), 0.03494155903657278), ((12, 13), 0.03428732603788376), ((3, 12), 0.03407031297683716), ((5, 13), 0.033998534083366394), ((2, 7), 0.033488284796476364), ((4, 8), 0.03346598893404007), ((5, 8), 0.03341400623321533), ((1, 13), 0.03329255431890488), ((7, 10), 0.03316185623407364), ((4, 12), 0.033075121541817985), ((7, 11), 0.03276332467794418), ((2, 9), 0.03189340606331825), ((1, 4), 0.03189338445663452), ((4, 5), 0.031183084473013878), ((2, 13), 0.030941899865865707), ((1, 9), 0.030757848173379898), ((7, 9), 0.02986595407128334), ((3, 8), 0.029835276305675507), ((4, 9), 0.02937331795692444), ((1, 3), 0.029145854711532592), ((7, 13), 0.02912731282413006), ((3, 13), 0.029096705218156178), ((3, 9), 0.02902083347241084), ((10, 11), 0.02854580618441105), ((3, 4), 0.028158605098724365), ((3, 5), 0.028144966810941696), ((2, 4), 0.027353912591934204), ((1, 8), 0.027327395975589752), ((5, 12), 0.02681537965933482), ((5, 7), 0.026109687983989716), ((0, 8), 0.02549917995929718), ((2, 8), 0.025097031146287918), ((2, 3), 0.02478119432926178), ((1, 12), 0.024057108908891678), ((0, 5), 0.024048311014970142), ((0, 4), 0.023726704219977062), ((0, 12), 0.023569005727767944), ((2, 12), 0.023423366248607635), ((0, 2), 0.023345979196684703), ((0, 9), 0.02245005816221237), ((1, 7), 0.022400015965104103), ((0, 1), 0.022364114012037004), ((7, 8), 0.021914634853601456), ((7, 12), 0.02052866667509079), ((4, 7), 0.020439268400271732), ((0, 3), 0.02031747003396352), ((3, 7), 0.018366826077302296), ((0, 13), 0.01720421016216278), ((4, 6), 0.015566488107045492), ((6, 7), 0.015423157252371311), ((10, 13), 0.014058796688914299), ((6, 13), 0.013254182413220406), ((6, 10), 0.01305177342146635), ((5, 6), 0.012923998137315115), ((6, 11), 0.012573303654789925), ((6, 9), 0.012412459589540958), ((0, 7), 0.012326698750257492), ((5, 10), 0.012253581235806147), ((4, 10), 0.012063700705766678), ((2, 10), 0.011990102007985115), ((9, 10), 0.01166680920869112), ((6, 8), 0.01147620752453804), ((1, 10), 0.011382058262825012), ((6, 12), 0.010482540354132652), ((2, 6), 0.010104487650096416), ((1, 6), 0.009749217890202999), ((8, 10), 0.009335142560303211), ((10, 12), 0.008454635739326477), ((3, 6), 0.008344667653242746), ((2, 11), 0.00794683862477541), ((5, 11), 0.007822208727399508), ((9, 11), 0.007665055338293314), ((11, 13), 0.0074663301929831505), ((4, 11), 0.006565021971861522), ((3, 10), 0.005810583010315895), ((1, 11), 0.0054308390244841576), ((8, 11), 0.005357114598155022), ((0, 6), 0.0050785597413778305), ((11, 12), 0.004651451483368874), ((0, 10), 0.004648886993527413), ((3, 11), 0.0035024418806036315), ((0, 11), 0.0025304250419139864)]
******* after merging (0.04): [((0,), 128), ((1,), 96), ((2,), 96), ((8, 12), 64), ((3,), 64), ((4,), 64), ((5,), 64), ((6,), 32), ((7,), 32), ((9,), 32), ((10,), 32), ((11,), 32), ((13,), 32)]
{'R_grad_norm': 2.7699494886398317, 'training_loss': 14.209739804267883}
{'R_grad_norm': 2.772096222639084, 'training_loss': 14.210450210571288}
{'R_grad_norm': 2.7617429947853087, 'training_loss': 14.182403626441955}
{'R_grad_norm': 2.7636717212200166, 'training_loss': 14.184155330657958}
{'R_grad_norm': 2.7662351739406588, 'training_loss': 14.184437074661254}
{'R_grad_norm': 2.7704702544212343, 'training_loss': 14.224850010871886}
{'R_grad_norm': 2.766247606277466, 'training_loss': 14.200030875205993}
{'R_grad_norm': 2.766936355829239, 'training_loss': 14.216208243370057}
{'R_grad_norm': 2.7770102536678314, 'training_loss': 14.272561831474304}
{'R_grad_norm': 2.778832858800888, 'training_loss': 14.254662380218505}
{'R_grad_norm': 2.7843447744846346, 'training_loss': 14.27424262046814}
{'R_grad_norm': 2.801245391368866, 'training_loss': 14.401977319717407}
{'R_grad_norm': 2.7956843268871308, 'training_loss': 14.342627844810487}
{'R_grad_norm': 2.8082694470882417, 'training_loss': 14.426566090583801}
{'R_grad_norm': 2.8229874074459076, 'training_loss': 14.504064512252807}
{'R_grad_norm': 2.8257468688488006, 'training_loss': 14.524600939750671}
{'R_grad_norm': 2.8413114178180696, 'training_loss': 14.570711736679078}
{'R_grad_norm': 2.853053057193756, 'training_loss': 14.689047460556031}
{'R_grad_norm': 2.8659731101989747, 'training_loss': 14.724546093940734}
{'R_grad_norm': 2.872436830997467, 'training_loss': 14.77778483390808}
{'R_grad_norm': 2.8884111499786376, 'training_loss': 14.880753412246705}
{'R_grad_norm': 2.92725572347641, 'training_loss': 15.083831739425658}
{'R_grad_norm': 2.9384645211696623, 'training_loss': 15.155950064659118}
{'R_grad_norm': 2.7987139201164246, 'training_loss': 14.419057192802429}
{'R_grad_norm': 2.7625937247276307, 'training_loss': 14.235358333587646}
{'R_grad_norm': 2.7746267819404604, 'training_loss': 14.300287098884583}
{'R_grad_norm': 2.754750109910965, 'training_loss': 14.18814682483673}
{'R_grad_norm': 2.7613701891899107, 'training_loss': 14.216910800933839}
{'R_grad_norm': 2.759271545410156, 'training_loss': 14.224324803352356}
{'R_grad_norm': 2.757500330209732, 'training_loss': 14.239879631996155}
{'R_grad_norm': 2.758379496335983, 'training_loss': 14.219991898536682}
{'R_grad_norm': 2.757679339647293, 'training_loss': 14.21897102355957}
{'R_grad_norm': 2.7533042442798616, 'training_loss': 14.201893301010132}
{'R_grad_norm': 2.754614392518997, 'training_loss': 14.216994905471802}
{'R_grad_norm': 2.754984951019287, 'training_loss': 14.20513162136078}
{'R_grad_norm': 2.749739546775818, 'training_loss': 14.197670841217041}
{'R_grad_norm': 2.7585702681541444, 'training_loss': 14.26537694454193}
{'R_grad_norm': 2.7611637043952943, 'training_loss': 14.255574688911437}
{'R_grad_norm': 2.758002998828888, 'training_loss': 14.237412223815918}
{'R_grad_norm': 2.748431911468506, 'training_loss': 14.216244883537293}
eval result tensor([26.74018, 24.84839, 14.71311, 14.35657, 18.28751, 18.60936, 15.56456,
         9.26427,  6.81860,  8.47730,  9.63825,  9.09165,  8.65559],
       device='cuda:0')
computing merge metric
normed mi [((1, 6), 0.03853675723075867), ((9, 12), 0.037482455372810364), ((1, 2), 0.03566018988688787), ((2, 6), 0.035286280512809756), ((5, 12), 0.03444194048643112), ((6, 9), 0.03440662225087484), ((6, 12), 0.03435389200846354), ((8, 10), 0.03257128223776817), ((2, 12), 0.032490044832229614), ((1, 12), 0.03240404650568962), ((2, 9), 0.03203672915697098), ((3, 9), 0.03200665613015493), ((1, 5), 0.029828557372093202), ((3, 5), 0.029779890552163124), ((8, 11), 0.029376711696386337), ((1, 9), 0.02924397587776184), ((5, 6), 0.028909126296639442), ((4, 9), 0.02814735472202301), ((5, 9), 0.02803804228703181), ((3, 4), 0.0273145604878664), ((1, 4), 0.02730342447757721), ((10, 11), 0.026917822659015656), ((4, 5), 0.026909172534942627), ((4, 12), 0.02667354792356491), ((0, 3), 0.02641414850950241), ((2, 5), 0.026356568932533263), ((4, 6), 0.026307769119739532), ((3, 6), 0.026247944682836533), ((2, 4), 0.024022531509399415), ((2, 3), 0.023678290843963622), ((3, 12), 0.022900472084681194), ((0, 6), 0.022853208084901173), ((0, 5), 0.022735958298047382), ((1, 3), 0.022451919317245484), ((8, 12), 0.022302081808447838), ((2, 8), 0.021617993712425232), ((0, 2), 0.021512731909751892), ((8, 9), 0.021500885486602783), ((0, 9), 0.021061190962791444), ((0, 1), 0.020520429526056563), ((0, 4), 0.01916042963663737), ((6, 8), 0.01889636491735776), ((0, 12), 0.014978380501270294), ((5, 7), 0.014952401320139566), ((1, 8), 0.014411292038857937), ((5, 8), 0.013507235795259476), ((7, 12), 0.013411606661975384), ((7, 8), 0.013207132928073406), ((6, 7), 0.013067387044429779), ((7, 9), 0.012326961383223534), ((4, 8), 0.011819024880727133), ((3, 8), 0.010973690698544184), ((10, 12), 0.010383186861872673), ((2, 7), 0.009954907931387424), ((1, 7), 0.009526161476969719), ((7, 10), 0.009375997819006443), ((6, 10), 0.008751288677255312), ((5, 10), 0.008501724029580751), ((4, 7), 0.008377555136879286), ((2, 10), 0.008286939933896065), ((9, 10), 0.008280903100967407), ((1, 10), 0.007803271058946848), ((3, 7), 0.00761426364382108), ((0, 8), 0.007449927926063538), ((7, 11), 0.005587967578321695), ((0, 7), 0.004941641539335251), ((3, 10), 0.003913696234424909), ((9, 11), 0.0038806479424238205), ((6, 11), 0.0037179353336493173), ((2, 11), 0.003486351575702429), ((11, 12), 0.00343144778162241), ((4, 10), 0.0033009241645534835), ((0, 10), 0.0031029051169753075), ((5, 11), 0.002852140925824642), ((1, 11), 0.0020447552669793367), ((3, 11), 0.0017177451712389786), ((4, 11), 0.0015925411134958267), ((0, 11), 0.0012248980812728405)]
finish training (68000)
evaluating (25 steps)...
 ******* eval result *******
mean (weighted) 17.161829630533855
mean (unweighted) 14.252054214477539
tensor([26.84952, 24.84864, 14.79140, 14.42213, 18.18893, 18.54927, 15.61821,
         9.22398,  6.87130,  8.47051,  9.63137,  9.13597,  8.67546],
       device='cuda:0')
