{'R_grad_norm': 1.0742009681463243, 'training_loss': 6.918238229751587}
{'R_grad_norm': 1.081103840470314, 'training_loss': 6.790417749881744}
{'R_grad_norm': 1.086712919473648, 'training_loss': 6.636018891334533}
{'R_grad_norm': 1.099434182047844, 'training_loss': 6.559449539184571}
{'R_grad_norm': 1.10424647629261, 'training_loss': 6.444077413082123}
{'R_grad_norm': 1.1073936325311662, 'training_loss': 6.353788959980011}
{'R_grad_norm': 1.10951285302639, 'training_loss': 6.2647919082641605}
{'R_grad_norm': 1.1113542878627778, 'training_loss': 6.1902305388450625}
{'R_grad_norm': 1.113296412229538, 'training_loss': 6.1271100425720215}
{'R_grad_norm': 1.1128470593690871, 'training_loss': 6.074050331115723}
{'R_grad_norm': 1.1139055943489076, 'training_loss': 6.0197367858886714}
{'R_grad_norm': 1.1154466319084166, 'training_loss': 6.000114803314209}
{'R_grad_norm': 1.1141316306591034, 'training_loss': 5.943992829322815}
{'R_grad_norm': 1.1151576179265976, 'training_loss': 5.92163206577301}
{'R_grad_norm': 1.1129520934820176, 'training_loss': 5.889509825706482}
{'R_grad_norm': 1.1093158030509949, 'training_loss': 5.842315094470978}
{'R_grad_norm': 1.1123470556735993, 'training_loss': 5.834128606319427}
{'R_grad_norm': 1.1142375588417053, 'training_loss': 5.833048017024994}
{'R_grad_norm': 1.1138089966773987, 'training_loss': 5.805718050003052}
{'R_grad_norm': 1.1108967703580857, 'training_loss': 5.784439337253571}
{'R_grad_norm': 1.109881546497345, 'training_loss': 5.747589709758759}
{'R_grad_norm': 1.1081174147129058, 'training_loss': 5.722929830551148}
{'R_grad_norm': 1.1074757289886474, 'training_loss': 5.718653526306152}
{'R_grad_norm': 1.1078806525468827, 'training_loss': 5.704199349880218}
{'R_grad_norm': 1.1068642061948777, 'training_loss': 5.6999691653251645}
{'R_grad_norm': 1.1069106811285019, 'training_loss': 5.68345046043396}
{'R_grad_norm': 1.1055549383163452, 'training_loss': 5.68098557472229}
{'R_grad_norm': 1.1064482939243316, 'training_loss': 5.666450748443603}
{'R_grad_norm': 1.1056167924404143, 'training_loss': 5.655325074195861}
{'R_grad_norm': 1.1070763230323792, 'training_loss': 5.654513163566589}
{'R_grad_norm': 1.103422735929489, 'training_loss': 5.634463708400727}
{'R_grad_norm': 1.1039666920900344, 'training_loss': 5.629758758544922}
{'R_grad_norm': 1.1020118641853331, 'training_loss': 5.610414662361145}
{'R_grad_norm': 1.1015303087234498, 'training_loss': 5.601997716426849}
{'R_grad_norm': 1.0996989488601685, 'training_loss': 5.598422014713288}
{'R_grad_norm': 1.1009728163480759, 'training_loss': 5.587927443981171}
{'R_grad_norm': 1.0997501522302628, 'training_loss': 5.56913074016571}
{'R_grad_norm': 1.1015522879362107, 'training_loss': 5.576826205253601}
{'R_grad_norm': 1.0980962812900543, 'training_loss': 5.550968773365021}
{'R_grad_norm': 1.0982662677764892, 'training_loss': 5.556325786113739}
{'R_grad_norm': 1.1002623850107194, 'training_loss': 5.56539510011673}
{'R_grad_norm': 1.0992079597711564, 'training_loss': 5.550473799705506}
{'R_grad_norm': 1.0982531887292861, 'training_loss': 5.5581068110466}
{'R_grad_norm': 1.0957859659194946, 'training_loss': 5.526362342834473}
{'R_grad_norm': 1.0955572998523713, 'training_loss': 5.521870744228363}
{'R_grad_norm': 1.0966826248168946, 'training_loss': 5.531286287307739}
{'R_grad_norm': 1.0968354737758637, 'training_loss': 5.529613564014435}
{'R_grad_norm': 1.0959454607963561, 'training_loss': 5.512465617656708}
{'R_grad_norm': 1.091028533577919, 'training_loss': 5.479168334007263}
{'R_grad_norm': 1.0902449202537536, 'training_loss': 5.484222629070282}
{'R_grad_norm': 1.095169979929924, 'training_loss': 5.497191798686981}
{'R_grad_norm': 1.0933545708656311, 'training_loss': 5.486963798999787}
{'R_grad_norm': 1.0927326452732087, 'training_loss': 5.482579839229584}
{'R_grad_norm': 1.0888062405586243, 'training_loss': 5.465300693511963}
{'R_grad_norm': 1.092967894077301, 'training_loss': 5.487582309246063}
{'R_grad_norm': 1.0915897488594055, 'training_loss': 5.471571228504181}
{'R_grad_norm': 1.0933137828111648, 'training_loss': 5.484848945140839}
{'R_grad_norm': 1.0911629623174668, 'training_loss': 5.460605762004852}
{'R_grad_norm': 1.0911302012205124, 'training_loss': 5.457867727279663}
{'R_grad_norm': 1.0920566594600678, 'training_loss': 5.452966897487641}
{'R_grad_norm': 1.0893427640199662, 'training_loss': 5.457700073719025}
{'R_grad_norm': 1.0892245310544968, 'training_loss': 5.444619743824005}
{'R_grad_norm': 1.0903222262859344, 'training_loss': 5.451985614299774}
{'R_grad_norm': 1.088775976896286, 'training_loss': 5.43342444896698}
{'R_grad_norm': 1.086865753531456, 'training_loss': 5.4353024816513065}
{'R_grad_norm': 1.0891939067840577, 'training_loss': 5.443282268047333}
{'R_grad_norm': 1.0896244466304779, 'training_loss': 5.44138843536377}
{'R_grad_norm': 1.0900498980283737, 'training_loss': 5.4412988185882565}
{'R_grad_norm': 1.0887456595897675, 'training_loss': 5.4289204382896425}
{'R_grad_norm': 1.0892067885398864, 'training_loss': 5.440099790096283}
{'R_grad_norm': 1.089289743900299, 'training_loss': 5.433372781276703}
{'R_grad_norm': 1.0857647401094437, 'training_loss': 5.422641952037811}
{'R_grad_norm': 1.0860380220413208, 'training_loss': 5.416505999565125}
{'R_grad_norm': 1.0881132501363755, 'training_loss': 5.422012915611267}
{'R_grad_norm': 1.0873418527841567, 'training_loss': 5.414048163890839}
{'R_grad_norm': 1.0870013535022736, 'training_loss': 5.421410686969757}
{'R_grad_norm': 1.0847895723581313, 'training_loss': 5.40071163892746}
{'R_grad_norm': 1.0853557735681534, 'training_loss': 5.39669184923172}
{'R_grad_norm': 1.0847019892930985, 'training_loss': 5.390584547519683}
{'R_grad_norm': 1.0872105872631073, 'training_loss': 5.4139705395698545}
{'R_grad_norm': 1.0859346395730973, 'training_loss': 5.402284302711487}
{'R_grad_norm': 1.084616362452507, 'training_loss': 5.39976879119873}
{'R_grad_norm': 1.0836687284708022, 'training_loss': 5.388449504375457}
{'R_grad_norm': 1.0839538925886154, 'training_loss': 5.389770355224609}
{'R_grad_norm': 1.083513195514679, 'training_loss': 5.390813806056976}
{'R_grad_norm': 1.085296779870987, 'training_loss': 5.40360187292099}
{'R_grad_norm': 1.0863039326667785, 'training_loss': 5.410111865997314}
{'R_grad_norm': 1.0823391354084015, 'training_loss': 5.3785186815261845}
{'R_grad_norm': 1.0826158660650254, 'training_loss': 5.372101504802703}
{'R_grad_norm': 1.0844909316301345, 'training_loss': 5.385467708110809}
{'R_grad_norm': 1.0834628200531007, 'training_loss': 5.375234441757202}
{'R_grad_norm': 1.0830851995944977, 'training_loss': 5.373294949531555}
{'R_grad_norm': 1.0836371457576752, 'training_loss': 5.38044116973877}
{'R_grad_norm': 1.0828634977340699, 'training_loss': 5.37619568824768}
{'R_grad_norm': 1.0809746649861336, 'training_loss': 5.366637077331543}
{'R_grad_norm': 1.0838478207588196, 'training_loss': 5.383863177299499}
{'R_grad_norm': 1.083424260020256, 'training_loss': 5.369636478424073}
{'R_grad_norm': 1.0821817964315414, 'training_loss': 5.373652436733246}
{'R_grad_norm': 1.0824863809347152, 'training_loss': 5.36981570482254}
{'R_grad_norm': 1.0831399631500245, 'training_loss': 5.379008684158325}
eval result tensor([4.44142, 5.03205, 6.27577, 5.36941, 4.75612, 4.34139, 4.67787, 4.83259,
        5.69799, 4.72386, 4.99909, 5.61830, 5.65691, 6.40643, 6.13218, 6.26809,
        5.03156, 5.58276, 5.56297, 4.99417, 4.72823, 6.47575, 4.84205, 6.19961],
       device='cuda:0')
computing merge metric
normed mi [((0, 5), 0.13071049749851227), ((9, 20), 0.12952251732349396), ((5, 9), 0.12822924554347992), ((0, 9), 0.12482619285583496), ((5, 6), 0.12254032492637634), ((5, 20), 0.12218870222568512), ((6, 7), 0.11983498185873032), ((5, 7), 0.11950916796922684), ((0, 20), 0.11859510838985443), ((0, 6), 0.11838184297084808), ((7, 9), 0.11803710460662842), ((6, 9), 0.11664745956659317), ((9, 16), 0.11476399749517441), ((7, 20), 0.1138782724738121), ((7, 16), 0.11379546672105789), ((0, 7), 0.11361147463321686), ((6, 20), 0.11164888739585876), ((16, 20), 0.1112372949719429), ((5, 16), 0.10958035290241241), ((9, 19), 0.10855644941329956), ((6, 16), 0.10852447897195816), ((19, 20), 0.10782068967819214), ((16, 19), 0.10489221662282944), ((0, 16), 0.10433600842952728), ((12, 20), 0.10191002488136292), ((7, 19), 0.10162551701068878), ((7, 22), 0.1008787602186203), ((9, 12), 0.09942198544740677), ((12, 19), 0.09920746833086014), ((16, 22), 0.09900058805942535), ((9, 22), 0.09878318756818771), ((5, 19), 0.0984281674027443), ((20, 22), 0.09708154201507568), ((6, 19), 0.09619130939245224), ((19, 22), 0.09437176585197449), ((12, 16), 0.09386962652206421), ((0, 19), 0.09304288774728775), ((6, 22), 0.09272599220275879), ((5, 22), 0.09099069982767105), ((0, 4), 0.0900806114077568), ((7, 12), 0.08863047510385513), ((10, 16), 0.0866592675447464), ((4, 5), 0.08618498593568802), ((5, 12), 0.08579153567552567), ((12, 22), 0.08550616353750229), ((7, 10), 0.08506369590759277), ((0, 22), 0.08493797481060028), ((10, 20), 0.08470147848129272), ((10, 19), 0.08458785712718964), ((9, 10), 0.08369185030460358), ((4, 9), 0.08359827846288681), ((10, 22), 0.08309705555438995), ((6, 12), 0.08156599849462509), ((10, 12), 0.08129332959651947), ((4, 20), 0.08073879778385162), ((0, 12), 0.0800480917096138), ((1, 22), 0.07737887650728226), ((12, 21), 0.07710079103708267), ((3, 12), 0.07690389454364777), ((6, 10), 0.07635814696550369), ((16, 18), 0.07499390840530396), ((1, 7), 0.0749092698097229), ((5, 10), 0.07399553805589676), ((3, 19), 0.07388753443956375), ((1, 16), 0.07213155180215836), ((3, 16), 0.07128170877695084), ((3, 22), 0.07123583555221558), ((18, 19), 0.07098248600959778), ((10, 18), 0.07035034149885178), ((7, 18), 0.07030773907899857), ((18, 22), 0.07030024379491806), ((9, 21), 0.06996220350265503), ((20, 21), 0.06932294368743896), ((19, 21), 0.069187231361866), ((12, 18), 0.06900844722986221), ((0, 10), 0.06868978589773178), ((16, 21), 0.06854083389043808), ((3, 20), 0.06806381791830063), ((16, 17), 0.06787075102329254), ((1, 10), 0.06766518205404282), ((1, 6), 0.06757548451423645), ((3, 9), 0.06710069626569748), ((1, 19), 0.06679876893758774), ((3, 7), 0.06641332805156708), ((9, 18), 0.06622893363237381), ((17, 19), 0.0659121423959732), ((3, 10), 0.06555718928575516), ((18, 20), 0.06553631275892258), ((1, 9), 0.06536853313446045), ((4, 6), 0.06501702964305878), ((12, 14), 0.06391435116529465), ((3, 18), 0.06342577934265137), ((1, 18), 0.06332099437713623), ((1, 20), 0.06300180405378342), ((7, 17), 0.06293992698192596), ((9, 17), 0.06282352656126022), ((6, 18), 0.06224972754716873), ((1, 5), 0.06215136498212814), ((17, 22), 0.061884742230176926), ((1, 12), 0.06180575117468834), ((7, 21), 0.06067080795764923), ((1, 3), 0.06041159853339195), ((17, 20), 0.06013794243335724), ((5, 21), 0.059835921972990036), ((14, 23), 0.05958712473511696), ((11, 12), 0.05950983986258507), ((12, 17), 0.05947914347052574), ((5, 18), 0.059380922466516495), ((9, 11), 0.0588345006108284), ((11, 19), 0.05876541882753372), ((3, 6), 0.058647520840168), ((11, 20), 0.058607637882232666), ((3, 5), 0.05765337496995926), ((12, 23), 0.05752810463309288), ((5, 17), 0.057522762566804886), ((11, 16), 0.0575062595307827), ((3, 14), 0.05726141855120659), ((6, 17), 0.05715038627386093), ((4, 7), 0.05697214603424072), ((0, 1), 0.05668177083134651), ((21, 22), 0.056626200675964355), ((14, 18), 0.05636646971106529), ((14, 19), 0.05636417120695114), ((0, 21), 0.05630025267601013), ((10, 17), 0.05594101920723915), ((10, 21), 0.055816393345594406), ((6, 21), 0.055764373391866684), ((17, 18), 0.05570796877145767), ((4, 16), 0.055195197463035583), ((7, 11), 0.055141448974609375), ((3, 21), 0.05462953448295593), ((18, 21), 0.05448820814490318), ((18, 23), 0.054403066635131836), ((0, 18), 0.05436323583126068), ((1, 14), 0.05430988222360611), ((14, 22), 0.05414321646094322), ((16, 23), 0.05404648184776306), ((4, 19), 0.05386253818869591), ((14, 16), 0.053562719374895096), ((5, 11), 0.053401753306388855), ((3, 17), 0.05336922034621239), ((0, 17), 0.053341206163167953), ((17, 21), 0.05327768623828888), ((19, 23), 0.05325941741466522), ((10, 14), 0.05324271693825722), ((1, 17), 0.05318364500999451), ((3, 23), 0.05289492383599281), ((0, 3), 0.05281241610646248), ((11, 22), 0.052504584193229675), ((8, 18), 0.052416495978832245), ((22, 23), 0.052264489233493805), ((1, 23), 0.05156779661774635), ((6, 11), 0.05144073814153671), ((0, 11), 0.05030705779790878), ((7, 23), 0.049775026738643646), ((10, 23), 0.04959077388048172), ((14, 20), 0.04872836545109749), ((10, 11), 0.04800501838326454), ((11, 21), 0.04774942621588707), ((7, 14), 0.04773930460214615), ((9, 14), 0.047409433871507645), ((9, 23), 0.046439919620752335), ((4, 12), 0.04615618288516998), ((3, 11), 0.04560285806655884), ((3, 8), 0.04555201902985573), ((20, 23), 0.04539436846971512), ((6, 23), 0.04518873244524002), ((1, 8), 0.04514417052268982), ((14, 17), 0.044611044228076935), ((8, 10), 0.04410112276673317), ((14, 21), 0.04382193088531494), ((8, 22), 0.04375952109694481), ((1, 21), 0.043554868549108505), ((11, 18), 0.04323744773864746), ((8, 16), 0.043024174869060516), ((8, 14), 0.04241061955690384), ((5, 23), 0.042113542556762695), ((8, 19), 0.04210630804300308), ((4, 22), 0.04146253317594528), ((6, 14), 0.041209425777196884), ((8, 12), 0.04107482731342316), ((8, 23), 0.04044448211789131), ((7, 8), 0.04039737582206726), ((17, 23), 0.040145110338926315), ((11, 17), 0.03961121663451195), ((5, 14), 0.039373621344566345), ((21, 23), 0.03935414180159569), ((0, 23), 0.03831188753247261), ((1, 11), 0.037414662539958954), ((8, 17), 0.0374075248837471), ((4, 13), 0.03660750761628151), ((8, 9), 0.03615647181868553), ((8, 21), 0.03595198690891266), ((0, 14), 0.03593991696834564), ((8, 20), 0.03582330048084259), ((6, 8), 0.03540300577878952), ((11, 14), 0.03377731516957283), ((4, 10), 0.03367144241929054), ((11, 23), 0.033546965569257736), ((5, 8), 0.03235264867544174), ((2, 15), 0.03222327306866646), ((4, 11), 0.03148138150572777), ((4, 21), 0.03071371652185917), ((0, 8), 0.029801493510603905), ((8, 11), 0.028599610552191734), ((0, 13), 0.02791748009622097), ((5, 13), 0.026503585278987885), ((13, 20), 0.025904417037963867), ((9, 13), 0.0253846924751997), ((13, 15), 0.024756819009780884), ((3, 4), 0.02428145334124565), ((4, 18), 0.02412346564233303), ((4, 15), 0.023054974153637886), ((4, 17), 0.02195732109248638), ((1, 4), 0.020337900146842003), ((2, 9), 0.019205663353204727), ((2, 20), 0.01893395185470581), ((0, 15), 0.018913311883807182), ((2, 21), 0.018880393356084824), ((12, 13), 0.018552005290985107), ((6, 13), 0.018551092594861984), ((2, 12), 0.018343966454267502), ((5, 15), 0.018184805288910866), ((15, 20), 0.018085669726133347), ((2, 19), 0.01770862005650997), ((2, 5), 0.017463359981775284), ((9, 15), 0.01737714745104313), ((4, 23), 0.01734599657356739), ((2, 16), 0.016962498426437378), ((0, 2), 0.016638193279504776), ((2, 11), 0.016628138720989227), ((7, 13), 0.01653246022760868), ((13, 19), 0.015946878120303154), ((13, 16), 0.015553062781691551), ((2, 7), 0.015353413298726082), ((2, 17), 0.014876826666295528), ((6, 15), 0.014396273531019688), ((2, 6), 0.014021998271346092), ((2, 13), 0.013943214900791645), ((4, 14), 0.013896942138671875), ((2, 22), 0.013688434846699238), ((2, 10), 0.013573631644248962), ((12, 15), 0.013433624990284443), ((2, 3), 0.013254715129733086), ((2, 18), 0.013237610459327698), ((4, 8), 0.013236064463853836), ((7, 15), 0.013053936883807182), ((15, 19), 0.012326824478805065), ((15, 16), 0.012179840356111526), ((13, 22), 0.011991992592811584), ((13, 21), 0.011896735988557339), ((2, 4), 0.011740506626665592), ((11, 13), 0.01155238226056099), ((2, 8), 0.011489332653582096), ((11, 15), 0.011037981137633324), ((10, 13), 0.010876082815229893), ((1, 2), 0.010442969389259815), ((15, 22), 0.010391623713076115), ((2, 23), 0.010110033676028252), ((15, 21), 0.009582910686731339), ((2, 14), 0.009577041491866112), ((10, 15), 0.009365183301270008), ((3, 13), 0.009293393231928349), ((13, 18), 0.008159326389431953), ((3, 15), 0.008039071224629879), ((15, 18), 0.007562244776636362), ((13, 17), 0.007376911584287882), ((13, 23), 0.00732513889670372), ((1, 13), 0.006863591726869345), ((15, 17), 0.006838006433099508), ((1, 15), 0.006648701149970293), ((15, 23), 0.006596177816390991), ((13, 14), 0.005632269196212292), ((14, 15), 0.005252156872302294), ((8, 15), 0.004954822827130556), ((8, 13), 0.0047246175818145275)]
******* after merging (0.04): [((0, 5), 64), ((9, 20), 64), ((6, 7), 64), ((1,), 32), ((2,), 32), ((3,), 32), ((4,), 32), ((8,), 32), ((10,), 32), ((11,), 32), ((12,), 32), ((13,), 32), ((14,), 32), ((15,), 32), ((16,), 32), ((17,), 32), ((18,), 32), ((19,), 32), ((21,), 32), ((22,), 32), ((23,), 32)]
{'R_grad_norm': 1.358801744580269, 'training_loss': 5.794357900619507}
{'R_grad_norm': 1.361778666973114, 'training_loss': 5.804727694988251}
{'R_grad_norm': 1.3612844026088715, 'training_loss': 5.799955170154572}
{'R_grad_norm': 1.3623414021730422, 'training_loss': 5.799624743461609}
{'R_grad_norm': 1.3597940748929978, 'training_loss': 5.780756800174713}
{'R_grad_norm': 1.3649521243572236, 'training_loss': 5.807293031215668}
{'R_grad_norm': 1.3610682481527328, 'training_loss': 5.7825578022003175}
{'R_grad_norm': 1.3607488930225373, 'training_loss': 5.778873474597931}
{'R_grad_norm': 1.3585547268390656, 'training_loss': 5.757433485984802}
{'R_grad_norm': 1.362075212597847, 'training_loss': 5.773209202289581}
{'R_grad_norm': 1.3551768159866333, 'training_loss': 5.752207856178284}
{'R_grad_norm': 1.3568875783681869, 'training_loss': 5.76048501253128}
{'R_grad_norm': 1.3530429941415787, 'training_loss': 5.752804167270661}
{'R_grad_norm': 1.3504011422395705, 'training_loss': 5.733454546928406}
{'R_grad_norm': 1.3497153043746948, 'training_loss': 5.727222788333893}
{'R_grad_norm': 1.3533257067203521, 'training_loss': 5.745300710201263}
{'R_grad_norm': 1.351376758813858, 'training_loss': 5.738014416694641}
{'R_grad_norm': 1.3486183428764342, 'training_loss': 5.733125879764557}
{'R_grad_norm': 1.3498909240961074, 'training_loss': 5.730449643135071}
{'R_grad_norm': 1.349292608499527, 'training_loss': 5.731420683860779}
{'R_grad_norm': 1.3468944835662842, 'training_loss': 5.714898331165314}
{'R_grad_norm': 1.3472888851165772, 'training_loss': 5.717433075904847}
{'R_grad_norm': 1.3483327466249466, 'training_loss': 5.729638760089874}
{'R_grad_norm': 1.346806788444519, 'training_loss': 5.720991675853729}
{'R_grad_norm': 1.34615627348423, 'training_loss': 5.72228773355484}
{'R_grad_norm': 1.342561168074608, 'training_loss': 5.709988152980804}
{'R_grad_norm': 1.3433595150709152, 'training_loss': 5.713122272491455}
{'R_grad_norm': 1.3436625534296036, 'training_loss': 5.718107163906097}
{'R_grad_norm': 1.3412287354469299, 'training_loss': 5.712977170944214}
{'R_grad_norm': 1.345450593829155, 'training_loss': 5.721623430252075}
{'R_grad_norm': 1.3458869075775146, 'training_loss': 5.710614552497864}
{'R_grad_norm': 1.3407780420780182, 'training_loss': 5.695270271301269}
{'R_grad_norm': 1.339111201763153, 'training_loss': 5.693460042476654}
{'R_grad_norm': 1.3451894217729568, 'training_loss': 5.721643555164337}
{'R_grad_norm': 1.3424829441308974, 'training_loss': 5.708487198352814}
{'R_grad_norm': 1.3410841339826585, 'training_loss': 5.700963711738586}
{'R_grad_norm': 1.3391546994447707, 'training_loss': 5.69128482580185}
{'R_grad_norm': 1.3348801720142365, 'training_loss': 5.671131784915924}
{'R_grad_norm': 1.3414339065551757, 'training_loss': 5.712832715511322}
{'R_grad_norm': 1.3346577453613282, 'training_loss': 5.691373515129089}
eval result tensor([6.57493, 7.83379, 7.76047, 4.82440, 6.06584, 5.16980, 4.49100, 5.68106,
        4.83379, 5.38839, 5.46644, 6.30830, 5.84786, 5.83568, 4.67088, 5.54932,
        5.40760, 4.73792, 6.31151, 4.52572, 5.99166], device='cuda:0')
computing merge metric
normed mi [((14, 17), 0.09727124869823456), ((10, 17), 0.09496314823627472), ((14, 19), 0.09123940020799637), ((10, 14), 0.09008587896823883), ((17, 19), 0.08763215690851212), ((10, 19), 0.0825032889842987), ((8, 14), 0.08151065558195114), ((1, 14), 0.07965639730294545), ((8, 17), 0.07775841653347015), ((8, 10), 0.07773543894290924), ((8, 19), 0.07743760943412781), ((10, 18), 0.07551339268684387), ((1, 17), 0.07523619135220845), ((2, 14), 0.07504946986834209), ((14, 16), 0.07296122610569), ((1, 10), 0.07199814418951671), ((0, 14), 0.0707812209924062), ((1, 19), 0.06978285312652588), ((5, 10), 0.0691506639122963), ((5, 19), 0.06785456091165543), ((8, 16), 0.06738357990980148), ((17, 18), 0.0672227144241333), ((16, 17), 0.06692726910114288), ((14, 15), 0.06649193912744522), ((10, 20), 0.06618013232946396), ((2, 17), 0.06579973797003429), ((5, 17), 0.06566821038722992), ((3, 19), 0.06559887528419495), ((0, 17), 0.06543760001659393), ((14, 18), 0.0654272511601448), ((10, 16), 0.06540851294994354), ((2, 19), 0.06525551279385884), ((5, 14), 0.06519054621458054), ((0, 1), 0.0650467723608017), ((16, 19), 0.0645352229475975), ((15, 17), 0.06419634073972702), ((1, 2), 0.06376814097166061), ((3, 14), 0.0634981319308281), ((5, 8), 0.06196887046098709), ((1, 8), 0.06189475953578949), ((5, 16), 0.0615847110748291), ((0, 2), 0.06064607575535774), ((3, 8), 0.06018683686852455), ((10, 12), 0.05982595309615135), ((2, 10), 0.05909664432207743), ((0, 19), 0.058666164676348366), ((3, 5), 0.058502305299043655), ((0, 6), 0.058281908432642617), ((15, 19), 0.05802763253450394), ((0, 10), 0.05771865944067637), ((14, 20), 0.05763446167111397), ((2, 8), 0.05746156473954519), ((10, 15), 0.057436782866716385), ((3, 17), 0.05739657208323479), ((3, 16), 0.057350464165210724), ((17, 20), 0.05703190714120865), ((7, 16), 0.05585984140634537), ((5, 12), 0.05557560175657272), ((15, 16), 0.0551849827170372), ((12, 20), 0.055018968880176544), ((3, 10), 0.05461783707141876), ((16, 18), 0.054529353976249695), ((8, 15), 0.05420021340250969), ((18, 19), 0.05382134020328522), ((15, 18), 0.05367334187030792), ((12, 16), 0.05340896546840668), ((8, 18), 0.053321365267038345), ((6, 17), 0.053298190236091614), ((16, 20), 0.05281277373433113), ((5, 20), 0.05187920480966568), ((1, 16), 0.051769291361172996), ((6, 14), 0.05171031504869461), ((19, 20), 0.051270876079797745), ((12, 17), 0.05118377134203911), ((3, 12), 0.05118181183934212), ((1, 18), 0.05082163214683533), ((12, 14), 0.050505902618169785), ((8, 12), 0.05013687163591385), ((8, 20), 0.04976605623960495), ((5, 15), 0.04965412989258766), ((2, 16), 0.04958353439966837), ((5, 18), 0.049358710646629333), ((12, 19), 0.049302976578474045), ((1, 5), 0.04897059500217438), ((1, 15), 0.04860302805900574), ((3, 15), 0.048537082970142365), ((9, 10), 0.04846333712339401), ((0, 8), 0.04825801650683085), ((2, 3), 0.04796953499317169), ((9, 17), 0.04742973670363426), ((5, 7), 0.04640091210603714), ((1, 3), 0.04583291709423065), ((3, 20), 0.045630987733602524), ((1, 6), 0.04495939612388611), ((2, 15), 0.0446309099594752), ((9, 14), 0.04451991990208626), ((2, 5), 0.044500177105267845), ((6, 19), 0.04343724250793457), ((6, 10), 0.04329853132367134), ((18, 20), 0.04325562343001366), ((7, 12), 0.04316580295562744), ((7, 14), 0.042760804295539856), ((15, 20), 0.04275863245129585), ((3, 7), 0.04267679527401924), ((12, 18), 0.04258088394999504), ((7, 8), 0.04243839159607887), ((6, 9), 0.04189905896782875), ((12, 15), 0.0415562242269516), ((2, 18), 0.0409063845872879), ((7, 10), 0.04077206552028656), ((0, 16), 0.04054011901219686), ((3, 18), 0.04050238057971001), ((7, 17), 0.040445439517498016), ((0, 18), 0.040373298029104866), ((0, 15), 0.039960771799087524), ((1, 20), 0.03978333373864492), ((9, 19), 0.03918083757162094), ((7, 19), 0.0388621985912323), ((0, 9), 0.038139864802360535), ((0, 3), 0.03760173420111338), ((2, 20), 0.03740839660167694), ((7, 20), 0.037182968109846115), ((1, 9), 0.036987374226252236), ((1, 12), 0.03693728645642599), ((7, 18), 0.03678867965936661), ((7, 15), 0.036638639867305756), ((6, 11), 0.036061182618141174), ((0, 5), 0.03554720183213552), ((9, 18), 0.0339546799659729), ((8, 9), 0.03297991305589676), ((2, 6), 0.03273337831099828), ((6, 13), 0.03263479098677635), ((6, 8), 0.032374124974012375), ((2, 12), 0.031935671965281166), ((11, 13), 0.031822819262742996), ((0, 20), 0.03164668629566828), ((1, 7), 0.030083114902178448), ((2, 9), 0.029434623817602795), ((2, 7), 0.02919247994820277), ((9, 16), 0.027140898630023003), ((6, 18), 0.026899639517068863), ((5, 9), 0.02636628784239292), ((9, 13), 0.026052121073007584), ((9, 15), 0.02522982284426689), ((9, 20), 0.02520201914012432), ((0, 12), 0.025152611235777538), ((6, 16), 0.023853374645113945), ((6, 15), 0.023108307272195816), ((0, 7), 0.02271736164887746), ((10, 13), 0.022696182131767273), ((5, 6), 0.02112431451678276), ((10, 11), 0.020774835720658302), ((0, 13), 0.020689887305100758), ((13, 17), 0.02060028538107872), ((3, 9), 0.02009403333067894), ((9, 11), 0.02004867047071457), ((6, 20), 0.019776085391640663), ((0, 11), 0.019500143826007843), ((4, 13), 0.01932738721370697), ((13, 14), 0.018690062686800957), ((3, 6), 0.018574858084321022), ((11, 17), 0.018136819824576378), ((13, 19), 0.017095020040869713), ((9, 12), 0.017018508166074753), ((4, 11), 0.016942331567406654), ((1, 13), 0.016775552183389664), ((11, 14), 0.016331179067492485), ((4, 9), 0.016275454312562943), ((4, 10), 0.015512481331825256), ((4, 18), 0.015364858321845531), ((7, 9), 0.015211421065032482), ((1, 11), 0.014615558087825775), ((4, 14), 0.014270000159740448), ((4, 17), 0.01426481083035469), ((11, 19), 0.013773683458566666), ((8, 13), 0.013689006678760052), ((13, 18), 0.013665699400007725), ((6, 12), 0.0127872908487916), ((6, 7), 0.012721573933959007), ((2, 13), 0.012675657868385315), ((11, 18), 0.012164444662630558), ((4, 15), 0.011989814229309559), ((4, 19), 0.01172832865267992), ((4, 16), 0.011451584286987782), ((4, 8), 0.011354769580066204), ((8, 11), 0.011293348856270313), ((1, 4), 0.011237765351931253), ((0, 4), 0.011235322803258896), ((13, 16), 0.010890026576817036), ((4, 6), 0.010719064623117447), ((13, 20), 0.010694866999983788), ((5, 13), 0.010609963908791542), ((2, 11), 0.010538755605618158), ((4, 7), 0.010321165435016155), ((4, 5), 0.009709877893328667), ((13, 15), 0.009627127088606358), ((11, 20), 0.009469988755881786), ((2, 4), 0.009047044441103935), ((4, 20), 0.009001980535686016), ((11, 16), 0.00887768343091011), ((3, 13), 0.008328365162014961), ((3, 4), 0.00823280867189169), ((5, 11), 0.008230595849454403), ((11, 15), 0.007837667129933834), ((4, 12), 0.007235920988023281), ((3, 11), 0.006626747082918882), ((7, 13), 0.006296517793089151), ((12, 13), 0.00616027507930994), ((11, 12), 0.00536205293610692), ((7, 11), 0.004993777722120285)]
******* after merging (0.04): [((14, 17), 64), ((10, 19), 64), ((0,), 64), ((1,), 64), ((2,), 64), ((3,), 32), ((4,), 32), ((5,), 32), ((6,), 32), ((7,), 32), ((8,), 32), ((9,), 32), ((11,), 32), ((12,), 32), ((13,), 32), ((15,), 32), ((16,), 32), ((18,), 32), ((20,), 32)]
{'R_grad_norm': 1.448106336593628, 'training_loss': 6.0963666009902955}
{'R_grad_norm': 1.444047564268112, 'training_loss': 6.068927390575409}
{'R_grad_norm': 1.446541423201561, 'training_loss': 6.091962549686432}
{'R_grad_norm': 1.4449787533283234, 'training_loss': 6.082274100780487}
{'R_grad_norm': 1.4438843989372254, 'training_loss': 6.073618638515472}
{'R_grad_norm': 1.4431880617141724, 'training_loss': 6.078054161071777}
{'R_grad_norm': 1.4416401612758636, 'training_loss': 6.0620484542846675}
{'R_grad_norm': 1.4447242736816406, 'training_loss': 6.0900937581062315}
{'R_grad_norm': 1.4474565660953522, 'training_loss': 6.107088809013367}
{'R_grad_norm': 1.4494843769073487, 'training_loss': 6.102472333908081}
{'R_grad_norm': 1.4511053258180617, 'training_loss': 6.131636946201325}
{'R_grad_norm': 1.4537458717823029, 'training_loss': 6.140398423671723}
{'R_grad_norm': 1.4562923049926757, 'training_loss': 6.142670385837555}
{'R_grad_norm': 1.4572799807786943, 'training_loss': 6.154983596801758}
{'R_grad_norm': 1.4645278477668762, 'training_loss': 6.194363164901733}
{'R_grad_norm': 1.4678812754154205, 'training_loss': 6.206241261959076}
{'R_grad_norm': 1.4705757129192352, 'training_loss': 6.220187151432038}
{'R_grad_norm': 1.4743853855133056, 'training_loss': 6.246728084087372}
{'R_grad_norm': 1.4815303725004196, 'training_loss': 6.278440992832184}
{'R_grad_norm': 1.4866691219806671, 'training_loss': 6.300431160926819}
{'R_grad_norm': 1.4911498016119002, 'training_loss': 6.331116971969604}
{'R_grad_norm': 1.5018218970298767, 'training_loss': 6.393015105724334}
{'R_grad_norm': 1.458172795176506, 'training_loss': 6.176694083213806}
{'R_grad_norm': 1.431032080054283, 'training_loss': 6.046796491146088}
{'R_grad_norm': 1.4331358712911606, 'training_loss': 6.059498372077942}
{'R_grad_norm': 1.4295842385292052, 'training_loss': 6.0477017045021055}
{'R_grad_norm': 1.4279194337129593, 'training_loss': 6.03193478345871}
{'R_grad_norm': 1.4235819494724273, 'training_loss': 6.029122595787048}
{'R_grad_norm': 1.4274362069368363, 'training_loss': 6.043259890079498}
{'R_grad_norm': 1.4234052419662475, 'training_loss': 6.034001255035401}
{'R_grad_norm': 1.423205357193947, 'training_loss': 6.024194984436035}
{'R_grad_norm': 1.4249125796556472, 'training_loss': 6.048103890419006}
{'R_grad_norm': 1.420349754691124, 'training_loss': 6.026295392513275}
{'R_grad_norm': 1.4217128890752793, 'training_loss': 6.023728911876678}
{'R_grad_norm': 1.4228469789028169, 'training_loss': 6.0394974493980405}
{'R_grad_norm': 1.4217874217033386, 'training_loss': 6.035525126457214}
{'R_grad_norm': 1.4182925951480865, 'training_loss': 6.025678088665009}
{'R_grad_norm': 1.4172307115793228, 'training_loss': 6.005821647644043}
{'R_grad_norm': 1.4179398787021638, 'training_loss': 6.022590410709381}
{'R_grad_norm': 1.4154468339681625, 'training_loss': 6.011845619678497}
eval result tensor([7.82238, 8.53151, 6.46094, 7.69638, 7.78993, 4.67860, 5.91596, 5.02036,
        4.29192, 5.62342, 4.65015, 5.22737, 6.19252, 5.74353, 5.73993, 5.44784,
        5.27522, 6.14831, 5.82906], device='cuda:0')
computing merge metric
normed mi [((2, 3), 0.06402105838060379), ((0, 3), 0.06318255513906479), ((10, 16), 0.06254047155380249), ((3, 4), 0.06219124794006348), ((3, 10), 0.060907418529192604), ((0, 10), 0.05965818464756012), ((1, 3), 0.05943894758820534), ((1, 10), 0.05942473808924357), ((7, 10), 0.05865184962749481), ((0, 1), 0.05834430083632469), ((2, 4), 0.05806747451424599), ((0, 4), 0.05802534148097038), ((7, 16), 0.05755225941538811), ((5, 7), 0.057057928293943405), ((9, 16), 0.057053931057453156), ((5, 10), 0.05681334063410759), ((4, 10), 0.05594765146573385), ((5, 16), 0.05467844754457474), ((0, 16), 0.05441968639691671), ((13, 18), 0.05382543429732323), ((7, 13), 0.053508151322603226), ((2, 8), 0.05326128502686819), ((15, 16), 0.05293337255716324), ((15, 17), 0.05285006761550903), ((1, 17), 0.052496309081713356), ((1, 7), 0.0524911085764567), ((10, 15), 0.05223694071173668), ((16, 17), 0.05203711986541748), ((0, 2), 0.05181083455681801), ((0, 15), 0.05176760256290436), ((13, 16), 0.05117345228791237), ((16, 18), 0.05057007819414139), ((1, 4), 0.050482377409935), ((10, 17), 0.0504036620259285), ((5, 13), 0.04981347545981407), ((3, 16), 0.04978473981221517), ((0, 7), 0.04966943462689718), ((1, 18), 0.04954792559146881), ((3, 17), 0.04946033159891764), ((7, 18), 0.04928432032465935), ((1, 16), 0.04906640946865082), ((0, 17), 0.04887451231479645), ((3, 15), 0.04870677491029104), ((10, 13), 0.04828415438532829), ((10, 18), 0.04820019751787186), ((0, 5), 0.04790998498598734), ((4, 16), 0.04764256874720255), ((2, 10), 0.04760628938674927), ((5, 15), 0.04734225198626518), ((7, 15), 0.04721236974000931), ((4, 5), 0.047176361083984375), ((3, 7), 0.04654288788636526), ((1, 15), 0.046183958649635315), ((1, 13), 0.0460249533255895), ((7, 17), 0.045940302312374115), ((8, 11), 0.04565586894750595), ((7, 9), 0.045505452901124954), ((1, 2), 0.04537460207939148), ((3, 5), 0.045247048139572144), ((0, 18), 0.04513770838578542), ((1, 5), 0.044591814279556274), ((5, 18), 0.044263023883104324), ((17, 18), 0.04372343048453331), ((4, 15), 0.04331447184085846), ((15, 18), 0.04324353486299515), ((9, 13), 0.042848218232393265), ((5, 9), 0.042589519172906876), ((13, 17), 0.042125947773456573), ((4, 7), 0.042094796895980835), ((13, 15), 0.041771598160266876), ((0, 13), 0.04130286475022634), ((9, 10), 0.04091266170144081), ((3, 18), 0.04049868881702423), ((2, 15), 0.03957274556159973), ((2, 17), 0.039369684954484306), ((3, 8), 0.03906393547852834), ((4, 17), 0.038821893433729805), ((2, 16), 0.03881537665923437), ((5, 17), 0.03864406794309616), ((4, 18), 0.037553101778030396), ((9, 17), 0.0373665876686573), ((9, 18), 0.0368935652077198), ((2, 5), 0.03683058420817057), ((3, 13), 0.03679826855659485), ((8, 12), 0.03645580634474754), ((9, 15), 0.03588973358273506), ((0, 9), 0.03537453214327494), ((2, 11), 0.033876366913318634), ((8, 14), 0.033561620861291885), ((2, 7), 0.033385964731375374), ((11, 14), 0.03260539844632149), ((1, 9), 0.03246379146973292), ((4, 13), 0.03231924523909887), ((2, 18), 0.032053095599015556), ((8, 10), 0.030492352321743965), ((3, 9), 0.030413803954919178), ((4, 9), 0.029493391513824463), ((12, 14), 0.02851087413728237), ((4, 8), 0.02783895532290141), ((3, 11), 0.02773217111825943), ((0, 8), 0.02765464037656784), ((2, 13), 0.025103879471619923), ((1, 8), 0.02505649874607722), ((11, 12), 0.02487037144601345), ((8, 17), 0.02382008545100689), ((10, 11), 0.02370321936905384), ((2, 14), 0.023067325353622437), ((2, 9), 0.023034113148848217), ((11, 17), 0.02273252233862877), ((8, 15), 0.02136838622391224), ((8, 16), 0.02118990570306778), ((1, 11), 0.020911909639835358), ((4, 11), 0.02072685460249583), ((6, 14), 0.019767533987760544), ((7, 8), 0.019518012180924416), ((0, 11), 0.01941811665892601), ((2, 12), 0.018867248048384983), ((3, 14), 0.018830920259157818), ((8, 18), 0.01881774142384529), ((11, 18), 0.018640143796801567), ((11, 16), 0.017449237406253815), ((5, 8), 0.017256546765565872), ((6, 12), 0.017048470675945282), ((10, 14), 0.016980400308966637), ((7, 11), 0.016635974869132042), ((11, 15), 0.016550948843359947), ((6, 11), 0.016462059691548347), ((14, 17), 0.015927163884043694), ((1, 14), 0.014795427521069845), ((6, 17), 0.01444993820041418), ((4, 14), 0.014387715607881546), ((5, 11), 0.01369621604681015), ((3, 12), 0.013533972203731537), ((0, 14), 0.013481720040241877), ((14, 18), 0.013322350569069386), ((14, 16), 0.013048777356743813), ((7, 14), 0.012620000168681145), ((6, 15), 0.01231870986521244), ((8, 13), 0.011953181587159634), ((2, 6), 0.011816070725520452), ((6, 10), 0.011744490824639797), ((3, 6), 0.011566083878278732), ((8, 9), 0.011376655660569668), ((14, 15), 0.011331524699926376), ((6, 16), 0.01125950925052166), ((10, 12), 0.011238104663789272), ((12, 17), 0.011103510856628418), ((11, 13), 0.010866868309676647), ((6, 9), 0.010726040229201317), ((6, 8), 0.010631944052875042), ((5, 14), 0.01059830654412508), ((0, 6), 0.00998989058037599), ((1, 12), 0.00994244155784448), ((1, 6), 0.00972298098107179), ((12, 18), 0.009689337573945522), ((9, 11), 0.009661677293479443), ((4, 12), 0.009613079950213432), ((6, 18), 0.009396566078066826), ((6, 7), 0.009306032210588455), ((0, 12), 0.008895364900430044), ((5, 6), 0.008883198723196983), ((4, 6), 0.008784546827276548), ((12, 16), 0.008306187577545643), ((9, 14), 0.008093884214758873), ((13, 14), 0.008033456280827522), ((7, 12), 0.007698037661612034), ((12, 15), 0.007657651323825121), ((6, 13), 0.007399806287139654), ((5, 12), 0.0067031849175691605), ((12, 13), 0.005572567228227854), ((9, 12), 0.004961454309523106)]
******* after merging (0.04): [((2, 3), 128), ((10, 16), 64), ((0,), 64), ((1,), 64), ((4,), 64), ((5,), 32), ((6,), 32), ((7,), 32), ((8,), 32), ((9,), 32), ((11,), 32), ((12,), 32), ((13,), 32), ((14,), 32), ((15,), 32), ((17,), 32), ((18,), 32)]
{'R_grad_norm': 1.5431256771087647, 'training_loss': 6.428288702964783}
{'R_grad_norm': 1.540290778875351, 'training_loss': 6.41532613992691}
{'R_grad_norm': 1.5382882511615754, 'training_loss': 6.403630738258362}
{'R_grad_norm': 1.5389192014932633, 'training_loss': 6.4061944508552555}
{'R_grad_norm': 1.5354303652048111, 'training_loss': 6.403354797363281}
{'R_grad_norm': 1.5361537796258926, 'training_loss': 6.390417394638061}
{'R_grad_norm': 1.5345722818374634, 'training_loss': 6.387240595817566}
{'R_grad_norm': 1.5382301503419875, 'training_loss': 6.4163813662528995}
{'R_grad_norm': 1.5339510279893875, 'training_loss': 6.388303864002228}
{'R_grad_norm': 1.5310770112276078, 'training_loss': 6.387049162387848}
{'R_grad_norm': 1.5350833415985108, 'training_loss': 6.3865975618362425}
{'R_grad_norm': 1.5323390847444534, 'training_loss': 6.375048813819885}
{'R_grad_norm': 1.5343444830179214, 'training_loss': 6.403368065357208}
{'R_grad_norm': 1.533296850323677, 'training_loss': 6.406303458213806}
{'R_grad_norm': 1.5319306564331054, 'training_loss': 6.39359860420227}
{'R_grad_norm': 1.5338329774141313, 'training_loss': 6.416425902843475}
{'R_grad_norm': 1.529230227470398, 'training_loss': 6.391339263916016}
{'R_grad_norm': 1.532364006638527, 'training_loss': 6.411376359462738}
{'R_grad_norm': 1.5263466250896454, 'training_loss': 6.372583136558533}
{'R_grad_norm': 1.5287330776453019, 'training_loss': 6.395668880939484}
{'R_grad_norm': 1.5261688089370729, 'training_loss': 6.383038737773895}
{'R_grad_norm': 1.5256935358047485, 'training_loss': 6.396995847225189}
{'R_grad_norm': 1.522160571217537, 'training_loss': 6.377882099151611}
{'R_grad_norm': 1.5264874929189682, 'training_loss': 6.38831561088562}
{'R_grad_norm': 1.523650570511818, 'training_loss': 6.384973263740539}
{'R_grad_norm': 1.5240326511859894, 'training_loss': 6.393261835575104}
{'R_grad_norm': 1.5208310413360595, 'training_loss': 6.367025423049927}
{'R_grad_norm': 1.5215305638313295, 'training_loss': 6.3828753566741945}
{'R_grad_norm': 1.5222988867759704, 'training_loss': 6.3878853583335875}
{'R_grad_norm': 1.5182402688264847, 'training_loss': 6.369927356243133}
{'R_grad_norm': 1.5201670068502426, 'training_loss': 6.385856764316559}
{'R_grad_norm': 1.5180135142803193, 'training_loss': 6.362731757164002}
{'R_grad_norm': 1.5204646509885789, 'training_loss': 6.385280895233154}
{'R_grad_norm': 1.517340700030327, 'training_loss': 6.378161296844483}
{'R_grad_norm': 1.5155849969387054, 'training_loss': 6.373435742855072}
{'R_grad_norm': 1.5134761172533036, 'training_loss': 6.3599039697647095}
{'R_grad_norm': 1.5148003721237182, 'training_loss': 6.381540126800537}
{'R_grad_norm': 1.514316274523735, 'training_loss': 6.37782252073288}
{'R_grad_norm': 1.5124419581890107, 'training_loss': 6.351587386131286}
{'R_grad_norm': 1.506773029565811, 'training_loss': 6.3303005361557005}
eval result tensor([11.91806,  8.61002,  7.58024,  8.48169,  7.11980,  4.60008,  5.87240,
         4.94535,  4.14597,  5.63908,  5.12969,  6.16631,  5.69089,  5.74463,
         5.37304,  6.04449,  5.77356], device='cuda:0')
computing merge metric
normed mi [((2, 3), 0.056963589042425156), ((2, 4), 0.055908069014549255), ((5, 7), 0.05568927526473999), ((12, 16), 0.05224638804793358), ((7, 12), 0.05186297744512558), ((3, 7), 0.050931801398595176), ((3, 15), 0.050837536652882896), ((14, 15), 0.05035712942481041), ((2, 14), 0.04980455835660299), ((3, 16), 0.04913953443368276), ((7, 16), 0.04888538643717766), ((2, 7), 0.04875721037387848), ((5, 12), 0.04863390699028969), ((1, 2), 0.04823794215917587), ((3, 4), 0.04813963174819946), ((2, 5), 0.046621123949686684), ((2, 15), 0.04624012112617493), ((1, 7), 0.0461189995209376), ((1, 3), 0.04551021382212639), ((8, 10), 0.04550229012966156), ((7, 14), 0.04543601721525192), ((0, 4), 0.045318553845087685), ((5, 14), 0.04524710029363632), ((1, 5), 0.04513511061668396), ((4, 5), 0.044465666015942894), ((7, 9), 0.044195108115673065), ((2, 16), 0.044104814529418945), ((3, 12), 0.04369406898816427), ((3, 14), 0.04352639615535736), ((5, 16), 0.043351687490940094), ((7, 15), 0.042942650616168976), ((9, 12), 0.042912039905786514), ((3, 5), 0.04227011899153391), ((15, 16), 0.04223001375794411), ((0, 2), 0.04220761855443319), ((14, 16), 0.04216613993048668), ((1, 4), 0.042155902832746506), ((5, 9), 0.041193656623363495), ((1, 14), 0.04104063163201014), ((1, 12), 0.040939733386039734), ((1, 9), 0.04051642119884491), ((12, 14), 0.040156882256269455), ((4, 14), 0.04007462412118912), ((2, 12), 0.03978875279426575), ((12, 15), 0.03969850391149521), ((4, 7), 0.03964436054229736), ((1, 16), 0.03890770425399145), ((0, 3), 0.03845106065273285), ((1, 15), 0.03758403162161509), ((9, 16), 0.03686064854264259), ((5, 15), 0.036459751427173615), ((4, 15), 0.03583184132973353), ((9, 15), 0.03579409420490265), ((8, 11), 0.035694610327482224), ((9, 14), 0.03526802361011505), ((4, 16), 0.03515319526195526), ((2, 9), 0.03420580426851908), ((8, 13), 0.032592326402664185), ((10, 13), 0.03235229104757309), ((0, 1), 0.03167108198006948), ((3, 9), 0.03146934509277344), ((4, 12), 0.029231178263823192), ((0, 14), 0.028626486659049988), ((0, 5), 0.028224024176597595), ((4, 9), 0.02756931632757187), ((0, 15), 0.02753278613090515), ((0, 7), 0.027372828125953673), ((11, 13), 0.026157548651099205), ((10, 11), 0.02472788281738758), ((0, 16), 0.024167144298553468), ((0, 12), 0.020954999327659606), ((0, 9), 0.018742284178733824), ((4, 8), 0.01863688478867213), ((6, 13), 0.01762986183166504), ((2, 8), 0.017318700750668842), ((3, 8), 0.01701512187719345), ((8, 15), 0.0153388362377882), ((6, 10), 0.013778716325759888), ((6, 15), 0.013744572177529335), ((0, 8), 0.013388079404830933), ((7, 8), 0.012920398265123367), ((8, 14), 0.0124268913641572), ((6, 11), 0.012165496125817299), ((8, 16), 0.011799726635217667), ((6, 14), 0.011504908092319965), ((4, 10), 0.011302535732587179), ((6, 9), 0.010581218637526035), ((4, 13), 0.010408405214548111), ((5, 8), 0.010369932278990746), ((10, 15), 0.010311566293239594), ((3, 10), 0.010291400675972303), ((3, 13), 0.009655402352412542), ((3, 6), 0.009343332300583521), ((2, 10), 0.009313524390260378), ((1, 8), 0.009266762683788935), ((13, 15), 0.009259013459086418), ((6, 7), 0.009193175472319126), ((2, 6), 0.009163315718372663), ((6, 8), 0.009117565117776394), ((10, 16), 0.009091678075492382), ((6, 16), 0.009012123569846153), ((2, 13), 0.008646099517742792), ((13, 16), 0.0083301467821002), ((4, 6), 0.00825643539428711), ((7, 10), 0.00807871948927641), ((7, 13), 0.008002420887351036), ((5, 6), 0.007992168888449669), ((1, 6), 0.007652752101421356), ((10, 14), 0.007509309332817793), ((0, 10), 0.00732269212603569), ((8, 12), 0.007282643113285303), ((8, 9), 0.007224442902952433), ((13, 14), 0.007006232626736164), ((5, 13), 0.006950880866497755), ((5, 10), 0.006857370026409626), ((6, 12), 0.006724468898028135), ((0, 13), 0.006601506471633911), ((4, 11), 0.006221260875463486), ((0, 6), 0.006156139075756073), ((1, 10), 0.00595231664677461), ((11, 16), 0.005939542315900326), ((11, 15), 0.00593368336558342), ((3, 11), 0.005932281414667766), ((1, 13), 0.005856698999802272), ((2, 11), 0.0053337762753168745), ((9, 13), 0.005157800391316414), ((7, 11), 0.005102882161736488), ((9, 10), 0.004971137270331383), ((10, 12), 0.004877036437392235), ((11, 14), 0.004867153242230415), ((5, 11), 0.00465219933539629), ((12, 13), 0.004652190487831831), ((0, 11), 0.004033775255084038), ((1, 11), 0.003771163523197174), ((9, 11), 0.0036022679414600134), ((11, 12), 0.0034496067091822624)]
******* after merging (0.04): [((2, 3), 128), ((0,), 128), ((5, 7), 64), ((1,), 64), ((4,), 64), ((6,), 32), ((8,), 32), ((9,), 32), ((10,), 32), ((11,), 32), ((12,), 32), ((13,), 32), ((14,), 32), ((15,), 32), ((16,), 32)]
{'R_grad_norm': 1.6470712679624557, 'training_loss': 6.851753551959991}
{'R_grad_norm': 1.6438532817363738, 'training_loss': 6.835605537891388}
{'R_grad_norm': 1.639618200659752, 'training_loss': 6.820864667892456}
{'R_grad_norm': 1.6439348423480988, 'training_loss': 6.84363753080368}
{'R_grad_norm': 1.640458164215088, 'training_loss': 6.817506356239319}
{'R_grad_norm': 1.6388895958662033, 'training_loss': 6.816209228038788}
{'R_grad_norm': 1.638587321639061, 'training_loss': 6.809914085865021}
{'R_grad_norm': 1.6357789051532745, 'training_loss': 6.798182229995728}
{'R_grad_norm': 1.6411516803503037, 'training_loss': 6.82447172164917}
{'R_grad_norm': 1.6341373825073242, 'training_loss': 6.793820984363556}
{'R_grad_norm': 1.6347305065393447, 'training_loss': 6.820648648738861}
{'R_grad_norm': 1.6347698760032654, 'training_loss': 6.79769287109375}
{'R_grad_norm': 1.6374612909555435, 'training_loss': 6.819652276039124}
{'R_grad_norm': 1.6315422081947326, 'training_loss': 6.791716070175171}
{'R_grad_norm': 1.6354888576269149, 'training_loss': 6.818568546772003}
{'R_grad_norm': 1.632916092276573, 'training_loss': 6.80285103559494}
{'R_grad_norm': 1.631168202161789, 'training_loss': 6.805621852874756}
{'R_grad_norm': 1.6355106389522553, 'training_loss': 6.83643976688385}
{'R_grad_norm': 1.6315535432100297, 'training_loss': 6.792961957454682}
{'R_grad_norm': 1.6304033660888673, 'training_loss': 6.796606638431549}
{'R_grad_norm': 1.6258172863721847, 'training_loss': 6.798597271442413}
{'R_grad_norm': 1.6279759520292283, 'training_loss': 6.797489702701569}
{'R_grad_norm': 1.629796170592308, 'training_loss': 6.815287034511567}
{'R_grad_norm': 1.6247997534275056, 'training_loss': 6.796224555969238}
{'R_grad_norm': 1.6297130864858627, 'training_loss': 6.816260657310486}
{'R_grad_norm': 1.6253975194692611, 'training_loss': 6.7954435992240905}
{'R_grad_norm': 1.6256513851881027, 'training_loss': 6.812370491027832}
{'R_grad_norm': 1.623955289721489, 'training_loss': 6.792566075325012}
{'R_grad_norm': 1.6156152802705765, 'training_loss': 6.77058182477951}
{'R_grad_norm': 1.6183012872934341, 'training_loss': 6.781795761585236}
{'R_grad_norm': 1.6156852555274963, 'training_loss': 6.763263714313507}
{'R_grad_norm': 1.6236490416526794, 'training_loss': 6.814999032020569}
{'R_grad_norm': 1.6139061897993088, 'training_loss': 6.771680698394776}
{'R_grad_norm': 1.6153119760751724, 'training_loss': 6.7729616689682}
{'R_grad_norm': 1.6159148132801056, 'training_loss': 6.772349607944489}
{'R_grad_norm': 1.6117742520570755, 'training_loss': 6.768285682201386}
{'R_grad_norm': 1.6195670294761657, 'training_loss': 6.798269379138946}
{'R_grad_norm': 1.6102453368902205, 'training_loss': 6.764283330440521}
{'R_grad_norm': 1.6152238380908965, 'training_loss': 6.792722413539886}
{'R_grad_norm': 1.609911311864853, 'training_loss': 6.770531129837036}
eval result tensor([13.56254, 11.70913,  7.77525,  8.15039,  6.28724,  5.75356,  3.95545,
         5.54990,  4.88903,  5.98955,  5.45663,  5.64462,  5.16239,  5.72786,
         5.61513], device='cuda:0')
computing merge metric
normed mi [((12, 13), 0.048952654004096985), ((10, 14), 0.04855417087674141), ((6, 8), 0.04571329429745674), ((1, 4), 0.04410970707734426), ((7, 10), 0.04183771088719368), ((12, 14), 0.04122266173362732), ((13, 14), 0.04083491861820221), ((3, 7), 0.0403900071978569), ((3, 12), 0.04026856770118078), ((2, 3), 0.03963342308998108), ((3, 10), 0.039136591056982674), ((2, 10), 0.038794065515200295), ((10, 12), 0.0381619930267334), ((3, 14), 0.038033150136470795), ((10, 13), 0.03783923387527466), ((3, 4), 0.037577394396066666), ((3, 13), 0.036638918022314705), ((4, 12), 0.03662149359782537), ((7, 14), 0.036617424339056015), ((7, 13), 0.03660280257463455), ((7, 12), 0.03616428002715111), ((6, 9), 0.03570226952433586), ((0, 3), 0.034625877936681114), ((2, 7), 0.033694895605246224), ((2, 14), 0.032990217208862305), ((2, 12), 0.032934087018171944), ((4, 13), 0.03289365768432617), ((0, 4), 0.032776626447836556), ((1, 3), 0.032753425339857735), ((4, 14), 0.03203225135803223), ((4, 6), 0.03181439389785131), ((6, 11), 0.0314621739089489), ((0, 13), 0.03132928609848022), ((0, 1), 0.031041983515024185), ((0, 14), 0.030559343099594117), ((8, 11), 0.030549291521310806), ((2, 4), 0.030183590948581696), ((0, 12), 0.02973414659500122), ((0, 2), 0.028400232394536335), ((1, 12), 0.028318172693252562), ((0, 10), 0.0281103253364563), ((2, 13), 0.027060923477013905), ((1, 2), 0.02621157964070638), ((1, 13), 0.025876930356025694), ((1, 14), 0.025059399008750916), ((4, 7), 0.024859425922234852), ((8, 9), 0.02439083531498909), ((4, 10), 0.024362531801064808), ((9, 11), 0.023722145706415176), ((0, 7), 0.022388431429862975), ((1, 10), 0.02066607177257538), ((1, 7), 0.019888176023960112), ((5, 11), 0.019294381141662598), ((6, 13), 0.016560398042201996), ((4, 11), 0.016258955001831055), ((6, 12), 0.015787398442626), ((4, 8), 0.015408816436926523), ((6, 14), 0.014772634021937847), ((1, 6), 0.014627508819103241), ((5, 9), 0.014060490764677525), ((5, 13), 0.013673942536115646), ((3, 6), 0.012951148053010305), ((5, 8), 0.012667490169405937), ((5, 7), 0.011409652419388294), ((11, 14), 0.011401042342185974), ((11, 13), 0.011399681679904461), ((5, 12), 0.011318717151880264), ((0, 6), 0.011276369541883468), ((2, 6), 0.01003346840540568), ((5, 6), 0.00997164100408554), ((6, 7), 0.009919087402522564), ((4, 9), 0.009695611273248991), ((6, 10), 0.009645543061196804), ((5, 14), 0.009447605349123478), ((11, 12), 0.009269271045923233), ((8, 14), 0.009166274219751358), ((8, 13), 0.008784418925642967), ((4, 5), 0.008342746645212173), ((1, 11), 0.007963021844625473), ((3, 11), 0.007956663767496744), ((9, 14), 0.007498559076339006), ((3, 5), 0.007489108790953954), ((7, 11), 0.007399052381515503), ((8, 12), 0.007248339708894491), ((9, 13), 0.006921509280800819), ((1, 8), 0.0066740155220031735), ((5, 10), 0.006444093305617571), ((2, 11), 0.006387699395418167), ((10, 11), 0.006274359300732613), ((0, 11), 0.006108367815613747), ((2, 5), 0.00609755702316761), ((3, 8), 0.005981383845210075), ((1, 5), 0.005969329178333283), ((9, 12), 0.005763222463428974), ((7, 8), 0.0053512961603701115), ((0, 5), 0.005022355541586876), ((0, 8), 0.004667614027857781), ((8, 10), 0.0046588885597884655), ((2, 8), 0.004619686243434747), ((1, 9), 0.004614560678601265), ((3, 9), 0.004568665598829587), ((7, 9), 0.004317704122513533), ((9, 10), 0.004262767732143402), ((2, 9), 0.0036658536021908126), ((0, 9), 0.0034514866769313813)]
******* after merging (0.04): [((0,), 128), ((1,), 128), ((12, 13), 64), ((2,), 64), ((3,), 64), ((4,), 64), ((5,), 32), ((6,), 32), ((7,), 32), ((8,), 32), ((9,), 32), ((10,), 32), ((11,), 32), ((14,), 32)]
{'R_grad_norm': 1.6911809116601944, 'training_loss': 7.149126329421997}
{'R_grad_norm': 1.687866483926773, 'training_loss': 7.127445225715637}
{'R_grad_norm': 1.6883295327425003, 'training_loss': 7.149079904556275}
{'R_grad_norm': 1.6850752425193787, 'training_loss': 7.127248973846435}
{'R_grad_norm': 1.680021413564682, 'training_loss': 7.09810144662857}
{'R_grad_norm': 1.6803030687570573, 'training_loss': 7.101062798500061}
{'R_grad_norm': 1.6835638219118119, 'training_loss': 7.125349626541138}
{'R_grad_norm': 1.681786647439003, 'training_loss': 7.105464859008789}
{'R_grad_norm': 1.6802529054880142, 'training_loss': 7.120590977668762}
{'R_grad_norm': 1.6798185700178145, 'training_loss': 7.128740544319153}
{'R_grad_norm': 1.6755967217683791, 'training_loss': 7.1016598272323606}
{'R_grad_norm': 1.6758500063419342, 'training_loss': 7.12068172454834}
{'R_grad_norm': 1.675812041759491, 'training_loss': 7.108753881454468}
{'R_grad_norm': 1.67521444439888, 'training_loss': 7.1249534797668455}
{'R_grad_norm': 1.6764930510520935, 'training_loss': 7.127496690750122}
{'R_grad_norm': 1.673077432513237, 'training_loss': 7.125915031433106}
{'R_grad_norm': 1.6746284115314483, 'training_loss': 7.1183844089508055}
{'R_grad_norm': 1.674571904540062, 'training_loss': 7.1237163066864015}
{'R_grad_norm': 1.6757659393548965, 'training_loss': 7.121546249389649}
{'R_grad_norm': 1.6760165923833847, 'training_loss': 7.127850375175476}
{'R_grad_norm': 1.6700050336122514, 'training_loss': 7.095490834712982}
{'R_grad_norm': 1.6689897626638412, 'training_loss': 7.095809073448181}
{'R_grad_norm': 1.6692741984128951, 'training_loss': 7.100822441577911}
{'R_grad_norm': 1.6684703779220582, 'training_loss': 7.122262887954712}
{'R_grad_norm': 1.6679158782958985, 'training_loss': 7.1163108038902285}
{'R_grad_norm': 1.6667114967107772, 'training_loss': 7.114837679862976}
{'R_grad_norm': 1.6680072742700576, 'training_loss': 7.12513916015625}
{'R_grad_norm': 1.6656229460239411, 'training_loss': 7.114686210155487}
{'R_grad_norm': 1.666036451458931, 'training_loss': 7.115134720802307}
{'R_grad_norm': 1.6650578302145005, 'training_loss': 7.108823561668396}
{'R_grad_norm': 1.6678276377916337, 'training_loss': 7.140065159797668}
{'R_grad_norm': 1.6621327620744706, 'training_loss': 7.109684374332428}
{'R_grad_norm': 1.6678534215688705, 'training_loss': 7.132173042297364}
{'R_grad_norm': 1.6607010442018508, 'training_loss': 7.101579954624176}
{'R_grad_norm': 1.65815744638443, 'training_loss': 7.089060332775116}
{'R_grad_norm': 1.6632352322340012, 'training_loss': 7.122051303386688}
{'R_grad_norm': 1.6631603026390076, 'training_loss': 7.117082946300506}
{'R_grad_norm': 1.658947584629059, 'training_loss': 7.11692583322525}
{'R_grad_norm': 1.659005937576294, 'training_loss': 7.095315251350403}
{'R_grad_norm': 1.657870780825615, 'training_loss': 7.107666952610016}
eval result tensor([14.09937, 11.71047,  9.36150,  7.67271,  7.87197,  6.17363,  5.74323,
         3.91338,  5.51755,  4.76332,  5.94277,  5.35178,  5.60229,  5.51595],
       device='cuda:0')
computing merge metric
normed mi [((11, 13), 0.04648568108677864), ((7, 9), 0.044865068048238754), ((5, 7), 0.04207485914230347), ((1, 5), 0.04205178717772166), ((8, 11), 0.041540298610925674), ((3, 4), 0.03994724899530411), ((4, 8), 0.039574536184469856), ((4, 11), 0.038057891031106315), ((3, 11), 0.0379196231563886), ((4, 5), 0.037799861282110214), ((4, 13), 0.03763635456562042), ((7, 10), 0.03609760105609894), ((8, 13), 0.035939086228609085), ((0, 4), 0.034302408496538796), ((1, 4), 0.03409798940022787), ((2, 4), 0.03348522260785103), ((3, 13), 0.03296544402837753), ((3, 8), 0.03262204428513845), ((2, 13), 0.032148284216721855), ((5, 13), 0.031160977979501087), ((7, 12), 0.031133944168686867), ((0, 13), 0.030772584676742553), ((0, 5), 0.030758800605932873), ((0, 1), 0.030401133000850677), ((0, 2), 0.030240359405676525), ((3, 5), 0.030219759792089462), ((9, 12), 0.030005136504769325), ((2, 11), 0.029698034127553303), ((2, 5), 0.02934560552239418), ((0, 3), 0.02884022394816081), ((2, 8), 0.028785601258277893), ((0, 11), 0.02791012227535248), ((1, 3), 0.027842705448468525), ((2, 3), 0.026979198679327965), ((1, 2), 0.0263987531264623), ((1, 13), 0.025483891367912292), ((5, 11), 0.023579835891723633), ((5, 9), 0.023348187406857807), ((5, 8), 0.02328723172346751), ((0, 8), 0.02252630591392517), ((10, 12), 0.02219793014228344), ((1, 11), 0.02109871953725815), ((9, 10), 0.020980214700102806), ((5, 12), 0.020626870294411976), ((6, 12), 0.02017577365040779), ((1, 8), 0.020125645399093627), ((7, 13), 0.018024945631623268), ((1, 7), 0.01693791002035141), ((4, 7), 0.01677515109380086), ((6, 10), 0.015261143445968628), ((12, 13), 0.014515163376927376), ((2, 7), 0.014014723400274912), ((3, 7), 0.01387123391032219), ((9, 13), 0.01335191447287798), ((5, 10), 0.013215741763512293), ((0, 7), 0.013089556992053986), ((6, 9), 0.012395388446748257), ((7, 11), 0.01218101941049099), ((7, 8), 0.01192115992307663), ((6, 8), 0.01122280489653349), ((6, 7), 0.010304108262062073), ((4, 12), 0.010291699320077896), ((1, 12), 0.009518561512231826), ((8, 12), 0.009297777898609638), ((1, 9), 0.009128578752279282), ((6, 13), 0.009038175456225872), ((4, 9), 0.008807606374224028), ((3, 12), 0.008769461885094643), ((5, 6), 0.008696276694536209), ((10, 13), 0.008416797034442425), ((2, 6), 0.008329176033536593), ((11, 12), 0.008159470744431019), ((2, 12), 0.007527366280555725), ((4, 6), 0.00751480149726073), ((0, 12), 0.007465407997369766), ((8, 9), 0.00723106088116765), ((3, 9), 0.007011170809467633), ((9, 11), 0.0067231017164886), ((6, 11), 0.006718010175973177), ((0, 9), 0.006568643450737), ((2, 9), 0.006485314418872197), ((3, 6), 0.005999589338898659), ((1, 6), 0.005674964934587479), ((4, 10), 0.005320638418197632), ((1, 10), 0.005203799530863762), ((0, 6), 0.004765236377716064), ((10, 11), 0.004577570594847202), ((8, 10), 0.004549887031316757), ((3, 10), 0.004235331589976947), ((2, 10), 0.0038610625391205153), ((0, 10), 0.0037696480751037596)]
******* after merging (0.04): [((0,), 128), ((1,), 128), ((11, 13), 64), ((2,), 64), ((3,), 64), ((4,), 64), ((5,), 64), ((6,), 32), ((7,), 32), ((8,), 32), ((9,), 32), ((10,), 32), ((12,), 32)]
{'R_grad_norm': 1.7226812052726745, 'training_loss': 7.52843986749649}
{'R_grad_norm': 1.7251418149471283, 'training_loss': 7.532606415748596}
{'R_grad_norm': 1.7257144236564637, 'training_loss': 7.5241144967079165}
{'R_grad_norm': 1.7194299936294555, 'training_loss': 7.510085487365723}
{'R_grad_norm': 1.7237803435325623, 'training_loss': 7.535908811092376}
{'R_grad_norm': 1.7200714737176894, 'training_loss': 7.518961136341095}
{'R_grad_norm': 1.7155954539775848, 'training_loss': 7.52022290468216}
{'R_grad_norm': 1.720051065683365, 'training_loss': 7.527167551517486}
{'R_grad_norm': 1.7226505130529404, 'training_loss': 7.509291305541992}
{'R_grad_norm': 1.7285840260982512, 'training_loss': 7.56062516450882}
{'R_grad_norm': 1.7298811846971511, 'training_loss': 7.56140380859375}
{'R_grad_norm': 1.7328052872419357, 'training_loss': 7.587075390815735}
{'R_grad_norm': 1.7350073200464249, 'training_loss': 7.6119569134712215}
{'R_grad_norm': 1.7395298784971238, 'training_loss': 7.632972640991211}
{'R_grad_norm': 1.7418743979930877, 'training_loss': 7.653694388866424}
{'R_grad_norm': 1.7496701967716217, 'training_loss': 7.693097965717316}
{'R_grad_norm': 1.7547892010211945, 'training_loss': 7.707044229507447}
{'R_grad_norm': 1.7538316279649735, 'training_loss': 7.722228982448578}
{'R_grad_norm': 1.7619367027282715, 'training_loss': 7.769218969345093}
{'R_grad_norm': 1.7645849752426148, 'training_loss': 7.779901714324951}
{'R_grad_norm': 1.772265189886093, 'training_loss': 7.842155280113221}
{'R_grad_norm': 1.7796955579519271, 'training_loss': 7.906624112129212}
{'R_grad_norm': 1.7942972654104232, 'training_loss': 7.96939373254776}
{'R_grad_norm': 1.7177233344316483, 'training_loss': 7.555732612609863}
{'R_grad_norm': 1.7077629506587981, 'training_loss': 7.497092468738556}
{'R_grad_norm': 1.7046212381124497, 'training_loss': 7.465694406032562}
{'R_grad_norm': 1.7028548586368562, 'training_loss': 7.455170373916626}
{'R_grad_norm': 1.6970596665143967, 'training_loss': 7.454053003787994}
{'R_grad_norm': 1.6996599841117859, 'training_loss': 7.458845963478089}
{'R_grad_norm': 1.6973042064905166, 'training_loss': 7.453974599838257}
{'R_grad_norm': 1.698140844106674, 'training_loss': 7.469592440128326}
{'R_grad_norm': 1.6951039147377014, 'training_loss': 7.462449297904969}
{'R_grad_norm': 1.7002354919910432, 'training_loss': 7.487552633285523}
{'R_grad_norm': 1.6923939675092696, 'training_loss': 7.447030057907105}
{'R_grad_norm': 1.6934485530853272, 'training_loss': 7.458503587245941}
{'R_grad_norm': 1.693769754767418, 'training_loss': 7.456376922130585}
{'R_grad_norm': 1.6933549147844316, 'training_loss': 7.453630862236023}
{'R_grad_norm': 1.6947134196758271, 'training_loss': 7.478084788322449}
{'R_grad_norm': 1.6896283841133117, 'training_loss': 7.4532374668121335}
{'R_grad_norm': 1.6902703416347504, 'training_loss': 7.4563380408287045}
eval result tensor([14.31938, 11.78192,  9.45228,  9.29169,  7.48643,  7.64392,  6.21046,
         5.72185,  3.90998,  5.39826,  4.65783,  5.87495,  5.51443],
       device='cuda:0')
computing merge metric
normed mi [((8, 10), 0.04667537659406662), ((6, 8), 0.04305096964041392), ((4, 5), 0.0415419265627861), ((1, 6), 0.04129278163115183), ((5, 9), 0.04040379822254181), ((5, 6), 0.03950193151831627), ((8, 11), 0.03683984652161598), ((1, 5), 0.03575921058654785), ((0, 5), 0.03454803675413132), ((3, 5), 0.03449101373553276), ((4, 9), 0.03356699893871943), ((8, 12), 0.032598622143268585), ((2, 5), 0.03226717934012413), ((3, 6), 0.03190338611602783), ((0, 3), 0.03154614816109339), ((4, 6), 0.03105059266090393), ((2, 4), 0.030937204137444496), ((2, 9), 0.03085234264532725), ((0, 6), 0.030803027252356213), ((0, 1), 0.030428243800997734), ((3, 9), 0.029948532581329346), ((10, 12), 0.02944362163543701), ((1, 4), 0.028903111815452576), ((0, 4), 0.02884688725074132), ((1, 3), 0.027924008667469025), ((3, 4), 0.027696523815393448), ((2, 3), 0.027256935834884644), ((0, 2), 0.027159718175729115), ((6, 9), 0.02439045161008835), ((0, 9), 0.02335602343082428), ((11, 12), 0.02253401279449463), ((10, 11), 0.022088436409831047), ((1, 2), 0.021617814898490906), ((6, 10), 0.021497371296087902), ((6, 12), 0.021480138103167217), ((2, 6), 0.0214463472366333), ((1, 9), 0.021247822046279907), ((7, 12), 0.019852599129080772), ((5, 8), 0.017727977285782497), ((1, 8), 0.016039749979972838), ((3, 8), 0.015064696470896402), ((7, 11), 0.014909663237631321), ((4, 8), 0.014203065385421118), ((6, 11), 0.013472358385721842), ((0, 8), 0.012853866815567017), ((8, 9), 0.0127035491168499), ((7, 10), 0.011294734664261341), ((7, 9), 0.01125665009021759), ((5, 12), 0.010848750670750936), ((7, 8), 0.010386760346591473), ((9, 12), 0.009591358713805676), ((1, 12), 0.009356819093227386), ((2, 8), 0.009244797130425772), ((6, 7), 0.009150064860781034), ((4, 12), 0.009096307680010796), ((3, 7), 0.008183882261315981), ((3, 12), 0.00809363586207231), ((5, 10), 0.008039619152744612), ((1, 10), 0.007539676129817962), ((5, 7), 0.007521490876873334), ((0, 12), 0.0073907271027565), ((9, 10), 0.0064158192835748196), ((2, 12), 0.00638613539437453), ((4, 7), 0.006307347988088925), ((4, 10), 0.006264636913935344), ((3, 10), 0.005888594935337703), ((1, 7), 0.005689002200961113), ((5, 11), 0.005568227420250575), ((0, 10), 0.005345384776592255), ((2, 7), 0.005191820673644543), ((1, 11), 0.004943542554974556), ((9, 11), 0.004734927788376808), ((0, 7), 0.004707128927111626), ((2, 10), 0.004688462242484093), ((4, 11), 0.004412244074046612), ((3, 11), 0.004067954917748769), ((2, 11), 0.003785525138179461), ((0, 11), 0.003569439798593521)]
******* after merging (0.04): [((0,), 128), ((1,), 128), ((8, 10), 64), ((2,), 64), ((3,), 64), ((4,), 64), ((5,), 64), ((6,), 64), ((7,), 32), ((9,), 32), ((11,), 32), ((12,), 32)]
{'R_grad_norm': 1.7579673552513122, 'training_loss': 7.987516069412232}
{'R_grad_norm': 1.7552990812063216, 'training_loss': 7.961074841022492}
{'R_grad_norm': 1.7541715222597123, 'training_loss': 7.958354678153992}
{'R_grad_norm': 1.7595876175165177, 'training_loss': 7.99512226819992}
{'R_grad_norm': 1.7593716007471085, 'training_loss': 7.998332216739654}
{'R_grad_norm': 1.7511345392465592, 'training_loss': 7.953084564208984}
{'R_grad_norm': 1.7520496493577957, 'training_loss': 7.963291952610016}
{'R_grad_norm': 1.7518164974451065, 'training_loss': 7.965569562911988}
{'R_grad_norm': 1.7551110714673996, 'training_loss': 7.973677730560302}
{'R_grad_norm': 1.7543213111162186, 'training_loss': 7.980699274539948}
{'R_grad_norm': 1.750545945763588, 'training_loss': 7.959983446598053}
{'R_grad_norm': 1.7484165704250336, 'training_loss': 7.964980878829956}
{'R_grad_norm': 1.746508064866066, 'training_loss': 7.944689347743988}
{'R_grad_norm': 1.7489458507299422, 'training_loss': 7.965671219825745}
{'R_grad_norm': 1.7467118859291078, 'training_loss': 7.953273525238037}
{'R_grad_norm': 1.7466469877958297, 'training_loss': 7.974425044059753}
{'R_grad_norm': 1.74103695333004, 'training_loss': 7.940729682445526}
{'R_grad_norm': 1.742749575972557, 'training_loss': 7.945533990859985}
{'R_grad_norm': 1.748820413351059, 'training_loss': 7.9897150135040285}
{'R_grad_norm': 1.7446343570947647, 'training_loss': 7.983209459781647}
{'R_grad_norm': 1.7429689663648604, 'training_loss': 7.967663700580597}
{'R_grad_norm': 1.737353949546814, 'training_loss': 7.93132419347763}
{'R_grad_norm': 1.735498828291893, 'training_loss': 7.935837109088897}
{'R_grad_norm': 1.737195371389389, 'training_loss': 7.939445719718933}
{'R_grad_norm': 1.7412532770633697, 'training_loss': 7.958805508613587}
{'R_grad_norm': 1.739127621650696, 'training_loss': 7.950725791454315}
{'R_grad_norm': 1.7329325097799302, 'training_loss': 7.9203740191459655}
{'R_grad_norm': 1.7334033781290055, 'training_loss': 7.933251802921295}
{'R_grad_norm': 1.7383799767494201, 'training_loss': 7.955922999382019}
{'R_grad_norm': 1.7366402280330657, 'training_loss': 7.960754129886627}
{'R_grad_norm': 1.7311242413520813, 'training_loss': 7.945200417041779}
{'R_grad_norm': 1.7336366277933122, 'training_loss': 7.964644541740418}
{'R_grad_norm': 1.7296463894844054, 'training_loss': 7.929317014217377}
{'R_grad_norm': 1.7310935455560683, 'training_loss': 7.94665798664093}
{'R_grad_norm': 1.727128894329071, 'training_loss': 7.932699365615845}
{'R_grad_norm': 1.7276668894290923, 'training_loss': 7.942870538234711}
{'R_grad_norm': 1.728008902668953, 'training_loss': 7.933646850585937}
{'R_grad_norm': 1.7317310661077499, 'training_loss': 7.953464879989624}
{'R_grad_norm': 1.7275914949178697, 'training_loss': 7.946578550338745}
{'R_grad_norm': 1.7273277616500855, 'training_loss': 7.944972264766693}
eval result tensor([14.68659, 11.68664,  6.91097,  9.33717,  9.13528,  7.42837,  7.51147,
         6.07498,  5.66792,  5.39688,  5.74015,  5.38217], device='cuda:0')
computing merge metric
normed mi [((1, 7), 0.040866648157437645), ((5, 6), 0.04071079567074776), ((6, 9), 0.04031263788541158), ((6, 7), 0.03856154903769493), ((2, 7), 0.038171324878931046), ((1, 6), 0.035348849991957344), ((4, 6), 0.03470589593052864), ((0, 6), 0.033955986301104225), ((5, 9), 0.033346657951672874), ((3, 6), 0.032655611634254456), ((0, 4), 0.031189553439617157), ((3, 5), 0.03083338402211666), ((3, 9), 0.030749415357907612), ((4, 7), 0.030569689348340034), ((4, 9), 0.029964697857697804), ((5, 7), 0.02962639182806015), ((0, 1), 0.02934950217604637), ((0, 7), 0.0292359193166097), ((1, 5), 0.02812168002128601), ((3, 4), 0.027966953814029694), ((1, 4), 0.027780229846636455), ((4, 5), 0.02769995667040348), ((0, 5), 0.027622347076733906), ((0, 3), 0.02710123856862386), ((2, 11), 0.025460096697012585), ((7, 9), 0.024170319239298504), ((0, 9), 0.023763473331928252), ((10, 11), 0.023214509710669518), ((7, 11), 0.02192336569229762), ((1, 3), 0.021657384932041168), ((3, 7), 0.021305909380316734), ((1, 9), 0.021276746690273286), ((8, 11), 0.01997562125325203), ((2, 10), 0.018672411640485127), ((8, 10), 0.01639241725206375), ((1, 2), 0.01563345268368721), ((2, 6), 0.015057708136737347), ((7, 10), 0.013724934309720993), ((2, 4), 0.012166745029389858), ((0, 2), 0.012104131281375885), ((2, 5), 0.011674132198095322), ((6, 11), 0.011036459356546402), ((8, 9), 0.010956661775708199), ((2, 9), 0.00999867357313633), ((9, 11), 0.009920511394739151), ((7, 8), 0.009680987646182379), ((1, 11), 0.009423692524433137), ((5, 11), 0.009092376256982485), ((2, 3), 0.008439700119197369), ((2, 8), 0.008131556833783785), ((4, 8), 0.007678811127940814), ((6, 8), 0.007612469295660655), ((4, 11), 0.007362567509214084), ((0, 11), 0.006967373192310333), ((3, 11), 0.006582899019122124), ((5, 8), 0.006204919268687566), ((1, 8), 0.005829667299985885), ((6, 10), 0.005625460917750995), ((3, 8), 0.005209204430381457), ((1, 10), 0.005072193592786789), ((9, 10), 0.004823227412998676), ((5, 10), 0.0045646196231245995), ((0, 8), 0.004414171725511551), ((3, 10), 0.003961648792028427), ((4, 10), 0.003916961140930653), ((0, 10), 0.003443247079849243)]
******* after merging (0.04): [((1, 7), 192), ((0,), 128), ((2,), 64), ((3,), 64), ((4,), 64), ((5,), 64), ((6,), 64), ((8,), 32), ((9,), 32), ((10,), 32), ((11,), 32)]
{'R_grad_norm': 1.8651950877904893, 'training_loss': 8.294577491283416}
{'R_grad_norm': 1.8612232756614686, 'training_loss': 8.25922699213028}
{'R_grad_norm': 1.8624526953697205, 'training_loss': 8.264092061519623}
{'R_grad_norm': 1.8615579032897949, 'training_loss': 8.258637235164642}
{'R_grad_norm': 1.8597750234603883, 'training_loss': 8.261173143386841}
{'R_grad_norm': 1.8605931609869004, 'training_loss': 8.252461619377137}
{'R_grad_norm': 1.8611170786619187, 'training_loss': 8.258350827693938}
{'R_grad_norm': 1.8614823818206787, 'training_loss': 8.28072283744812}
{'R_grad_norm': 1.8608481061458588, 'training_loss': 8.257267878055572}
{'R_grad_norm': 1.856330195069313, 'training_loss': 8.253513805866241}
{'R_grad_norm': 1.8513604587316512, 'training_loss': 8.22181432723999}
{'R_grad_norm': 1.8541011834144592, 'training_loss': 8.249165964126586}
{'R_grad_norm': 1.8483931869268417, 'training_loss': 8.211991314888001}
{'R_grad_norm': 1.8537197262048721, 'training_loss': 8.239670515060425}
{'R_grad_norm': 1.853889917731285, 'training_loss': 8.253262403011322}
{'R_grad_norm': 1.8522325325012208, 'training_loss': 8.254338965415954}
{'R_grad_norm': 1.8562029033899308, 'training_loss': 8.279587273597718}
{'R_grad_norm': 1.8506982547044755, 'training_loss': 8.246071267127991}
{'R_grad_norm': 1.8514234793186188, 'training_loss': 8.270238387584687}
{'R_grad_norm': 1.8452246338129044, 'training_loss': 8.210748505592345}
{'R_grad_norm': 1.8490933322906493, 'training_loss': 8.262583701610565}
{'R_grad_norm': 1.844533578157425, 'training_loss': 8.230972018241882}
{'R_grad_norm': 1.8476987701654435, 'training_loss': 8.263994028568268}
{'R_grad_norm': 1.8484866523742676, 'training_loss': 8.2673832154274}
{'R_grad_norm': 1.8470553696155547, 'training_loss': 8.247689757347107}
{'R_grad_norm': 1.845681867003441, 'training_loss': 8.257522232532502}
{'R_grad_norm': 1.8447836548089982, 'training_loss': 8.241060018539429}
{'R_grad_norm': 1.846542974114418, 'training_loss': 8.264609839916229}
{'R_grad_norm': 1.8389391607046128, 'training_loss': 8.20713320016861}
{'R_grad_norm': 1.8376036059856415, 'training_loss': 8.233641250133514}
{'R_grad_norm': 1.8450924640893935, 'training_loss': 8.259996404647827}
{'R_grad_norm': 1.8407755261659622, 'training_loss': 8.256138615608215}
{'R_grad_norm': 1.8361283165216447, 'training_loss': 8.221079902648926}
{'R_grad_norm': 1.8426418632268906, 'training_loss': 8.26617668390274}
{'R_grad_norm': 1.841744708418846, 'training_loss': 8.265996932983398}
{'R_grad_norm': 1.833937349319458, 'training_loss': 8.239210522174835}
{'R_grad_norm': 1.8393059945106507, 'training_loss': 8.255116276741028}
{'R_grad_norm': 1.8384253829717636, 'training_loss': 8.240464758872985}
{'R_grad_norm': 1.8323237055540085, 'training_loss': 8.223611173629761}
{'R_grad_norm': 1.8375709104537963, 'training_loss': 8.263257122039795}
eval result tensor([13.93587, 14.75605,  6.83289,  9.27483,  8.99284,  7.38218,  7.37715,
         5.53205,  5.34132,  5.68648,  5.27054], device='cuda:0')
computing merge metric
normed mi [((5, 6), 0.039962854236364365), ((6, 8), 0.03920920193195343), ((4, 6), 0.03511255234479904), ((1, 6), 0.03361590951681137), ((5, 8), 0.033292487263679504), ((3, 6), 0.032018501311540604), ((3, 8), 0.03031817575295766), ((3, 5), 0.030259033665060997), ((1, 4), 0.030158042907714844), ((4, 8), 0.029316020508607227), ((3, 4), 0.027405567467212677), ((4, 5), 0.027253977954387665), ((1, 5), 0.026925362646579742), ((1, 3), 0.026708016792933147), ((2, 6), 0.026546550914645195), ((0, 6), 0.02603915147483349), ((1, 8), 0.02344081997871399), ((2, 10), 0.02289697527885437), ((0, 1), 0.022469323873519898), ((9, 10), 0.02140490710735321), ((2, 4), 0.021031033247709274), ((0, 4), 0.020162107422947884), ((2, 5), 0.019950028508901596), ((0, 5), 0.019730620086193085), ((0, 2), 0.019307564944028854), ((1, 2), 0.01893017441034317), ((7, 9), 0.01883305422961712), ((7, 10), 0.018732549622654915), ((2, 8), 0.01684982453783353), ((0, 3), 0.01523590087890625), ((0, 8), 0.014656891780240195), ((2, 9), 0.014239481339852015), ((2, 3), 0.01402700413018465), ((6, 10), 0.01153076688448588), ((8, 10), 0.010489397682249546), ((5, 10), 0.009107304736971855), ((7, 8), 0.00908437930047512), ((4, 10), 0.007756018390258153), ((2, 7), 0.007540295521418254), ((0, 10), 0.007173439221722739), ((1, 10), 0.007079171389341355), ((3, 10), 0.006808772683143616), ((4, 7), 0.006401202951868375), ((6, 7), 0.006248397131760915), ((6, 9), 0.005936835582057635), ((8, 9), 0.005111971870064735), ((5, 7), 0.00497352300832669), ((3, 7), 0.004527082045873006), ((5, 9), 0.004491657018661499), ((3, 9), 0.004032383362452189), ((4, 9), 0.003962964440385501), ((0, 9), 0.003860984795859882), ((0, 7), 0.003450646996498108), ((1, 9), 0.003356051445007324), ((1, 7), 0.003304460272192955)]
finish training (84000)
evaluating (25 steps)...
 ******* eval result *******
mean (weighted) 10.17550786336263
mean (unweighted) 8.216618537902832
tensor([13.95408, 14.76107,  6.82801,  9.21456,  9.07637,  7.32998,  7.32689,
         5.58687,  5.34081,  5.68398,  5.28018], device='cuda:0')
