{'R_grad_norm': 0.8632604825496674, 'training_loss': 4.60588977098465}
{'R_grad_norm': 0.859391235113144, 'training_loss': 4.471857147216797}
{'R_grad_norm': 0.8645129391551017, 'training_loss': 4.358505265712738}
{'R_grad_norm': 0.8684311884641648, 'training_loss': 4.2515556204319}
{'R_grad_norm': 0.8730363473296165, 'training_loss': 4.173660233020782}
{'R_grad_norm': 0.8753876203298568, 'training_loss': 4.0996529221534725}
{'R_grad_norm': 0.8754064932465553, 'training_loss': 4.018018554449082}
{'R_grad_norm': 0.8816491422057152, 'training_loss': 3.999169490337372}
{'R_grad_norm': 0.8769809409976006, 'training_loss': 3.926053819656372}
{'R_grad_norm': 0.8793673312664032, 'training_loss': 3.8939242243766783}
{'R_grad_norm': 0.879701766371727, 'training_loss': 3.8676150858402254}
{'R_grad_norm': 0.8803453865647316, 'training_loss': 3.8345906853675844}
{'R_grad_norm': 0.8807382023334503, 'training_loss': 3.818341236114502}
{'R_grad_norm': 0.8774994713068008, 'training_loss': 3.787948820590973}
{'R_grad_norm': 0.8794773945212364, 'training_loss': 3.766571855545044}
{'R_grad_norm': 0.8809429395198822, 'training_loss': 3.757024837732315}
{'R_grad_norm': 0.8804507723450661, 'training_loss': 3.7361949670314787}
{'R_grad_norm': 0.8778593152761459, 'training_loss': 3.7134268999099733}
{'R_grad_norm': 0.8787814250588417, 'training_loss': 3.711386334896088}
{'R_grad_norm': 0.8763849812746048, 'training_loss': 3.682792195081711}
{'R_grad_norm': 0.8783214375376701, 'training_loss': 3.690658634901047}
{'R_grad_norm': 0.8760383728146554, 'training_loss': 3.661901295185089}
{'R_grad_norm': 0.874313297867775, 'training_loss': 3.644128339290619}
{'R_grad_norm': 0.8788347309827804, 'training_loss': 3.663324463367462}
{'R_grad_norm': 0.8786014235019683, 'training_loss': 3.657442978620529}
{'R_grad_norm': 0.877281482219696, 'training_loss': 3.6440562307834625}
{'R_grad_norm': 0.8786236056685448, 'training_loss': 3.641683969497681}
{'R_grad_norm': 0.8759557622671127, 'training_loss': 3.6254267179965973}
{'R_grad_norm': 0.8737377536296844, 'training_loss': 3.6087713086605073}
{'R_grad_norm': 0.874238130748272, 'training_loss': 3.6083264780044555}
{'R_grad_norm': 0.8754324248433113, 'training_loss': 3.614401499032974}
{'R_grad_norm': 0.8754928296804428, 'training_loss': 3.6050949466228484}
{'R_grad_norm': 0.8739071252942086, 'training_loss': 3.5967975676059725}
{'R_grad_norm': 0.8722112932801247, 'training_loss': 3.57677472949028}
{'R_grad_norm': 0.8741425788402557, 'training_loss': 3.592033863067627}
{'R_grad_norm': 0.8749625992774963, 'training_loss': 3.5903350675106047}
{'R_grad_norm': 0.8727571773529053, 'training_loss': 3.5737167060375215}
{'R_grad_norm': 0.8724377936124802, 'training_loss': 3.5749891602993014}
{'R_grad_norm': 0.8703082144260407, 'training_loss': 3.548820620775223}
{'R_grad_norm': 0.8709183752536773, 'training_loss': 3.5551629948616026}
{'R_grad_norm': 0.8699659234285355, 'training_loss': 3.5585449647903444}
{'R_grad_norm': 0.8698250728845597, 'training_loss': 3.5427349650859834}
{'R_grad_norm': 0.8705370298027992, 'training_loss': 3.5563398504257204}
{'R_grad_norm': 0.8708787676692009, 'training_loss': 3.5508067548274993}
{'R_grad_norm': 0.869422841668129, 'training_loss': 3.5354006493091585}
{'R_grad_norm': 0.8679090830683708, 'training_loss': 3.5367369627952576}
{'R_grad_norm': 0.8693143087625503, 'training_loss': 3.5404585504531862}
{'R_grad_norm': 0.8679199686646462, 'training_loss': 3.531178376674652}
{'R_grad_norm': 0.8662224102020264, 'training_loss': 3.514388691186905}
{'R_grad_norm': 0.8667766067385674, 'training_loss': 3.520830981731415}
{'R_grad_norm': 0.8686377057433128, 'training_loss': 3.5296397495269773}
{'R_grad_norm': 0.866576179265976, 'training_loss': 3.517272344827652}
{'R_grad_norm': 0.866583394408226, 'training_loss': 3.5133493936061857}
{'R_grad_norm': 0.8667853716015815, 'training_loss': 3.5205412530899047}
{'R_grad_norm': 0.8656270989775657, 'training_loss': 3.509760562181473}
{'R_grad_norm': 0.8640247526764869, 'training_loss': 3.5076392316818237}
{'R_grad_norm': 0.8643835350871086, 'training_loss': 3.5019729685783387}
{'R_grad_norm': 0.8653388288617134, 'training_loss': 3.508700096607208}
{'R_grad_norm': 0.8633335879445077, 'training_loss': 3.495502928495407}
{'R_grad_norm': 0.864390898346901, 'training_loss': 3.5015236675739287}
{'R_grad_norm': 0.8608958953619004, 'training_loss': 3.477473425865173}
{'R_grad_norm': 0.8624905094504356, 'training_loss': 3.4912036991119386}
{'R_grad_norm': 0.8594098940491677, 'training_loss': 3.476978999376297}
{'R_grad_norm': 0.8617670920491218, 'training_loss': 3.489211881160736}
{'R_grad_norm': 0.8633127203583717, 'training_loss': 3.489979088306427}
{'R_grad_norm': 0.8641048750281334, 'training_loss': 3.495142670869827}
{'R_grad_norm': 0.8623390960693359, 'training_loss': 3.4840847396850587}
{'R_grad_norm': 0.8606459736824036, 'training_loss': 3.479214622974396}
{'R_grad_norm': 0.8614023619890213, 'training_loss': 3.4805086994171144}
{'R_grad_norm': 0.8634295624494552, 'training_loss': 3.486456300020218}
{'R_grad_norm': 0.8642927441000938, 'training_loss': 3.4856677627563477}
{'R_grad_norm': 0.8594485267996788, 'training_loss': 3.464094340801239}
{'R_grad_norm': 0.8618076050281525, 'training_loss': 3.4723771166801454}
{'R_grad_norm': 0.8648968967795372, 'training_loss': 3.4903495001792906}
{'R_grad_norm': 0.859996321797371, 'training_loss': 3.4758101010322573}
{'R_grad_norm': 0.8632234823703766, 'training_loss': 3.486939027309418}
{'R_grad_norm': 0.859519237279892, 'training_loss': 3.4743850350379946}
{'R_grad_norm': 0.8598299556970597, 'training_loss': 3.46051139831543}
{'R_grad_norm': 0.8617048287391662, 'training_loss': 3.4753248929977416}
{'R_grad_norm': 0.8604741942882538, 'training_loss': 3.4719589519500733}
{'R_grad_norm': 0.8606764790415764, 'training_loss': 3.46363583445549}
{'R_grad_norm': 0.858636264204979, 'training_loss': 3.4696290636062623}
{'R_grad_norm': 0.8609543746709823, 'training_loss': 3.470046149492264}
{'R_grad_norm': 0.8586993873119354, 'training_loss': 3.456259616613388}
{'R_grad_norm': 0.8601740896701813, 'training_loss': 3.4633799719810487}
{'R_grad_norm': 0.8613217261433601, 'training_loss': 3.4673701632022857}
{'R_grad_norm': 0.8598616030812264, 'training_loss': 3.464151315689087}
{'R_grad_norm': 0.8580258768796921, 'training_loss': 3.4534326815605163}
{'R_grad_norm': 0.8581063032150269, 'training_loss': 3.4466899287700654}
{'R_grad_norm': 0.8579594710469246, 'training_loss': 3.4490572702884674}
{'R_grad_norm': 0.8590249693393708, 'training_loss': 3.4571273493766785}
{'R_grad_norm': 0.8567702394723892, 'training_loss': 3.437685581445694}
{'R_grad_norm': 0.8577418860793113, 'training_loss': 3.457967085838318}
{'R_grad_norm': 0.8552866050601006, 'training_loss': 3.4362761878967287}
{'R_grad_norm': 0.857863599061966, 'training_loss': 3.4554769659042357}
{'R_grad_norm': 0.8565749928355217, 'training_loss': 3.4449396312236784}
{'R_grad_norm': 0.859242913722992, 'training_loss': 3.4598052608966827}
{'R_grad_norm': 0.8565146899223328, 'training_loss': 3.4447805416584014}
{'R_grad_norm': 0.8570143827795982, 'training_loss': 3.4334151554107666}
{'R_grad_norm': 0.8568529438972473, 'training_loss': 3.441372787952423}
eval result tensor([3.09495, 3.17346, 3.81136, 3.35027, 2.94787, 2.96637, 3.35700, 3.34227,
        3.49656, 3.04525, 3.47067, 3.33107, 3.43186, 4.09417, 4.39286, 4.44053,
        3.24227, 3.60996, 3.59369, 3.13824, 3.11852, 4.07933, 3.24995, 3.60743],
       device='cuda:0')
computing merge metric
normed mi [((5, 9), 0.13823872804641724), ((0, 5), 0.13820020854473114), ((0, 9), 0.13594509661197662), ((9, 20), 0.132828027009964), ((1, 5), 0.13246466219425201), ((1, 7), 0.1320275366306305), ((1, 6), 0.13107794523239136), ((5, 7), 0.1308465600013733), ((1, 9), 0.130385160446167), ((7, 22), 0.13032518327236176), ((6, 7), 0.13010555505752563), ((7, 9), 0.12941336631774902), ((5, 20), 0.12911342084407806), ((1, 22), 0.1287846714258194), ((0, 1), 0.12833227217197418), ((6, 22), 0.1278810352087021), ((0, 7), 0.12700557708740234), ((0, 20), 0.12694957852363586), ((5, 6), 0.12665832042694092), ((5, 22), 0.12575706839561462), ((9, 22), 0.12537822127342224), ((6, 9), 0.12493277341127396), ((1, 20), 0.12367364764213562), ((7, 20), 0.12317029386758804), ((0, 6), 0.12187669426202774), ((0, 22), 0.12168220430612564), ((20, 22), 0.12156538665294647), ((19, 22), 0.11823373287916183), ((6, 20), 0.11821125447750092), ((10, 22), 0.11723431199789047), ((7, 19), 0.11523652076721191), ((7, 10), 0.11496230214834213), ((6, 10), 0.11475565284490585), ((1, 19), 0.11425703763961792), ((7, 16), 0.1136476993560791), ((16, 22), 0.11363615840673447), ((16, 20), 0.11356720328330994), ((6, 19), 0.11326649785041809), ((9, 16), 0.11324059218168259), ((1, 10), 0.11280731856822968), ((5, 16), 0.11272643506526947), ((1, 16), 0.11178764700889587), ((19, 20), 0.1115480363368988), ((16, 19), 0.11124598234891891), ((9, 19), 0.11114340275526047), ((5, 19), 0.10918215662240982), ((0, 16), 0.10894351452589035), ((6, 16), 0.10850389301776886), ((12, 20), 0.10657832026481628), ((10, 19), 0.1065748855471611), ((5, 10), 0.10608898103237152), ((9, 10), 0.10602335631847382), ((12, 22), 0.10517505556344986), ((0, 19), 0.10449722409248352), ((12, 19), 0.10301109403371811), ((10, 20), 0.10229416936635971), ((9, 12), 0.10193035751581192), ((3, 22), 0.10185042023658752), ((12, 16), 0.10141999274492264), ((7, 12), 0.1013864204287529), ((3, 19), 0.10125324875116348), ((0, 10), 0.10110051929950714), ((1, 12), 0.10089009255170822), ((10, 16), 0.10079452395439148), ((5, 12), 0.09979726374149323), ((6, 12), 0.09825124591588974), ((3, 7), 0.09765932708978653), ((0, 4), 0.09708128124475479), ((0, 12), 0.09627776592969894), ((1, 3), 0.0957481637597084), ((3, 6), 0.09536225348711014), ((3, 16), 0.09511278569698334), ((3, 20), 0.09437840431928635), ((4, 5), 0.09361949563026428), ((3, 10), 0.09354566037654877), ((3, 12), 0.09314596652984619), ((4, 9), 0.09283366799354553), ((11, 22), 0.0915413573384285), ((3, 9), 0.09143972396850586), ((10, 12), 0.09120537340641022), ((18, 21), 0.09005855023860931), ((11, 19), 0.08997934311628342), ((3, 5), 0.08944066613912582), ((7, 11), 0.08822476118803024), ((1, 11), 0.08656284213066101), ((4, 20), 0.08621261268854141), ((6, 11), 0.08597089350223541), ((0, 3), 0.08526305109262466), ((10, 11), 0.08384592831134796), ((11, 20), 0.08330149203538895), ((3, 11), 0.08320046216249466), ((11, 16), 0.083002969622612), ((18, 19), 0.08274446427822113), ((12, 21), 0.08216974139213562), ((11, 12), 0.0817505419254303), ((9, 11), 0.08167652040719986), ((5, 11), 0.08096593618392944), ((19, 21), 0.08037801831960678), ((14, 18), 0.07751219719648361), ((0, 11), 0.07700928300619125), ((14, 21), 0.07661066949367523), ((3, 18), 0.07549788802862167), ((3, 21), 0.07494740933179855), ((18, 22), 0.07465071231126785), ((20, 21), 0.07402430474758148), ((16, 21), 0.07400786131620407), ((21, 22), 0.07348193228244781), ((12, 18), 0.07240144163370132), ((1, 4), 0.0721215158700943), ((16, 18), 0.07208956778049469), ((16, 17), 0.07152827084064484), ((17, 22), 0.07139895111322403), ((4, 7), 0.07091519981622696), ((10, 18), 0.07034829258918762), ((17, 19), 0.06980999559164047), ((6, 18), 0.06962607800960541), ((17, 20), 0.06950386613607407), ((7, 17), 0.06915444135665894), ((7, 18), 0.06886342167854309), ((1, 18), 0.06843554973602295), ((1, 17), 0.06818481534719467), ((18, 20), 0.06767638027667999), ((1, 21), 0.0676310658454895), ((9, 17), 0.06761246919631958), ((7, 21), 0.06756725907325745), ((6, 21), 0.06739562004804611), ((5, 17), 0.06738661974668503), ((10, 21), 0.06688619405031204), ((9, 21), 0.0668535828590393), ((12, 17), 0.06673837453126907), ((6, 17), 0.06659957766532898), ((0, 17), 0.06595056504011154), ((10, 23), 0.06537076085805893), ((8, 10), 0.06517937034368515), ((4, 22), 0.06513220071792603), ((8, 22), 0.06445096433162689), ((9, 18), 0.0644293949007988), ((22, 23), 0.06432488560676575), ((4, 16), 0.06424648314714432), ((11, 18), 0.06393235921859741), ((4, 6), 0.06365908682346344), ((19, 23), 0.06349027901887894), ((8, 19), 0.06314138323068619), ((3, 17), 0.06301653385162354), ((5, 21), 0.0627666562795639), ((8, 16), 0.06198008358478546), ((5, 18), 0.061806801706552505), ((3, 8), 0.061633653938770294), ((7, 8), 0.06163279712200165), ((3, 23), 0.061429817229509354), ((10, 17), 0.061395030468702316), ((11, 21), 0.06127858906984329), ((6, 23), 0.06062548607587814), ((18, 23), 0.0602409727871418), ((7, 23), 0.060182198882102966), ((6, 8), 0.05948828533291817), ((0, 21), 0.059431254863739014), ((1, 8), 0.0588827021420002), ((1, 23), 0.05864176154136658), ((0, 18), 0.05848131701350212), ((16, 23), 0.05724630132317543), ((14, 19), 0.0566035732626915), ((11, 23), 0.05619117245078087), ((8, 11), 0.05558624491095543), ((8, 20), 0.055541619658470154), ((8, 12), 0.05498330295085907), ((4, 12), 0.0548110231757164), ((11, 17), 0.05452270805835724), ((4, 19), 0.054116301238536835), ((14, 22), 0.05375434458255768), ((5, 8), 0.05368532985448837), ((8, 9), 0.05354216322302818), ((12, 23), 0.053347110748291016), ((3, 14), 0.05313664674758911), ((9, 23), 0.05302409082651138), ((5, 23), 0.05283045768737793), ((21, 23), 0.052585337311029434), ((17, 21), 0.05248022824525833), ((14, 23), 0.05195499211549759), ((20, 23), 0.05169570446014404), ((0, 8), 0.051293715834617615), ((8, 23), 0.05063697323203087), ((10, 14), 0.050633855164051056), ((12, 14), 0.05063160881400108), ((14, 16), 0.050627708435058594), ((17, 18), 0.049971092492341995), ((6, 14), 0.04976541921496391), ((8, 18), 0.04948021471500397), ((0, 23), 0.04933067783713341), ((7, 14), 0.04865275323390961), ((1, 14), 0.048248548060655594), ((11, 14), 0.04717901721596718), ((4, 13), 0.04687170311808586), ((14, 20), 0.0463925302028656), ((8, 21), 0.0460863821208477), ((4, 10), 0.04563936963677406), ((9, 14), 0.04459373280405998), ((8, 17), 0.04424764961004257), ((2, 15), 0.044168319553136826), ((5, 14), 0.04343893751502037), ((8, 14), 0.041714806109666824), ((3, 4), 0.04166299104690552), ((0, 14), 0.04123799875378609), ((14, 17), 0.03716391697525978), ((4, 17), 0.03715214133262634), ((4, 11), 0.037089165300130844), ((17, 23), 0.03693291172385216), ((4, 21), 0.028183547779917717), ((4, 8), 0.026631612330675125), ((4, 18), 0.02625802531838417), ((15, 20), 0.02605493552982807), ((5, 15), 0.025924813002347946), ((0, 15), 0.025852028280496597), ((9, 15), 0.025480376556515694), ((15, 16), 0.022655298933386803), ((7, 15), 0.02222514897584915), ((1, 15), 0.022085215896368027), ((2, 4), 0.02206367626786232), ((15, 22), 0.021324608474969864), ((12, 15), 0.02096191607415676), ((0, 2), 0.020903410390019417), ((4, 15), 0.02078828029334545), ((2, 5), 0.020763127133250237), ((6, 15), 0.02056567370891571), ((2, 9), 0.020259592682123184), ((15, 19), 0.02022383362054825), ((2, 17), 0.02013050578534603), ((2, 20), 0.019872769713401794), ((4, 23), 0.019699495285749435), ((4, 14), 0.01894785836338997), ((15, 17), 0.01777919940650463), ((2, 16), 0.017742130905389786), ((3, 15), 0.017441226169466972), ((1, 2), 0.017439397051930428), ((10, 15), 0.017433756962418556), ((2, 7), 0.017383446916937828), ((15, 21), 0.017076751217246056), ((0, 13), 0.0166709553450346), ((2, 22), 0.01660841517150402), ((2, 6), 0.016490686684846878), ((11, 15), 0.016432078555226326), ((5, 13), 0.015637589618563652), ((2, 19), 0.01554978545755148), ((9, 13), 0.015506467781960964), ((13, 20), 0.015067573636770248), ((2, 12), 0.014378468506038189), ((8, 15), 0.014096478000283241), ((15, 18), 0.013868454843759537), ((2, 3), 0.013845737092196941), ((2, 10), 0.013718648813664913), ((2, 21), 0.01197871658951044), ((14, 15), 0.011635111644864082), ((2, 11), 0.011628525331616402), ((2, 18), 0.01110173761844635), ((2, 13), 0.010863120667636395), ((2, 8), 0.010768996551632881), ((1, 13), 0.010313157923519611), ((15, 23), 0.010179958306252956), ((13, 15), 0.009840114042162895), ((7, 13), 0.009773449040949345), ((13, 16), 0.00954174529761076), ((2, 14), 0.009081443771719933), ((6, 13), 0.008812296204268932), ((2, 23), 0.008795063011348248), ((13, 22), 0.008447057567536831), ((13, 19), 0.007571503985673189), ((12, 13), 0.007439301814883947), ((10, 13), 0.006383649539202452), ((3, 13), 0.005912962835282087), ((13, 21), 0.005778734106570482), ((11, 13), 0.005121417343616486), ((13, 17), 0.004938030615448952), ((13, 18), 0.004777385387569666), ((8, 13), 0.004375014454126358), ((13, 14), 0.003944935742765665), ((13, 23), 0.0032799779437482357)]
******* after merging (0.04): [((5, 9), 64), ((1, 7), 64), ((6, 22), 64), ((0,), 32), ((2,), 32), ((3,), 32), ((4,), 32), ((8,), 32), ((10,), 32), ((11,), 32), ((12,), 32), ((13,), 32), ((14,), 32), ((15,), 32), ((16,), 32), ((17,), 32), ((18,), 32), ((19,), 32), ((20,), 32), ((21,), 32), ((23,), 32)]
{'R_grad_norm': 1.0647329771518708, 'training_loss': 3.7265490388870237}
{'R_grad_norm': 1.0619641265273094, 'training_loss': 3.711724365949631}
{'R_grad_norm': 1.062274428009987, 'training_loss': 3.705681018829346}
{'R_grad_norm': 1.06265507876873, 'training_loss': 3.7088355231285095}
{'R_grad_norm': 1.0615151298046113, 'training_loss': 3.7050331354141237}
{'R_grad_norm': 1.0615124577283859, 'training_loss': 3.699510544538498}
{'R_grad_norm': 1.0606558606028558, 'training_loss': 3.6811246156692503}
{'R_grad_norm': 1.0649520722031594, 'training_loss': 3.698651601076126}
{'R_grad_norm': 1.0625162082910538, 'training_loss': 3.6908092844486236}
{'R_grad_norm': 1.061364482343197, 'training_loss': 3.6908085024356843}
{'R_grad_norm': 1.0595043498277663, 'training_loss': 3.6849493849277497}
{'R_grad_norm': 1.058380181491375, 'training_loss': 3.6679932940006257}
{'R_grad_norm': 1.0607995176315308, 'training_loss': 3.695407843589783}
{'R_grad_norm': 1.058663732111454, 'training_loss': 3.679786556959152}
{'R_grad_norm': 1.056330334842205, 'training_loss': 3.6678292310237883}
{'R_grad_norm': 1.058455333709717, 'training_loss': 3.673338795900345}
{'R_grad_norm': 1.0600632786750794, 'training_loss': 3.6854449212551117}
{'R_grad_norm': 1.0559273660182953, 'training_loss': 3.6693862998485565}
{'R_grad_norm': 1.0569318163394927, 'training_loss': 3.661530705690384}
{'R_grad_norm': 1.0594323694705963, 'training_loss': 3.680310558080673}
{'R_grad_norm': 1.0574760538339616, 'training_loss': 3.679336974620819}
{'R_grad_norm': 1.0573840728402137, 'training_loss': 3.676901887655258}
{'R_grad_norm': 1.0559059882164001, 'training_loss': 3.6704518139362334}
{'R_grad_norm': 1.056065862774849, 'training_loss': 3.668386276960373}
{'R_grad_norm': 1.0555851137638093, 'training_loss': 3.6690587651729585}
{'R_grad_norm': 1.052236601114273, 'training_loss': 3.657385801076889}
{'R_grad_norm': 1.0529280796647071, 'training_loss': 3.6551012539863588}
{'R_grad_norm': 1.0529503804445266, 'training_loss': 3.6713559544086456}
{'R_grad_norm': 1.0543938231468202, 'training_loss': 3.668295753002167}
{'R_grad_norm': 1.0521347308158875, 'training_loss': 3.6600848913192747}
{'R_grad_norm': 1.0513516628742219, 'training_loss': 3.662135510444641}
{'R_grad_norm': 1.053176339864731, 'training_loss': 3.6781407952308656}
{'R_grad_norm': 1.0494043236970902, 'training_loss': 3.648082286119461}
{'R_grad_norm': 1.0504695722460746, 'training_loss': 3.657674125432968}
{'R_grad_norm': 1.0464923325181008, 'training_loss': 3.642338515520096}
{'R_grad_norm': 1.0475947597622872, 'training_loss': 3.6516639232635497}
{'R_grad_norm': 1.0496962702274322, 'training_loss': 3.6580158746242524}
{'R_grad_norm': 1.0479960876703263, 'training_loss': 3.6537437319755552}
{'R_grad_norm': 1.0458916223049164, 'training_loss': 3.6380476450920103}
{'R_grad_norm': 1.0457930657267571, 'training_loss': 3.6475997483730316}
eval result tensor([4.75526, 5.27572, 5.48081, 2.73022, 3.58544, 3.19168, 2.64178, 3.50018,
        3.13822, 3.18811, 3.27779, 4.05375, 4.38642, 4.20507, 3.03485, 3.58459,
        3.40511, 2.92555, 2.76436, 3.83366, 3.45462], device='cuda:0')
computing merge metric
normed mi [((3, 18), 0.12106259912252426), ((3, 6), 0.11116981506347656), ((14, 17), 0.10826227068901062), ((14, 18), 0.10637128353118896), ((17, 18), 0.10461147874593735), ((3, 14), 0.10295060276985168), ((10, 17), 0.10258252173662186), ((10, 18), 0.10135678946971893), ((8, 17), 0.10029467940330505), ((3, 17), 0.1000419557094574), ((10, 14), 0.09844797104597092), ((5, 17), 0.09811320155858994), ((6, 18), 0.09621001034975052), ((8, 14), 0.092234767973423), ((5, 10), 0.09171519428491592), ((5, 14), 0.09129167348146439), ((5, 8), 0.0902821347117424), ((3, 8), 0.09026762843132019), ((0, 3), 0.09026066462198894), ((3, 10), 0.08988775312900543), ((8, 10), 0.0871221125125885), ((8, 18), 0.08660827577114105), ((5, 18), 0.08621079474687576), ((10, 19), 0.0861160010099411), ((0, 18), 0.08558640877405803), ((17, 19), 0.0832289606332779), ((2, 8), 0.08097418149312337), ((1, 3), 0.08007769286632538), ((1, 17), 0.07979268332322438), ((3, 5), 0.07951710373163223), ((16, 19), 0.07905875146389008), ((2, 17), 0.0786981185277303), ((9, 17), 0.07864994555711746), ((12, 19), 0.07788164168596268), ((1, 8), 0.07769814630349477), ((0, 17), 0.0776018997033437), ((0, 14), 0.07705460488796234), ((5, 19), 0.07691297680139542), ((8, 9), 0.07662603259086609), ((14, 19), 0.0766201838850975), ((12, 16), 0.07648403197526932), ((5, 9), 0.07636279612779617), ((1, 14), 0.07531522711118062), ((1, 18), 0.07525607943534851), ((16, 17), 0.0742068886756897), ((18, 19), 0.0741412565112114), ((2, 3), 0.07339140276114146), ((6, 14), 0.0733373835682869), ((9, 10), 0.07291345298290253), ((2, 14), 0.07176815470059712), ((1, 2), 0.07158248126506805), ((0, 8), 0.07101718087991078), ((1, 10), 0.07041243215401967), ((9, 14), 0.07009528577327728), ((0, 1), 0.06980344653129578), ((2, 5), 0.06971157093842824), ((2, 10), 0.0695447822411855), ((0, 10), 0.06890274087587993), ((2, 18), 0.06882041692733765), ((1, 5), 0.06806914508342743), ((5, 16), 0.0680374875664711), ((8, 19), 0.06734432280063629), ((14, 15), 0.06698771566152573), ((10, 16), 0.06645958125591278), ((15, 17), 0.06628482788801193), ((8, 16), 0.06617110967636108), ((6, 17), 0.06616505235433578), ((0, 2), 0.06468548625707626), ((9, 18), 0.06400075554847717), ((0, 6), 0.06364698211352031), ((7, 8), 0.06323330849409103), ((14, 16), 0.06286530196666718), ((15, 18), 0.06267865747213364), ((10, 15), 0.06240362673997879), ((0, 5), 0.06229424476623535), ((3, 9), 0.0616675429046154), ((8, 20), 0.06166710704565048), ((6, 10), 0.06144990772008896), ((9, 16), 0.06120942533016205), ((9, 19), 0.060060352087020874), ((3, 15), 0.058965496718883514), ((5, 15), 0.05894635245203972), ((2, 9), 0.05879966417948405), ((16, 20), 0.05827675387263298), ((3, 19), 0.05791943892836571), ((5, 7), 0.05756930634379387), ((17, 20), 0.057064127177000046), ((5, 20), 0.056962065398693085), ((9, 20), 0.05612785369157791), ((7, 17), 0.05606503039598465), ((12, 17), 0.055946338921785355), ((1, 9), 0.05571506420771281), ((7, 14), 0.05498580262064934), ((8, 15), 0.05495557188987732), ((16, 18), 0.05459358170628548), ((7, 20), 0.05393242835998535), ((2, 19), 0.053574333588282265), ((5, 12), 0.05286959186196327), ((15, 19), 0.052646998316049576), ((10, 12), 0.05240945145487785), ((6, 8), 0.05122918635606766), ((7, 9), 0.05103762447834015), ((12, 14), 0.050904110074043274), ((2, 16), 0.05062912901242574), ((1, 6), 0.05056235690911611), ((10, 20), 0.0505545400083065), ((1, 19), 0.05054587125778198), ((14, 20), 0.05034678801894188), ((6, 11), 0.050109900534152985), ((19, 20), 0.04991564154624939), ((8, 12), 0.04972140118479729), ((0, 9), 0.049185603857040405), ((5, 6), 0.049096670001745224), ((3, 16), 0.04892626032233238), ((7, 10), 0.04842038080096245), ((7, 16), 0.047889649868011475), ((12, 20), 0.047448862344026566), ((0, 19), 0.0471765398979187), ((7, 19), 0.04648789390921593), ((1, 16), 0.045973832408587136), ((2, 20), 0.04557881752649943), ((9, 12), 0.04524794593453407), ((1, 15), 0.0448489636182785), ((2, 7), 0.04483564694722494), ((0, 15), 0.04462638000647227), ((3, 7), 0.04426175355911255), ((12, 18), 0.04425549879670143), ((2, 15), 0.0442070464293162), ((4, 13), 0.04341140016913414), ((3, 20), 0.043392814695835114), ((9, 15), 0.04316962510347366), ((2, 6), 0.04297402501106262), ((15, 16), 0.041658997535705566), ((18, 20), 0.04146159067749977), ((1, 7), 0.041360085209210716), ((7, 12), 0.0413152240216732), ((7, 18), 0.04130293428897858), ((1, 20), 0.04115438461303711), ((0, 16), 0.040585304299990334), ((6, 15), 0.04040328040719032), ((3, 12), 0.039333418011665344), ((2, 12), 0.039271662632624306), ((7, 15), 0.03691808134317398), ((12, 15), 0.036574140191078186), ((1, 12), 0.0361517866452535), ((0, 20), 0.03534382333358129), ((0, 7), 0.035098567605018616), ((6, 19), 0.03440500795841217), ((6, 9), 0.03376128897070885), ((0, 12), 0.0319256583849589), ((15, 20), 0.03173885494470596), ((3, 11), 0.02799682319164276), ((6, 16), 0.02745402604341507), ((13, 18), 0.026128575205802917), ((3, 13), 0.02590455487370491), ((11, 18), 0.024618685245513916), ((6, 7), 0.02388904243707657), ((13, 14), 0.022995539009571075), ((4, 6), 0.022536370903253555), ((6, 12), 0.02250956930220127), ((6, 20), 0.021868640556931496), ((6, 13), 0.0216516125947237), ((3, 4), 0.021462049335241318), ((13, 17), 0.020054059103131294), ((4, 18), 0.01944604516029358), ((10, 13), 0.019424688071012497), ((4, 15), 0.018585050478577614), ((13, 15), 0.017162127420306206), ((4, 14), 0.017108893021941185), ((0, 13), 0.017027664929628372), ((5, 13), 0.01681702770292759), ((13, 19), 0.01680956594645977), ((4, 11), 0.016133954748511314), ((8, 13), 0.015870485454797745), ((11, 14), 0.015262349508702755), ((4, 17), 0.015116382390260696), ((11, 13), 0.014440935105085373), ((1, 13), 0.014105229328076044), ((9, 13), 0.013471873477101326), ((0, 4), 0.013202661027510961), ((0, 11), 0.013171352446079254), ((4, 5), 0.013011927716434002), ((4, 10), 0.012890974059700966), ((2, 13), 0.01268403852979342), ((4, 8), 0.012555848807096481), ((11, 17), 0.012544636614620686), ((12, 13), 0.012286205776035786), ((13, 16), 0.01218035165220499), ((10, 11), 0.01192108727991581), ((4, 19), 0.010931008495390415), ((1, 4), 0.010875283430020014), ((7, 13), 0.010279448702931404), ((2, 4), 0.010017264634370804), ((4, 9), 0.009812045842409134), ((11, 19), 0.009458967484533787), ((4, 16), 0.009347843006253242), ((13, 20), 0.009341788478195667), ((4, 7), 0.009215845726430416), ((5, 11), 0.00916497502475977), ((4, 12), 0.008923391811549664), ((1, 11), 0.008587619289755821), ((8, 11), 0.008524646982550621), ((11, 15), 0.008096428588032722), ((4, 20), 0.007972133345901966), ((11, 12), 0.007104659918695688), ((2, 11), 0.006782696271936099), ((11, 16), 0.006442170590162277), ((9, 11), 0.006036781705915928), ((7, 11), 0.004537640139460564), ((11, 20), 0.004287685267627239)]
******* after merging (0.04): [((3, 18), 64), ((14, 17), 64), ((0,), 64), ((1,), 64), ((2,), 64), ((4,), 32), ((5,), 32), ((6,), 32), ((7,), 32), ((8,), 32), ((9,), 32), ((10,), 32), ((11,), 32), ((12,), 32), ((13,), 32), ((15,), 32), ((16,), 32), ((19,), 32), ((20,), 32)]
{'R_grad_norm': 1.1296927011013032, 'training_loss': 3.8858099007606506}
{'R_grad_norm': 1.1315852808952331, 'training_loss': 3.8832501566410063}
{'R_grad_norm': 1.1343445616960526, 'training_loss': 3.902292000055313}
{'R_grad_norm': 1.1334938538074493, 'training_loss': 3.898075736761093}
{'R_grad_norm': 1.1360202705860138, 'training_loss': 3.905098352432251}
{'R_grad_norm': 1.1302535772323608, 'training_loss': 3.8782851576805113}
{'R_grad_norm': 1.132356458902359, 'training_loss': 3.891740829944611}
{'R_grad_norm': 1.1335376119613647, 'training_loss': 3.897832225561142}
{'R_grad_norm': 1.1388297700881957, 'training_loss': 3.9139865493774413}
{'R_grad_norm': 1.138292167186737, 'training_loss': 3.9223775100708007}
{'R_grad_norm': 1.138968933224678, 'training_loss': 3.916836394071579}
{'R_grad_norm': 1.1421807765960694, 'training_loss': 3.9374963319301606}
{'R_grad_norm': 1.1444672226905823, 'training_loss': 3.93828706741333}
{'R_grad_norm': 1.1466013258695602, 'training_loss': 3.95559522151947}
{'R_grad_norm': 1.1508939743041993, 'training_loss': 3.9771278965473176}
{'R_grad_norm': 1.1500112289190292, 'training_loss': 3.9770204627513888}
{'R_grad_norm': 1.1572980618476867, 'training_loss': 4.006047360897064}
{'R_grad_norm': 1.1600744420289992, 'training_loss': 4.0268713414669035}
{'R_grad_norm': 1.1638110733032228, 'training_loss': 4.047859697341919}
{'R_grad_norm': 1.1670491862297059, 'training_loss': 4.067711697816849}
{'R_grad_norm': 1.1760471844673157, 'training_loss': 4.118132102489471}
{'R_grad_norm': 1.1816164088249206, 'training_loss': 4.13934187412262}
{'R_grad_norm': 1.147973634004593, 'training_loss': 3.9853886008262633}
{'R_grad_norm': 1.1315215802192689, 'training_loss': 3.905595110654831}
{'R_grad_norm': 1.127564930319786, 'training_loss': 3.878290207386017}
{'R_grad_norm': 1.1235289192199707, 'training_loss': 3.8673482930660246}
{'R_grad_norm': 1.1277540552616119, 'training_loss': 3.8837749576568603}
{'R_grad_norm': 1.1307768261432647, 'training_loss': 3.8874245059490202}
{'R_grad_norm': 1.1272316479682922, 'training_loss': 3.874820817708969}
{'R_grad_norm': 1.123918907046318, 'training_loss': 3.8787030243873595}
{'R_grad_norm': 1.1218330317735672, 'training_loss': 3.8646657359600067}
{'R_grad_norm': 1.1277938264608383, 'training_loss': 3.8871717631816862}
{'R_grad_norm': 1.1246304857730864, 'training_loss': 3.8832140386104586}
{'R_grad_norm': 1.124854325056076, 'training_loss': 3.8782965326309204}
{'R_grad_norm': 1.1234990501403808, 'training_loss': 3.8800256395339967}
{'R_grad_norm': 1.1225642812252046, 'training_loss': 3.872377506494522}
{'R_grad_norm': 1.126507648229599, 'training_loss': 3.885490251779556}
{'R_grad_norm': 1.122992416024208, 'training_loss': 3.8713146936893463}
{'R_grad_norm': 1.1226373142004014, 'training_loss': 3.881386090517044}
{'R_grad_norm': 1.1207188791036606, 'training_loss': 3.8693120169639585}
eval result tensor([4.43881, 5.06399, 4.73305, 5.28340, 5.61985, 3.51060, 3.06512, 2.55291,
        3.55716, 2.91754, 3.09163, 3.11024, 4.09639, 4.38601, 4.06488, 3.56683,
        3.24037, 3.72348, 3.43996], device='cuda:0')
computing merge metric
normed mi [((6, 11), 0.08968440443277359), ((6, 9), 0.08655472844839096), ((11, 17), 0.08412661403417587), ((9, 11), 0.08287078887224197), ((4, 9), 0.07891331613063812), ((13, 17), 0.07871699333190918), ((6, 17), 0.07632828503847122), ((3, 9), 0.07567938168843587), ((9, 10), 0.07521918416023254), ((16, 17), 0.07406049221754074), ((6, 10), 0.07259476184844971), ((0, 2), 0.07209773361682892), ((0, 11), 0.0703622152407964), ((1, 9), 0.07023181517918904), ((10, 11), 0.06996562331914902), ((1, 11), 0.06942148506641388), ((1, 6), 0.06918109953403473), ((3, 4), 0.0691252276301384), ((13, 16), 0.06874420493841171), ((0, 9), 0.06850707034269969), ((2, 3), 0.06820927560329437), ((7, 11), 0.06799817085266113), ((2, 9), 0.06786562999089558), ((2, 11), 0.06784716248512268), ((3, 11), 0.06751543283462524), ((2, 7), 0.06705473860104878), ((9, 16), 0.06687013059854507), ((0, 3), 0.06675371527671814), ((9, 17), 0.06673875451087952), ((3, 6), 0.06639378269513448), ((4, 6), 0.0656966616710027), ((0, 7), 0.06517867247263591), ((8, 9), 0.06490081548690796), ((4, 11), 0.06372445821762085), ((0, 6), 0.06352171301841736), ((6, 16), 0.06263504177331924), ((1, 3), 0.06159123405814171), ((2, 6), 0.06148622433344523), ((1, 17), 0.060901870330174766), ((9, 18), 0.060773815959692), ((10, 17), 0.060601599514484406), ((1, 4), 0.060564540326595306), ((11, 16), 0.06055958569049835), ((2, 4), 0.060490865260362625), ((10, 16), 0.06033073365688324), ((0, 4), 0.06023487076163292), ((16, 18), 0.059789203107357025), ((6, 8), 0.05914491415023804), ((11, 15), 0.05904196575284004), ((0, 1), 0.05813167616724968), ((1, 2), 0.05753370001912117), ((6, 15), 0.05700200796127319), ((4, 10), 0.05698638657728831), ((6, 7), 0.055961474776268005), ((1, 10), 0.055662562449773155), ((3, 10), 0.05457410216331482), ((7, 9), 0.05408278852701187), ((4, 17), 0.05336815615495046), ((10, 18), 0.053053248673677444), ((3, 7), 0.05291168888409933), ((8, 18), 0.0517771914601326), ((15, 17), 0.05151747912168503), ((1, 16), 0.0514192134141922), ((6, 18), 0.051365867257118225), ((4, 16), 0.05134098728497823), ((11, 13), 0.0508095882833004), ((8, 10), 0.05053451284766197), ((8, 17), 0.0504285991191864), ((9, 15), 0.050160009413957596), ((3, 17), 0.05011798441410065), ((6, 13), 0.0499035008251667), ((17, 18), 0.04990140348672867), ((0, 10), 0.049678459763526917), ((8, 11), 0.04951174929738045), ((0, 17), 0.04949985941251119), ((8, 16), 0.0492168664932251), ((9, 13), 0.048729438334703445), ((2, 10), 0.0477385421593984), ((1, 8), 0.04745110869407654), ((11, 18), 0.04734886437654495), ((7, 12), 0.04723664000630379), ((4, 8), 0.04707867403825124), ((13, 18), 0.046120528131723404), ((2, 17), 0.04577342172463735), ((4, 18), 0.04569004476070404), ((3, 16), 0.04497002065181732), ((1, 7), 0.04480973879496256), ((1, 15), 0.04448103408018748), ((10, 13), 0.04382646828889847), ((0, 15), 0.04363875091075897), ((2, 15), 0.04353568454583486), ((3, 8), 0.043324872851371765), ((7, 15), 0.04320688173174858), ((8, 13), 0.04257027059793472), ((4, 7), 0.04226552943388621), ((3, 15), 0.042110636830329895), ((0, 16), 0.0410323441028595), ((1, 18), 0.04098456849654516), ((5, 14), 0.04042189568281174), ((3, 18), 0.04022276153167089), ((10, 15), 0.04015769436955452), ((1, 13), 0.040068626403808594), ((8, 15), 0.03948962315917015), ((4, 15), 0.03943924605846405), ((4, 13), 0.03942821423212687), ((7, 10), 0.03938435763120651), ((2, 16), 0.03857885301113129), ((0, 8), 0.037801976005236305), ((15, 16), 0.037263400852680206), ((7, 17), 0.03716465085744858), ((2, 8), 0.036758127311865486), ((0, 18), 0.03547212481498718), ((3, 13), 0.035330171386400856), ((13, 15), 0.03479801490902901), ((2, 18), 0.03348821153243383), ((0, 13), 0.031709221502145134), ((2, 13), 0.030704446136951447), ((7, 8), 0.030119890347123146), ((7, 16), 0.02860325202345848), ((15, 18), 0.028469238430261612), ((7, 18), 0.023395070806145668), ((7, 13), 0.023031534627079964), ((5, 7), 0.021857619285583496), ((7, 14), 0.021857451647520065), ((11, 14), 0.018782489001750946), ((6, 14), 0.016768209636211395), ((14, 15), 0.016735687851905823), ((5, 12), 0.016240889206528664), ((2, 14), 0.016229528933763504), ((0, 14), 0.01586026946703593), ((14, 17), 0.015131598338484764), ((5, 15), 0.014615465886890888), ((9, 14), 0.013711141422390938), ((12, 14), 0.012630298733711243), ((10, 14), 0.012577484361827374), ((3, 14), 0.012534336497386297), ((1, 14), 0.012044355273246765), ((2, 12), 0.012013574441274008), ((0, 12), 0.011710093667109808), ((11, 12), 0.011531558819115162), ((8, 14), 0.011428079567849636), ((2, 5), 0.010934477051099142), ((5, 6), 0.010850549675524235), ((13, 14), 0.010812961496412754), ((5, 11), 0.01072058454155922), ((4, 14), 0.010656333218018213), ((0, 5), 0.010560310135285059), ((14, 16), 0.009963104501366615), ((5, 9), 0.009484405629336834), ((5, 8), 0.00875894632190466), ((6, 12), 0.008749695494771004), ((5, 17), 0.008733979426324368), ((3, 5), 0.008181789269049963), ((14, 18), 0.008019419386982918), ((1, 5), 0.007854592055082321), ((5, 10), 0.00766056589782238), ((12, 17), 0.007596154231578112), ((12, 15), 0.007573640905320644), ((4, 5), 0.0071466608593861265), ((5, 16), 0.007060328498482704), ((3, 12), 0.006958019609252612), ((9, 12), 0.006953021511435509), ((5, 13), 0.006917647086083889), ((1, 12), 0.006168782711029053), ((12, 13), 0.0059150271117687225), ((5, 18), 0.005848302505910397), ((10, 12), 0.005380033049732447), ((4, 12), 0.005178539703289668), ((12, 16), 0.0049409386701881886), ((8, 12), 0.004664515610784292), ((12, 18), 0.003420536406338215)]
******* after merging (0.04): [((4, 9), 96), ((6, 11), 64), ((0,), 64), ((1,), 64), ((2,), 64), ((3,), 64), ((5,), 32), ((7,), 32), ((8,), 32), ((10,), 32), ((12,), 32), ((13,), 32), ((14,), 32), ((15,), 32), ((16,), 32), ((17,), 32), ((18,), 32)]
{'R_grad_norm': 1.2057478141784668, 'training_loss': 4.1377098548412325}
{'R_grad_norm': 1.2040340226888657, 'training_loss': 4.134904457330704}
{'R_grad_norm': 1.2086549007892609, 'training_loss': 4.155548267364502}
{'R_grad_norm': 1.206191057562828, 'training_loss': 4.1339968085289005}
{'R_grad_norm': 1.2031395906209945, 'training_loss': 4.128722236156464}
{'R_grad_norm': 1.204015657901764, 'training_loss': 4.131334756612778}
{'R_grad_norm': 1.201390705704689, 'training_loss': 4.12512065410614}
{'R_grad_norm': 1.2084922575950623, 'training_loss': 4.158944424390793}
{'R_grad_norm': 1.203509633541107, 'training_loss': 4.14952847123146}
{'R_grad_norm': 1.2040044766664506, 'training_loss': 4.133934922218323}
{'R_grad_norm': 1.1990891778469086, 'training_loss': 4.10401496887207}
{'R_grad_norm': 1.2046210181713104, 'training_loss': 4.129086084365845}
{'R_grad_norm': 1.2001355278491974, 'training_loss': 4.105184650421142}
{'R_grad_norm': 1.2031597733497619, 'training_loss': 4.12328115940094}
{'R_grad_norm': 1.201223947405815, 'training_loss': 4.12579430937767}
{'R_grad_norm': 1.2017201501131058, 'training_loss': 4.12309210896492}
{'R_grad_norm': 1.1948965001106262, 'training_loss': 4.10113116145134}
{'R_grad_norm': 1.1981895506381988, 'training_loss': 4.117121683359146}
{'R_grad_norm': 1.20022469997406, 'training_loss': 4.111998380422592}
{'R_grad_norm': 1.2002480429410936, 'training_loss': 4.1164311969280245}
{'R_grad_norm': 1.1996265864372253, 'training_loss': 4.124126440286636}
{'R_grad_norm': 1.197422121167183, 'training_loss': 4.114557402133942}
{'R_grad_norm': 1.1956965160369872, 'training_loss': 4.1000421321392055}
{'R_grad_norm': 1.1989414292573928, 'training_loss': 4.115297961235046}
{'R_grad_norm': 1.1951809018850326, 'training_loss': 4.110806884765625}
{'R_grad_norm': 1.1966041880846023, 'training_loss': 4.100950974225998}
{'R_grad_norm': 1.1963802707195281, 'training_loss': 4.111896107196808}
{'R_grad_norm': 1.1911384433507919, 'training_loss': 4.089265341758728}
{'R_grad_norm': 1.197244176864624, 'training_loss': 4.1161697220802305}
{'R_grad_norm': 1.192437395453453, 'training_loss': 4.101738028526306}
{'R_grad_norm': 1.1915999484062194, 'training_loss': 4.095173659324646}
{'R_grad_norm': 1.197200134396553, 'training_loss': 4.114255566596984}
{'R_grad_norm': 1.1947023510932921, 'training_loss': 4.113286019563675}
{'R_grad_norm': 1.1937530487775803, 'training_loss': 4.104634541273117}
{'R_grad_norm': 1.1920212078094483, 'training_loss': 4.101356093883514}
{'R_grad_norm': 1.1898585808277131, 'training_loss': 4.0924729943275455}
{'R_grad_norm': 1.1941405791044235, 'training_loss': 4.108685826063156}
{'R_grad_norm': 1.1909416764974594, 'training_loss': 4.093248579502106}
{'R_grad_norm': 1.1885923558473588, 'training_loss': 4.082158032655716}
{'R_grad_norm': 1.1933715045452118, 'training_loss': 4.1138013339042665}
eval result tensor([7.54786, 5.12266, 4.35682, 4.90179, 4.60685, 4.86806, 3.35926, 2.49930,
        3.55405, 2.96128, 4.08031, 4.26801, 3.99785, 3.55169, 3.15420, 3.63654,
        3.31269], device='cuda:0')
computing merge metric
normed mi [((4, 7), 0.09245885411898296), ((2, 7), 0.08723009626070659), ((11, 15), 0.07944415509700775), ((5, 7), 0.07926552494366963), ((7, 9), 0.07275941967964172), ((14, 15), 0.07096855342388153), ((2, 4), 0.07058107852935791), ((3, 7), 0.06767114500204723), ((2, 5), 0.06695123761892319), ((4, 5), 0.06690490990877151), ((11, 14), 0.06620306521654129), ((1, 7), 0.06352066000302632), ((1, 15), 0.06227045754591624), ((3, 5), 0.0614393875002861), ((2, 3), 0.05982698127627373), ((7, 13), 0.05941208824515343), ((3, 15), 0.05936993658542633), ((1, 3), 0.0588061697781086), ((14, 16), 0.05875008925795555), ((7, 15), 0.05694519355893135), ((1, 2), 0.05687505751848221), ((9, 15), 0.05686529353260994), ((1, 5), 0.05675021559000015), ((3, 4), 0.05671535059809685), ((2, 9), 0.05600509544213613), ((1, 9), 0.055067857106526695), ((0, 5), 0.05485972762107849), ((3, 9), 0.05482120315233866), ((5, 9), 0.05480047563711802), ((4, 9), 0.05280530949433645), ((0, 7), 0.05236554518342018), ((1, 4), 0.05187096446752548), ((8, 16), 0.051693256944417953), ((8, 15), 0.05123232677578926), ((3, 14), 0.050256470839182533), ((15, 16), 0.05002281442284584), ((7, 14), 0.049604013562202454), ((2, 15), 0.049561142921447754), ((13, 15), 0.04911831393837929), ((0, 2), 0.048544099926948546), ((5, 15), 0.04843732714653015), ((0, 3), 0.04832957684993744), ((9, 14), 0.04823044314980507), ((8, 14), 0.04815303161740303), ((7, 8), 0.0477445051074028), ((3, 8), 0.04725182553132375), ((1, 14), 0.04708130657672882), ((0, 4), 0.046755021810531615), ((11, 16), 0.04654182866215706), ((5, 14), 0.04468332231044769), ((0, 1), 0.04444568455219269), ((7, 16), 0.04377018287777901), ((9, 13), 0.04373953863978386), ((2, 13), 0.04346958796183268), ((4, 15), 0.04329909384250641), ((3, 13), 0.04311436414718628), ((4, 13), 0.043004900217056274), ((8, 11), 0.04275255650281906), ((5, 8), 0.042588189244270325), ((2, 14), 0.0423117329676946), ((8, 9), 0.04181424900889397), ((1, 13), 0.041041662295659385), ((9, 16), 0.04101736098527908), ((5, 13), 0.04077828427155813), ((3, 16), 0.04076123237609863), ((0, 15), 0.0405641607940197), ((3, 11), 0.04051105926434199), ((5, 16), 0.04024958858887354), ((1, 8), 0.04023896406094233), ((0, 14), 0.03972507268190384), ((7, 11), 0.03907696530222893), ((1, 11), 0.039011808733145394), ((2, 8), 0.03865606834491094), ((9, 11), 0.03841385990381241), ((1, 16), 0.038338745633761086), ((0, 8), 0.03768559917807579), ((0, 9), 0.03759109973907471), ((8, 13), 0.037559330463409424), ((4, 14), 0.0373244434595108), ((2, 16), 0.036134411891301475), ((4, 8), 0.0360139732559522), ((0, 16), 0.035949502140283585), ((6, 12), 0.03554147109389305), ((5, 11), 0.03517356266578039), ((13, 14), 0.033828675746917725), ((11, 13), 0.03343776986002922), ((2, 11), 0.03291167070468267), ((4, 16), 0.032774689296881356), ((0, 11), 0.03125195950269699), ((4, 11), 0.03031102071205775), ((0, 13), 0.028005236759781837), ((13, 16), 0.026791295036673546), ((7, 12), 0.02272152528166771), ((7, 10), 0.01842407137155533), ((6, 10), 0.01714877039194107), ((4, 12), 0.014429144561290741), ((12, 13), 0.01413305476307869), ((9, 12), 0.013717015273869038), ((2, 12), 0.013231138388315836), ((6, 7), 0.013206039555370808), ((12, 15), 0.011561445891857147), ((10, 12), 0.010471107438206673), ((6, 13), 0.010465527884662151), ((5, 12), 0.010335657124718031), ((3, 12), 0.009982475390036901), ((1, 12), 0.009280441949764887), ((4, 10), 0.008822720497846603), ((8, 12), 0.00877754483371973), ((11, 12), 0.008603235706686974), ((12, 14), 0.007915288209915161), ((4, 6), 0.007780926922957103), ((2, 10), 0.007505582024653752), ((2, 6), 0.006789014985164006), ((12, 16), 0.0064996168948709965), ((6, 9), 0.006345017347484827), ((6, 8), 0.006193316541612148), ((9, 10), 0.006095518823713064), ((0, 12), 0.005935839377343655), ((5, 6), 0.0054404592762390775), ((10, 13), 0.005330988671630621), ((6, 15), 0.005294770002365112), ((3, 6), 0.0051877911513050394), ((5, 10), 0.00469755878051122), ((6, 11), 0.004695127718150616), ((10, 15), 0.0045945546589791775), ((6, 14), 0.004524573218077421), ((3, 10), 0.004223335844775041), ((10, 11), 0.004108325578272343), ((1, 6), 0.004044723076124986), ((1, 10), 0.003933606358865897), ((6, 16), 0.0038553308695554733), ((0, 6), 0.0034482090268284082), ((10, 14), 0.0033869759645313025), ((8, 10), 0.003133222460746765), ((10, 16), 0.0025842797476798296), ((0, 10), 0.0023528202436864376)]
******* after merging (0.04): [((4, 7), 96), ((0,), 96), ((11, 15), 64), ((1,), 64), ((2,), 64), ((3,), 64), ((5,), 64), ((6,), 32), ((8,), 32), ((9,), 32), ((10,), 32), ((12,), 32), ((13,), 32), ((14,), 32), ((16,), 32)]
{'R_grad_norm': 1.286900578737259, 'training_loss': 4.449623961448669}
{'R_grad_norm': 1.287141306400299, 'training_loss': 4.4354735851287845}
{'R_grad_norm': 1.2889509266614914, 'training_loss': 4.4570537948608395}
{'R_grad_norm': 1.2865749859809876, 'training_loss': 4.445334823131561}
{'R_grad_norm': 1.2874901509284973, 'training_loss': 4.450191731452942}
{'R_grad_norm': 1.2860571980476379, 'training_loss': 4.453573925495148}
{'R_grad_norm': 1.2841806846857071, 'training_loss': 4.449530386924744}
{'R_grad_norm': 1.2849141883850097, 'training_loss': 4.446025141477585}
{'R_grad_norm': 1.2794062942266464, 'training_loss': 4.417498304843902}
{'R_grad_norm': 1.2857013833522797, 'training_loss': 4.457453033924103}
{'R_grad_norm': 1.2832199370861053, 'training_loss': 4.434758148193359}
{'R_grad_norm': 1.2811271440982819, 'training_loss': 4.435594077110291}
{'R_grad_norm': 1.283744586110115, 'training_loss': 4.430836634635925}
{'R_grad_norm': 1.282952488064766, 'training_loss': 4.432732617855072}
{'R_grad_norm': 1.281016286611557, 'training_loss': 4.426392722129822}
{'R_grad_norm': 1.2805049228668213, 'training_loss': 4.4221275472640995}
{'R_grad_norm': 1.2819617384672164, 'training_loss': 4.433092348575592}
{'R_grad_norm': 1.277294757962227, 'training_loss': 4.419606251716614}
{'R_grad_norm': 1.2766958314180374, 'training_loss': 4.418071713447571}
{'R_grad_norm': 1.2798514527082443, 'training_loss': 4.425409231185913}
{'R_grad_norm': 1.279027448296547, 'training_loss': 4.432951278686524}
{'R_grad_norm': 1.2758784741163254, 'training_loss': 4.413472924232483}
{'R_grad_norm': 1.2785297310352326, 'training_loss': 4.434973275661468}
{'R_grad_norm': 1.2782941925525666, 'training_loss': 4.4324361515045165}
{'R_grad_norm': 1.2767099732160567, 'training_loss': 4.424530022144317}
{'R_grad_norm': 1.2745524001121522, 'training_loss': 4.40468332529068}
{'R_grad_norm': 1.279572776556015, 'training_loss': 4.434693624973297}
{'R_grad_norm': 1.2761772960424422, 'training_loss': 4.420340390205383}
{'R_grad_norm': 1.2735337227582932, 'training_loss': 4.411296308040619}
{'R_grad_norm': 1.274977935552597, 'training_loss': 4.4230690407752995}
{'R_grad_norm': 1.2731689590215682, 'training_loss': 4.409133367538452}
{'R_grad_norm': 1.276589138507843, 'training_loss': 4.42590027809143}
{'R_grad_norm': 1.2730999225378037, 'training_loss': 4.403642890453338}
{'R_grad_norm': 1.276775273680687, 'training_loss': 4.423169474601746}
{'R_grad_norm': 1.2757245057821274, 'training_loss': 4.4209339261055}
{'R_grad_norm': 1.2763572853803635, 'training_loss': 4.433601591587067}
{'R_grad_norm': 1.273555759191513, 'training_loss': 4.423268656730652}
{'R_grad_norm': 1.2730404376983642, 'training_loss': 4.417919979095459}
{'R_grad_norm': 1.2734058094024658, 'training_loss': 4.431371061801911}
{'R_grad_norm': 1.2722578823566437, 'training_loss': 4.4187613153457646}
eval result tensor([5.69678, 7.60830, 6.88743, 5.09019, 4.19250, 4.75168, 4.54215, 3.26349,
        3.55826, 2.85299, 4.05474, 3.90266, 3.52272, 3.02034, 3.18123],
       device='cuda:0')
computing merge metric
normed mi [((4, 6), 0.06599561870098114), ((5, 6), 0.060659002512693405), ((4, 5), 0.06034925952553749), ((13, 14), 0.05994526296854019), ((3, 5), 0.058359283953905106), ((3, 4), 0.05751090869307518), ((3, 6), 0.05678821727633476), ((0, 4), 0.05652903914451599), ((6, 9), 0.05643882850805918), ((5, 9), 0.05599302053451538), ((3, 9), 0.05594374736150106), ((4, 9), 0.055595929423967995), ((1, 6), 0.05411386489868164), ((0, 6), 0.05398041605949402), ((9, 13), 0.0520012229681015), ((2, 13), 0.049125408132870994), ((8, 13), 0.04880840703845024), ((8, 14), 0.047892097383737564), ((5, 13), 0.047570655743281044), ((3, 13), 0.04745550453662872), ((1, 5), 0.046906933188438416), ((1, 4), 0.04690433144569397), ((5, 8), 0.04671605428059896), ((0, 5), 0.04586721658706665), ((5, 12), 0.0457087904214859), ((9, 14), 0.0454513244330883), ((1, 3), 0.045124560594558716), ((8, 9), 0.045014459639787674), ((6, 13), 0.044359068075815834), ((4, 12), 0.044001296162605286), ((9, 12), 0.04363235458731651), ((6, 8), 0.04307650029659271), ((3, 12), 0.042925516764322914), ((8, 12), 0.04279547929763794), ((6, 12), 0.04238524039586385), ((3, 8), 0.04152807096640269), ((4, 13), 0.041511240104834236), ((0, 3), 0.04094536900520325), ((1, 9), 0.04018576070666313), ((6, 14), 0.03973382463057836), ((1, 13), 0.03960886970162392), ((4, 8), 0.039032623171806335), ((3, 14), 0.038977215687433876), ((1, 8), 0.038872502744197845), ((0, 1), 0.03880133976538976), ((0, 9), 0.038797296583652496), ((2, 3), 0.038390904664993286), ((5, 14), 0.038203385969003044), ((12, 13), 0.0368226058781147), ((2, 5), 0.035862043499946594), ((2, 14), 0.03575339913368225), ((1, 14), 0.03553858771920204), ((4, 14), 0.03530879318714142), ((7, 11), 0.03405138477683067), ((2, 8), 0.03326343993345896), ((2, 9), 0.03214580565690994), ((0, 12), 0.031546153128147125), ((1, 12), 0.031145157292485237), ((2, 4), 0.029522806406021118), ((2, 6), 0.029372548684477806), ((12, 14), 0.029349414631724358), ((1, 2), 0.029346662759780883), ((0, 13), 0.028125282377004623), ((0, 8), 0.027751415967941284), ((2, 12), 0.027440195282300312), ((0, 14), 0.024923749268054962), ((0, 2), 0.02071065306663513), ((7, 10), 0.01947919651865959), ((11, 12), 0.01575985923409462), ((9, 11), 0.015619592741131783), ((4, 11), 0.015599649399518967), ((4, 10), 0.013901369025309881), ((6, 11), 0.013034683962663015), ((10, 11), 0.012991312891244888), ((5, 11), 0.012846606473128), ((0, 11), 0.012536701746284962), ((8, 11), 0.01243762020021677), ((0, 10), 0.011858150362968445), ((3, 11), 0.011787881453831991), ((7, 12), 0.010769241489470005), ((11, 13), 0.010394532233476639), ((9, 10), 0.009420132264494896), ((6, 10), 0.009279770776629448), ((10, 12), 0.008667000569403172), ((5, 10), 0.00852334313094616), ((11, 14), 0.008144129067659378), ((4, 7), 0.008143928522864977), ((1, 11), 0.007828955538570881), ((3, 10), 0.007710412765542666), ((2, 11), 0.00756218284368515), ((7, 8), 0.007247093133628368), ((7, 9), 0.00711152283474803), ((0, 7), 0.00690895551815629), ((6, 7), 0.006641834353407224), ((5, 7), 0.0062135569751262665), ((8, 10), 0.006079697050154209), ((10, 13), 0.005989815574139357), ((7, 13), 0.005439071916043758), ((3, 7), 0.004778230873246987), ((2, 10), 0.004510301165282726), ((10, 14), 0.00435690488666296), ((1, 10), 0.00434460723772645), ((7, 14), 0.004307335242629051), ((1, 7), 0.003923354204744101), ((2, 7), 0.0035091396421194077)]
******* after merging (0.04): [((4, 6), 128), ((0,), 96), ((1,), 96), ((2,), 64), ((3,), 64), ((5,), 64), ((7,), 32), ((8,), 32), ((9,), 32), ((10,), 32), ((11,), 32), ((12,), 32), ((13,), 32), ((14,), 32)]
{'R_grad_norm': 1.3481430280208588, 'training_loss': 4.561437022686005}
{'R_grad_norm': 1.3499743413925172, 'training_loss': 4.57108421087265}
{'R_grad_norm': 1.350389900803566, 'training_loss': 4.574165804386139}
{'R_grad_norm': 1.351107353568077, 'training_loss': 4.5630380725860595}
{'R_grad_norm': 1.34366475045681, 'training_loss': 4.55424512386322}
{'R_grad_norm': 1.3454760080575943, 'training_loss': 4.562073307037354}
{'R_grad_norm': 1.3445179325342178, 'training_loss': 4.55234215259552}
{'R_grad_norm': 1.3485297214984895, 'training_loss': 4.576907138824463}
{'R_grad_norm': 1.3449548637866975, 'training_loss': 4.561398448944092}
{'R_grad_norm': 1.3446944963932037, 'training_loss': 4.562918677330017}
{'R_grad_norm': 1.3426569575071334, 'training_loss': 4.5502501130104065}
{'R_grad_norm': 1.3454740983247757, 'training_loss': 4.55949503660202}
{'R_grad_norm': 1.3433117645978927, 'training_loss': 4.544613499641418}
{'R_grad_norm': 1.3454795455932618, 'training_loss': 4.5597936630249025}
{'R_grad_norm': 1.3455665129423142, 'training_loss': 4.563137762546539}
{'R_grad_norm': 1.3410670471191406, 'training_loss': 4.5505597066879275}
{'R_grad_norm': 1.3445776051282883, 'training_loss': 4.565306282043457}
{'R_grad_norm': 1.3451332634687423, 'training_loss': 4.566678657531738}
{'R_grad_norm': 1.341996995806694, 'training_loss': 4.557119309902191}
{'R_grad_norm': 1.3390249556303024, 'training_loss': 4.537492060661316}
{'R_grad_norm': 1.3404467689990998, 'training_loss': 4.550605568885803}
{'R_grad_norm': 1.3425562006235123, 'training_loss': 4.545673174858093}
{'R_grad_norm': 1.3409354811906815, 'training_loss': 4.555679347515106}
{'R_grad_norm': 1.3426733577251435, 'training_loss': 4.569247639179229}
{'R_grad_norm': 1.3417075741291047, 'training_loss': 4.558616969585419}
{'R_grad_norm': 1.3409127116203308, 'training_loss': 4.54709755897522}
{'R_grad_norm': 1.336928122639656, 'training_loss': 4.534671223163604}
{'R_grad_norm': 1.3395010149478912, 'training_loss': 4.564362161159515}
{'R_grad_norm': 1.340782766342163, 'training_loss': 4.554455926418305}
{'R_grad_norm': 1.3400453686714173, 'training_loss': 4.551705985069275}
{'R_grad_norm': 1.338136882185936, 'training_loss': 4.541057891845703}
{'R_grad_norm': 1.3362209540605545, 'training_loss': 4.553458521366119}
{'R_grad_norm': 1.3387273609638215, 'training_loss': 4.553884720802307}
{'R_grad_norm': 1.3384608697891236, 'training_loss': 4.547123351097107}
{'R_grad_norm': 1.3361857271194457, 'training_loss': 4.551281957626343}
{'R_grad_norm': 1.3365810960531235, 'training_loss': 4.53621964931488}
{'R_grad_norm': 1.335844970345497, 'training_loss': 4.5513676428794865}
{'R_grad_norm': 1.3363329803943633, 'training_loss': 4.545909988880157}
{'R_grad_norm': 1.3340741795301438, 'training_loss': 4.542812507152558}
{'R_grad_norm': 1.3346582573652268, 'training_loss': 4.551591217517853}
eval result tensor([7.11901, 5.53166, 7.54641, 6.87894, 4.93860, 4.58956, 3.20885, 3.53952,
        2.79549, 4.06973, 3.82886, 3.51143, 2.97116, 3.11858], device='cuda:0')
computing merge metric
normed mi [((12, 13), 0.06234895437955856), ((4, 5), 0.05865618214011192), ((5, 8), 0.0543828954299291), ((4, 8), 0.05331502358118693), ((7, 12), 0.05044545605778694), ((7, 13), 0.048754289746284485), ((5, 12), 0.0478574534257253), ((3, 12), 0.047609652082125344), ((4, 12), 0.04663813610871633), ((5, 7), 0.04638880491256714), ((1, 5), 0.04631592035293579), ((2, 5), 0.045355162024497984), ((5, 11), 0.04516616960366567), ((8, 11), 0.043606750667095184), ((2, 4), 0.043029630184173585), ((8, 12), 0.04284278303384781), ((4, 11), 0.042699928085009255), ((0, 5), 0.04205084343751272), ((7, 11), 0.04182139411568642), ((1, 8), 0.04162795841693878), ((1, 4), 0.04128002524375916), ((2, 12), 0.04060487821698189), ((4, 7), 0.040601747731367745), ((0, 4), 0.040581206480662026), ((5, 13), 0.040560190876324974), ((4, 13), 0.04008929431438446), ((2, 7), 0.039875298738479614), ((7, 8), 0.03958270698785782), ((8, 13), 0.03953231871128082), ((0, 2), 0.03929642268589565), ((0, 1), 0.03739699721336365), ((2, 13), 0.03738195449113846), ((1, 2), 0.03725750744342804), ((3, 4), 0.03656884282827377), ((3, 13), 0.035776302218437195), ((6, 10), 0.0355035625398159), ((11, 12), 0.03505554795265198), ((3, 5), 0.03459358960390091), ((3, 7), 0.033689625561237335), ((2, 8), 0.03356379270553589), ((0, 8), 0.032442137598991394), ((1, 11), 0.03135116025805473), ((0, 12), 0.029991495609283447), ((11, 13), 0.029217882081866264), ((2, 11), 0.02916846238076687), ((2, 3), 0.029136106371879578), ((1, 12), 0.0282762311398983), ((1, 7), 0.027884947136044502), ((0, 7), 0.027728313207626344), ((0, 13), 0.02730836272239685), ((3, 8), 0.026243505378564198), ((1, 13), 0.02600758895277977), ((0, 11), 0.025478798151016235), ((3, 11), 0.025250973800818127), ((0, 3), 0.02129199852546056), ((1, 3), 0.019878266751766203), ((6, 9), 0.01875624805688858), ((8, 10), 0.017216308042407036), ((10, 11), 0.014227081090211868), ((1, 10), 0.011654254980385303), ((9, 10), 0.011433119885623455), ((5, 10), 0.011421219756205877), ((7, 10), 0.010517999529838562), ((4, 10), 0.010399945080280304), ((6, 11), 0.010388963855803013), ((8, 9), 0.009647857397794724), ((10, 12), 0.008930671960115433), ((1, 9), 0.008312255144119263), ((6, 8), 0.00788437481969595), ((10, 13), 0.007696092594414949), ((6, 7), 0.0072782281786203384), ((1, 6), 0.006623963359743357), ((0, 10), 0.006513866782188416), ((2, 10), 0.006322481669485569), ((5, 6), 0.006280013049642245), ((9, 11), 0.006265883333981037), ((5, 9), 0.006039131432771683), ((3, 10), 0.0057836199800173444), ((4, 9), 0.005703254913290341), ((6, 12), 0.005152570083737373), ((4, 6), 0.004753806007405122), ((7, 9), 0.004614470060914755), ((6, 13), 0.004556663334369659), ((9, 12), 0.004448896739631891), ((9, 13), 0.0038334461860358715), ((2, 6), 0.0037632447201758623), ((0, 6), 0.003593086078763008), ((0, 9), 0.0034529563039541245), ((3, 6), 0.003046665651102861), ((2, 9), 0.0029774412978440523), ((3, 9), 0.0029036359240611396)]
******* after merging (0.04): [((0,), 128), ((1,), 96), ((2,), 96), ((12, 13), 64), ((3,), 64), ((4,), 64), ((5,), 64), ((6,), 32), ((7,), 32), ((8,), 32), ((9,), 32), ((10,), 32), ((11,), 32)]
{'R_grad_norm': 1.383127546310425, 'training_loss': 4.801282181739807}
{'R_grad_norm': 1.3785162162780762, 'training_loss': 4.787730565071106}
{'R_grad_norm': 1.3819420784711838, 'training_loss': 4.798204469680786}
{'R_grad_norm': 1.382044830918312, 'training_loss': 4.801472878456115}
{'R_grad_norm': 1.3831036025285721, 'training_loss': 4.817444922924042}
{'R_grad_norm': 1.3805707305669785, 'training_loss': 4.793367509841919}
{'R_grad_norm': 1.3815427470207213, 'training_loss': 4.810270464420318}
{'R_grad_norm': 1.3770787513256073, 'training_loss': 4.788416101932525}
{'R_grad_norm': 1.3819038593769073, 'training_loss': 4.808207895755768}
{'R_grad_norm': 1.3860049337148665, 'training_loss': 4.830244889259339}
{'R_grad_norm': 1.3847469669580459, 'training_loss': 4.835440416336059}
{'R_grad_norm': 1.3879904049634932, 'training_loss': 4.849762818813324}
{'R_grad_norm': 1.3928595370054244, 'training_loss': 4.86368358373642}
{'R_grad_norm': 1.3948648208379746, 'training_loss': 4.8700867891311646}
{'R_grad_norm': 1.4006193190813065, 'training_loss': 4.908540587425232}
{'R_grad_norm': 1.4015403860807418, 'training_loss': 4.916485188007354}
{'R_grad_norm': 1.40506471991539, 'training_loss': 4.930038776397705}
{'R_grad_norm': 1.412996248602867, 'training_loss': 4.978083410263062}
{'R_grad_norm': 1.4145863968133927, 'training_loss': 4.98029399394989}
{'R_grad_norm': 1.419810170531273, 'training_loss': 5.021364283561707}
{'R_grad_norm': 1.4215560191869736, 'training_loss': 5.054565165042877}
{'R_grad_norm': 1.428760741353035, 'training_loss': 5.094124293327331}
{'R_grad_norm': 1.4414053982496262, 'training_loss': 5.1700699377059935}
{'R_grad_norm': 1.386154677271843, 'training_loss': 4.8451473736763}
{'R_grad_norm': 1.3725901341438294, 'training_loss': 4.766274209022522}
{'R_grad_norm': 1.3703409928083419, 'training_loss': 4.740563027858734}
{'R_grad_norm': 1.3702064102888107, 'training_loss': 4.750645599365234}
{'R_grad_norm': 1.370175063610077, 'training_loss': 4.757761435508728}
{'R_grad_norm': 1.3665946501493453, 'training_loss': 4.736755299568176}
{'R_grad_norm': 1.3698546171188355, 'training_loss': 4.742609872817993}
{'R_grad_norm': 1.3678157687187196, 'training_loss': 4.7346270513534545}
{'R_grad_norm': 1.367696675658226, 'training_loss': 4.756447491645813}
{'R_grad_norm': 1.3675218439102172, 'training_loss': 4.753482918739319}
{'R_grad_norm': 1.368164981007576, 'training_loss': 4.746205623149872}
{'R_grad_norm': 1.3667144429683686, 'training_loss': 4.745406563282013}
{'R_grad_norm': 1.3632591980695725, 'training_loss': 4.742680609226227}
{'R_grad_norm': 1.368320990204811, 'training_loss': 4.761433398723602}
{'R_grad_norm': 1.366337283849716, 'training_loss': 4.75377099275589}
{'R_grad_norm': 1.367342975139618, 'training_loss': 4.759948909282684}
{'R_grad_norm': 1.3683458417654037, 'training_loss': 4.770684590339661}
eval result tensor([7.28858, 5.34482, 7.29822, 4.95843, 6.86341, 4.76333, 4.42459, 3.15888,
        3.45224, 2.68290, 4.04108, 3.74132, 3.45204], device='cuda:0')
computing merge metric
normed mi [((5, 6), 0.05839936435222626), ((6, 9), 0.05167024830977122), ((5, 9), 0.0501698354880015), ((1, 6), 0.04685434997081757), ((6, 8), 0.04657322665055593), ((2, 6), 0.044661331176757815), ((6, 12), 0.04363034665584564), ((9, 12), 0.04331532493233681), ((0, 6), 0.04214481016000112), ((2, 5), 0.041991278529167175), ((1, 9), 0.04189041629433632), ((1, 5), 0.04149918556213379), ((2, 8), 0.0411236546933651), ((5, 12), 0.040852596362431846), ((5, 8), 0.040829127033551536), ((0, 5), 0.04023272047440211), ((8, 12), 0.03951774537563324), ((0, 2), 0.03903919032641819), ((3, 8), 0.037703717748324074), ((0, 1), 0.03750237396785191), ((1, 2), 0.03687156240145365), ((8, 9), 0.03616838529706001), ((4, 5), 0.0359954908490181), ((3, 4), 0.03574907034635544), ((7, 11), 0.03530529513955116), ((2, 3), 0.03518110811710358), ((3, 6), 0.03512987866997719), ((4, 6), 0.03429083898663521), ((3, 5), 0.03405008092522621), ((4, 8), 0.03398701796929041), ((1, 12), 0.03217661380767822), ((0, 9), 0.030328360199928284), ((2, 9), 0.029499564319849014), ((2, 4), 0.029076671600341795), ((1, 8), 0.02857041545212269), ((0, 8), 0.028518301248550416), ((2, 12), 0.027090653777122498), ((0, 3), 0.026641423503557842), ((3, 9), 0.025883078575134277), ((0, 12), 0.025012752413749693), ((1, 3), 0.023869436979293824), ((4, 9), 0.023356991509596508), ((4, 12), 0.022867384056250255), ((0, 4), 0.02138163149356842), ((1, 4), 0.019564080238342284), ((3, 12), 0.01916761075456937), ((7, 10), 0.018840134143829346), ((9, 11), 0.01737413927912712), ((11, 12), 0.015126869082450867), ((6, 11), 0.011200049271186193), ((1, 11), 0.011113693006336689), ((7, 12), 0.010680420324206352), ((5, 11), 0.01013814720014731), ((10, 11), 0.010124032385647297), ((8, 11), 0.009864258579909801), ((9, 10), 0.009408722631633282), ((7, 9), 0.00860174186527729), ((7, 8), 0.007056543603539467), ((1, 10), 0.00675296550616622), ((1, 7), 0.006394580937922001), ((10, 12), 0.006260864436626434), ((0, 11), 0.006232113763689995), ((6, 7), 0.006045027946432431), ((2, 11), 0.0059141130186617374), ((3, 11), 0.005544622118274371), ((4, 11), 0.005527590091029803), ((6, 10), 0.0051455016558369), ((5, 10), 0.004837844210366408), ((5, 7), 0.004683647925655047), ((8, 10), 0.004133796785026789), ((2, 7), 0.003671451471745968), ((3, 7), 0.003476654179394245), ((0, 7), 0.0034119248390197753), ((4, 7), 0.0032051062832276025), ((0, 10), 0.0028222324326634407), ((4, 10), 0.002558235234270493), ((2, 10), 0.002538626780733466), ((3, 10), 0.002528048430879911)]
******* after merging (0.04): [((5, 6), 128), ((0,), 128), ((1,), 96), ((2,), 96), ((3,), 64), ((4,), 64), ((7,), 32), ((8,), 32), ((9,), 32), ((10,), 32), ((11,), 32), ((12,), 32)]
{'R_grad_norm': 1.450083112716675, 'training_loss': 4.9718239116668705}
{'R_grad_norm': 1.4452111268043517, 'training_loss': 4.952676515579224}
{'R_grad_norm': 1.4392735624313355, 'training_loss': 4.940160760879516}
{'R_grad_norm': 1.4427803045511245, 'training_loss': 4.949947311878204}
{'R_grad_norm': 1.4423918390274049, 'training_loss': 4.9440207767486575}
{'R_grad_norm': 1.4462175214290618, 'training_loss': 4.955234651565552}
{'R_grad_norm': 1.4411871021986007, 'training_loss': 4.956175882816314}
{'R_grad_norm': 1.4483701276779175, 'training_loss': 4.961063122749328}
{'R_grad_norm': 1.44312424659729, 'training_loss': 4.940566279888153}
{'R_grad_norm': 1.4440036565065384, 'training_loss': 4.944478769302368}
{'R_grad_norm': 1.4483933144807815, 'training_loss': 4.97413902759552}
{'R_grad_norm': 1.439453883767128, 'training_loss': 4.948378653526306}
{'R_grad_norm': 1.4428426551818847, 'training_loss': 4.9474995017051695}
{'R_grad_norm': 1.4400005280971526, 'training_loss': 4.929645712375641}
{'R_grad_norm': 1.4451687771081925, 'training_loss': 4.970794687271118}
{'R_grad_norm': 1.4409032297134399, 'training_loss': 4.944223103523254}
{'R_grad_norm': 1.4386271625757217, 'training_loss': 4.936130158901214}
{'R_grad_norm': 1.4379888737201691, 'training_loss': 4.944975740909577}
{'R_grad_norm': 1.4409626424312592, 'training_loss': 4.951012830734253}
{'R_grad_norm': 1.4354309529066085, 'training_loss': 4.930020456314087}
{'R_grad_norm': 1.4402007693052292, 'training_loss': 4.951512153148651}
{'R_grad_norm': 1.4361035692691804, 'training_loss': 4.942709639072418}
{'R_grad_norm': 1.4389228987693787, 'training_loss': 4.951090743541718}
{'R_grad_norm': 1.4359745478630066, 'training_loss': 4.935288667678833}
{'R_grad_norm': 1.4345533204078675, 'training_loss': 4.934024112224579}
{'R_grad_norm': 1.4329305124282836, 'training_loss': 4.938272342681885}
{'R_grad_norm': 1.439630494117737, 'training_loss': 4.94961688041687}
{'R_grad_norm': 1.4365399867296218, 'training_loss': 4.9288030314445495}
{'R_grad_norm': 1.438458923101425, 'training_loss': 4.945717239379883}
{'R_grad_norm': 1.4377860367298125, 'training_loss': 4.9522263622283935}
{'R_grad_norm': 1.4351865917444229, 'training_loss': 4.937954871654511}
{'R_grad_norm': 1.4340125066041947, 'training_loss': 4.932557835578918}
{'R_grad_norm': 1.4353352993726731, 'training_loss': 4.946799385547638}
{'R_grad_norm': 1.4340841007232665, 'training_loss': 4.930940296649933}
{'R_grad_norm': 1.428780746459961, 'training_loss': 4.921979670524597}
{'R_grad_norm': 1.4329099810123445, 'training_loss': 4.931227881908416}
{'R_grad_norm': 1.4305543839931487, 'training_loss': 4.930016930103302}
{'R_grad_norm': 1.4340510100126267, 'training_loss': 4.940056750774383}
{'R_grad_norm': 1.4316637527942657, 'training_loss': 4.952542748451233}
{'R_grad_norm': 1.4312719172239303, 'training_loss': 4.928761727809906}
eval result tensor([7.88453, 7.34231, 5.26753, 6.88287, 4.82607, 6.81630, 3.14623, 3.47622,
        2.65340, 4.03204, 3.69033, 3.41794], device='cuda:0')
computing merge metric
normed mi [((8, 11), 0.04367907717823982), ((7, 11), 0.043401770293712616), ((2, 8), 0.04249734804034233), ((3, 7), 0.040352895855903625), ((7, 8), 0.04008416458964348), ((4, 7), 0.03864259521166483), ((1, 3), 0.03820557679448809), ((1, 2), 0.037694816078458517), ((2, 3), 0.0365039532383283), ((3, 4), 0.0362040251493454), ((4, 5), 0.03516831994056702), ((6, 10), 0.03423817455768585), ((5, 7), 0.03421991318464279), ((0, 3), 0.033675438591412137), ((1, 8), 0.03327172100543976), ((3, 8), 0.032504770904779434), ((0, 1), 0.03197523206472397), ((0, 8), 0.03169066607952118), ((2, 11), 0.03119117207825184), ((0, 2), 0.030374431184359958), ((4, 8), 0.030122054119904835), ((3, 11), 0.029247192665934563), ((3, 5), 0.028879308700561525), ((0, 7), 0.0288783997297287), ((0, 5), 0.028110014895598095), ((0, 11), 0.02789410054683685), ((1, 7), 0.02776312530040741), ((2, 7), 0.027663804590702057), ((1, 4), 0.026853832105795544), ((1, 11), 0.026775026321411134), ((5, 11), 0.02645810941855113), ((0, 4), 0.026309875150521595), ((5, 8), 0.026274258891741436), ((2, 4), 0.024415431916713713), ((4, 11), 0.022677920758724213), ((1, 5), 0.02122603605190913), ((6, 9), 0.01981423608958721), ((2, 5), 0.019687552750110627), ((8, 10), 0.018131453543901443), ((10, 11), 0.015849849209189415), ((7, 10), 0.012177090160548687), ((2, 10), 0.01215448509901762), ((8, 9), 0.011702568270266056), ((9, 10), 0.011503245681524277), ((6, 11), 0.011170699261128902), ((2, 9), 0.010195625014603138), ((6, 8), 0.008287337608635426), ((6, 7), 0.007635262329131365), ((9, 11), 0.007473835255950689), ((1, 10), 0.0073354564607143406), ((2, 6), 0.007034176029264927), ((3, 10), 0.006907853297889233), ((5, 10), 0.00690307654440403), ((4, 10), 0.006520528967181842), ((0, 10), 0.006485172361135483), ((7, 9), 0.005274011753499508), ((1, 9), 0.004287391155958176), ((3, 6), 0.004055003635585308), ((1, 6), 0.0039856694638729095), ((4, 6), 0.00393891924371322), ((5, 9), 0.00360830407589674), ((5, 6), 0.0035154372453689575), ((0, 9), 0.0034813549369573592), ((3, 9), 0.0034770676866173744), ((4, 9), 0.0032501077900330224), ((0, 6), 0.002877241000533104)]
******* after merging (0.04): [((0,), 128), ((1,), 128), ((2,), 96), ((3,), 96), ((8, 11), 64), ((4,), 64), ((5,), 64), ((6,), 32), ((7,), 32), ((9,), 32), ((10,), 32)]
{'R_grad_norm': 1.486502612233162, 'training_loss': 5.31699832201004}
{'R_grad_norm': 1.4878188514709472, 'training_loss': 5.315824975967407}
{'R_grad_norm': 1.4848061573505402, 'training_loss': 5.316780152320862}
{'R_grad_norm': 1.4838517713546753, 'training_loss': 5.318214786052704}
{'R_grad_norm': 1.4864278739690782, 'training_loss': 5.321473495960236}
{'R_grad_norm': 1.4837865388393403, 'training_loss': 5.311445302963257}
{'R_grad_norm': 1.4866438698768616, 'training_loss': 5.318957860469818}
{'R_grad_norm': 1.4814429050683975, 'training_loss': 5.297349977493286}
{'R_grad_norm': 1.482555267214775, 'training_loss': 5.30624888420105}
{'R_grad_norm': 1.4781086558103562, 'training_loss': 5.269844541549682}
{'R_grad_norm': 1.4801077711582185, 'training_loss': 5.292465882301331}
{'R_grad_norm': 1.485900889635086, 'training_loss': 5.327263965606689}
{'R_grad_norm': 1.4809105706214905, 'training_loss': 5.309218337535858}
{'R_grad_norm': 1.4795512020587922, 'training_loss': 5.292890384197235}
{'R_grad_norm': 1.4772461038827895, 'training_loss': 5.270042731761932}
{'R_grad_norm': 1.481337732076645, 'training_loss': 5.299327232837677}
{'R_grad_norm': 1.4766565597057342, 'training_loss': 5.2881053137779235}
{'R_grad_norm': 1.47923719227314, 'training_loss': 5.307491204738617}
{'R_grad_norm': 1.4767783188819885, 'training_loss': 5.284934475421905}
{'R_grad_norm': 1.4809073096513747, 'training_loss': 5.304796235561371}
{'R_grad_norm': 1.4748367124795914, 'training_loss': 5.282799663543702}
{'R_grad_norm': 1.4798777586221694, 'training_loss': 5.304205584526062}
{'R_grad_norm': 1.4751161283254624, 'training_loss': 5.283887484073639}
{'R_grad_norm': 1.4756921929121019, 'training_loss': 5.291560254096985}
{'R_grad_norm': 1.4771464955806732, 'training_loss': 5.284934821128846}
{'R_grad_norm': 1.477649583220482, 'training_loss': 5.2942767691612245}
{'R_grad_norm': 1.4788066112995149, 'training_loss': 5.30632732629776}
{'R_grad_norm': 1.4761890608072281, 'training_loss': 5.292628209590912}
{'R_grad_norm': 1.4738788437843322, 'training_loss': 5.283586246967316}
{'R_grad_norm': 1.477822152376175, 'training_loss': 5.3158751749992375}
{'R_grad_norm': 1.4752371591329574, 'training_loss': 5.292048361301422}
{'R_grad_norm': 1.4758193415403367, 'training_loss': 5.291867189407348}
{'R_grad_norm': 1.478098435997963, 'training_loss': 5.324183897972107}
{'R_grad_norm': 1.4778359353542327, 'training_loss': 5.308311927318573}
{'R_grad_norm': 1.4746375834941865, 'training_loss': 5.305683426856994}
{'R_grad_norm': 1.4755633574724198, 'training_loss': 5.292621216773987}
{'R_grad_norm': 1.4759631323814393, 'training_loss': 5.300080296993255}
{'R_grad_norm': 1.4738466066122056, 'training_loss': 5.284221079349518}
{'R_grad_norm': 1.4707707703113555, 'training_loss': 5.282680308818817}
{'R_grad_norm': 1.4694691479206086, 'training_loss': 5.28288880109787}
eval result tensor([8.22538, 7.46915, 5.20390, 6.42725, 5.20985, 4.65505, 6.77650, 3.12256,
        3.44299, 3.98151, 3.60218], device='cuda:0')
computing merge metric
normed mi [((3, 8), 0.03941047564148903), ((1, 3), 0.038170384509222846), ((5, 8), 0.0380903755625089), ((1, 2), 0.038086508001599996), ((3, 5), 0.037360116839408875), ((2, 3), 0.03675801306962967), ((4, 8), 0.03480660915374756), ((5, 6), 0.03383881226181984), ((6, 8), 0.033335767686367035), ((0, 3), 0.033275265778814046), ((2, 4), 0.033024263381958005), ((7, 10), 0.0323733314871788), ((0, 1), 0.03143464773893356), ((3, 4), 0.03003620505332947), ((0, 2), 0.02987824167524065), ((1, 4), 0.029637637237707775), ((0, 4), 0.02955712874730428), ((0, 8), 0.02878442108631134), ((2, 8), 0.027814246714115143), ((0, 6), 0.027721767624219257), ((1, 5), 0.027691903213659923), ((1, 8), 0.02759438157081604), ((3, 6), 0.02743777334690094), ((0, 5), 0.0268437663714091), ((2, 5), 0.02586190402507782), ((4, 5), 0.023969240486621857), ((4, 6), 0.022323517128825188), ((1, 6), 0.020647688458363216), ((2, 6), 0.019423983991146088), ((7, 9), 0.018880784511566162), ((8, 10), 0.0126231350004673), ((2, 10), 0.01239550206810236), ((4, 10), 0.012310215582450231), ((9, 10), 0.008866718970239162), ((2, 9), 0.008685636334121227), ((7, 8), 0.00791456364095211), ((1, 10), 0.007801823318004608), ((5, 10), 0.007324949527780215), ((3, 10), 0.007273257244378328), ((4, 7), 0.007105056817332904), ((6, 10), 0.006972280020515124), ((2, 7), 0.006818846333771944), ((0, 10), 0.006547512859106064), ((4, 9), 0.004840925956765811), ((8, 9), 0.004799287300556898), ((3, 7), 0.004088616464287043), ((5, 7), 0.004075957462191582), ((1, 7), 0.003985879942774773), ((1, 9), 0.0036207418888807297), ((6, 7), 0.0035831481218338013), ((3, 9), 0.003141813213005662), ((5, 9), 0.003088232750693957), ((6, 9), 0.00305824913084507), ((0, 7), 0.002736029028892517), ((0, 9), 0.0026217175647616385)]
finish training (84000)
evaluating (25 steps)...
 ******* eval result *******
mean (weighted) 6.035312652587891
mean (unweighted) 5.276670455932617
tensor([8.23089, 7.43220, 5.15915, 6.41515, 5.18517, 4.67774, 6.80335, 3.12046,
        3.44615, 3.96458, 3.60854], device='cuda:0')
