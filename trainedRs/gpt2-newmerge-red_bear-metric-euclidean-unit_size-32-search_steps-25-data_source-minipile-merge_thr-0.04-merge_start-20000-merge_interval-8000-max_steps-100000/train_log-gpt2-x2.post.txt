{'R_grad_norm': 0.7531521764397621, 'training_loss': 2.7127686309814454}
{'R_grad_norm': 0.7437704193592072, 'training_loss': 2.516917450428009}
{'R_grad_norm': 0.7421226823329925, 'training_loss': 2.4272425055503843}
{'R_grad_norm': 0.7452867782115936, 'training_loss': 2.373617970943451}
{'R_grad_norm': 0.7477624553442002, 'training_loss': 2.3366872441768645}
{'R_grad_norm': 0.7476086539030075, 'training_loss': 2.3014336585998536}
{'R_grad_norm': 0.7481575438380241, 'training_loss': 2.2735603821277617}
{'R_grad_norm': 0.7508508667349816, 'training_loss': 2.2531924521923066}
{'R_grad_norm': 0.7498329049348831, 'training_loss': 2.2229399275779724}
{'R_grad_norm': 0.7503880131244659, 'training_loss': 2.19237946331501}
{'R_grad_norm': 0.7513233134150505, 'training_loss': 2.187037565112114}
{'R_grad_norm': 0.7497551336884498, 'training_loss': 2.1636068487167357}
{'R_grad_norm': 0.751043940782547, 'training_loss': 2.148531751036644}
{'R_grad_norm': 0.7505372354388237, 'training_loss': 2.1274312955141066}
{'R_grad_norm': 0.7535459184646607, 'training_loss': 2.1334543335437774}
{'R_grad_norm': 0.7516935020685196, 'training_loss': 2.124512845277786}
{'R_grad_norm': 0.7519071087241173, 'training_loss': 2.1060434913635255}
{'R_grad_norm': 0.7508689144253731, 'training_loss': 2.086565052270889}
{'R_grad_norm': 0.7517535209655761, 'training_loss': 2.0870917266607285}
{'R_grad_norm': 0.7497603461146355, 'training_loss': 2.067978737950325}
{'R_grad_norm': 0.7493008518218994, 'training_loss': 2.062129467725754}
{'R_grad_norm': 0.7513231042027474, 'training_loss': 2.0656188255548478}
{'R_grad_norm': 0.7494239401817322, 'training_loss': 2.0620771247148513}
{'R_grad_norm': 0.7494355368614197, 'training_loss': 2.047534064054489}
{'R_grad_norm': 0.7485752123594284, 'training_loss': 2.035399485230446}
{'R_grad_norm': 0.7504810944199563, 'training_loss': 2.054138799905777}
{'R_grad_norm': 0.7478397995233536, 'training_loss': 2.0317021334171295}
{'R_grad_norm': 0.7489066824316979, 'training_loss': 2.02218994140625}
{'R_grad_norm': 0.7518681240081787, 'training_loss': 2.038578112721443}
{'R_grad_norm': 0.7482158222794533, 'training_loss': 2.021076990365982}
{'R_grad_norm': 0.7481391558051109, 'training_loss': 2.019539233446121}
{'R_grad_norm': 0.7464535495638848, 'training_loss': 2.020157843232155}
{'R_grad_norm': 0.7471010437607766, 'training_loss': 2.004588569402695}
{'R_grad_norm': 0.7454492235183716, 'training_loss': 1.999955512881279}
{'R_grad_norm': 0.7456143596768379, 'training_loss': 2.004406618475914}
{'R_grad_norm': 0.746165925860405, 'training_loss': 1.9962319076061248}
{'R_grad_norm': 0.7442786180973053, 'training_loss': 1.9897049218416214}
{'R_grad_norm': 0.7443483147025108, 'training_loss': 2.0006417518854143}
{'R_grad_norm': 0.7444439095258713, 'training_loss': 1.9849932998418809}
{'R_grad_norm': 0.7427187395095826, 'training_loss': 1.9748336178064347}
{'R_grad_norm': 0.7434702697396278, 'training_loss': 1.9855699211359024}
{'R_grad_norm': 0.7452630862593651, 'training_loss': 1.997139999270439}
{'R_grad_norm': 0.7415567350387573, 'training_loss': 1.985672531723976}
{'R_grad_norm': 0.743205592930317, 'training_loss': 1.9853462928533554}
{'R_grad_norm': 0.7422527489066124, 'training_loss': 1.970799471139908}
{'R_grad_norm': 0.7439968860149384, 'training_loss': 1.9748364120721817}
{'R_grad_norm': 0.7416366294026375, 'training_loss': 1.9787528604269027}
{'R_grad_norm': 0.7412205213308334, 'training_loss': 1.9826096439361571}
{'R_grad_norm': 0.7415245217084885, 'training_loss': 1.965395848751068}
{'R_grad_norm': 0.741710271537304, 'training_loss': 1.959275822043419}
{'R_grad_norm': 0.7418280243873596, 'training_loss': 1.977664520740509}
{'R_grad_norm': 0.7386752158403397, 'training_loss': 1.9537983012199402}
{'R_grad_norm': 0.7398057264089585, 'training_loss': 1.9691656690835952}
{'R_grad_norm': 0.7385089224576951, 'training_loss': 1.954506174325943}
{'R_grad_norm': 0.7393148162961006, 'training_loss': 1.9494988906383515}
{'R_grad_norm': 0.7382038113474846, 'training_loss': 1.953146984577179}
{'R_grad_norm': 0.7375156396627426, 'training_loss': 1.9465530461072922}
{'R_grad_norm': 0.7390786528587341, 'training_loss': 1.952535315155983}
{'R_grad_norm': 0.7402029228210449, 'training_loss': 1.9558962136507034}
{'R_grad_norm': 0.7386870789527893, 'training_loss': 1.94803877055645}
{'R_grad_norm': 0.7384188035130501, 'training_loss': 1.9480411624908447}
{'R_grad_norm': 0.736711251437664, 'training_loss': 1.9399832248687745}
{'R_grad_norm': 0.7370784085988998, 'training_loss': 1.942092318534851}
{'R_grad_norm': 0.7380346542596817, 'training_loss': 1.945979555249214}
{'R_grad_norm': 0.7377177205681801, 'training_loss': 1.9503794068098068}
{'R_grad_norm': 0.7382012310624123, 'training_loss': 1.9493365484476088}
{'R_grad_norm': 0.7360158225893975, 'training_loss': 1.9466436284780502}
{'R_grad_norm': 0.7378823989629746, 'training_loss': 1.9486948132514954}
{'R_grad_norm': 0.7345120969414711, 'training_loss': 1.9393480283021927}
{'R_grad_norm': 0.7338538956642151, 'training_loss': 1.9348691803216935}
{'R_grad_norm': 0.7355125257372856, 'training_loss': 1.9419731336832047}
{'R_grad_norm': 0.7344666469097137, 'training_loss': 1.9301950293779373}
{'R_grad_norm': 0.736180924475193, 'training_loss': 1.9484557282924653}
{'R_grad_norm': 0.734434634745121, 'training_loss': 1.9374475187063218}
{'R_grad_norm': 0.7329712483286858, 'training_loss': 1.9268553644418716}
{'R_grad_norm': 0.7325757274031639, 'training_loss': 1.9285138136148452}
{'R_grad_norm': 0.7337162005901336, 'training_loss': 1.9208134704828261}
{'R_grad_norm': 0.7336029401421547, 'training_loss': 1.9357739502191544}
{'R_grad_norm': 0.7326827964186668, 'training_loss': 1.9282771903276443}
{'R_grad_norm': 0.7326190835237503, 'training_loss': 1.9262163424491883}
{'R_grad_norm': 0.7347112303972244, 'training_loss': 1.9405730998516082}
{'R_grad_norm': 0.7333770728111267, 'training_loss': 1.9329211103916168}
{'R_grad_norm': 0.7336217114329338, 'training_loss': 1.9324054944515228}
{'R_grad_norm': 0.7326732206344605, 'training_loss': 1.924004477262497}
{'R_grad_norm': 0.733894620835781, 'training_loss': 1.9253229796886444}
{'R_grad_norm': 0.7329080331325531, 'training_loss': 1.927456601858139}
{'R_grad_norm': 0.7321484285593033, 'training_loss': 1.9315378320217134}
{'R_grad_norm': 0.7327865943312645, 'training_loss': 1.9386355900764465}
{'R_grad_norm': 0.7303846868872642, 'training_loss': 1.9210594421625138}
{'R_grad_norm': 0.7291229832172393, 'training_loss': 1.9126307493448258}
{'R_grad_norm': 0.73256068110466, 'training_loss': 1.9343175315856933}
{'R_grad_norm': 0.7322956830263138, 'training_loss': 1.9239224570989608}
{'R_grad_norm': 0.7307636654376983, 'training_loss': 1.9176903229951858}
{'R_grad_norm': 0.7326979765295982, 'training_loss': 1.9129089665412904}
{'R_grad_norm': 0.7322997772693634, 'training_loss': 1.9237607038021087}
{'R_grad_norm': 0.7298697653412819, 'training_loss': 1.9174787592887879}
{'R_grad_norm': 0.7302576047182083, 'training_loss': 1.9221573710441588}
{'R_grad_norm': 0.7318122625350952, 'training_loss': 1.9243443703651428}
{'R_grad_norm': 0.7306450977921486, 'training_loss': 1.9142936813831328}
{'R_grad_norm': 0.7302545595169068, 'training_loss': 1.915726187825203}
eval result tensor([2.01066, 1.69422, 2.35378, 2.17007, 1.56362, 1.57135, 1.81091, 2.16462,
        1.38238, 1.68510, 1.92083, 1.73392, 2.01405, 1.63298, 1.67770, 2.53236,
        2.10289, 1.63869, 2.14449, 2.55666, 1.79926, 2.11297, 1.88678, 1.57467],
       device='cuda:0')
computing merge metric
normed mi [((5, 23), 0.13922394812107086), ((1, 23), 0.13920317590236664), ((9, 23), 0.13906237483024597), ((1, 5), 0.13849426805973053), ((5, 14), 0.138345867395401), ((5, 9), 0.13832548260688782), ((1, 9), 0.13788487017154694), ((5, 20), 0.13694854080677032), ((5, 6), 0.1368584930896759), ((14, 23), 0.13674446940422058), ((6, 23), 0.13663530349731445), ((1, 6), 0.13650114834308624), ((0, 6), 0.13644099235534668), ((0, 14), 0.1364169418811798), ((1, 14), 0.13632167875766754), ((0, 5), 0.1363118290901184), ((6, 14), 0.13601967692375183), ((9, 20), 0.1359284520149231), ((5, 22), 0.13529706001281738), ((0, 1), 0.13529333472251892), ((1, 20), 0.13517050445079803), ((20, 23), 0.13499656319618225), ((0, 23), 0.13496969640254974), ((9, 14), 0.13495655357837677), ((0, 22), 0.13485178351402283), ((6, 9), 0.134502574801445), ((14, 20), 0.13441221415996552), ((14, 22), 0.13398438692092896), ((1, 22), 0.133832186460495), ((22, 23), 0.13378064334392548), ((6, 22), 0.13375268876552582), ((0, 10), 0.13326190412044525), ((6, 20), 0.1329544484615326), ((0, 9), 0.13290941715240479), ((9, 22), 0.13270297646522522), ((0, 20), 0.1326957494020462), ((9, 11), 0.13212130963802338), ((20, 22), 0.13138490915298462), ((11, 23), 0.1310272365808487), ((10, 14), 0.13091117143630981), ((6, 10), 0.13075995445251465), ((10, 22), 0.13060225546360016), ((5, 10), 0.12999118864536285), ((1, 11), 0.12974371016025543), ((5, 11), 0.12901628017425537), ((1, 10), 0.12810757756233215), ((10, 23), 0.1278718113899231), ((11, 20), 0.1272243857383728), ((0, 16), 0.12570366263389587), ((10, 20), 0.12550555169582367), ((9, 10), 0.1252056062221527), ((5, 16), 0.12506821751594543), ((11, 14), 0.12501326203346252), ((6, 11), 0.12494982779026031), ((16, 23), 0.12419907003641129), ((14, 16), 0.12408367544412613), ((1, 16), 0.1238514706492424), ((6, 16), 0.12372294068336487), ((16, 20), 0.12357718497514725), ((9, 16), 0.12318500876426697), ((11, 22), 0.12297851592302322), ((0, 11), 0.12280557304620743), ((16, 22), 0.1227397546172142), ((10, 16), 0.12049151957035065), ((5, 17), 0.11962871253490448), ((14, 17), 0.11847078055143356), ((17, 23), 0.11809608340263367), ((11, 16), 0.11779424548149109), ((9, 17), 0.11738120019435883), ((17, 20), 0.11723269522190094), ((1, 17), 0.11714247614145279), ((0, 7), 0.11689845472574234), ((7, 10), 0.11673673987388611), ((6, 17), 0.116507887840271), ((10, 11), 0.11581753194332123), ((17, 22), 0.11525646597146988), ((0, 17), 0.11490996181964874), ((11, 17), 0.11378496140241623), ((7, 14), 0.11343938857316971), ((7, 22), 0.11248207092285156), ((6, 7), 0.11202747374773026), ((5, 7), 0.11202212423086166), ((10, 17), 0.11142419278621674), ((7, 16), 0.10997053235769272), ((16, 17), 0.10966107249259949), ((4, 8), 0.10935768485069275), ((1, 7), 0.1091093197464943), ((7, 20), 0.10898580402135849), ((7, 23), 0.10864340513944626), ((7, 9), 0.10673301666975021), ((4, 11), 0.10368197411298752), ((9, 12), 0.10362677276134491), ((11, 12), 0.1034514531493187), ((12, 23), 0.10318677872419357), ((5, 12), 0.10219244658946991), ((7, 11), 0.10141386091709137), ((1, 12), 0.10125240683555603), ((12, 20), 0.10085185617208481), ((12, 22), 0.09876101464033127), ((12, 14), 0.09870089590549469), ((7, 17), 0.09757497906684875), ((4, 9), 0.09755126386880875), ((6, 12), 0.09713096171617508), ((0, 12), 0.0963679775595665), ((4, 23), 0.09466443955898285), ((8, 11), 0.09450043737888336), ((12, 16), 0.09414943307638168), ((1, 4), 0.09281101077795029), ((12, 17), 0.09244248270988464), ((4, 20), 0.09168271720409393), ((4, 5), 0.09118577837944031), ((10, 12), 0.09092990309000015), ((8, 9), 0.08743699640035629), ((4, 6), 0.08601881563663483), ((4, 14), 0.08575847744941711), ((4, 22), 0.08471813797950745), ((8, 23), 0.08281014114618301), ((7, 12), 0.08246222138404846), ((4, 12), 0.08216292411088943), ((4, 16), 0.08091084659099579), ((0, 4), 0.08071660995483398), ((1, 8), 0.08016333729028702), ((8, 20), 0.08005034923553467), ((18, 19), 0.07973750680685043), ((4, 17), 0.07909098267555237), ((5, 8), 0.07793477177619934), ((3, 22), 0.07664593309164047), ((10, 21), 0.07467833906412125), ((21, 22), 0.07444939762353897), ((8, 12), 0.0743570327758789), ((0, 21), 0.0741240531206131), ((3, 5), 0.07382319867610931), ((19, 21), 0.07379883527755737), ((3, 10), 0.07331053912639618), ((4, 10), 0.07330216467380524), ((0, 3), 0.07329027354717255), ((18, 22), 0.07323954999446869), ((3, 14), 0.07293415069580078), ((14, 21), 0.07288095355033875), ((6, 8), 0.07249853760004044), ((19, 22), 0.07227804511785507), ((6, 21), 0.07220447063446045), ((5, 21), 0.0721573531627655), ((3, 18), 0.07169436663389206), ((3, 6), 0.07143253087997437), ((3, 20), 0.07142322510480881), ((8, 14), 0.07141934335231781), ((3, 16), 0.07138654589653015), ((3, 7), 0.07118423283100128), ((10, 18), 0.07116420567035675), ((0, 18), 0.07050760090351105), ((20, 21), 0.07041358202695847), ((8, 22), 0.07038147002458572), ((19, 20), 0.07033649832010269), ((1, 3), 0.07028039544820786), ((5, 18), 0.0701930969953537), ((3, 23), 0.06998465955257416), ((14, 18), 0.06996948271989822), ((1, 21), 0.06988310813903809), ((18, 20), 0.06980013102293015), ((8, 16), 0.06970527023077011), ((5, 19), 0.06938180327415466), ((0, 19), 0.06929939240217209), ((3, 9), 0.06914199143648148), ((21, 23), 0.06907767802476883), ((14, 19), 0.06902151554822922), ((9, 21), 0.06861686706542969), ((6, 18), 0.06861434876918793), ((7, 18), 0.06858572363853455), ((8, 17), 0.06835394352674484), ((7, 21), 0.06834441423416138), ((3, 11), 0.06799225509166718), ((10, 19), 0.06794451922178268), ((0, 8), 0.06784461438655853), ((6, 19), 0.06770531833171844), ((18, 21), 0.0676543340086937), ((9, 19), 0.06674432009458542), ((16, 19), 0.06668596714735031), ((1, 18), 0.06650806218385696), ((16, 18), 0.06641888618469238), ((1, 19), 0.06612160056829453), ((16, 21), 0.06611303240060806), ((18, 23), 0.06606192141771317), ((9, 18), 0.06584794074296951), ((19, 23), 0.06543039530515671), ((7, 19), 0.06520059704780579), ((3, 17), 0.06441707909107208), ((3, 12), 0.06438267976045609), ((3, 19), 0.06357255578041077), ((17, 18), 0.062410686165094376), ((8, 10), 0.061288461089134216), ((11, 18), 0.061053913086652756), ((11, 21), 0.06076491251587868), ((11, 19), 0.06035933271050453), ((12, 19), 0.05988851934671402), ((17, 21), 0.05956004932522774), ((4, 7), 0.058935679495334625), ((12, 18), 0.05858917161822319), ((17, 19), 0.058160655200481415), ((4, 13), 0.05599819868803024), ((3, 21), 0.05081718787550926), ((7, 8), 0.049917083233594894), ((12, 21), 0.04930778965353966), ((2, 15), 0.04642776772379875), ((3, 4), 0.04190884530544281), ((4, 19), 0.037149809300899506), ((3, 8), 0.03618587926030159), ((8, 13), 0.034716084599494934), ((8, 19), 0.034291427582502365), ((8, 18), 0.034140121191740036), ((4, 18), 0.03305038437247276), ((4, 21), 0.030187277123332024), ((8, 21), 0.027560574933886528), ((2, 4), 0.02606498822569847), ((8, 15), 0.02576855756342411), ((11, 15), 0.024350125342607498), ((4, 15), 0.0225242767482996), ((9, 15), 0.022437559440732002), ((15, 23), 0.022011002525687218), ((11, 13), 0.021924085915088654), ((2, 8), 0.021611860021948814), ((15, 20), 0.0214037224650383), ((1, 15), 0.021137386560440063), ((5, 15), 0.02038249932229519), ((12, 15), 0.020304348319768906), ((2, 11), 0.019735923036932945), ((6, 15), 0.0192465428262949), ((14, 15), 0.018999136984348297), ((9, 13), 0.01875871792435646), ((15, 16), 0.018755892291665077), ((2, 12), 0.018754051998257637), ((2, 9), 0.018637366592884064), ((15, 17), 0.018480807542800903), ((2, 23), 0.01838294044137001), ((0, 15), 0.018328720703721046), ((15, 22), 0.017918987199664116), ((1, 2), 0.01738908886909485), ((2, 20), 0.01733996532857418), ((13, 23), 0.016974328085780144), ((2, 17), 0.016742035746574402), ((2, 5), 0.016719525679945946), ((12, 13), 0.016443980857729912), ((1, 13), 0.016280846670269966), ((10, 15), 0.016122017055749893), ((2, 14), 0.01593863032758236), ((2, 6), 0.015767289325594902), ((13, 20), 0.01562339998781681), ((0, 2), 0.01503279060125351), ((2, 16), 0.015016723424196243), ((2, 22), 0.014629045501351357), ((5, 13), 0.014438445679843426), ((2, 10), 0.013883795589208603), ((6, 13), 0.013026788830757141), ((13, 14), 0.012236528098583221), ((13, 16), 0.012138175778090954), ((13, 22), 0.011866120621562004), ((7, 15), 0.011817595921456814), ((2, 13), 0.011702317744493484), ((0, 13), 0.011638358235359192), ((3, 15), 0.011411233805119991), ((13, 17), 0.010374389588832855), ((2, 7), 0.010184808634221554), ((15, 19), 0.009783122688531876), ((2, 3), 0.009691095910966396), ((15, 18), 0.009365098550915718), ((10, 13), 0.008781563490629196), ((2, 18), 0.008663089945912361), ((2, 19), 0.008429599925875664), ((15, 21), 0.007941859774291515), ((2, 21), 0.007652088068425655), ((13, 15), 0.007444458547979593), ((7, 13), 0.005036998074501753), ((13, 19), 0.004168521147221327), ((3, 13), 0.0036088943015784025), ((13, 18), 0.003352923085913062), ((13, 21), 0.002661961829289794)]
******* after merging (0.04): [((5, 23), 64), ((1, 9), 64), ((0, 6), 64), ((2,), 32), ((3,), 32), ((4,), 32), ((7,), 32), ((8,), 32), ((10,), 32), ((11,), 32), ((12,), 32), ((13,), 32), ((14,), 32), ((15,), 32), ((16,), 32), ((17,), 32), ((18,), 32), ((19,), 32), ((20,), 32), ((21,), 32), ((22,), 32)]
{'R_grad_norm': 0.8838437288999558, 'training_loss': 2.0638070821762087}
{'R_grad_norm': 0.8823593798279762, 'training_loss': 2.070552639365196}
{'R_grad_norm': 0.8823185130953789, 'training_loss': 2.073047016263008}
{'R_grad_norm': 0.8785776796936989, 'training_loss': 2.0499951994419097}
{'R_grad_norm': 0.8790721771121025, 'training_loss': 2.045031777024269}
{'R_grad_norm': 0.8813916581869126, 'training_loss': 2.062702625989914}
{'R_grad_norm': 0.8772228682041168, 'training_loss': 2.0510851472616194}
{'R_grad_norm': 0.8770127341151237, 'training_loss': 2.041038535237312}
{'R_grad_norm': 0.8747308537364006, 'training_loss': 2.0480664092302323}
{'R_grad_norm': 0.8781888338923455, 'training_loss': 2.0392915952205657}
{'R_grad_norm': 0.8811927315592766, 'training_loss': 2.0531843209266665}
{'R_grad_norm': 0.875828742980957, 'training_loss': 2.0483844792842865}
{'R_grad_norm': 0.87575826972723, 'training_loss': 2.0457947570085526}
{'R_grad_norm': 0.8749445694684982, 'training_loss': 2.050443817973137}
{'R_grad_norm': 0.8763854792714119, 'training_loss': 2.044619491696358}
{'R_grad_norm': 0.8739878979325294, 'training_loss': 2.03086189866066}
{'R_grad_norm': 0.8776202815771103, 'training_loss': 2.051301118135452}
{'R_grad_norm': 0.8712764304876327, 'training_loss': 2.028165667057037}
{'R_grad_norm': 0.873814643919468, 'training_loss': 2.0361675101518633}
{'R_grad_norm': 0.8712993222475052, 'training_loss': 2.028491575717926}
{'R_grad_norm': 0.8739733895659447, 'training_loss': 2.043906196951866}
{'R_grad_norm': 0.8712275430560112, 'training_loss': 2.036739805936813}
{'R_grad_norm': 0.8704745075106621, 'training_loss': 2.026564484238625}
{'R_grad_norm': 0.8721712148189544, 'training_loss': 2.0372430139780047}
{'R_grad_norm': 0.8705739969015122, 'training_loss': 2.032692480683327}
{'R_grad_norm': 0.8687791442871093, 'training_loss': 2.036068991422653}
{'R_grad_norm': 0.872312918305397, 'training_loss': 2.038487128615379}
{'R_grad_norm': 0.8710161688923835, 'training_loss': 2.0257042825222014}
{'R_grad_norm': 0.8666279518604278, 'training_loss': 2.0320373547077177}
{'R_grad_norm': 0.8685143634676933, 'training_loss': 2.0197409385442735}
{'R_grad_norm': 0.866978994011879, 'training_loss': 2.018584113717079}
{'R_grad_norm': 0.8675157874822617, 'training_loss': 2.034156548976898}
{'R_grad_norm': 0.8635108238458633, 'training_loss': 2.017170574069023}
{'R_grad_norm': 0.8635102114081383, 'training_loss': 2.0131908094882967}
{'R_grad_norm': 0.8664608940482139, 'training_loss': 2.033224892616272}
{'R_grad_norm': 0.8628137975931167, 'training_loss': 2.018065876364708}
{'R_grad_norm': 0.8657713240385055, 'training_loss': 2.026663842201233}
{'R_grad_norm': 0.8662742480635643, 'training_loss': 2.029645849466324}
{'R_grad_norm': 0.8635216185450554, 'training_loss': 2.0228917437791822}
{'R_grad_norm': 0.8617003655433655, 'training_loss': 2.016749307513237}
eval result tensor([2.68452, 2.84610, 3.44475, 2.29893, 2.22622, 1.45013, 2.02643, 1.33385,
        1.73184, 1.50216, 1.97910, 1.57532, 1.47424, 2.48138, 1.95482, 1.52749,
        2.08094, 2.48523, 1.59123, 2.10843, 1.63750], device='cuda:0')
computing merge metric
normed mi [((9, 12), 0.1349707543849945), ((12, 18), 0.13386018574237823), ((12, 20), 0.13293926417827606), ((9, 20), 0.13161444664001465), ((18, 20), 0.13109345734119415), ((9, 18), 0.13080516457557678), ((8, 12), 0.12739168107509613), ((8, 9), 0.1258944720029831), ((8, 20), 0.12543489038944244), ((8, 18), 0.12077881395816803), ((12, 14), 0.11987271904945374), ((14, 20), 0.11859285086393356), ((9, 14), 0.11856505274772644), ((8, 14), 0.11833661794662476), ((14, 18), 0.11711575835943222), ((12, 15), 0.11630699783563614), ((15, 18), 0.11569081246852875), ((15, 20), 0.11447404325008392), ((6, 8), 0.11443136632442474), ((9, 15), 0.11377859860658646), ((6, 9), 0.11043058335781097), ((6, 14), 0.11016074568033218), ((6, 12), 0.10992927104234695), ((6, 20), 0.10830161720514297), ((5, 7), 0.10816803574562073), ((6, 18), 0.1050487756729126), ((8, 15), 0.10440937429666519), ((14, 15), 0.10203971713781357), ((10, 18), 0.09688577800989151), ((10, 20), 0.09670260548591614), ((0, 12), 0.09511751929918925), ((10, 12), 0.09468214958906174), ((9, 10), 0.0942404568195343), ((1, 12), 0.09408339858055115), ((2, 12), 0.093874990940094), ((0, 9), 0.09349154432614644), ((1, 9), 0.09320608774820964), ((2, 9), 0.09231289227803548), ((1, 20), 0.0921639899412791), ((6, 15), 0.09214946627616882), ((1, 18), 0.09201634923617046), ((0, 20), 0.09192431966463725), ((2, 20), 0.09184509515762329), ((2, 18), 0.09156602621078491), ((0, 18), 0.09125050902366638), ((10, 15), 0.0894487276673317), ((2, 8), 0.08719739317893982), ((0, 8), 0.08681744337081909), ((1, 8), 0.08481855193773906), ((10, 14), 0.08472753316164017), ((8, 10), 0.08356358110904694), ((2, 14), 0.08301206926504771), ((0, 14), 0.08216089010238647), ((7, 18), 0.0818713903427124), ((1, 14), 0.08062386512756348), ((1, 15), 0.08011357982953389), ((0, 15), 0.07994752128918965), ((2, 15), 0.0794111043214798), ((5, 18), 0.07873664796352386), ((7, 10), 0.07859797030687332), ((16, 17), 0.07759618759155273), ((5, 10), 0.0774950385093689), ((7, 20), 0.07695820182561874), ((6, 10), 0.07636918127536774), ((5, 20), 0.07636389136314392), ((2, 6), 0.07515413065751393), ((7, 12), 0.0750887393951416), ((0, 6), 0.074373592933019), ((7, 15), 0.07436845451593399), ((0, 1), 0.07429830729961395), ((16, 20), 0.07425719499588013), ((4, 20), 0.0741986557841301), ((5, 12), 0.07376260310411453), ((16, 18), 0.07342557609081268), ((0, 2), 0.07337646931409836), ((1, 2), 0.07333050668239594), ((17, 19), 0.07324381917715073), ((5, 9), 0.07299178093671799), ((7, 9), 0.07275339961051941), ((4, 9), 0.07261654734611511), ((1, 6), 0.07238490879535675), ((9, 16), 0.07230228930711746), ((12, 16), 0.0722007229924202), ((8, 16), 0.0721769854426384), ((5, 15), 0.0707835778594017), ((14, 16), 0.0707281082868576), ((17, 20), 0.07048826664686203), ((4, 12), 0.07042358815670013), ((4, 16), 0.07040894776582718), ((4, 18), 0.06983036547899246), ((4, 14), 0.06976155936717987), ((17, 18), 0.06958456337451935), ((4, 8), 0.06942542642354965), ((6, 16), 0.06926830857992172), ((1, 10), 0.06836551427841187), ((8, 19), 0.06796639412641525), ((4, 6), 0.06674835830926895), ((9, 17), 0.06653417646884918), ((12, 17), 0.06649982929229736), ((0, 10), 0.06644383569558461), ((14, 17), 0.06637320667505264), ((8, 17), 0.06620971858501434), ((2, 10), 0.06601940095424652), ((19, 20), 0.06550072878599167), ((9, 19), 0.06496383249759674), ((12, 19), 0.06494460254907608), ((14, 19), 0.06403132528066635), ((6, 17), 0.06393306702375412), ((4, 10), 0.06312503665685654), ((18, 19), 0.06301498413085938), ((7, 14), 0.06256916373968124), ((16, 19), 0.06208411231637001), ((6, 19), 0.06205504760146141), ((4, 15), 0.061766643077135086), ((4, 17), 0.06162329018115997), ((15, 16), 0.0615524984896183), ((5, 14), 0.05913466215133667), ((7, 8), 0.05888605862855911), ((10, 16), 0.058640722185373306), ((1, 7), 0.05666681627432505), ((5, 11), 0.05635790526866913), ((5, 8), 0.05554914474487305), ((10, 17), 0.05552084371447563), ((1, 5), 0.05543150007724762), ((15, 17), 0.054794616997241974), ((2, 7), 0.05288932720820109), ((0, 7), 0.05226213733355204), ((0, 5), 0.051676973700523376), ((2, 5), 0.051676273345947266), ((15, 19), 0.05137314647436142), ((6, 7), 0.05068948119878769), ((0, 16), 0.04879067341486613), ((0, 4), 0.048656453688939415), ((2, 4), 0.04786482950051626), ((1, 4), 0.047355795900026955), ((2, 16), 0.04734454055627187), ((1, 16), 0.04700435698032379), ((5, 6), 0.04619363695383072), ((0, 17), 0.04526787499586741), ((3, 13), 0.045095209032297134), ((4, 19), 0.04502791911363602), ((1, 17), 0.044266397754351296), ((2, 17), 0.04418664673964182), ((0, 19), 0.04365530610084534), ((2, 19), 0.04315131405989329), ((1, 19), 0.043035075068473816), ((10, 19), 0.04240052029490471), ((4, 7), 0.04022667929530144), ((4, 5), 0.03826890140771866), ((7, 16), 0.03820103406906128), ((7, 17), 0.0339357927441597), ((7, 11), 0.03272722288966179), ((5, 16), 0.030432168394327164), ((5, 17), 0.030131105333566666), ((7, 19), 0.026926273480057716), ((3, 5), 0.024886472150683403), ((7, 13), 0.024247366935014725), ((5, 19), 0.022811323404312134), ((5, 13), 0.020866582170128822), ((3, 7), 0.019989561289548874), ((3, 10), 0.01951562985777855), ((13, 18), 0.018778905272483826), ((10, 13), 0.018523776903748512), ((12, 13), 0.01719716563820839), ((13, 15), 0.01679498516023159), ((13, 20), 0.016369197517633438), ((9, 13), 0.016236424446105957), ((3, 15), 0.01619863510131836), ((3, 18), 0.016109146177768707), ((10, 11), 0.015527256764471531), ((3, 12), 0.015462207607924938), ((3, 20), 0.014665503054857254), ((3, 9), 0.014241407625377178), ((13, 14), 0.013924805447459221), ((1, 13), 0.013149076451857885), ((11, 18), 0.013072517700493336), ((3, 14), 0.012924917973577976), ((2, 13), 0.012828328957160315), ((8, 13), 0.012751920148730278), ((3, 8), 0.01246382761746645), ((0, 13), 0.012191841999689737), ((11, 20), 0.011570794507861137), ((4, 13), 0.011477415449917316), ((1, 3), 0.011459339410066605), ((11, 12), 0.011084569618105888), ((2, 3), 0.011068002631266912), ((3, 4), 0.011040189303457737), ((0, 3), 0.010715006540218988), ((3, 11), 0.010531529784202576), ((3, 6), 0.010431498289108276), ((9, 11), 0.010237366892397404), ((11, 15), 0.010166110470890999), ((6, 13), 0.009684182703495026), ((1, 11), 0.009230616192022959), ((13, 16), 0.00867545511573553), ((3, 16), 0.008661504834890366), ((3, 17), 0.008433238603174686), ((2, 11), 0.00819036861260732), ((13, 17), 0.007971764542162418), ((0, 11), 0.007648147642612457), ((11, 14), 0.007523204665631056), ((3, 19), 0.007447015028446913), ((11, 13), 0.0066825831308960915), ((13, 19), 0.006578528322279453), ((8, 11), 0.0064231473952531815), ((4, 11), 0.004266479983925819), ((6, 11), 0.0040998007170856), ((11, 17), 0.003493968863040209), ((11, 16), 0.0033775141928344965), ((11, 19), 0.0024024881422519684)]
******* after merging (0.04): [((9, 12), 64), ((18, 20), 64), ((0,), 64), ((1,), 64), ((2,), 64), ((3,), 32), ((4,), 32), ((5,), 32), ((6,), 32), ((7,), 32), ((8,), 32), ((10,), 32), ((11,), 32), ((13,), 32), ((14,), 32), ((15,), 32), ((16,), 32), ((17,), 32), ((19,), 32)]
{'R_grad_norm': 0.938770223557949, 'training_loss': 2.146556378006935}
{'R_grad_norm': 0.9348279085755348, 'training_loss': 2.1462478816509245}
{'R_grad_norm': 0.9353028094768524, 'training_loss': 2.149729123711586}
{'R_grad_norm': 0.9362970373034477, 'training_loss': 2.159715338349342}
{'R_grad_norm': 0.9324746134877205, 'training_loss': 2.1486410915851595}
{'R_grad_norm': 0.9297755053639412, 'training_loss': 2.1333416855335234}
{'R_grad_norm': 0.933582428097725, 'training_loss': 2.1447699815034866}
{'R_grad_norm': 0.9394651824235916, 'training_loss': 2.161395664215088}
{'R_grad_norm': 0.9351753211021423, 'training_loss': 2.1546251690387725}
{'R_grad_norm': 0.9412927123904228, 'training_loss': 2.173832183480263}
{'R_grad_norm': 0.9411041063070297, 'training_loss': 2.173296948671341}
{'R_grad_norm': 0.9412754106521607, 'training_loss': 2.169782775044441}
{'R_grad_norm': 0.9412763997912407, 'training_loss': 2.1815420681238176}
{'R_grad_norm': 0.9460006529092788, 'training_loss': 2.190909064412117}
{'R_grad_norm': 0.9468666207790375, 'training_loss': 2.2023174279928206}
{'R_grad_norm': 0.9492744168639183, 'training_loss': 2.223071518540382}
{'R_grad_norm': 0.9513742765784263, 'training_loss': 2.220336822271347}
{'R_grad_norm': 0.9556454715132713, 'training_loss': 2.242889243364334}
{'R_grad_norm': 0.9544910591840744, 'training_loss': 2.2389133882522585}
{'R_grad_norm': 0.9606479105353355, 'training_loss': 2.2735672616958618}
{'R_grad_norm': 0.9610294118523598, 'training_loss': 2.2797695022821425}
{'R_grad_norm': 0.967415286898613, 'training_loss': 2.3078442096710203}
{'R_grad_norm': 0.9418174710869789, 'training_loss': 2.1893191605806352}
{'R_grad_norm': 0.9228677368164062, 'training_loss': 2.107097707390785}
{'R_grad_norm': 0.9245623326301575, 'training_loss': 2.1159444749355316}
{'R_grad_norm': 0.9254148456454278, 'training_loss': 2.1242656564712523}
{'R_grad_norm': 0.9231749102473259, 'training_loss': 2.116158767938614}
{'R_grad_norm': 0.9196942752599716, 'training_loss': 2.105552695989609}
{'R_grad_norm': 0.9213852679729462, 'training_loss': 2.1148596215248108}
{'R_grad_norm': 0.9209307780861855, 'training_loss': 2.1094416612386704}
{'R_grad_norm': 0.9187127891182899, 'training_loss': 2.1074493604898454}
{'R_grad_norm': 0.9206812283396721, 'training_loss': 2.103612653017044}
{'R_grad_norm': 0.9211073940992356, 'training_loss': 2.110401114225388}
{'R_grad_norm': 0.92224778175354, 'training_loss': 2.1178392541408537}
{'R_grad_norm': 0.9214177763462067, 'training_loss': 2.1130758279562}
{'R_grad_norm': 0.9216603922843933, 'training_loss': 2.1100329577922823}
{'R_grad_norm': 0.9234697166085243, 'training_loss': 2.1180955243110655}
{'R_grad_norm': 0.9186269262433052, 'training_loss': 2.1082898563146593}
{'R_grad_norm': 0.9206147760152816, 'training_loss': 2.109821561574936}
{'R_grad_norm': 0.9195822820067405, 'training_loss': 2.1087207275629045}
eval result tensor([2.36129, 2.61931, 2.62252, 2.74422, 3.46663, 2.23896, 2.20409, 1.35522,
        1.89178, 1.26242, 1.54576, 1.90975, 1.49491, 2.38128, 1.80999, 1.42554,
        2.01599, 2.35511, 2.10159], device='cuda:0')
computing merge metric
normed mi [((10, 14), 0.11746610701084137), ((8, 10), 0.11076147854328156), ((8, 14), 0.10683801770210266), ((10, 15), 0.10672799497842789), ((7, 9), 0.10524944216012955), ((14, 15), 0.09947573393583298), ((9, 15), 0.09363409131765366), ((4, 10), 0.0896982451279958), ((8, 15), 0.08952715992927551), ((9, 11), 0.08912786096334457), ((0, 10), 0.08872156341870625), ((11, 15), 0.08770919591188431), ((1, 10), 0.08655563990275066), ((2, 10), 0.08556272586186726), ((10, 11), 0.0843946635723114), ((3, 10), 0.08392130335172017), ((4, 14), 0.08270761867364247), ((11, 14), 0.08158663660287857), ((1, 14), 0.0815138965845108), ((0, 14), 0.08121772110462189), ((9, 10), 0.08083884418010712), ((2, 15), 0.08023445804913838), ((7, 11), 0.08023086190223694), ((3, 15), 0.07999466856320699), ((16, 17), 0.07965201884508133), ((4, 15), 0.07823283473650615), ((2, 14), 0.07816127439339955), ((1, 15), 0.07733224829037984), ((0, 15), 0.07714769244194031), ((3, 14), 0.0770032952229182), ((9, 14), 0.07693373411893845), ((4, 8), 0.07546173532803853), ((0, 8), 0.0752912312746048), ((7, 15), 0.07501225173473358), ((2, 3), 0.07459922134876251), ((3, 9), 0.07362136244773865), ((10, 16), 0.07347536087036133), ((1, 8), 0.07336162527402242), ((8, 11), 0.07323017716407776), ((17, 18), 0.07317430526018143), ((6, 16), 0.07255115360021591), ((0, 4), 0.07215215265750885), ((2, 4), 0.07205145061016083), ((14, 16), 0.07186879217624664), ((2, 9), 0.07094785571098328), ((3, 4), 0.07090207189321518), ((0, 2), 0.07056908309459686), ((6, 10), 0.07010810822248459), ((1, 4), 0.07006552815437317), ((2, 8), 0.07005386054515839), ((0, 1), 0.06985639780759811), ((6, 14), 0.06917630881071091), ((0, 3), 0.06892220675945282), ((14, 17), 0.06890543550252914), ((3, 11), 0.0688179184993108), ((3, 8), 0.06881723304589589), ((1, 2), 0.06868507713079453), ((8, 16), 0.06843873858451843), ((10, 17), 0.06840221583843231), ((1, 3), 0.06793545931577682), ((2, 11), 0.0679025948047638), ((8, 9), 0.06606389582157135), ((6, 8), 0.06596124172210693), ((10, 18), 0.06519583612680435), ((6, 17), 0.06445994973182678), ((8, 17), 0.06405144184827805), ((7, 10), 0.06390330940485), ((1, 11), 0.0638418694337209), ((4, 11), 0.06377123296260834), ((4, 9), 0.0631799300511678), ((16, 18), 0.06261765956878662), ((1, 9), 0.06249458094437917), ((14, 18), 0.06212114542722702), ((0, 11), 0.061701262990633644), ((15, 16), 0.061162855476140976), ((6, 11), 0.06085807830095291), ((3, 7), 0.06018365919589996), ((7, 12), 0.06007344648241997), ((6, 15), 0.059656184166669846), ((7, 14), 0.059619732201099396), ((0, 9), 0.05917133390903473), ((11, 16), 0.05907662212848663), ((8, 18), 0.059069763869047165), ((2, 7), 0.05792547265688578), ((11, 17), 0.056687626987695694), ((1, 16), 0.055004517237345375), ((15, 17), 0.05492447689175606), ((1, 17), 0.05365413427352905), ((0, 16), 0.0513580838839213), ((1, 6), 0.051219324270884194), ((4, 7), 0.05104755858580271), ((1, 7), 0.05058136582374573), ((7, 8), 0.05052785202860832), ((4, 16), 0.049387420217196144), ((15, 18), 0.04906918480992317), ((0, 6), 0.048669601480166115), ((9, 16), 0.048109691590070724), ((0, 17), 0.04804773132006327), ((0, 7), 0.04789299766222636), ((4, 6), 0.04773499568303426), ((4, 17), 0.046935265262921654), ((6, 18), 0.04682706296443939), ((2, 16), 0.04679730534553528), ((6, 9), 0.04629698023200035), ((3, 16), 0.045655334989229836), ((2, 6), 0.04542493323485056), ((1, 18), 0.04539965589841207), ((2, 17), 0.04477385183175405), ((3, 6), 0.04450256625811259), ((0, 18), 0.04434291025002798), ((3, 17), 0.0443218598763148), ((9, 17), 0.043563660234212875), ((5, 13), 0.04324931651353836), ((4, 18), 0.04288040598233541), ((11, 18), 0.04162810742855072), ((2, 18), 0.04061551888783773), ((3, 18), 0.040430051585038505), ((6, 7), 0.03787766769528389), ((9, 18), 0.03526468202471733), ((7, 17), 0.0339684933423996), ((7, 16), 0.033681470900774), ((9, 12), 0.03252726420760155), ((5, 7), 0.02545386180281639), ((7, 18), 0.025069253519177437), ((9, 13), 0.024873165413737297), ((11, 12), 0.0223787110298872), ((7, 13), 0.021786300465464592), ((11, 13), 0.02095542848110199), ((5, 11), 0.020273860543966293), ((5, 9), 0.01978815719485283), ((13, 15), 0.019290653988718987), ((5, 15), 0.016966724768280983), ((10, 13), 0.015617316588759422), ((3, 13), 0.015595378975073496), ((13, 14), 0.01559362281113863), ((12, 15), 0.015379315242171288), ((2, 13), 0.014960664014021555), ((3, 12), 0.014798303445180258), ((4, 13), 0.01356800397237142), ((5, 10), 0.01342370267957449), ((2, 12), 0.013360649347305298), ((5, 14), 0.01300650555640459), ((5, 12), 0.012994132936000824), ((6, 13), 0.012620479799807072), ((3, 5), 0.012609525273243586), ((1, 13), 0.01255657027165095), ((2, 5), 0.012068086614211401), ((0, 13), 0.012053906917572021), ((8, 13), 0.01174225565046072), ((10, 12), 0.011570400558412075), ((5, 6), 0.011263696476817131), ((12, 14), 0.01103583350777626), ((4, 5), 0.010856403658787409), ((4, 12), 0.010817264517148336), ((5, 8), 0.010701851919293404), ((13, 16), 0.010601385496556759), ((1, 5), 0.010186099136869112), ((1, 12), 0.010002689436078072), ((0, 5), 0.009836124877134958), ((13, 17), 0.009490936994552612), ((5, 16), 0.00923432968556881), ((5, 17), 0.009143552742898464), ((0, 12), 0.008770518625775972), ((12, 13), 0.008153139613568783), ((13, 18), 0.008084946312010288), ((5, 18), 0.007910694926977158), ((8, 12), 0.00734596885740757), ((6, 12), 0.0062681022100150585), ((12, 16), 0.005671619437634945), ((12, 17), 0.005510916467756033), ((12, 18), 0.003835954936221242)]
******* after merging (0.04): [((10, 14), 64), ((7, 9), 64), ((0,), 64), ((1,), 64), ((2,), 64), ((3,), 64), ((4,), 64), ((5,), 32), ((6,), 32), ((8,), 32), ((11,), 32), ((12,), 32), ((13,), 32), ((15,), 32), ((16,), 32), ((17,), 32), ((18,), 32)]
{'R_grad_norm': 0.9959293848276138, 'training_loss': 2.276299694776535}
{'R_grad_norm': 0.9913443249464035, 'training_loss': 2.2731821286678313}
{'R_grad_norm': 0.9906496515870095, 'training_loss': 2.270626286864281}
{'R_grad_norm': 0.9907316344976426, 'training_loss': 2.264730041027069}
{'R_grad_norm': 0.9897299635410309, 'training_loss': 2.272553185224533}
{'R_grad_norm': 0.990357229411602, 'training_loss': 2.272220922112465}
{'R_grad_norm': 0.9923832142353057, 'training_loss': 2.2770352363586426}
{'R_grad_norm': 0.9889309972524643, 'training_loss': 2.2657472920417785}
{'R_grad_norm': 0.987484423816204, 'training_loss': 2.269999783039093}
{'R_grad_norm': 0.9903220808506012, 'training_loss': 2.2702379810810087}
{'R_grad_norm': 0.9886703950166702, 'training_loss': 2.2692705011367797}
{'R_grad_norm': 0.9859754687547684, 'training_loss': 2.260607419013977}
{'R_grad_norm': 0.9855400523543358, 'training_loss': 2.2529820585250855}
{'R_grad_norm': 0.9870999518036843, 'training_loss': 2.2645745313167573}
{'R_grad_norm': 0.986300998032093, 'training_loss': 2.264064804315567}
{'R_grad_norm': 0.987336254119873, 'training_loss': 2.2720263147354127}
{'R_grad_norm': 0.9882739770412445, 'training_loss': 2.2712069225311278}
{'R_grad_norm': 0.9839071118831635, 'training_loss': 2.2570634561777116}
{'R_grad_norm': 0.9845731800794602, 'training_loss': 2.2555789303779603}
{'R_grad_norm': 0.9863303163647652, 'training_loss': 2.261157249212265}
{'R_grad_norm': 0.9827488255500794, 'training_loss': 2.2592075496912}
{'R_grad_norm': 0.9850583708286286, 'training_loss': 2.264964904785156}
{'R_grad_norm': 0.9813124519586564, 'training_loss': 2.255920181274414}
{'R_grad_norm': 0.9831934529542923, 'training_loss': 2.25229150891304}
{'R_grad_norm': 0.9860490289330482, 'training_loss': 2.2567892622947694}
{'R_grad_norm': 0.9844080540537834, 'training_loss': 2.275161283016205}
{'R_grad_norm': 0.9835645392537117, 'training_loss': 2.2608560729026794}
{'R_grad_norm': 0.9816245687007904, 'training_loss': 2.261417561173439}
{'R_grad_norm': 0.9824515655636787, 'training_loss': 2.26400247335434}
{'R_grad_norm': 0.9820273733139038, 'training_loss': 2.2529892534017564}
{'R_grad_norm': 0.9796288830041885, 'training_loss': 2.2562292182445525}
{'R_grad_norm': 0.9828424701094627, 'training_loss': 2.2531631779670716}
{'R_grad_norm': 0.9809788548946381, 'training_loss': 2.2512857735157015}
{'R_grad_norm': 0.984265299141407, 'training_loss': 2.265756014585495}
{'R_grad_norm': 0.9819505056738853, 'training_loss': 2.259637578725815}
{'R_grad_norm': 0.982304180264473, 'training_loss': 2.2622177147865297}
{'R_grad_norm': 0.9787612241506577, 'training_loss': 2.256825295686722}
{'R_grad_norm': 0.9785663110017776, 'training_loss': 2.255936158299446}
{'R_grad_norm': 0.9770061767101288, 'training_loss': 2.236942985057831}
{'R_grad_norm': 0.9827275368571281, 'training_loss': 2.2589082419872284}
eval result tensor([2.85874, 2.05769, 2.31675, 2.63654, 2.53024, 2.66025, 3.46038, 2.16407,
        2.19251, 1.76160, 1.84517, 1.43577, 2.31334, 1.33981, 1.98556, 2.26075,
        2.11336], device='cuda:0')
computing merge metric
normed mi [((10, 13), 0.08520261943340302), ((9, 13), 0.08490505069494247), ((1, 13), 0.07994598646958669), ((4, 13), 0.07958200077215831), ((6, 13), 0.0795636922121048), ((5, 13), 0.07948956390221913), ((14, 15), 0.07930736243724823), ((0, 9), 0.07567018767197926), ((3, 13), 0.0752884844938914), ((2, 9), 0.07487702369689941), ((4, 5), 0.07478255033493042), ((2, 13), 0.07384975751241048), ((15, 16), 0.07272403687238693), ((4, 6), 0.07207335531711578), ((5, 6), 0.0719713643193245), ((3, 9), 0.07180161774158478), ((8, 14), 0.07096762210130692), ((1, 5), 0.07073717564344406), ((1, 6), 0.07041158527135849), ((1, 4), 0.07019088417291641), ((6, 9), 0.06962990760803223), ((2, 3), 0.06909170001745224), ((9, 10), 0.06854648888111115), ((2, 4), 0.06814878433942795), ((4, 9), 0.06787192324797313), ((5, 9), 0.06754724184672038), ((2, 5), 0.06748021394014359), ((2, 6), 0.06747020781040192), ((3, 6), 0.06711157411336899), ((1, 10), 0.06707723935445149), ((5, 10), 0.06687416136264801), ((4, 10), 0.06646791100502014), ((3, 4), 0.06645146757364273), ((3, 5), 0.06636706739664078), ((9, 14), 0.06629324704408646), ((1, 9), 0.06589785714944203), ((1, 3), 0.06567350029945374), ((8, 15), 0.06518498808145523), ((6, 10), 0.06517685949802399), ((0, 13), 0.06462667882442474), ((0, 2), 0.06459904462099075), ((9, 15), 0.0643143430352211), ((1, 2), 0.06384433805942535), ((8, 9), 0.06338686496019363), ((0, 3), 0.06333786249160767), ((14, 16), 0.06277131289243698), ((3, 10), 0.06182067096233368), ((0, 6), 0.059940822422504425), ((0, 4), 0.0587068609893322), ((2, 10), 0.058414801955223083), ((0, 5), 0.058202505111694336), ((13, 14), 0.057844843715429306), ((9, 16), 0.05707836151123047), ((8, 10), 0.05691901594400406), ((3, 15), 0.05644385516643524), ((10, 14), 0.05632521212100983), ((0, 1), 0.05621877685189247), ((3, 14), 0.05571844677130381), ((10, 15), 0.055693916976451874), ((8, 13), 0.05454517900943756), ((13, 15), 0.05445900931954384), ((0, 10), 0.05173647403717041), ((2, 14), 0.051182880997657776), ((0, 14), 0.05106550951798757), ((3, 8), 0.0504911740620931), ((2, 15), 0.05005259315172831), ((0, 15), 0.050013879934946694), ((0, 8), 0.04797866940498352), ((2, 8), 0.047548492749532066), ((13, 16), 0.046408168971538544), ((8, 16), 0.046104252338409424), ((0, 16), 0.045182451605796814), ((6, 14), 0.04517640173435211), ((4, 14), 0.045168121655782066), ((6, 15), 0.04516060650348663), ((4, 15), 0.04514061411221822), ((5, 15), 0.04504022002220154), ((5, 14), 0.0447008361419042), ((1, 14), 0.044583141803741455), ((3, 16), 0.04430776337782542), ((1, 15), 0.04422413309415182), ((6, 8), 0.043843746185302734), ((2, 16), 0.043483421206474304), ((1, 8), 0.04309193789958954), ((4, 8), 0.04272786279519399), ((5, 8), 0.04229967792828878), ((10, 16), 0.039609041064977646), ((7, 12), 0.03898078575730324), ((5, 16), 0.03892502933740616), ((4, 16), 0.03877988706032435), ((6, 16), 0.0383742426832517), ((1, 16), 0.037106638153394066), ((10, 12), 0.02043599635362625), ((10, 11), 0.01977650634944439), ((12, 13), 0.01905706524848938), ((7, 10), 0.017205221578478813), ((7, 13), 0.015285905450582504), ((5, 12), 0.015094569573799769), ((1, 12), 0.01501547172665596), ((6, 12), 0.014892251541217169), ((4, 12), 0.014816739906867346), ((11, 13), 0.013827469199895859), ((7, 11), 0.013714330270886421), ((5, 11), 0.012417939802010855), ((1, 11), 0.012052353471517563), ((4, 11), 0.011878705273071924), ((3, 12), 0.011735867708921432), ((6, 11), 0.011459598938624064), ((9, 12), 0.011410766281187534), ((2, 12), 0.010807729015747706), ((8, 12), 0.010789847932755947), ((1, 7), 0.010584143300851187), ((5, 7), 0.010515312353769938), ((4, 7), 0.010334742565949758), ((6, 7), 0.010249731441338858), ((12, 14), 0.009908080101013184), ((7, 9), 0.009307107888162136), ((0, 12), 0.00925244390964508), ((12, 15), 0.009245987050235271), ((7, 8), 0.008626622147858143), ((3, 7), 0.008501019949714342), ((7, 14), 0.008238323032855988), ((3, 11), 0.008002079402407011), ((2, 7), 0.00789187972744306), ((7, 15), 0.007784209679812193), ((12, 16), 0.00764069240540266), ((7, 16), 0.00754033587872982), ((11, 12), 0.00736975995823741), ((0, 7), 0.007153862466414769), ((2, 11), 0.006583788121740024), ((9, 11), 0.005554212722927332), ((0, 11), 0.004704582504928112), ((8, 11), 0.004637653008103371), ((11, 15), 0.004627594258636236), ((11, 14), 0.004449849016964436), ((11, 16), 0.0034054017160087824)]
******* after merging (0.04): [((10, 13), 64), ((14, 15), 64), ((0,), 64), ((1,), 64), ((2,), 64), ((3,), 64), ((4,), 64), ((5,), 64), ((6,), 64), ((7,), 32), ((8,), 32), ((9,), 32), ((11,), 32), ((12,), 32), ((16,), 32)]
{'R_grad_norm': 1.0482530134916306, 'training_loss': 2.480624223947525}
{'R_grad_norm': 1.0474236378073691, 'training_loss': 2.4773654651641848}
{'R_grad_norm': 1.044718599319458, 'training_loss': 2.468261728286743}
{'R_grad_norm': 1.042478742301464, 'training_loss': 2.467830857038498}
{'R_grad_norm': 1.0440343448519707, 'training_loss': 2.463659371137619}
{'R_grad_norm': 1.0474010035395622, 'training_loss': 2.4809619772434233}
{'R_grad_norm': 1.0437362751364707, 'training_loss': 2.4749940633773804}
{'R_grad_norm': 1.0410953971743584, 'training_loss': 2.4568398785591126}
{'R_grad_norm': 1.040252977013588, 'training_loss': 2.4648662996292114}
{'R_grad_norm': 1.0415934336185455, 'training_loss': 2.4718995261192322}
{'R_grad_norm': 1.0441838201880456, 'training_loss': 2.4776796650886537}
{'R_grad_norm': 1.0407849535346032, 'training_loss': 2.4607848834991457}
{'R_grad_norm': 1.0436977142095565, 'training_loss': 2.4755172502994536}
{'R_grad_norm': 1.0377335062623023, 'training_loss': 2.4658740019798278}
{'R_grad_norm': 1.0410641705989838, 'training_loss': 2.4509401416778562}
{'R_grad_norm': 1.0410154956579207, 'training_loss': 2.4673711824417115}
{'R_grad_norm': 1.0381878232955932, 'training_loss': 2.4526423871517182}
{'R_grad_norm': 1.039974405169487, 'training_loss': 2.4664337396621705}
{'R_grad_norm': 1.0375298750400543, 'training_loss': 2.453322446346283}
{'R_grad_norm': 1.0421292424201964, 'training_loss': 2.4640363883972167}
{'R_grad_norm': 1.036356547474861, 'training_loss': 2.4605858504772185}
{'R_grad_norm': 1.04099823564291, 'training_loss': 2.46462691783905}
{'R_grad_norm': 1.0410663267970086, 'training_loss': 2.4730919396877287}
{'R_grad_norm': 1.0383252954483033, 'training_loss': 2.470752556324005}
{'R_grad_norm': 1.0386416071653366, 'training_loss': 2.4647857296466826}
{'R_grad_norm': 1.0384278547763826, 'training_loss': 2.4669721376895906}
{'R_grad_norm': 1.0384422871470451, 'training_loss': 2.4721436381340025}
{'R_grad_norm': 1.0347102770209313, 'training_loss': 2.4675139021873473}
{'R_grad_norm': 1.0366376814246179, 'training_loss': 2.4644398927688598}
{'R_grad_norm': 1.0352023494243623, 'training_loss': 2.4565575027465822}
{'R_grad_norm': 1.0367563155293464, 'training_loss': 2.4583077216148377}
{'R_grad_norm': 1.036075516939163, 'training_loss': 2.466983689069748}
{'R_grad_norm': 1.0372960022091866, 'training_loss': 2.4637150740623475}
{'R_grad_norm': 1.035577919781208, 'training_loss': 2.463678069114685}
{'R_grad_norm': 1.0343477749824523, 'training_loss': 2.4526812613010405}
{'R_grad_norm': 1.0348683068156241, 'training_loss': 2.4565925967693327}
{'R_grad_norm': 1.0341995623707771, 'training_loss': 2.4553214144706725}
{'R_grad_norm': 1.034502259492874, 'training_loss': 2.459889978170395}
{'R_grad_norm': 1.0358908146619796, 'training_loss': 2.479089844226837}
{'R_grad_norm': 1.033127454519272, 'training_loss': 2.455256028175354}
eval result tensor([2.82164, 3.69682, 3.01144, 2.06702, 2.31113, 2.66291, 2.54387, 2.65972,
        3.47125, 2.15658, 2.15825, 1.70069, 1.39050, 2.26067, 2.06933],
       device='cuda:0')
computing merge metric
normed mi [((4, 11), 0.07547624409198761), ((6, 7), 0.07460392266511917), ((2, 11), 0.07367093861103058), ((5, 11), 0.0721930315097173), ((6, 8), 0.07166056334972382), ((7, 8), 0.07155168801546097), ((8, 11), 0.07091230650742848), ((3, 7), 0.07083841413259506), ((3, 6), 0.07072489708662033), ((3, 8), 0.07067360728979111), ((3, 11), 0.06946082909901936), ((7, 11), 0.06922906637191772), ((6, 11), 0.06908683478832245), ((4, 5), 0.06892956793308258), ((3, 5), 0.06685850769281387), ((4, 7), 0.06663616746664047), ((4, 6), 0.06651852279901505), ((5, 8), 0.06636064499616623), ((5, 7), 0.06617772579193115), ((4, 8), 0.06571665406227112), ((5, 6), 0.06568409502506256), ((3, 4), 0.06491219997406006), ((2, 4), 0.06358849257230759), ((2, 5), 0.061403095722198486), ((10, 11), 0.06079336628317833), ((0, 11), 0.05768019457658132), ((0, 3), 0.05691268667578697), ((2, 8), 0.05679677426815033), ((0, 6), 0.056617531925439835), ((0, 7), 0.05661389231681824), ((2, 7), 0.05655752867460251), ((2, 6), 0.056439466774463654), ((0, 8), 0.05643489211797714), ((2, 3), 0.05614020675420761), ((0, 5), 0.05570518970489502), ((11, 14), 0.05384226143360138), ((0, 4), 0.053213171660900116), ((1, 14), 0.05211831132570902), ((5, 10), 0.050086647272109985), ((1, 10), 0.04948038856188456), ((4, 10), 0.04697856307029724), ((0, 2), 0.046880047768354416), ((1, 5), 0.046623595058918), ((2, 10), 0.04652821024258932), ((1, 11), 0.04597741365432739), ((2, 14), 0.044081797202428184), ((3, 10), 0.04367645084857941), ((5, 14), 0.04348943134148916), ((4, 14), 0.04343147575855255), ((10, 14), 0.04338369891047478), ((8, 10), 0.04321439564228058), ((0, 10), 0.04308559000492096), ((6, 10), 0.04247306287288666), ((7, 10), 0.0424241175254186), ((1, 2), 0.0421023927628994), ((1, 4), 0.04148180037736893), ((9, 13), 0.03872847184538841), ((7, 14), 0.0385992576678594), ((6, 14), 0.037993873159090676), ((3, 14), 0.03745209922393163), ((1, 3), 0.03641268238425255), ((1, 7), 0.036111921072006226), ((1, 6), 0.036058325320482254), ((8, 14), 0.036027478675047554), ((0, 1), 0.03573193773627281), ((1, 8), 0.034477896988391876), ((0, 14), 0.031601774195830025), ((8, 13), 0.013508257766564688), ((7, 13), 0.01345385859409968), ((6, 13), 0.013395016392072042), ((9, 12), 0.012708649039268494), ((3, 13), 0.012678710122903189), ((7, 12), 0.011860345800717672), ((6, 12), 0.011725291609764099), ((8, 12), 0.011483274400234222), ((0, 13), 0.010760586708784103), ((3, 12), 0.010743095229069391), ((11, 13), 0.010372665710747242), ((0, 9), 0.010269597172737122), ((5, 13), 0.010220057020584742), ((6, 9), 0.010196706900993982), ((7, 9), 0.010047067577640215), ((8, 9), 0.010042343909541765), ((10, 13), 0.00991484522819519), ((3, 9), 0.009735706572731337), ((4, 13), 0.009219803536931673), ((9, 11), 0.00918969139456749), ((9, 10), 0.008822492323815823), ((0, 12), 0.008572054406007132), ((5, 9), 0.007991542418797811), ((5, 12), 0.007858760034044584), ((12, 13), 0.007435316685587168), ((2, 13), 0.007432945693532626), ((4, 9), 0.0072370537867148714), ((9, 14), 0.006929847411811352), ((2, 9), 0.006700648615757625), ((13, 14), 0.006462148390710354), ((4, 12), 0.006288375084598859), ((11, 12), 0.006286954507231712), ((1, 13), 0.0051357438787817955), ((1, 9), 0.005030956429739793), ((10, 12), 0.004978134296834469), ((2, 12), 0.004082130578656991), ((12, 14), 0.0026958000380545855), ((1, 12), 0.0025698067620396614)]
******* after merging (0.04): [((4, 11), 96), ((0,), 64), ((1,), 64), ((2,), 64), ((3,), 64), ((5,), 64), ((6,), 64), ((7,), 64), ((8,), 64), ((9,), 32), ((10,), 32), ((12,), 32), ((13,), 32), ((14,), 32)]
{'R_grad_norm': 1.0894250839948654, 'training_loss': 2.5661058843135836}
{'R_grad_norm': 1.085501019358635, 'training_loss': 2.57140589594841}
{'R_grad_norm': 1.0826433670520783, 'training_loss': 2.5663342905044555}
{'R_grad_norm': 1.0830908197164535, 'training_loss': 2.571974662542343}
{'R_grad_norm': 1.0796239918470383, 'training_loss': 2.5585024511814116}
{'R_grad_norm': 1.0813377553224564, 'training_loss': 2.5638277339935303}
{'R_grad_norm': 1.0825743716955185, 'training_loss': 2.5593847501277924}
{'R_grad_norm': 1.0805636948347093, 'training_loss': 2.559646838903427}
{'R_grad_norm': 1.0771878731250764, 'training_loss': 2.5645949459075927}
{'R_grad_norm': 1.0776213186979293, 'training_loss': 2.564884605407715}
{'R_grad_norm': 1.0768882817029952, 'training_loss': 2.554417028427124}
{'R_grad_norm': 1.0776801699399947, 'training_loss': 2.5593916046619416}
{'R_grad_norm': 1.0789681285619737, 'training_loss': 2.562206372022629}
{'R_grad_norm': 1.078636456131935, 'training_loss': 2.567580009698868}
{'R_grad_norm': 1.0798858651518821, 'training_loss': 2.582784423828125}
{'R_grad_norm': 1.0741022890806198, 'training_loss': 2.558154398202896}
{'R_grad_norm': 1.0760056829452516, 'training_loss': 2.5525089383125303}
{'R_grad_norm': 1.0758978712558747, 'training_loss': 2.5616776192188264}
{'R_grad_norm': 1.0744689917564392, 'training_loss': 2.565909501314163}
{'R_grad_norm': 1.0772814005613327, 'training_loss': 2.5688601195812226}
{'R_grad_norm': 1.0739763623476029, 'training_loss': 2.5556956934928894}
{'R_grad_norm': 1.075283635854721, 'training_loss': 2.552782027721405}
{'R_grad_norm': 1.075158475637436, 'training_loss': 2.559855215549469}
{'R_grad_norm': 1.073508579134941, 'training_loss': 2.5513334929943086}
{'R_grad_norm': 1.071936899125576, 'training_loss': 2.552835940122604}
{'R_grad_norm': 1.0751976943016053, 'training_loss': 2.570187269449234}
{'R_grad_norm': 1.070753542780876, 'training_loss': 2.5527590036392214}
{'R_grad_norm': 1.070970972776413, 'training_loss': 2.5658406162261964}
{'R_grad_norm': 1.0692064660787581, 'training_loss': 2.555850377082825}
{'R_grad_norm': 1.0708694329857826, 'training_loss': 2.561830475330353}
{'R_grad_norm': 1.0700661396980287, 'training_loss': 2.545903277397156}
{'R_grad_norm': 1.0720839482545852, 'training_loss': 2.5707228779792786}
{'R_grad_norm': 1.0728544121980668, 'training_loss': 2.560640861988068}
{'R_grad_norm': 1.0708585643768311, 'training_loss': 2.5631998455524445}
{'R_grad_norm': 1.0714511787891388, 'training_loss': 2.5552953624725343}
{'R_grad_norm': 1.0687041759490967, 'training_loss': 2.5463693070411684}
{'R_grad_norm': 1.070955906510353, 'training_loss': 2.544146499633789}
{'R_grad_norm': 1.0698613601922988, 'training_loss': 2.5380736792087557}
{'R_grad_norm': 1.0659345501661301, 'training_loss': 2.5333264517784118}
{'R_grad_norm': 1.0688140007853508, 'training_loss': 2.557142872810364}
eval result tensor([3.54430, 2.80832, 3.69758, 3.06540, 2.01881, 2.58170, 2.47964, 2.57633,
        3.41323, 2.13976, 2.14813, 1.35299, 2.20142, 2.07576], device='cuda:0')
computing merge metric
normed mi [((6, 7), 0.0747399851679802), ((4, 7), 0.07051806896924973), ((4, 6), 0.07032977789640427), ((7, 8), 0.06984888017177582), ((6, 8), 0.06982223689556122), ((4, 8), 0.06850328296422958), ((5, 8), 0.06763417273759842), ((4, 5), 0.0665479525923729), ((5, 7), 0.06484662741422653), ((5, 6), 0.0643569827079773), ((3, 5), 0.05991595238447189), ((3, 8), 0.059134844690561295), ((1, 4), 0.0560297891497612), ((1, 5), 0.0557025671005249), ((1, 6), 0.0555139034986496), ((1, 7), 0.055408768355846405), ((1, 8), 0.05525211989879608), ((3, 7), 0.05378969386219978), ((3, 6), 0.053784873336553574), ((3, 4), 0.053697533905506134), ((0, 8), 0.05211291909217834), ((2, 13), 0.05188210308551788), ((0, 5), 0.0518207848072052), ((0, 3), 0.05133747458457947), ((0, 7), 0.04835031032562256), ((0, 6), 0.04824768602848053), ((2, 10), 0.04818051060040792), ((5, 10), 0.047367483377456665), ((0, 4), 0.047270733118057254), ((1, 3), 0.04609989374876022), ((2, 5), 0.045902449637651443), ((3, 10), 0.044899885853131614), ((8, 10), 0.04224608838558197), ((2, 3), 0.04200587049126625), ((3, 13), 0.041670799255371094), ((5, 13), 0.04115660488605499), ((1, 10), 0.04111922780672709), ((10, 13), 0.041057098656892776), ((4, 10), 0.04074099659919739), ((0, 1), 0.039618784189224245), ((6, 10), 0.039260029792785645), ((9, 12), 0.03913925215601921), ((7, 10), 0.03896794468164444), ((8, 13), 0.037293121218681335), ((2, 8), 0.036071304231882095), ((7, 13), 0.036056029299894966), ((6, 13), 0.03561883419752121), ((4, 13), 0.035371060172716774), ((1, 2), 0.03524153307080269), ((2, 4), 0.0351153202354908), ((2, 7), 0.03456135839223862), ((2, 6), 0.03454958647489548), ((0, 2), 0.03447013795375824), ((0, 10), 0.0342070534825325), ((0, 13), 0.03268900886178017), ((1, 13), 0.03001674513022105), ((7, 11), 0.014398048321406046), ((6, 11), 0.014143355190753937), ((6, 12), 0.01393116886417071), ((7, 12), 0.013897037754456202), ((9, 11), 0.012915501371026039), ((4, 12), 0.012832430501778921), ((4, 11), 0.012728488693634668), ((8, 12), 0.011659212410449982), ((8, 11), 0.011322621256113052), ((7, 9), 0.010778993368148804), ((1, 12), 0.010695723195870718), ((6, 9), 0.010623764246702194), ((5, 12), 0.010425835847854614), ((1, 9), 0.010259592284758886), ((4, 9), 0.00990083689490954), ((5, 11), 0.009742146357893944), ((1, 11), 0.009618104745944342), ((10, 12), 0.009587362408638), ((8, 9), 0.00925085631509622), ((9, 10), 0.008606250397861004), ((5, 9), 0.008235153431693712), ((11, 12), 0.00790038239210844), ((3, 12), 0.0072342536101738615), ((3, 9), 0.006768324101964633), ((9, 13), 0.006296386942267418), ((12, 13), 0.006041455082595348), ((10, 11), 0.005567304324358702), ((0, 12), 0.005249804351478815), ((3, 11), 0.005241880193352699), ((2, 12), 0.004865918308496475), ((2, 9), 0.004832981464763482), ((0, 9), 0.004645540378987789), ((0, 11), 0.004262885544449091), ((11, 13), 0.00297790439799428), ((2, 11), 0.0028115188082059226)]
******* after merging (0.04): [((6, 7), 128), ((0,), 96), ((1,), 64), ((2,), 64), ((3,), 64), ((4,), 64), ((5,), 64), ((8,), 64), ((9,), 32), ((10,), 32), ((11,), 32), ((12,), 32), ((13,), 32)]
{'R_grad_norm': 1.1412647807598113, 'training_loss': 2.663439748287201}
{'R_grad_norm': 1.135411216020584, 'training_loss': 2.6454924547672274}
{'R_grad_norm': 1.1304287207126618, 'training_loss': 2.6319535624980928}
{'R_grad_norm': 1.1339362579584122, 'training_loss': 2.641226487159729}
{'R_grad_norm': 1.1338744181394578, 'training_loss': 2.6590032613277437}
{'R_grad_norm': 1.1334042263031006, 'training_loss': 2.644572149515152}
{'R_grad_norm': 1.1280729418992996, 'training_loss': 2.642166082859039}
{'R_grad_norm': 1.1288551878929138, 'training_loss': 2.636708003282547}
{'R_grad_norm': 1.1320900911092757, 'training_loss': 2.6486396312713625}
{'R_grad_norm': 1.1342811840772629, 'training_loss': 2.6539796984195707}
{'R_grad_norm': 1.1352157628536224, 'training_loss': 2.6633900272846223}
{'R_grad_norm': 1.1403249144554137, 'training_loss': 2.694773555994034}
{'R_grad_norm': 1.1407034087181092, 'training_loss': 2.6836134219169616}
{'R_grad_norm': 1.140157236456871, 'training_loss': 2.702813903093338}
{'R_grad_norm': 1.1429104679822921, 'training_loss': 2.713954714536667}
{'R_grad_norm': 1.146302586197853, 'training_loss': 2.716744058132172}
{'R_grad_norm': 1.1446363484859468, 'training_loss': 2.7300280427932737}
{'R_grad_norm': 1.152533752322197, 'training_loss': 2.7523826611042024}
{'R_grad_norm': 1.1503469508886337, 'training_loss': 2.7606161785125733}
{'R_grad_norm': 1.154684481024742, 'training_loss': 2.773964009284973}
{'R_grad_norm': 1.1615768891572953, 'training_loss': 2.8123457741737368}
{'R_grad_norm': 1.1616648721694947, 'training_loss': 2.830428360700607}
{'R_grad_norm': 1.1669810807704926, 'training_loss': 2.8776907885074614}
{'R_grad_norm': 1.1311103439331054, 'training_loss': 2.6948747968673707}
{'R_grad_norm': 1.1269244349002838, 'training_loss': 2.6629033493995666}
{'R_grad_norm': 1.1221126800775527, 'training_loss': 2.647704207897186}
{'R_grad_norm': 1.1226538223028184, 'training_loss': 2.6405352652072906}
{'R_grad_norm': 1.1249169677495956, 'training_loss': 2.6506829380989076}
{'R_grad_norm': 1.1228193593025209, 'training_loss': 2.655463823080063}
{'R_grad_norm': 1.1238416504859925, 'training_loss': 2.652124593257904}
{'R_grad_norm': 1.122884613275528, 'training_loss': 2.6550183963775633}
{'R_grad_norm': 1.121925095319748, 'training_loss': 2.652824100255966}
{'R_grad_norm': 1.1196132588386536, 'training_loss': 2.6436807036399843}
{'R_grad_norm': 1.1182127237319945, 'training_loss': 2.6454939186573028}
{'R_grad_norm': 1.120992294549942, 'training_loss': 2.6564229273796083}
{'R_grad_norm': 1.1220043003559113, 'training_loss': 2.657065614461899}
{'R_grad_norm': 1.1172429651021958, 'training_loss': 2.640624346733093}
{'R_grad_norm': 1.1185768270492553, 'training_loss': 2.643752008676529}
{'R_grad_norm': 1.1220171850919725, 'training_loss': 2.646078336238861}
{'R_grad_norm': 1.1200652915239333, 'training_loss': 2.654277307987213}
eval result tensor([4.22488, 3.55118, 2.79667, 3.68810, 3.12796, 1.96388, 2.45336, 2.89680,
        2.13094, 2.11243, 1.34325, 2.16909, 2.07588], device='cuda:0')
computing merge metric
normed mi [((6, 7), 0.06694816052913666), ((5, 6), 0.06567566841840744), ((5, 7), 0.06215661019086838), ((4, 7), 0.06189130246639252), ((4, 6), 0.058321889489889145), ((2, 6), 0.055666182190179825), ((1, 7), 0.05530721545219421), ((2, 5), 0.05510178580880165), ((2, 7), 0.05215154215693474), ((1, 6), 0.05185479521751404), ((3, 12), 0.05152416229248047), ((4, 5), 0.05137709528207779), ((1, 4), 0.05060997009277344), ((0, 5), 0.04785935084025065), ((3, 9), 0.04718539118766785), ((1, 5), 0.046156668663024904), ((2, 4), 0.04532318189740181), ((3, 6), 0.04527978226542473), ((6, 9), 0.04500614106655121), ((0, 7), 0.044951299826304116), ((0, 6), 0.04460514088471731), ((4, 9), 0.043334200978279114), ((7, 9), 0.041605557004610695), ((3, 4), 0.041603587567806244), ((4, 12), 0.04159470399220785), ((6, 12), 0.041377889613310494), ((7, 12), 0.04107231646776199), ((9, 12), 0.04038945958018303), ((8, 11), 0.040231335908174515), ((2, 9), 0.039759330451488495), ((1, 2), 0.0392859935760498), ((3, 7), 0.03896058350801468), ((5, 9), 0.038483694195747375), ((0, 2), 0.037979669868946075), ((0, 4), 0.03577912598848343), ((2, 3), 0.03512688726186752), ((0, 1), 0.03465491959026882), ((1, 3), 0.034641772508621216), ((5, 12), 0.03463827073574066), ((3, 5), 0.033794838935136795), ((1, 9), 0.033335182815790176), ((1, 12), 0.03320690616965294), ((2, 12), 0.03047719846169154), ((0, 3), 0.023223184049129486), ((0, 9), 0.023122692108154298), ((0, 12), 0.022010451555252074), ((5, 10), 0.015921394030253094), ((8, 10), 0.013726052828133106), ((5, 11), 0.01305539533495903), ((6, 10), 0.012086628625790278), ((2, 10), 0.011498206605513891), ((2, 8), 0.01106147343913714), ((5, 8), 0.010862547904253006), ((7, 10), 0.010631668070952097), ((2, 11), 0.01053528736035029), ((6, 11), 0.010345900431275368), ((0, 10), 0.009864968061447144), ((9, 11), 0.009312823414802551), ((8, 9), 0.009285002015531063), ((7, 11), 0.00920800119638443), ((10, 11), 0.008977928198873997), ((6, 8), 0.0089203758786122), ((7, 8), 0.008659927795330683), ((0, 11), 0.008313044160604476), ((4, 8), 0.007116988922158877), ((0, 8), 0.007005602866411209), ((8, 12), 0.0068697514943778515), ((9, 10), 0.006827234290540218), ((4, 11), 0.006788117190202077), ((4, 10), 0.0065480489283800125), ((11, 12), 0.0063302284106612206), ((1, 10), 0.005466387141495943), ((3, 8), 0.005421300729115804), ((1, 11), 0.00504595972597599), ((1, 8), 0.004996152129024267), ((3, 11), 0.004724889372785886), ((10, 12), 0.003949917387217283), ((3, 10), 0.003820134016374747)]
******* after merging (0.04): [((6, 7), 128), ((0,), 128), ((1,), 96), ((2,), 64), ((3,), 64), ((4,), 64), ((5,), 64), ((8,), 32), ((9,), 32), ((10,), 32), ((11,), 32), ((12,), 32)]
{'R_grad_norm': 1.1991720801591874, 'training_loss': 2.750711590051651}
{'R_grad_norm': 1.1961896324157715, 'training_loss': 2.7614187729358672}
{'R_grad_norm': 1.192015311717987, 'training_loss': 2.7451361989974976}
{'R_grad_norm': 1.1948668789863586, 'training_loss': 2.756603260040283}
{'R_grad_norm': 1.1889756774902345, 'training_loss': 2.738024272918701}
{'R_grad_norm': 1.1896811199188233, 'training_loss': 2.749832351207733}
{'R_grad_norm': 1.184560642838478, 'training_loss': 2.7477053606510164}
{'R_grad_norm': 1.185358942747116, 'training_loss': 2.7498593485355376}
{'R_grad_norm': 1.1838034921884537, 'training_loss': 2.7497972571849822}
{'R_grad_norm': 1.1868681263923646, 'training_loss': 2.744510442018509}
{'R_grad_norm': 1.185825275182724, 'training_loss': 2.7497282791137696}
{'R_grad_norm': 1.1816979104280472, 'training_loss': 2.747184227705002}
{'R_grad_norm': 1.184091984629631, 'training_loss': 2.7389172995090485}
{'R_grad_norm': 1.1838075762987137, 'training_loss': 2.7604665720462798}
{'R_grad_norm': 1.1829284077882767, 'training_loss': 2.753176279067993}
{'R_grad_norm': 1.1775805032253266, 'training_loss': 2.7439929103851317}
{'R_grad_norm': 1.1783272075653075, 'training_loss': 2.7281382238864897}
{'R_grad_norm': 1.1800706160068513, 'training_loss': 2.7478417563438415}
{'R_grad_norm': 1.180584135055542, 'training_loss': 2.748759754896164}
{'R_grad_norm': 1.1819019836187363, 'training_loss': 2.7537820565700533}
{'R_grad_norm': 1.1747312617301942, 'training_loss': 2.730174117088318}
{'R_grad_norm': 1.1750364416837693, 'training_loss': 2.7355596375465394}
{'R_grad_norm': 1.178834810256958, 'training_loss': 2.7474220848083495}
{'R_grad_norm': 1.17711088180542, 'training_loss': 2.7430499172210694}
{'R_grad_norm': 1.175580787062645, 'training_loss': 2.7423980045318603}
{'R_grad_norm': 1.172496325969696, 'training_loss': 2.7305731952190397}
{'R_grad_norm': 1.176152680516243, 'training_loss': 2.7511658656597135}
{'R_grad_norm': 1.1740060973167419, 'training_loss': 2.739548488855362}
{'R_grad_norm': 1.1757947969436646, 'training_loss': 2.755585654973984}
{'R_grad_norm': 1.1715780663490296, 'training_loss': 2.731694608926773}
{'R_grad_norm': 1.1722705954313277, 'training_loss': 2.7404252064228056}
{'R_grad_norm': 1.1724833077192307, 'training_loss': 2.744576406478882}
{'R_grad_norm': 1.1704279267787934, 'training_loss': 2.7362365233898163}
{'R_grad_norm': 1.1733760648965836, 'training_loss': 2.747482419013977}
{'R_grad_norm': 1.168865711092949, 'training_loss': 2.7388823664188386}
{'R_grad_norm': 1.1745049804449081, 'training_loss': 2.754954125881195}
{'R_grad_norm': 1.1656804943084718, 'training_loss': 2.7223252308368684}
{'R_grad_norm': 1.170812459588051, 'training_loss': 2.7344684696197508}
{'R_grad_norm': 1.1650248634815217, 'training_loss': 2.7412002313137056}
{'R_grad_norm': 1.1689970690011977, 'training_loss': 2.7340614449977876}
eval result tensor([4.85126, 3.99707, 3.20292, 2.72860, 3.60559, 3.03362, 1.93819, 2.10164,
        2.08392, 1.34850, 2.13285, 2.06920], device='cuda:0')
computing merge metric
normed mi [((3, 6), 0.055173128843307495), ((5, 6), 0.051555003970861435), ((4, 11), 0.050265555580457054), ((2, 5), 0.04876956045627594), ((2, 6), 0.04831622540950775), ((1, 6), 0.047519038120905556), ((4, 8), 0.04623123506704966), ((0, 6), 0.04482559363047282), ((3, 5), 0.044345807284116745), ((7, 10), 0.04216537997126579), ((5, 8), 0.041645566622416176), ((0, 5), 0.04110656678676605), ((4, 5), 0.040330611169338226), ((2, 3), 0.0401977002620697), ((0, 2), 0.04008721028055463), ((5, 11), 0.039647527039051056), ((3, 8), 0.039036830266316734), ((8, 11), 0.03878668323159218), ((6, 8), 0.03871795783440272), ((1, 3), 0.03756906340519587), ((0, 3), 0.03740587582190832), ((1, 2), 0.03581312724522182), ((1, 5), 0.035301677882671356), ((3, 4), 0.03529142215847969), ((4, 6), 0.034668728709220886), ((6, 11), 0.03446246683597565), ((0, 1), 0.03423943370580673), ((2, 4), 0.03397347629070282), ((2, 8), 0.03266344591975212), ((2, 11), 0.03139742836356163), ((0, 4), 0.029528597990671795), ((3, 11), 0.02950851370890935), ((0, 8), 0.02727419137954712), ((0, 11), 0.025185871124267577), ((1, 4), 0.023404518763224285), ((1, 8), 0.0233494371175766), ((1, 11), 0.021427634358406066), ((7, 9), 0.012419817969202995), ((6, 9), 0.011447089413801828), ((6, 10), 0.01102728396654129), ((6, 7), 0.010048094515999159), ((3, 7), 0.010024939974149069), ((7, 8), 0.00881569366902113), ((3, 10), 0.00870215892791748), ((9, 10), 0.008448486216366291), ((3, 9), 0.008267417550086975), ((8, 10), 0.007664179429411888), ((1, 9), 0.007198706269264221), ((5, 7), 0.006753981113433838), ((1, 10), 0.0067419461905956265), ((7, 11), 0.0067035178653895855), ((1, 7), 0.0063478976488113405), ((5, 10), 0.0057854317128658295), ((10, 11), 0.0052330526523292065), ((0, 7), 0.005166404694318771), ((0, 10), 0.005092769488692283), ((4, 7), 0.005018182098865509), ((0, 9), 0.004946087300777435), ((2, 7), 0.004827728029340506), ((8, 9), 0.004712347872555256), ((2, 10), 0.004344157408922911), ((5, 9), 0.003940402530133724), ((4, 10), 0.0039006279160579047), ((2, 9), 0.0038777266163378954), ((9, 11), 0.002520942594856024), ((4, 9), 0.0023854835890233517)]
******* after merging (0.04): [((3, 6), 128), ((0,), 128), ((1,), 128), ((2,), 96), ((4,), 64), ((5,), 64), ((7,), 32), ((8,), 32), ((9,), 32), ((10,), 32), ((11,), 32)]
{'R_grad_norm': 1.2574301218986512, 'training_loss': 2.902827320098877}
{'R_grad_norm': 1.2574316900968552, 'training_loss': 2.9136962449550627}
{'R_grad_norm': 1.2524984937906265, 'training_loss': 2.9107738626003266}
{'R_grad_norm': 1.2522621083259582, 'training_loss': 2.8927871322631837}
{'R_grad_norm': 1.252486920952797, 'training_loss': 2.902764139175415}
{'R_grad_norm': 1.2500337427854538, 'training_loss': 2.9022760152816773}
{'R_grad_norm': 1.2482134532928466, 'training_loss': 2.9055614960193634}
{'R_grad_norm': 1.2504372221231461, 'training_loss': 2.8949943029880525}
{'R_grad_norm': 1.2432070463895797, 'training_loss': 2.893889670372009}
{'R_grad_norm': 1.2454900634288788, 'training_loss': 2.901328160762787}
{'R_grad_norm': 1.246451634168625, 'training_loss': 2.909015477895737}
{'R_grad_norm': 1.241627294421196, 'training_loss': 2.882532832622528}
{'R_grad_norm': 1.2405608093738556, 'training_loss': 2.8913621747493745}
{'R_grad_norm': 1.2429950988292695, 'training_loss': 2.917016160488129}
{'R_grad_norm': 1.2389163249731063, 'training_loss': 2.8894581055641173}
{'R_grad_norm': 1.2383109402656556, 'training_loss': 2.8909823155403136}
{'R_grad_norm': 1.237817867398262, 'training_loss': 2.8949996995925904}
{'R_grad_norm': 1.2397163659334183, 'training_loss': 2.89114311337471}
{'R_grad_norm': 1.2420843237638473, 'training_loss': 2.9122457015514374}
{'R_grad_norm': 1.2378865939378738, 'training_loss': 2.8920587301254272}
{'R_grad_norm': 1.2365299195051194, 'training_loss': 2.891367291212082}
{'R_grad_norm': 1.2377618259191514, 'training_loss': 2.898272330760956}
{'R_grad_norm': 1.2353377532958985, 'training_loss': 2.8928278172016144}
{'R_grad_norm': 1.2324419611692428, 'training_loss': 2.8912304627895353}
{'R_grad_norm': 1.2314403980970383, 'training_loss': 2.890772446393967}
{'R_grad_norm': 1.2331983453035356, 'training_loss': 2.9055248045921327}
{'R_grad_norm': 1.231289979815483, 'training_loss': 2.89106116771698}
{'R_grad_norm': 1.2351757484674453, 'training_loss': 2.907586089372635}
{'R_grad_norm': 1.230000032186508, 'training_loss': 2.8978936886787414}
{'R_grad_norm': 1.2315570521354675, 'training_loss': 2.8948127949237823}
{'R_grad_norm': 1.2274421298503875, 'training_loss': 2.8888481104373933}
{'R_grad_norm': 1.2301426243782043, 'training_loss': 2.8945948374271393}
{'R_grad_norm': 1.2263723212480544, 'training_loss': 2.8841467225551605}
{'R_grad_norm': 1.2289439517259597, 'training_loss': 2.8825014317035675}
{'R_grad_norm': 1.2229785984754562, 'training_loss': 2.8809921705722807}
{'R_grad_norm': 1.2260795122385024, 'training_loss': 2.888097964525223}
{'R_grad_norm': 1.221197366118431, 'training_loss': 2.8862808108329774}
{'R_grad_norm': 1.2233115470409393, 'training_loss': 2.8842824602127077}
{'R_grad_norm': 1.221877925992012, 'training_loss': 2.8911817860603333}
{'R_grad_norm': 1.225010295510292, 'training_loss': 2.905277034044266}
eval result tensor([3.78835, 5.02850, 3.81719, 2.87673, 3.52965, 2.88906, 2.09346, 2.02068,
        1.32547, 2.09307, 2.02209], device='cuda:0')
computing merge metric
normed mi [((4, 10), 0.05079469084739685), ((3, 5), 0.04706394970417023), ((4, 7), 0.044307311375935875), ((6, 9), 0.04367290437221527), ((1, 3), 0.04124736360141209), ((1, 5), 0.0410007710258166), ((5, 7), 0.04047679901123047), ((4, 5), 0.03981947898864746), ((5, 10), 0.03981039176384608), ((7, 10), 0.03865077719092369), ((2, 3), 0.037376382521220615), ((0, 3), 0.03626472183636257), ((0, 5), 0.03560773034890493), ((2, 5), 0.03512180348237356), ((1, 2), 0.03394819796085358), ((0, 1), 0.03369706869125366), ((3, 7), 0.03347590193152428), ((3, 4), 0.03307231366634369), ((0, 2), 0.03229554742574692), ((3, 10), 0.030725760385394096), ((1, 4), 0.02947637438774109), ((1, 7), 0.028038480877876283), ((0, 4), 0.026512178281943004), ((0, 7), 0.025867748260498046), ((1, 10), 0.025458014011383055), ((2, 7), 0.024446776509284972), ((2, 4), 0.023251940806706745), ((0, 10), 0.021906167268753052), ((2, 10), 0.021615739166736602), ((6, 8), 0.012708672322332859), ((6, 7), 0.010282355360686779), ((7, 9), 0.009769100695848465), ((8, 9), 0.008863679133355618), ((5, 6), 0.007050068428119023), ((2, 8), 0.007024691998958587), ((2, 9), 0.0069182485342025755), ((6, 10), 0.006896674633026123), ((2, 6), 0.0064986802637577055), ((5, 9), 0.006352152054508527), ((0, 6), 0.006121676787734032), ((9, 10), 0.005722159054130316), ((0, 9), 0.005692888051271439), ((7, 8), 0.00567966140806675), ((3, 6), 0.005325596779584885), ((1, 6), 0.005273117870092392), ((4, 6), 0.005248518039782842), ((3, 9), 0.005245698615908623), ((1, 9), 0.005171916261315346), ((1, 8), 0.00465448647737503), ((0, 8), 0.00453728623688221), ((3, 8), 0.004479687660932541), ((4, 9), 0.0041226887454589205), ((5, 8), 0.0037555210292339325), ((8, 10), 0.0024127562064677477), ((4, 8), 0.0022156511743863425)]
******* after merging (0.04): [((0,), 128), ((1,), 128), ((2,), 128), ((4, 10), 96), ((3,), 96), ((5,), 64), ((6,), 32), ((7,), 32), ((8,), 32), ((9,), 32)]
{'R_grad_norm': 1.302193602323532, 'training_loss': 3.0821821105480196}
{'R_grad_norm': 1.3003190457820892, 'training_loss': 3.0812322056293486}
{'R_grad_norm': 1.295602862238884, 'training_loss': 3.089492745399475}
{'R_grad_norm': 1.2963269335031509, 'training_loss': 3.076818735599518}
{'R_grad_norm': 1.292748086452484, 'training_loss': 3.0788646006584166}
{'R_grad_norm': 1.2943126052618026, 'training_loss': 3.0865482902526855}
{'R_grad_norm': 1.2878828114271164, 'training_loss': 3.0714708507061004}
{'R_grad_norm': 1.287464063167572, 'training_loss': 3.0716067349910734}
{'R_grad_norm': 1.2922464191913605, 'training_loss': 3.0756297981739045}
{'R_grad_norm': 1.286082354784012, 'training_loss': 3.074249266386032}
{'R_grad_norm': 1.2902077746391296, 'training_loss': 3.0969246661663057}
{'R_grad_norm': 1.2815774470567702, 'training_loss': 3.065080752372742}
{'R_grad_norm': 1.2816149252653122, 'training_loss': 3.0682454669475554}
{'R_grad_norm': 1.2783241403102874, 'training_loss': 3.065638678073883}
{'R_grad_norm': 1.2821575331687927, 'training_loss': 3.072518937587738}
{'R_grad_norm': 1.2798505538702012, 'training_loss': 3.074996523857117}
{'R_grad_norm': 1.278675176501274, 'training_loss': 3.0856557154655455}
{'R_grad_norm': 1.2734653550386428, 'training_loss': 3.0579486310482027}
{'R_grad_norm': 1.2749473714828492, 'training_loss': 3.0664795565605165}
{'R_grad_norm': 1.2757323312759399, 'training_loss': 3.0716233706474303}
{'R_grad_norm': 1.2770889073610305, 'training_loss': 3.078299347162247}
{'R_grad_norm': 1.2725577390193938, 'training_loss': 3.0550218546390533}
{'R_grad_norm': 1.2737568402290345, 'training_loss': 3.062163920402527}
{'R_grad_norm': 1.2729884606599808, 'training_loss': 3.0546404898166655}
{'R_grad_norm': 1.2692785251140595, 'training_loss': 3.0666721153259275}
{'R_grad_norm': 1.2707754516601562, 'training_loss': 3.075639098882675}
{'R_grad_norm': 1.2647178441286087, 'training_loss': 3.0528611719608305}
{'R_grad_norm': 1.2684518218040466, 'training_loss': 3.057128393650055}
{'R_grad_norm': 1.2667011004686355, 'training_loss': 3.061942754983902}
{'R_grad_norm': 1.2658522266149521, 'training_loss': 3.060019142627716}
{'R_grad_norm': 1.2674973678588868, 'training_loss': 3.0492325973510743}
{'R_grad_norm': 1.2672389674186706, 'training_loss': 3.0545483160018922}
{'R_grad_norm': 1.2629455095529556, 'training_loss': 3.0654327774047854}
{'R_grad_norm': 1.2613769817352294, 'training_loss': 3.0509148609638213}
{'R_grad_norm': 1.2693181186914444, 'training_loss': 3.0715401577949524}
{'R_grad_norm': 1.2625288599729538, 'training_loss': 3.058448917865753}
{'R_grad_norm': 1.261262727379799, 'training_loss': 3.0676561617851257}
{'R_grad_norm': 1.261825606226921, 'training_loss': 3.060113297700882}
{'R_grad_norm': 1.2638031899929048, 'training_loss': 3.0617122197151185}
{'R_grad_norm': 1.2626095187664033, 'training_loss': 3.060035203695297}
eval result tensor([3.69880, 5.19965, 3.97063, 4.78931, 2.79637, 2.85354, 2.10321, 2.04424,
        1.34004, 2.06723], device='cuda:0')
computing merge metric
normed mi [((4, 5), 0.04521285891532898), ((6, 9), 0.04290444403886795), ((1, 4), 0.04060899359839303), ((2, 4), 0.039136414016996114), ((1, 5), 0.03907559315363566), ((0, 4), 0.03845823662621634), ((0, 5), 0.03642344971497854), ((0, 1), 0.03582412004470825), ((1, 2), 0.03544849529862404), ((5, 7), 0.035208662350972496), ((2, 5), 0.035168275237083435), ((0, 2), 0.03330322727560997), ((4, 7), 0.031303923577070236), ((3, 5), 0.028793293237686157), ((1, 7), 0.027037277817726135), ((0, 7), 0.025748562812805176), ((2, 7), 0.02504832446575165), ((3, 4), 0.02401694655418396), ((3, 7), 0.022377053275704384), ((1, 3), 0.021217122673988342), ((0, 3), 0.020135756049837385), ((2, 3), 0.017873510718345642), ((7, 9), 0.015067469328641891), ((6, 7), 0.012574261985719204), ((6, 8), 0.012505311518907547), ((7, 8), 0.01018456555902958), ((8, 9), 0.008620724081993103), ((5, 9), 0.007311257844169934), ((2, 8), 0.007240855693817138), ((2, 9), 0.007225422561168671), ((5, 6), 0.006917196015516917), ((0, 9), 0.006392880529165268), ((4, 9), 0.006373667623847723), ((1, 9), 0.00624224878847599), ((1, 8), 0.006166995689272881), ((2, 6), 0.006159263476729393), ((4, 8), 0.00599255645647645), ((4, 6), 0.005744236521422863), ((0, 6), 0.005600007250905037), ((1, 6), 0.005484302714467049), ((0, 8), 0.005262503027915954), ((5, 8), 0.004547460315128167), ((3, 6), 0.003536128904670477), ((3, 9), 0.003224003594368696), ((3, 8), 0.00144246278796345)]
******* after merging (0.04): [((4, 5), 160), ((0,), 128), ((1,), 128), ((2,), 128), ((3,), 96), ((6,), 32), ((7,), 32), ((8,), 32), ((9,), 32)]
{'R_grad_norm': 1.3825745511054992, 'training_loss': 3.2673180496692655}
{'R_grad_norm': 1.3784582585096359, 'training_loss': 3.2448509168624877}
{'R_grad_norm': 1.3762315624952317, 'training_loss': 3.24373814702034}
{'R_grad_norm': 1.3683653980493546, 'training_loss': 3.230965019464493}
{'R_grad_norm': 1.37188894033432, 'training_loss': 3.249165964126587}
{'R_grad_norm': 1.366322736144066, 'training_loss': 3.2390938639640807}
{'R_grad_norm': 1.3674107217788696, 'training_loss': 3.243010904788971}
{'R_grad_norm': 1.3662129014730453, 'training_loss': 3.249040051698685}
{'R_grad_norm': 1.3627946370840072, 'training_loss': 3.234440095424652}
{'R_grad_norm': 1.3649916988611221, 'training_loss': 3.2540601825714113}
{'R_grad_norm': 1.3677238404750824, 'training_loss': 3.2510676300525665}
{'R_grad_norm': 1.3701971942186355, 'training_loss': 3.27621475815773}
{'R_grad_norm': 1.3757779997587205, 'training_loss': 3.2901435458660124}
{'R_grad_norm': 1.3719554764032365, 'training_loss': 3.3031524193286894}
{'R_grad_norm': 1.3714485162496566, 'training_loss': 3.3038929414749147}
{'R_grad_norm': 1.3736977934837342, 'training_loss': 3.318189035654068}
{'R_grad_norm': 1.3714566951990128, 'training_loss': 3.327786577939987}
{'R_grad_norm': 1.378320473432541, 'training_loss': 3.351737949848175}
{'R_grad_norm': 1.380119332075119, 'training_loss': 3.3677703332901}
{'R_grad_norm': 1.3849854284524918, 'training_loss': 3.39879798412323}
{'R_grad_norm': 1.3869220215082168, 'training_loss': 3.423503452539444}
{'R_grad_norm': 1.3863044166564942, 'training_loss': 3.4391560792922973}
{'R_grad_norm': 1.3934739226102828, 'training_loss': 3.4772785234451296}
{'R_grad_norm': 1.3979003083705903, 'training_loss': 3.534831756353378}
{'R_grad_norm': 1.3470291846990585, 'training_loss': 3.2372143030166627}
{'R_grad_norm': 1.344170359969139, 'training_loss': 3.233567327260971}
{'R_grad_norm': 1.3448485678434372, 'training_loss': 3.21574756026268}
{'R_grad_norm': 1.3467705929279328, 'training_loss': 3.2147539079189302}
{'R_grad_norm': 1.3437615871429442, 'training_loss': 3.2242828333377838}
{'R_grad_norm': 1.3463754844665528, 'training_loss': 3.2425787723064423}
{'R_grad_norm': 1.3431324028968812, 'training_loss': 3.2184214985370634}
{'R_grad_norm': 1.3461378598213196, 'training_loss': 3.2331314039230348}
{'R_grad_norm': 1.3410056674480437, 'training_loss': 3.214759808778763}
{'R_grad_norm': 1.3406658458709717, 'training_loss': 3.219754319190979}
{'R_grad_norm': 1.3370355772972107, 'training_loss': 3.211800513267517}
{'R_grad_norm': 1.339312863945961, 'training_loss': 3.2165625381469725}
{'R_grad_norm': 1.3348167741298675, 'training_loss': 3.2013892984390258}
{'R_grad_norm': 1.3332388108968736, 'training_loss': 3.19680370926857}
{'R_grad_norm': 1.3363155680894852, 'training_loss': 3.224224628210068}
{'R_grad_norm': 1.3300761926174163, 'training_loss': 3.195574761629105}
finish training (100000)
evaluating (25 steps)...
 ******* eval result *******
mean (weighted) 3.898639678955078
mean (unweighted) 3.2100915908813477
tensor([5.05043, 3.37863, 4.65910, 3.66183, 4.68806, 2.08369, 2.01400, 1.32233,
        2.03275], device='cuda:0')
