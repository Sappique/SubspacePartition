{'R_grad_norm': 2.223083311319351, 'training_loss': 15.35639084815979}
{'R_grad_norm': 2.2691480207443235, 'training_loss': 15.110988459587098}
{'R_grad_norm': 2.3133641016483306, 'training_loss': 14.898475389480591}
{'R_grad_norm': 2.344737114906311, 'training_loss': 14.757156000137329}
{'R_grad_norm': 2.3642731201648712, 'training_loss': 14.581492176055908}
{'R_grad_norm': 2.3745089244842528, 'training_loss': 14.447095775604248}
{'R_grad_norm': 2.397550376653671, 'training_loss': 14.409848752021789}
{'R_grad_norm': 2.3961181128025055, 'training_loss': 14.26631889820099}
{'R_grad_norm': 2.3991382336616516, 'training_loss': 14.18449655532837}
{'R_grad_norm': 2.3997343909740447, 'training_loss': 14.059916896820068}
{'R_grad_norm': 2.4083770048618316, 'training_loss': 14.034693932533264}
{'R_grad_norm': 2.414797739982605, 'training_loss': 13.972214422225953}
{'R_grad_norm': 2.413793159723282, 'training_loss': 13.936125202178955}
{'R_grad_norm': 2.4117254889011384, 'training_loss': 13.861723656654357}
{'R_grad_norm': 2.4109135937690733, 'training_loss': 13.795609707832336}
{'R_grad_norm': 2.411199972629547, 'training_loss': 13.73801962852478}
{'R_grad_norm': 2.4073673713207246, 'training_loss': 13.678923211097718}
{'R_grad_norm': 2.41172868847847, 'training_loss': 13.665474452972411}
{'R_grad_norm': 2.410579240322113, 'training_loss': 13.629500479698182}
{'R_grad_norm': 2.406038085222244, 'training_loss': 13.593432812690734}
{'R_grad_norm': 2.412320202589035, 'training_loss': 13.590334014892578}
{'R_grad_norm': 2.398412123918533, 'training_loss': 13.512964987754822}
{'R_grad_norm': 2.3994041979312897, 'training_loss': 13.464904217720031}
{'R_grad_norm': 2.3994559061527254, 'training_loss': 13.465076684951782}
{'R_grad_norm': 2.4056043899059296, 'training_loss': 13.486531429290771}
{'R_grad_norm': 2.3981924414634705, 'training_loss': 13.389812798500062}
{'R_grad_norm': 2.396709929704666, 'training_loss': 13.39011773109436}
{'R_grad_norm': 2.389962947368622, 'training_loss': 13.341213493347167}
{'R_grad_norm': 2.3923403441905977, 'training_loss': 13.343793940544128}
{'R_grad_norm': 2.3912500095367433, 'training_loss': 13.29664643764496}
{'R_grad_norm': 2.388354036808014, 'training_loss': 13.291528544425965}
{'R_grad_norm': 2.386924314498901, 'training_loss': 13.233945136070252}
{'R_grad_norm': 2.3974075388908385, 'training_loss': 13.302248616218566}
{'R_grad_norm': 2.3885639584064484, 'training_loss': 13.23039074420929}
{'R_grad_norm': 2.3814085733890535, 'training_loss': 13.182256860733032}
{'R_grad_norm': 2.381104724407196, 'training_loss': 13.148670682907104}
{'R_grad_norm': 2.3821692180633547, 'training_loss': 13.156283674240113}
{'R_grad_norm': 2.375642514228821, 'training_loss': 13.148986806869507}
{'R_grad_norm': 2.3747725105285644, 'training_loss': 13.109564089775086}
{'R_grad_norm': 2.3777263975143432, 'training_loss': 13.126324343681336}
{'R_grad_norm': 2.370321786403656, 'training_loss': 13.070984573364258}
{'R_grad_norm': 2.3646063578128813, 'training_loss': 13.042728114128114}
{'R_grad_norm': 2.365027651786804, 'training_loss': 13.046826434135436}
{'R_grad_norm': 2.3655460929870604, 'training_loss': 13.027375311851502}
{'R_grad_norm': 2.3571651017665864, 'training_loss': 12.994941811561585}
{'R_grad_norm': 2.3637030863761903, 'training_loss': 13.03512689113617}
{'R_grad_norm': 2.3621797692775726, 'training_loss': 13.000713725090026}
{'R_grad_norm': 2.361483484506607, 'training_loss': 12.983015007972718}
{'R_grad_norm': 2.3618943774700165, 'training_loss': 12.961120576858521}
{'R_grad_norm': 2.347744821310043, 'training_loss': 12.896011652946472}
{'R_grad_norm': 2.359484758377075, 'training_loss': 12.97854639530182}
{'R_grad_norm': 2.349799690246582, 'training_loss': 12.917358441352844}
{'R_grad_norm': 2.3514791536331177, 'training_loss': 12.909632630348206}
{'R_grad_norm': 2.353783733844757, 'training_loss': 12.958145709037781}
{'R_grad_norm': 2.3455116260051727, 'training_loss': 12.869587597846985}
{'R_grad_norm': 2.3495190703868865, 'training_loss': 12.922691655158996}
{'R_grad_norm': 2.3457757127285004, 'training_loss': 12.845814771652222}
{'R_grad_norm': 2.3478418135643007, 'training_loss': 12.899336094856261}
{'R_grad_norm': 2.3505481207370758, 'training_loss': 12.903266339302062}
{'R_grad_norm': 2.3467249059677124, 'training_loss': 12.8655717086792}
{'R_grad_norm': 2.3380718457698824, 'training_loss': 12.816890907287597}
{'R_grad_norm': 2.338113795518875, 'training_loss': 12.8280917263031}
{'R_grad_norm': 2.33760257601738, 'training_loss': 12.796105508804322}
{'R_grad_norm': 2.3376171255111693, 'training_loss': 12.811806449890137}
{'R_grad_norm': 2.341574354171753, 'training_loss': 12.832631683349609}
{'R_grad_norm': 2.3375593888759614, 'training_loss': 12.832976627349854}
{'R_grad_norm': 2.338982026576996, 'training_loss': 12.815440011024474}
{'R_grad_norm': 2.3261688137054444, 'training_loss': 12.757139186859131}
{'R_grad_norm': 2.3340211272239686, 'training_loss': 12.83260133266449}
{'R_grad_norm': 2.33140443444252, 'training_loss': 12.787910676002502}
{'R_grad_norm': 2.3336269092559814, 'training_loss': 12.772606768608092}
{'R_grad_norm': 2.320202720165253, 'training_loss': 12.730843949317933}
{'R_grad_norm': 2.3270946025848387, 'training_loss': 12.74605866909027}
{'R_grad_norm': 2.3261716091632842, 'training_loss': 12.74625364780426}
{'R_grad_norm': 2.3257495617866515, 'training_loss': 12.743223156929016}
{'R_grad_norm': 2.3220318400859834, 'training_loss': 12.701136927604676}
{'R_grad_norm': 2.323660732507706, 'training_loss': 12.736073741912842}
{'R_grad_norm': 2.329037319421768, 'training_loss': 12.770943007469178}
{'R_grad_norm': 2.3252255439758303, 'training_loss': 12.747951917648315}
{'R_grad_norm': 2.3252133178710936, 'training_loss': 12.740322403907776}
{'R_grad_norm': 2.3232151091098787, 'training_loss': 12.758724074363709}
{'R_grad_norm': 2.317847888469696, 'training_loss': 12.695071744918824}
{'R_grad_norm': 2.3150853943824767, 'training_loss': 12.673215394020081}
{'R_grad_norm': 2.318923497200012, 'training_loss': 12.735372605323791}
{'R_grad_norm': 2.3132908964157104, 'training_loss': 12.647675666809082}
{'R_grad_norm': 2.316613554954529, 'training_loss': 12.68061665058136}
{'R_grad_norm': 2.318699976205826, 'training_loss': 12.710289177894593}
{'R_grad_norm': 2.321611605882645, 'training_loss': 12.721674704551697}
{'R_grad_norm': 2.3153146612644195, 'training_loss': 12.692854180335999}
{'R_grad_norm': 2.3139040911197664, 'training_loss': 12.667125945091248}
{'R_grad_norm': 2.3160968112945555, 'training_loss': 12.708549585342407}
{'R_grad_norm': 2.31007866024971, 'training_loss': 12.650880699157716}
{'R_grad_norm': 2.3092970669269564, 'training_loss': 12.638611454963684}
{'R_grad_norm': 2.3101992440223693, 'training_loss': 12.64916666507721}
{'R_grad_norm': 2.3152111887931826, 'training_loss': 12.70785973072052}
{'R_grad_norm': 2.3133951902389525, 'training_loss': 12.675065817832946}
{'R_grad_norm': 2.3106550931930543, 'training_loss': 12.65146176815033}
{'R_grad_norm': 2.3134440970420838, 'training_loss': 12.69457805633545}
{'R_grad_norm': 2.312886881828308, 'training_loss': 12.671519665718078}
{'R_grad_norm': 2.3113409948348997, 'training_loss': 12.686349678039551}
eval result tensor([14.17668, 12.70439, 12.12808, 13.42386, 10.68027, 13.00113, 13.64404,
        12.53176, 13.00365, 11.99016, 12.72579, 12.63445, 13.11580, 12.95356,
        14.09283, 12.76942, 13.28385,  9.31269, 13.98559, 12.72635, 10.64508,
        14.08328, 12.69866, 13.46555], device='cuda:0')
computing merge metric
normed mi [((17, 20), 0.08490720391273499), ((12, 17), 0.08274107426404953), ((9, 17), 0.08148854970932007), ((9, 12), 0.08118677884340286), ((12, 22), 0.07716865837574005), ((12, 20), 0.07672416418790817), ((9, 20), 0.0721501037478447), ((0, 12), 0.07089857012033463), ((4, 20), 0.06915424019098282), ((12, 19), 0.06905624270439148), ((3, 12), 0.06885872036218643), ((12, 16), 0.06872197240591049), ((4, 17), 0.06801392883062363), ((4, 12), 0.06559871882200241), ((9, 22), 0.0652395710349083), ((9, 19), 0.06459928303956985), ((16, 21), 0.06408381462097168), ((19, 22), 0.06288392096757889), ((9, 16), 0.06269521266222), ((17, 19), 0.06256760656833649), ((5, 12), 0.06213731691241264), ((17, 22), 0.062056221067905426), ((0, 16), 0.060956910252571106), ((16, 17), 0.06070723384618759), ((20, 22), 0.05994454771280289), ((0, 9), 0.059873733669519424), ((11, 12), 0.059573087841272354), ((5, 22), 0.05955816060304642), ((3, 17), 0.0591813325881958), ((19, 20), 0.059065062552690506), ((3, 9), 0.05888073891401291), ((0, 21), 0.05874083563685417), ((16, 22), 0.05839274823665619), ((4, 9), 0.05815975368022919), ((0, 3), 0.057889435440301895), ((16, 19), 0.057617273181676865), ((9, 11), 0.057501744478940964), ((1, 9), 0.05724501982331276), ((0, 17), 0.05669232830405235), ((5, 9), 0.05644708499312401), ((16, 20), 0.05602363497018814), ((1, 19), 0.05571605637669563), ((10, 16), 0.0551743358373642), ((12, 21), 0.05515282601118088), ((11, 22), 0.05484937131404877), ((5, 16), 0.05473703145980835), ((4, 22), 0.05453396588563919), ((11, 19), 0.05451309680938721), ((1, 12), 0.054269492626190186), ((3, 20), 0.053940679877996445), ((0, 22), 0.05376442149281502), ((11, 17), 0.053201112896203995), ((0, 5), 0.05312067270278931), ((3, 22), 0.053113095462322235), ((5, 19), 0.053086057305336), ((5, 11), 0.05257763713598251), ((11, 16), 0.05236760154366493), ((10, 21), 0.052124932408332825), ((1, 17), 0.05211520195007324), ((1, 11), 0.05201156437397003), ((0, 20), 0.05200615152716637), ((9, 10), 0.05198346823453903), ((1, 22), 0.0518958605825901), ((10, 12), 0.05166840925812721), ((17, 21), 0.051651306450366974), ((16, 23), 0.05156440660357475), ((3, 4), 0.05148867517709732), ((1, 16), 0.051316406577825546), ((3, 16), 0.0511612631380558), ((14, 23), 0.05053789168596268), ((7, 9), 0.05051016807556152), ((7, 17), 0.05029023438692093), ((21, 23), 0.050224967300891876), ((1, 5), 0.050127290189266205), ((8, 18), 0.04999437555670738), ((5, 17), 0.04974896460771561), ((18, 23), 0.04962170124053955), ((10, 23), 0.04958536848425865), ((11, 20), 0.049529604613780975), ((10, 17), 0.04943481832742691), ((6, 18), 0.04942005127668381), ((0, 19), 0.04930095002055168), ((10, 19), 0.04915411025285721), ((7, 10), 0.0491502471268177), ((7, 16), 0.04882349818944931), ((14, 18), 0.04882219061255455), ((14, 16), 0.0487263947725296), ((1, 7), 0.04871127009391785), ((5, 20), 0.04864242300391197), ((8, 23), 0.048635054379701614), ((10, 14), 0.04853665828704834), ((7, 23), 0.04829249903559685), ((12, 23), 0.04823441430926323), ((9, 21), 0.048180051147937775), ((0, 10), 0.048129014670848846), ((6, 23), 0.04802491143345833), ((4, 19), 0.0480155423283577), ((9, 23), 0.047982532531023026), ((8, 21), 0.04791026562452316), ((6, 14), 0.04786284267902374), ((1, 10), 0.04782601818442345), ((7, 12), 0.047812122851610184), ((3, 19), 0.047772519290447235), ((0, 23), 0.04774336889386177), ((1, 20), 0.04773808270692825), ((14, 21), 0.047602687031030655), ((8, 14), 0.04753584414720535), ((20, 21), 0.0474083311855793), ((18, 21), 0.047254528850317), ((10, 11), 0.046947214752435684), ((7, 14), 0.04687883332371712), ((6, 7), 0.04668417200446129), ((3, 21), 0.04654303938150406), ((19, 21), 0.04653012007474899), ((5, 10), 0.04647011309862137), ((6, 8), 0.04643213748931885), ((0, 11), 0.04632178321480751), ((7, 19), 0.04618731886148453), ((6, 10), 0.046173546463251114), ((8, 10), 0.04584946855902672), ((10, 18), 0.045804183930158615), ((3, 5), 0.04569287598133087), ((0, 14), 0.04568277671933174), ((7, 11), 0.0456543043255806), ((16, 18), 0.045240264385938644), ((9, 14), 0.04523079842329025), ((7, 8), 0.04519626498222351), ((1, 23), 0.045161981135606766), ((7, 18), 0.045122694224119186), ((0, 18), 0.04507414624094963), ((4, 16), 0.04461051523685455), ((17, 23), 0.044553883373737335), ((10, 22), 0.044526975601911545), ((7, 21), 0.0444522425532341), ((10, 20), 0.04440413787961006), ((7, 20), 0.04433773085474968), ((1, 14), 0.04415189474821091), ((12, 14), 0.044074900448322296), ((5, 23), 0.04393493011593819), ((6, 9), 0.0439060740172863), ((12, 18), 0.043813783675432205), ((19, 23), 0.04378644749522209), ((5, 14), 0.04378212243318558), ((11, 23), 0.04375315085053444), ((5, 7), 0.04374248906970024), ((8, 16), 0.04344487562775612), ((21, 22), 0.04340667277574539), ((0, 4), 0.043386030942201614), ((0, 1), 0.043370604515075684), ((5, 21), 0.043331511318683624), ((9, 18), 0.043279360979795456), ((6, 16), 0.04323688894510269), ((1, 6), 0.04286862909793854), ((0, 7), 0.042722444981336594), ((11, 14), 0.04256441816687584), ((6, 12), 0.04209470748901367), ((14, 19), 0.04122418165206909), ((3, 11), 0.041177645325660706), ((11, 21), 0.04094996303319931), ((7, 22), 0.040799859911203384), ((17, 18), 0.04075286164879799), ((4, 5), 0.040721550583839417), ((6, 11), 0.0403810553252697), ((4, 11), 0.04034632071852684), ((20, 23), 0.040318526327610016), ((0, 8), 0.040253449231386185), ((0, 6), 0.04016799479722977), ((6, 17), 0.04013478755950928), ((1, 18), 0.03991082310676575), ((6, 21), 0.03979557007551193), ((22, 23), 0.03978770971298218), ((1, 21), 0.039719659835100174), ((5, 6), 0.039645396173000336), ((14, 17), 0.03955360874533653), ((1, 3), 0.03948075324296951), ((8, 9), 0.03945057839155197), ((4, 21), 0.03936392441391945), ((3, 10), 0.039239898324012756), ((5, 18), 0.0390220582485199), ((1, 8), 0.03900758549571037), ((6, 19), 0.03891797363758087), ((11, 18), 0.038756296038627625), ((14, 22), 0.03843369334936142), ((5, 8), 0.03833605349063873), ((8, 12), 0.03813394531607628), ((8, 11), 0.03788460046052933), ((3, 23), 0.03748881444334984), ((18, 19), 0.03684012219309807), ((1, 4), 0.03676709905266762), ((6, 20), 0.0366995632648468), ((14, 20), 0.03653036803007126), ((18, 20), 0.03645556792616844), ((8, 17), 0.03625263273715973), ((3, 18), 0.03613293170928955), ((12, 13), 0.035826221108436584), ((18, 22), 0.03578963130712509), ((3, 7), 0.03562039136886597), ((6, 22), 0.03541962429881096), ((8, 19), 0.03506794944405556), ((3, 14), 0.03505583852529526), ((4, 13), 0.03475961089134216), ((4, 10), 0.03368581831455231), ((8, 20), 0.0333079919219017), ((4, 7), 0.032801900058984756), ((8, 22), 0.03236920014023781), ((3, 6), 0.03230148181319237), ((4, 23), 0.03041868470609188), ((3, 8), 0.03021409921348095), ((13, 20), 0.029995255172252655), ((2, 12), 0.029426977038383484), ((3, 13), 0.029354184865951538), ((13, 22), 0.02899896539747715), ((4, 18), 0.02860189415514469), ((2, 21), 0.028110379353165627), ((4, 14), 0.0280628502368927), ((13, 17), 0.02805596962571144), ((4, 6), 0.027641139924526215), ((2, 22), 0.027264868840575218), ((2, 19), 0.026578638702630997), ((2, 16), 0.02646624483168125), ((4, 8), 0.02592793107032776), ((2, 5), 0.02508433349430561), ((9, 13), 0.02498527802526951), ((2, 9), 0.024799294769763947), ((2, 11), 0.0245506688952446), ((2, 20), 0.024457242339849472), ((0, 2), 0.02396169863641262), ((2, 8), 0.023927034810185432), ((0, 13), 0.023857397958636284), ((2, 10), 0.023454176262021065), ((1, 2), 0.02329256199300289), ((2, 17), 0.023235391825437546), ((2, 23), 0.02299862541258335), ((13, 21), 0.022921698167920113), ((13, 15), 0.02252908982336521), ((2, 7), 0.02251260168850422), ((2, 18), 0.02227838523685932), ((2, 4), 0.022243771702051163), ((2, 14), 0.02223920077085495), ((13, 19), 0.022154198959469795), ((2, 3), 0.021536171436309814), ((13, 16), 0.02153598517179489), ((2, 6), 0.020719680935144424), ((5, 13), 0.01895204931497574), ((4, 15), 0.01827273890376091), ((12, 15), 0.01770091988146305), ((11, 13), 0.017229991033673286), ((15, 20), 0.01607285998761654), ((1, 13), 0.016027817502617836), ((10, 13), 0.01565845124423504), ((15, 17), 0.015423456206917763), ((15, 22), 0.014729383401572704), ((13, 23), 0.014021242968738079), ((3, 15), 0.013751477934420109), ((7, 13), 0.01369910966604948), ((15, 21), 0.013515975326299667), ((13, 18), 0.013367257080972195), ((13, 14), 0.013027814216911793), ((2, 13), 0.012736533768475056), ((9, 15), 0.012578293681144714), ((15, 19), 0.012380179949104786), ((0, 15), 0.012337830848991871), ((2, 15), 0.012003340758383274), ((15, 16), 0.011650783941149712), ((6, 13), 0.011644156649708748), ((8, 13), 0.011166560463607311), ((5, 15), 0.010546843521296978), ((11, 15), 0.009308019652962685), ((1, 15), 0.00848870538175106), ((10, 15), 0.008413970470428467), ((7, 15), 0.007849996909499168), ((15, 23), 0.007770063821226358), ((14, 15), 0.007459075655788183), ((15, 18), 0.007333045359700918), ((8, 15), 0.007008672691881657), ((6, 15), 0.006577877793461084)]
******* after merging (0.04): [((17, 20), 64), ((9, 12), 64), ((16, 21), 64), ((0,), 32), ((1,), 32), ((2,), 32), ((3,), 32), ((4,), 32), ((5,), 32), ((6,), 32), ((7,), 32), ((8,), 32), ((10,), 32), ((11,), 32), ((13,), 32), ((14,), 32), ((15,), 32), ((18,), 32), ((19,), 32), ((22,), 32), ((23,), 32)]
{'R_grad_norm': 2.8632367074489595, 'training_loss': 13.800747551918029}
{'R_grad_norm': 2.852195317745209, 'training_loss': 13.717387971878052}
{'R_grad_norm': 2.858509922027588, 'training_loss': 13.76844328403473}
{'R_grad_norm': 2.8652258598804474, 'training_loss': 13.78242392539978}
{'R_grad_norm': 2.85281280875206, 'training_loss': 13.71513228416443}
{'R_grad_norm': 2.861816235780716, 'training_loss': 13.774025983810425}
{'R_grad_norm': 2.858962061405182, 'training_loss': 13.732276263236999}
{'R_grad_norm': 2.8570985531806947, 'training_loss': 13.736193056106567}
{'R_grad_norm': 2.8611745369434356, 'training_loss': 13.764651527404785}
{'R_grad_norm': 2.8558782613277436, 'training_loss': 13.712288670539856}
{'R_grad_norm': 2.863602433204651, 'training_loss': 13.74502951145172}
{'R_grad_norm': 2.857799199819565, 'training_loss': 13.72181487083435}
{'R_grad_norm': 2.8495179426670076, 'training_loss': 13.663487977981568}
{'R_grad_norm': 2.8545764076709745, 'training_loss': 13.700883474349975}
{'R_grad_norm': 2.861579211950302, 'training_loss': 13.754229345321654}
{'R_grad_norm': 2.8492474544048307, 'training_loss': 13.693237328529358}
{'R_grad_norm': 2.8544962322711944, 'training_loss': 13.6927508020401}
{'R_grad_norm': 2.846691696643829, 'training_loss': 13.668630375862122}
{'R_grad_norm': 2.8426993703842163, 'training_loss': 13.6602476978302}
{'R_grad_norm': 2.840676333904266, 'training_loss': 13.635091614723205}
{'R_grad_norm': 2.8430770444869995, 'training_loss': 13.671462225914002}
{'R_grad_norm': 2.836541736125946, 'training_loss': 13.624770765304566}
{'R_grad_norm': 2.8376999354362487, 'training_loss': 13.625773596763612}
{'R_grad_norm': 2.8396231508255005, 'training_loss': 13.6567525100708}
{'R_grad_norm': 2.8310200750827788, 'training_loss': 13.608730697631836}
{'R_grad_norm': 2.829196584224701, 'training_loss': 13.618862328529358}
{'R_grad_norm': 2.833218277692795, 'training_loss': 13.63337221622467}
{'R_grad_norm': 2.829716273546219, 'training_loss': 13.592718868255615}
{'R_grad_norm': 2.8366054368019102, 'training_loss': 13.653045291900634}
{'R_grad_norm': 2.831423237323761, 'training_loss': 13.621672520637512}
{'R_grad_norm': 2.8180167758464814, 'training_loss': 13.556213188171387}
{'R_grad_norm': 2.8291115164756775, 'training_loss': 13.63480236530304}
{'R_grad_norm': 2.823304708003998, 'training_loss': 13.615905466079711}
{'R_grad_norm': 2.818160444498062, 'training_loss': 13.550082969665528}
{'R_grad_norm': 2.8248675060272217, 'training_loss': 13.608446869850159}
{'R_grad_norm': 2.8222727715969085, 'training_loss': 13.600052399635315}
{'R_grad_norm': 2.814333322048187, 'training_loss': 13.537663083076477}
{'R_grad_norm': 2.818996733427048, 'training_loss': 13.578346676826477}
{'R_grad_norm': 2.814648985862732, 'training_loss': 13.536096258163452}
{'R_grad_norm': 2.809475259780884, 'training_loss': 13.540875616073608}
eval result tensor([15.44662, 22.04795, 24.02769, 13.63263, 12.22485, 11.73113, 12.95338,
         9.91725, 12.72563, 13.19557, 11.91674, 12.41928, 12.04383, 12.14073,
        12.48855, 13.38426, 12.23644, 13.56112, 12.32305, 12.14588, 12.81379],
       device='cuda:0')
computing merge metric
normed mi [((18, 19), 0.05946246162056923), ((8, 19), 0.057775769382715225), ((1, 19), 0.05550772945086161), ((3, 6), 0.05419322848320007), ((1, 18), 0.05404804150263468), ((1, 3), 0.05389536917209625), ((0, 1), 0.05335720255970955), ((4, 18), 0.05257224291563034), ((7, 19), 0.05256958305835724), ((3, 8), 0.052524223923683167), ((8, 18), 0.05174490436911583), ((4, 13), 0.05120519548654556), ((0, 7), 0.0505022257566452), ((13, 18), 0.050036828964948654), ((6, 19), 0.04976741597056389), ((1, 6), 0.04952347775300344), ((8, 13), 0.04941662773489952), ((1, 8), 0.0493281881014506), ((6, 7), 0.04928997531533241), ((3, 19), 0.049199871718883514), ((4, 8), 0.049014896154403687), ((11, 17), 0.04899556189775467), ((10, 12), 0.04880858212709427), ((4, 19), 0.04867275059223175), ((15, 20), 0.04815660044550896), ((9, 17), 0.04806666448712349), ((4, 10), 0.04774130880832672), ((4, 12), 0.04765978083014488), ((9, 20), 0.047445133328437805), ((12, 13), 0.047204773873090744), ((17, 20), 0.04720357432961464), ((7, 18), 0.04714103415608406), ((10, 13), 0.04711965098977089), ((12, 20), 0.047111280262470245), ((13, 19), 0.04703149199485779), ((3, 18), 0.047029394656419754), ((11, 20), 0.0468750037252903), ((2, 3), 0.04654070734977722), ((0, 18), 0.0463555653889974), ((12, 18), 0.046253133565187454), ((10, 20), 0.046158790588378906), ((12, 15), 0.04611213877797127), ((6, 18), 0.045889630913734436), ((10, 18), 0.04583079367876053), ((0, 19), 0.045830210049947105), ((15, 17), 0.04580213502049446), ((9, 15), 0.04572015628218651), ((9, 10), 0.04561991989612579), ((8, 12), 0.04542837664484978), ((11, 15), 0.04538929834961891), ((9, 11), 0.045363884419202805), ((9, 12), 0.04470796510577202), ((6, 8), 0.04464302957057953), ((10, 15), 0.044622112065553665), ((0, 6), 0.04421164095401764), ((11, 12), 0.044119514524936676), ((4, 20), 0.044103484600782394), ((8, 10), 0.04403233528137207), ((3, 12), 0.04392034560441971), ((1, 4), 0.043914725383122764), ((1, 13), 0.04391029973824819), ((1, 7), 0.04380519191424052), ((3, 17), 0.0436357781291008), ((13, 20), 0.043389104306697845), ((10, 11), 0.043388351798057556), ((3, 13), 0.043367139995098114), ((3, 20), 0.042943935841321945), ((4, 15), 0.0429060198366642), ((3, 15), 0.042616479098796844), ((3, 4), 0.04240190237760544), ((13, 15), 0.04234601929783821), ((8, 15), 0.04234043136239052), ((10, 17), 0.04230983555316925), ((12, 17), 0.04229387640953064), ((3, 10), 0.04226061329245567), ((2, 11), 0.04202279448509216), ((4, 9), 0.041979048401117325), ((0, 3), 0.041967456539471946), ((1, 2), 0.041563980281353), ((2, 12), 0.04151379813750585), ((8, 20), 0.04135819897055626), ((9, 13), 0.04104573652148247), ((12, 19), 0.040674012154340744), ((18, 20), 0.040522489696741104), ((2, 20), 0.04022405296564102), ((1, 12), 0.04012292375167211), ((3, 11), 0.04011726379394531), ((3, 7), 0.04008164256811142), ((1, 10), 0.03982329865296682), ((7, 8), 0.03981601819396019), ((10, 19), 0.03966951370239258), ((3, 9), 0.03943325951695442), ((2, 18), 0.03927041838566462), ((8, 9), 0.03926568850874901), ((2, 17), 0.039087772369384766), ((9, 18), 0.03848615288734436), ((2, 15), 0.03846178203821182), ((0, 4), 0.03840819994608561), ((15, 18), 0.03817259520292282), ((0, 10), 0.038047795494397484), ((0, 8), 0.03800874203443527), ((2, 10), 0.0379943052927653), ((2, 8), 0.03783459464708964), ((4, 6), 0.037736423313617706), ((4, 11), 0.03766237571835518), ((11, 13), 0.03764171898365021), ((4, 17), 0.03756143897771835), ((4, 7), 0.03752124309539795), ((1, 20), 0.037441941599051155), ((8, 17), 0.037420980632305145), ((13, 17), 0.03721760958433151), ((8, 11), 0.03709661215543747), ((7, 13), 0.03658365085721016), ((0, 13), 0.03650705267985662), ((6, 13), 0.036048512905836105), ((19, 20), 0.035894837230443954), ((6, 10), 0.03580362722277641), ((7, 10), 0.035711534321308136), ((1, 17), 0.03565600017706553), ((7, 14), 0.03565158694982529), ((17, 18), 0.03552130237221718), ((15, 19), 0.035502731800079346), ((2, 6), 0.0354183167219162), ((1, 9), 0.03520034998655319), ((2, 19), 0.03499960402647654), ((6, 12), 0.03498268127441406), ((6, 17), 0.03488902002573013), ((2, 4), 0.03476641823848089), ((0, 12), 0.03476629157861074), ((1, 15), 0.0346391499042511), ((9, 19), 0.03463628143072128), ((2, 13), 0.03446564575036367), ((2, 9), 0.034037113189697266), ((0, 2), 0.03390521556138992), ((11, 18), 0.03387170657515526), ((17, 19), 0.03343250975012779), ((6, 20), 0.03254510462284088), ((7, 12), 0.03224239870905876), ((6, 15), 0.03178612142801285), ((11, 19), 0.03129353001713753), ((6, 9), 0.031241005286574364), ((1, 11), 0.03123282641172409), ((0, 20), 0.031044016281763714), ((14, 19), 0.03028915822505951), ((0, 9), 0.03027213364839554), ((6, 11), 0.03024831786751747), ((6, 14), 0.030211351811885834), ((0, 17), 0.029645420610904694), ((7, 20), 0.02912762761116028), ((7, 17), 0.029034674167633057), ((7, 9), 0.02882525697350502), ((2, 7), 0.028411053121089935), ((0, 15), 0.02750208228826523), ((7, 15), 0.026814600452780724), ((7, 11), 0.02678847685456276), ((0, 11), 0.02674987663825353), ((5, 19), 0.025457877665758133), ((5, 18), 0.02481384016573429), ((3, 14), 0.02403911016881466), ((5, 8), 0.023994773626327515), ((14, 18), 0.023531874641776085), ((1, 14), 0.023163494964440662), ((14, 16), 0.023159729316830635), ((5, 11), 0.022406531497836113), ((5, 7), 0.02185974456369877), ((0, 14), 0.021789225439230602), ((3, 5), 0.021601907908916473), ((4, 5), 0.02159617841243744), ((5, 10), 0.02148030698299408), ((5, 13), 0.021106865257024765), ((1, 5), 0.02086927245060603), ((5, 12), 0.02063588798046112), ((2, 5), 0.020445918043454487), ((5, 6), 0.020288290455937386), ((5, 17), 0.020027494058012962), ((8, 14), 0.020021090283989906), ((5, 20), 0.01943051815032959), ((5, 15), 0.019289258867502213), ((7, 16), 0.01921878568828106), ((5, 9), 0.019085070118308067), ((0, 5), 0.017211558918158214), ((4, 14), 0.016546353697776794), ((2, 14), 0.01625045637289683), ((13, 14), 0.015824567526578903), ((16, 19), 0.01511196605861187), ((10, 14), 0.014740290120244026), ((14, 17), 0.01447039470076561), ((12, 14), 0.014355311170220375), ((6, 16), 0.014006687328219414), ((14, 20), 0.01368826162070036), ((5, 14), 0.013616912066936493), ((5, 16), 0.013269825838506222), ((14, 15), 0.012918872758746147), ((16, 18), 0.01283068023622036), ((9, 14), 0.012288913130760193), ((3, 16), 0.012148951180279255), ((11, 14), 0.012006845325231552), ((0, 16), 0.011156745254993439), ((1, 16), 0.010846743981043497), ((8, 16), 0.010819664224982262), ((4, 16), 0.00877181626856327), ((13, 16), 0.0086046252399683), ((2, 16), 0.008543746545910835), ((10, 16), 0.008435911498963833), ((12, 16), 0.008037518709897995), ((16, 17), 0.007762895431369543), ((11, 16), 0.007650435436517), ((16, 20), 0.007389509119093418), ((9, 16), 0.007122369948774576), ((15, 16), 0.007103085983544588)]
******* after merging (0.04): [((18, 19), 64), ((3, 6), 64), ((0,), 64), ((1,), 64), ((2,), 64), ((4,), 32), ((5,), 32), ((7,), 32), ((8,), 32), ((9,), 32), ((10,), 32), ((11,), 32), ((12,), 32), ((13,), 32), ((14,), 32), ((15,), 32), ((16,), 32), ((17,), 32), ((20,), 32)]
{'R_grad_norm': 3.0131239008903505, 'training_loss': 14.53354588985443}
{'R_grad_norm': 3.0080238366127015, 'training_loss': 14.484494905471802}
{'R_grad_norm': 3.014786357879639, 'training_loss': 14.522834143638612}
{'R_grad_norm': 3.012864418029785, 'training_loss': 14.531236410140991}
{'R_grad_norm': 3.0131210148334504, 'training_loss': 14.512094030380249}
{'R_grad_norm': 3.0002676391601564, 'training_loss': 14.476392860412597}
{'R_grad_norm': 3.009529309272766, 'training_loss': 14.513861646652222}
{'R_grad_norm': 3.0171691966056824, 'training_loss': 14.512203540802002}
{'R_grad_norm': 3.0308337271213532, 'training_loss': 14.586017398834228}
{'R_grad_norm': 3.0355313456058504, 'training_loss': 14.553144750595093}
{'R_grad_norm': 3.033285678625107, 'training_loss': 14.584601259231567}
{'R_grad_norm': 3.0483134889602663, 'training_loss': 14.64003095149994}
{'R_grad_norm': 3.0483094120025633, 'training_loss': 14.620378270149232}
{'R_grad_norm': 3.064595341682434, 'training_loss': 14.703743495941161}
{'R_grad_norm': 3.088209625482559, 'training_loss': 14.805632061958313}
{'R_grad_norm': 3.092240927219391, 'training_loss': 14.822344584465027}
{'R_grad_norm': 3.1070316433906555, 'training_loss': 14.88327100276947}
{'R_grad_norm': 3.128752045631409, 'training_loss': 14.99007773399353}
{'R_grad_norm': 3.148099936246872, 'training_loss': 15.089063720703125}
{'R_grad_norm': 3.167165291309357, 'training_loss': 15.21056782245636}
{'R_grad_norm': 3.1855490720272064, 'training_loss': 15.24710720539093}
{'R_grad_norm': 3.2135995447635652, 'training_loss': 15.417419228553772}
{'R_grad_norm': 3.096281719207764, 'training_loss': 14.944701728820801}
{'R_grad_norm': 3.007791095972061, 'training_loss': 14.57225384235382}
{'R_grad_norm': 3.0097989106178282, 'training_loss': 14.578765506744384}
{'R_grad_norm': 2.9946751546859742, 'training_loss': 14.54537799358368}
{'R_grad_norm': 3.00911275267601, 'training_loss': 14.602204856872559}
{'R_grad_norm': 3.005386768579483, 'training_loss': 14.581146597862244}
{'R_grad_norm': 2.9962474298477173, 'training_loss': 14.532756595611572}
{'R_grad_norm': 2.992351614236832, 'training_loss': 14.523736095428466}
{'R_grad_norm': 3.00048614859581, 'training_loss': 14.587811074256898}
{'R_grad_norm': 2.9970996522903444, 'training_loss': 14.523125586509705}
{'R_grad_norm': 2.995429915189743, 'training_loss': 14.523026666641236}
{'R_grad_norm': 2.9962695944309234, 'training_loss': 14.515819029808045}
{'R_grad_norm': 2.995817724466324, 'training_loss': 14.54612398147583}
{'R_grad_norm': 2.9910246503353117, 'training_loss': 14.548658757209777}
{'R_grad_norm': 2.9872362923622133, 'training_loss': 14.522216973304749}
{'R_grad_norm': 2.992255769968033, 'training_loss': 14.527585067749023}
{'R_grad_norm': 2.998132703304291, 'training_loss': 14.568314566612244}
{'R_grad_norm': 2.984972307682037, 'training_loss': 14.491458659172059}
eval result tensor([21.51324, 23.78133, 15.39412, 22.23318, 24.30482, 11.89362, 11.49018,
         9.69150, 12.49473, 13.07809, 11.66264, 12.18529, 11.77027, 11.91217,
        12.32666, 13.15961, 11.79517, 13.53975, 12.59213], device='cuda:0')
computing merge metric
normed mi [((2, 3), 0.05160549655556679), ((5, 13), 0.049885042011737823), ((1, 3), 0.0492330826818943), ((0, 3), 0.04896903783082962), ((11, 17), 0.04848803952336311), ((2, 7), 0.048269117871920265), ((5, 10), 0.04744957387447357), ((3, 8), 0.047434757153193154), ((9, 17), 0.04742272570729256), ((10, 12), 0.04731793701648712), ((5, 12), 0.046457868069410324), ((10, 13), 0.04640748351812363), ((15, 18), 0.04636825621128082), ((12, 18), 0.046308569610118866), ((5, 8), 0.04612468183040619), ((9, 18), 0.046060699969530106), ((12, 13), 0.04593384265899658), ((8, 13), 0.045324571430683136), ((11, 18), 0.04527156427502632), ((10, 18), 0.045030295848846436), ((17, 18), 0.04475747421383858), ((0, 8), 0.044730941454569496), ((12, 15), 0.04455943778157234), ((9, 11), 0.044435158371925354), ((9, 15), 0.04412981495261192), ((11, 15), 0.043848130851984024), ((9, 10), 0.04383791238069534), ((15, 17), 0.04367132484912872), ((10, 15), 0.043217554688453674), ((9, 12), 0.04289183393120766), ((5, 18), 0.0423419326543808), ((11, 12), 0.04228505119681358), ((10, 11), 0.041948866099119186), ((13, 18), 0.041941724717617035), ((0, 5), 0.041926940282185875), ((3, 5), 0.041831394036610924), ((8, 10), 0.041587505489587784), ((8, 12), 0.041546277701854706), ((5, 15), 0.041373543441295624), ((3, 7), 0.04123504956563314), ((13, 15), 0.04119851067662239), ((4, 11), 0.04086277882258097), ((10, 17), 0.04062598943710327), ((12, 17), 0.04052385687828064), ((1, 8), 0.040350216130415596), ((5, 9), 0.04024737700819969), ((9, 13), 0.04010104387998581), ((3, 13), 0.04007511337598165), ((3, 4), 0.03973717987537384), ((0, 13), 0.038934119045734406), ((4, 12), 0.0388025219241778), ((3, 10), 0.03865612794955572), ((2, 10), 0.03831977645556132), ((0, 2), 0.038086727261543274), ((2, 5), 0.03796745091676712), ((1, 2), 0.037803344428539276), ((8, 15), 0.03779744356870651), ((4, 18), 0.03765251487493515), ((4, 17), 0.037639886140823364), ((8, 18), 0.037627361714839935), ((1, 4), 0.03760131821036339), ((7, 8), 0.037085454910993576), ((3, 12), 0.03706823786099752), ((2, 8), 0.03690285235643387), ((4, 10), 0.036810467640558876), ((8, 9), 0.03646502643823624), ((11, 13), 0.03607721999287605), ((4, 15), 0.035779486099878945), ((0, 10), 0.03574321667353312), ((5, 17), 0.035458169877529144), ((0, 12), 0.035415537655353546), ((5, 11), 0.035388704389333725), ((13, 17), 0.035211190581321716), ((4, 8), 0.035187880198160805), ((8, 17), 0.03516717255115509), ((5, 7), 0.03502793610095978), ((7, 10), 0.034695930778980255), ((0, 1), 0.034574590623378754), ((2, 13), 0.03432695319255193), ((3, 17), 0.03421861926714579), ((3, 18), 0.03411685178677241), ((0, 4), 0.03408665955066681), ((8, 11), 0.034035880118608475), ((1, 17), 0.03372636437416077), ((3, 9), 0.03369356940189997), ((7, 14), 0.03361394628882408), ((4, 5), 0.033171556890010834), ((4, 9), 0.03315393626689911), ((1, 5), 0.03300843139489492), ((2, 12), 0.03273734698692957), ((7, 13), 0.0326947458088398), ((0, 7), 0.03259892761707306), ((1, 10), 0.03245144089063009), ((4, 13), 0.03209467480580012), ((2, 4), 0.03204525634646416), ((1, 12), 0.03167980660994848), ((3, 15), 0.031620909770329796), ((0, 18), 0.031407309075196586), ((1, 13), 0.031231145064036053), ((1, 7), 0.03105035424232483), ((1, 18), 0.03062733511130015), ((1, 15), 0.030511759221553802), ((1, 9), 0.0304769699772199), ((0, 15), 0.030402354896068573), ((0, 9), 0.030096602936585743), ((3, 11), 0.029614277184009552), ((1, 11), 0.029282165070374806), ((2, 9), 0.02896149456501007), ((7, 12), 0.028904927894473076), ((2, 18), 0.028827679653962452), ((2, 17), 0.02776213486989339), ((0, 17), 0.02749021848042806), ((7, 17), 0.026711873710155487), ((7, 9), 0.026392700150609016), ((4, 7), 0.026363025108973186), ((7, 18), 0.025781622156500816), ((0, 11), 0.02564236770073573), ((2, 15), 0.025423939029375713), ((14, 16), 0.025354444980621338), ((2, 11), 0.02483937640984853), ((7, 15), 0.023743394762277603), ((7, 11), 0.023562902584671974), ((3, 14), 0.021856146554152172), ((7, 16), 0.021575136110186577), ((6, 8), 0.020418571308255196), ((2, 14), 0.019792185475428898), ((6, 7), 0.019483136013150215), ((6, 11), 0.018683437258005142), ((4, 6), 0.018460435171922047), ((3, 6), 0.018245983868837357), ((8, 14), 0.018077008426189423), ((6, 10), 0.017970575019717216), ((5, 6), 0.01716325804591179), ((1, 14), 0.017124198377132416), ((0, 6), 0.017071346441904705), ((6, 17), 0.01681642048060894), ((6, 13), 0.016268514096736908), ((6, 12), 0.016220994293689728), ((6, 18), 0.015874996781349182), ((0, 14), 0.01583258807659149), ((6, 9), 0.01559401024132967), ((6, 15), 0.015061399899423122), ((2, 6), 0.014815450956424078), ((4, 14), 0.014677217851082483), ((5, 14), 0.014565541408956051), ((1, 6), 0.013789985328912735), ((10, 14), 0.013243481516838074), ((6, 14), 0.013105997815728188), ((13, 14), 0.0126636428758502), ((14, 17), 0.012512038461863995), ((12, 14), 0.011650759726762772), ((14, 18), 0.011211054399609566), ((3, 16), 0.011109045396248499), ((2, 16), 0.01110850895444552), ((8, 16), 0.010610793717205524), ((14, 15), 0.010310821235179901), ((9, 14), 0.010216359049081802), ((11, 14), 0.00982134323567152), ((0, 16), 0.009228199099500975), ((6, 16), 0.009097845293581486), ((4, 16), 0.008405037224292755), ((5, 16), 0.008118775673210621), ((10, 16), 0.0077728526666760445), ((13, 16), 0.007312176749110222), ((1, 16), 0.007064566637078921), ((12, 16), 0.006836636457592249), ((16, 17), 0.006532039027661085), ((11, 16), 0.006209301296621561), ((9, 16), 0.005932795349508524), ((16, 18), 0.0058959489688277245), ((15, 16), 0.005730902310460806)]
******* after merging (0.04): [((2, 3), 128), ((5, 13), 64), ((0,), 64), ((1,), 64), ((4,), 64), ((6,), 32), ((7,), 32), ((8,), 32), ((9,), 32), ((10,), 32), ((11,), 32), ((12,), 32), ((14,), 32), ((15,), 32), ((16,), 32), ((17,), 32), ((18,), 32)]
{'R_grad_norm': 3.2214172875881193, 'training_loss': 15.477044820785522}
{'R_grad_norm': 3.2193848943710326, 'training_loss': 15.469247722625733}
{'R_grad_norm': 3.218274840116501, 'training_loss': 15.476672234535217}
{'R_grad_norm': 3.224467319250107, 'training_loss': 15.49710618019104}
{'R_grad_norm': 3.2232454943656923, 'training_loss': 15.459919290542603}
{'R_grad_norm': 3.2263131165504455, 'training_loss': 15.486641612052917}
{'R_grad_norm': 3.2230036878585815, 'training_loss': 15.474808373451232}
{'R_grad_norm': 3.208617557287216, 'training_loss': 15.39469738483429}
{'R_grad_norm': 3.2080789744853973, 'training_loss': 15.421701741218566}
{'R_grad_norm': 3.2146347665786745, 'training_loss': 15.453563446998595}
{'R_grad_norm': 3.2168715810775756, 'training_loss': 15.433094220161438}
{'R_grad_norm': 3.2142752981185914, 'training_loss': 15.425946416854858}
{'R_grad_norm': 3.2062269389629363, 'training_loss': 15.39584276676178}
{'R_grad_norm': 3.2166219115257264, 'training_loss': 15.436697506904602}
{'R_grad_norm': 3.212093379497528, 'training_loss': 15.433848872184754}
{'R_grad_norm': 3.2076940643787384, 'training_loss': 15.411942739486694}
{'R_grad_norm': 3.2037531721591948, 'training_loss': 15.418903799057007}
{'R_grad_norm': 3.203888019323349, 'training_loss': 15.426389722824096}
{'R_grad_norm': 3.201998258829117, 'training_loss': 15.3766916847229}
{'R_grad_norm': 3.1959352827072145, 'training_loss': 15.361067352294922}
{'R_grad_norm': 3.191184446811676, 'training_loss': 15.372809467315674}
{'R_grad_norm': 3.2060951256752013, 'training_loss': 15.434589834213257}
{'R_grad_norm': 3.204958097934723, 'training_loss': 15.42885679244995}
{'R_grad_norm': 3.1872628819942475, 'training_loss': 15.354314293861389}
{'R_grad_norm': 3.2004531598091126, 'training_loss': 15.441281905174256}
{'R_grad_norm': 3.206594524383545, 'training_loss': 15.441131229400634}
{'R_grad_norm': 3.1936957466602327, 'training_loss': 15.37871293067932}
{'R_grad_norm': 3.1892050445079803, 'training_loss': 15.365318388938904}
{'R_grad_norm': 3.1975063276290894, 'training_loss': 15.431065669059754}
{'R_grad_norm': 3.181953227519989, 'training_loss': 15.34990596294403}
{'R_grad_norm': 3.187374861240387, 'training_loss': 15.411218681335448}
{'R_grad_norm': 3.188531142473221, 'training_loss': 15.374906144142152}
{'R_grad_norm': 3.193453001976013, 'training_loss': 15.426237244606018}
{'R_grad_norm': 3.1837646436691283, 'training_loss': 15.35698485851288}
{'R_grad_norm': 3.185739680528641, 'training_loss': 15.40128785610199}
{'R_grad_norm': 3.181334624290466, 'training_loss': 15.359707999229432}
{'R_grad_norm': 3.179337817430496, 'training_loss': 15.376146922111511}
{'R_grad_norm': 3.176650313138962, 'training_loss': 15.386034941673278}
{'R_grad_norm': 3.1736362981796264, 'training_loss': 15.370396399497986}
{'R_grad_norm': 3.1806816303730012, 'training_loss': 15.433507342338562}
eval result tensor([32.36037, 19.86712, 21.02381, 23.91028, 24.03276, 11.24098,  9.01887,
        12.05236, 12.76415, 11.03036, 11.80053, 11.21405, 11.88923, 12.61093,
        11.53773, 13.27817, 12.06878], device='cuda:0')
computing merge metric
normed mi [((10, 15), 0.04720752686262131), ((8, 15), 0.045878101140260696), ((9, 11), 0.04580560699105263), ((13, 16), 0.04459403455257416), ((11, 16), 0.04435606300830841), ((2, 7), 0.0438986619313558), ((8, 16), 0.04376031458377838), ((9, 16), 0.043272413313388824), ((10, 16), 0.0430486761033535), ((15, 16), 0.04295754432678223), ((11, 13), 0.04272976145148277), ((8, 13), 0.042476680129766464), ((8, 10), 0.04240339249372482), ((10, 13), 0.04197349399328232), ((8, 9), 0.04197167605161667), ((13, 15), 0.04177027568221092), ((4, 10), 0.04148622850577036), ((8, 11), 0.04130451753735542), ((9, 13), 0.041201695799827576), ((7, 9), 0.04047536849975586), ((10, 11), 0.04039221629500389), ((9, 10), 0.04010963439941406), ((3, 7), 0.03873888651529948), ((9, 15), 0.03853822499513626), ((7, 11), 0.038247253745794296), ((11, 15), 0.03759607672691345), ((1, 9), 0.0369168221950531), ((3, 4), 0.03670744597911835), ((1, 11), 0.03656950841347376), ((4, 15), 0.03638445337613424), ((7, 13), 0.036015450954437256), ((7, 16), 0.03556861728429794), ((4, 11), 0.03547127544879913), ((4, 16), 0.03523929168780645), ((4, 9), 0.03481010099252065), ((7, 8), 0.034596312791109085), ((6, 9), 0.0344519205391407), ((2, 9), 0.034273333847522736), ((4, 13), 0.03412900616725286), ((1, 16), 0.03374374657869339), ((1, 7), 0.033655104537804924), ((0, 2), 0.03362290561199188), ((4, 7), 0.03345775852600733), ((1, 2), 0.03344569727778435), ((2, 3), 0.033366609364748), ((7, 15), 0.03328106179833412), ((1, 13), 0.033275529742240906), ((6, 7), 0.0332261323928833), ((3, 15), 0.03309005002180735), ((6, 12), 0.032989684492349625), ((7, 10), 0.032865215092897415), ((2, 4), 0.03236612677574158), ((2, 11), 0.032025814056396484), ((3, 9), 0.03165718664725622), ((1, 8), 0.03152771790822347), ((0, 3), 0.03134512404600779), ((4, 8), 0.031208460529645283), ((2, 6), 0.029988522330919903), ((3, 13), 0.02984282374382019), ((3, 8), 0.02938170979420344), ((3, 16), 0.029287440081437428), ((3, 10), 0.029221127430597942), ((0, 7), 0.028999796509742735), ((3, 11), 0.028956073025862377), ((2, 16), 0.02856554090976715), ((0, 9), 0.02843930423259735), ((2, 13), 0.028029195964336395), ((2, 8), 0.028012648224830627), ((0, 4), 0.027902357280254364), ((1, 10), 0.027892448008060455), ((1, 4), 0.026740366593003273), ((1, 15), 0.026590272784233093), ((3, 6), 0.026450589299201965), ((12, 14), 0.026280242949724197), ((0, 1), 0.026164541641871136), ((6, 11), 0.02584194578230381), ((2, 15), 0.025768111149470013), ((0, 11), 0.025100189447402953), ((6, 15), 0.024519819766283035), ((4, 6), 0.02441226691007614), ((2, 10), 0.024359628558158875), ((6, 8), 0.024000918492674828), ((0, 16), 0.02370109558105469), ((6, 16), 0.023682579398155212), ((1, 3), 0.023595089092850685), ((6, 14), 0.023388821631669998), ((0, 8), 0.023272979259490966), ((0, 6), 0.022710558772087098), ((6, 10), 0.02245662361383438), ((0, 15), 0.022139003872871398), ((0, 13), 0.022132259607315064), ((1, 6), 0.022009621063868206), ((6, 13), 0.021958427503705025), ((0, 10), 0.020612695813179018), ((5, 7), 0.01993405818939209), ((5, 10), 0.01783788576722145), ((4, 5), 0.0177728570997715), ((5, 6), 0.017679909244179726), ((2, 5), 0.017479790995518368), ((7, 12), 0.017360862344503403), ((5, 9), 0.0171479731798172), ((5, 15), 0.015684833750128746), ((2, 12), 0.015221919864416122), ((3, 12), 0.015004380295674006), ((5, 8), 0.014893464744091034), ((5, 11), 0.014668763615190983), ((5, 16), 0.014532585628330708), ((5, 13), 0.014281529001891613), ((4, 12), 0.013557463884353638), ((3, 5), 0.01327201227347056), ((9, 12), 0.01221581269055605), ((5, 12), 0.012087026610970497), ((7, 14), 0.011362600140273571), ((1, 5), 0.011267855763435364), ((12, 15), 0.011260106228291988), ((0, 12), 0.01016802415251732), ((0, 5), 0.010109439492225647), ((2, 14), 0.010043980553746223), ((5, 14), 0.01002537738531828), ((11, 12), 0.009765567258000374), ((12, 16), 0.009763181209564209), ((12, 13), 0.009731960482895374), ((8, 12), 0.009538818150758743), ((10, 12), 0.009324189275503159), ((4, 14), 0.008779464289546013), ((9, 14), 0.008087768219411373), ((3, 14), 0.007018265003959338), ((10, 14), 0.0069052306935191154), ((14, 15), 0.0068524181842803955), ((1, 12), 0.006750589857498805), ((11, 14), 0.006718763150274754), ((8, 14), 0.006245824974030256), ((13, 14), 0.006147431209683418), ((14, 16), 0.006057839374989271), ((0, 14), 0.00573463998734951), ((1, 14), 0.005418422321478526)]
******* after merging (0.04): [((0,), 128), ((10, 15), 64), ((9, 11), 64), ((1,), 64), ((2,), 64), ((3,), 64), ((4,), 64), ((5,), 32), ((6,), 32), ((7,), 32), ((8,), 32), ((12,), 32), ((13,), 32), ((14,), 32), ((16,), 32)]
{'R_grad_norm': 3.369184430837631, 'training_loss': 16.891621527671813}
{'R_grad_norm': 3.357525163888931, 'training_loss': 16.83624080181122}
{'R_grad_norm': 3.357882934808731, 'training_loss': 16.82108648777008}
{'R_grad_norm': 3.356410502195358, 'training_loss': 16.82875065803528}
{'R_grad_norm': 3.3634987127780915, 'training_loss': 16.853700823783875}
{'R_grad_norm': 3.368810999393463, 'training_loss': 16.862436537742614}
{'R_grad_norm': 3.3547923135757447, 'training_loss': 16.828020548820497}
{'R_grad_norm': 3.349286779165268, 'training_loss': 16.798016924858093}
{'R_grad_norm': 3.350573008060455, 'training_loss': 16.80848424434662}
{'R_grad_norm': 3.3408671402931214, 'training_loss': 16.7757869386673}
{'R_grad_norm': 3.345618063211441, 'training_loss': 16.784272985458372}
{'R_grad_norm': 3.345199761390686, 'training_loss': 16.807814402580263}
{'R_grad_norm': 3.3487523210048677, 'training_loss': 16.80484428882599}
{'R_grad_norm': 3.348637444972992, 'training_loss': 16.79350562095642}
{'R_grad_norm': 3.349779508113861, 'training_loss': 16.84009165287018}
{'R_grad_norm': 3.342395913600922, 'training_loss': 16.80594343185425}
{'R_grad_norm': 3.336457179784775, 'training_loss': 16.74215382575989}
{'R_grad_norm': 3.343171203136444, 'training_loss': 16.75583384037018}
{'R_grad_norm': 3.342459353208542, 'training_loss': 16.81782469749451}
{'R_grad_norm': 3.3377452373504637, 'training_loss': 16.75769359111786}
{'R_grad_norm': 3.337292490005493, 'training_loss': 16.798178100585936}
{'R_grad_norm': 3.331256766319275, 'training_loss': 16.712609391212464}
{'R_grad_norm': 3.3347269535064696, 'training_loss': 16.77071321964264}
{'R_grad_norm': 3.338206812143326, 'training_loss': 16.785914154052733}
{'R_grad_norm': 3.3289914393424986, 'training_loss': 16.763228793144226}
{'R_grad_norm': 3.3205441522598265, 'training_loss': 16.73070097923279}
{'R_grad_norm': 3.328965861797333, 'training_loss': 16.797058095932005}
{'R_grad_norm': 3.3340759873390198, 'training_loss': 16.811076202392577}
{'R_grad_norm': 3.3215326833724976, 'training_loss': 16.736441588401796}
{'R_grad_norm': 3.327058538198471, 'training_loss': 16.765441341400148}
{'R_grad_norm': 3.3228233671188354, 'training_loss': 16.74544680595398}
{'R_grad_norm': 3.3240098679065704, 'training_loss': 16.757533955574036}
{'R_grad_norm': 3.3161085188388824, 'training_loss': 16.76382161140442}
{'R_grad_norm': 3.3228035879135134, 'training_loss': 16.824924969673155}
{'R_grad_norm': 3.321777913570404, 'training_loss': 16.77694007873535}
{'R_grad_norm': 3.3177818036079407, 'training_loss': 16.758676772117614}
{'R_grad_norm': 3.318289113044739, 'training_loss': 16.785920748710634}
{'R_grad_norm': 3.3193707811832427, 'training_loss': 16.752576060295105}
{'R_grad_norm': 3.31265483379364, 'training_loss': 16.73566265583038}
{'R_grad_norm': 3.3067067646980286, 'training_loss': 16.717081174850463}
eval result tensor([34.60376, 21.68319, 17.27174, 19.32132, 20.37302, 23.52277, 23.44500,
        11.07203,  8.81164, 11.59029, 12.28287, 11.54437, 12.07755, 11.37906,
        11.40353], device='cuda:0')
computing merge metric
normed mi [((12, 14), 0.043278682976961136), ((4, 9), 0.04325986901919047), ((10, 14), 0.043071988970041275), ((10, 12), 0.04181802272796631), ((5, 9), 0.03716147939364115), ((2, 14), 0.03709339598814646), ((1, 10), 0.03659834464391073), ((5, 6), 0.03591665253043175), ((2, 3), 0.03583162650465965), ((9, 14), 0.035354748368263245), ((9, 12), 0.035090427845716476), ((2, 10), 0.03475263218084971), ((8, 11), 0.034599948674440384), ((2, 12), 0.034499071538448334), ((1, 6), 0.03445747122168541), ((9, 10), 0.034384600818157196), ((1, 14), 0.034194973607858024), ((1, 12), 0.03409062325954437), ((0, 4), 0.03386302540699641), ((3, 9), 0.033678693075974785), ((3, 14), 0.033606251080830894), ((3, 4), 0.03326201066374779), ((3, 12), 0.03264293819665909), ((6, 9), 0.03262567768494288), ((6, 14), 0.032452176014582314), ((4, 5), 0.03207007423043251), ((4, 6), 0.03177901357412338), ((6, 12), 0.03162506471077601), ((8, 9), 0.03133723884820938), ((3, 10), 0.03119775156180064), ((0, 5), 0.030969828367233276), ((2, 9), 0.03072855869928996), ((6, 10), 0.029767659803231556), ((2, 6), 0.02963528409600258), ((2, 4), 0.028935275971889496), ((0, 9), 0.028813841938972472), ((0, 6), 0.028667517006397247), ((0, 2), 0.028526668747266132), ((1, 2), 0.02842455357313156), ((5, 10), 0.02841637780268987), ((5, 12), 0.028080421189467113), ((5, 14), 0.0275656854112943), ((4, 14), 0.027553630371888477), ((4, 10), 0.027446816364924114), ((0, 3), 0.02736574411392212), ((4, 8), 0.02719887097676595), ((1, 5), 0.027052609249949455), ((4, 12), 0.02678035944700241), ((3, 6), 0.02622806467115879), ((11, 13), 0.024701645597815514), ((1, 9), 0.024540203313032787), ((0, 14), 0.024134698510169982), ((8, 13), 0.023986462503671646), ((0, 10), 0.023777048289775848), ((1, 3), 0.02358579821884632), ((5, 8), 0.02356243133544922), ((3, 5), 0.023308398202061653), ((2, 5), 0.023192159831523895), ((6, 8), 0.02270139753818512), ((0, 12), 0.022510965168476105), ((2, 8), 0.02209147810935974), ((8, 10), 0.021897923201322556), ((8, 14), 0.02171158976852894), ((0, 1), 0.021611216167608898), ((3, 8), 0.021301659444967907), ((1, 4), 0.020380504429340363), ((7, 9), 0.019997915253043175), ((8, 12), 0.019402965903282166), ((0, 8), 0.0192489892244339), ((6, 7), 0.01798924431204796), ((4, 7), 0.017375060667594273), ((7, 8), 0.017171382904052734), ((9, 11), 0.015948571264743805), ((1, 8), 0.01544386645158132), ((7, 10), 0.014701934531331062), ((4, 11), 0.014223010589679083), ((7, 14), 0.014128008857369423), ((7, 12), 0.014050012454390526), ((5, 11), 0.013463497161865234), ((5, 7), 0.012998073051373163), ((6, 11), 0.01284558450182279), ((1, 7), 0.012582516918579737), ((2, 7), 0.011682702849308649), ((7, 11), 0.011582453735172749), ((3, 7), 0.01127633328239123), ((9, 13), 0.010065173730254173), ((0, 7), 0.00990610420703888), ((7, 13), 0.009017580188810825), ((0, 11), 0.008919361978769302), ((4, 13), 0.00887219545741876), ((11, 14), 0.008748243562877178), ((11, 12), 0.008710861206054688), ((10, 11), 0.008529867976903915), ((6, 13), 0.0077379972984393435), ((3, 11), 0.006809570516149203), ((5, 13), 0.0056086306770642596), ((2, 11), 0.005529151608546575), ((10, 13), 0.005150512792170048), ((12, 13), 0.005118251778185368), ((13, 14), 0.005066935904324055), ((3, 13), 0.0048795171702901525), ((2, 13), 0.004699675676723321), ((1, 11), 0.0045828791335225105), ((0, 13), 0.004542850330471993), ((1, 13), 0.003452419303357601)]
******* after merging (0.04): [((0,), 128), ((12, 14), 64), ((1,), 64), ((2,), 64), ((3,), 64), ((4,), 64), ((5,), 64), ((6,), 64), ((7,), 32), ((8,), 32), ((9,), 32), ((10,), 32), ((11,), 32), ((13,), 32)]
{'R_grad_norm': 3.4158456456661224, 'training_loss': 17.58057231903076}
{'R_grad_norm': 3.4155409133434294, 'training_loss': 17.628885860443116}
{'R_grad_norm': 3.4219138646125793, 'training_loss': 17.572749147415163}
{'R_grad_norm': 3.4168676030635834, 'training_loss': 17.61911473274231}
{'R_grad_norm': 3.4159142601490022, 'training_loss': 17.58247986793518}
{'R_grad_norm': 3.409892464876175, 'training_loss': 17.56098006248474}
{'R_grad_norm': 3.420145266056061, 'training_loss': 17.639842109680174}
{'R_grad_norm': 3.423457057476044, 'training_loss': 17.634142961502075}
{'R_grad_norm': 3.3994976365566254, 'training_loss': 17.54538510322571}
{'R_grad_norm': 3.401647448539734, 'training_loss': 17.574116783142088}
{'R_grad_norm': 3.403368809223175, 'training_loss': 17.527480945587158}
{'R_grad_norm': 3.411791989803314, 'training_loss': 17.596508893966675}
{'R_grad_norm': 3.4001305961608885, 'training_loss': 17.536768369674682}
{'R_grad_norm': 3.3981974828243255, 'training_loss': 17.53677240371704}
{'R_grad_norm': 3.3890704703330994, 'training_loss': 17.45719223022461}
{'R_grad_norm': 3.399106066226959, 'training_loss': 17.55948793411255}
{'R_grad_norm': 3.3948163199424743, 'training_loss': 17.53097243309021}
{'R_grad_norm': 3.3936432230472566, 'training_loss': 17.536257104873656}
{'R_grad_norm': 3.390715866088867, 'training_loss': 17.525561656951904}
{'R_grad_norm': 3.392106637954712, 'training_loss': 17.470809688568114}
{'R_grad_norm': 3.3770263814926147, 'training_loss': 17.4545028591156}
{'R_grad_norm': 3.3765404510498045, 'training_loss': 17.463185205459595}
{'R_grad_norm': 3.3863361740112303, 'training_loss': 17.568676443099974}
{'R_grad_norm': 3.3784892213344575, 'training_loss': 17.485503368377685}
{'R_grad_norm': 3.386460678577423, 'training_loss': 17.506794743537903}
{'R_grad_norm': 3.380251990556717, 'training_loss': 17.521265602111818}
{'R_grad_norm': 3.3776187932491304, 'training_loss': 17.479108781814574}
{'R_grad_norm': 3.384051377773285, 'training_loss': 17.501663045883177}
{'R_grad_norm': 3.36557156085968, 'training_loss': 17.484880924224854}
{'R_grad_norm': 3.372334440946579, 'training_loss': 17.49476760864258}
{'R_grad_norm': 3.3710678577423097, 'training_loss': 17.466977071762084}
{'R_grad_norm': 3.3689623713493346, 'training_loss': 17.450621995925903}
{'R_grad_norm': 3.3616381418704986, 'training_loss': 17.4801567363739}
{'R_grad_norm': 3.373856807947159, 'training_loss': 17.512067213058472}
{'R_grad_norm': 3.3595253825187683, 'training_loss': 17.4788880109787}
{'R_grad_norm': 3.355780392885208, 'training_loss': 17.453052620887757}
{'R_grad_norm': 3.356928505897522, 'training_loss': 17.421111402511595}
{'R_grad_norm': 3.355271190404892, 'training_loss': 17.455033864974975}
{'R_grad_norm': 3.360202275514603, 'training_loss': 17.454071264266968}
{'R_grad_norm': 3.3507729887962343, 'training_loss': 17.44483744621277}
eval result tensor([38.10466, 19.49035, 21.83051, 15.10344, 18.77138, 19.65019, 22.72623,
        22.88519, 10.96118,  8.76159, 11.27510, 11.83355, 11.32996, 11.29121],
       device='cuda:0')
computing merge metric
normed mi [((5, 10), 0.04292631149291992), ((3, 4), 0.039193328469991684), ((3, 10), 0.03755931804577509), ((3, 5), 0.037362389266490936), ((6, 10), 0.037049671014149986), ((2, 11), 0.035831441481908165), ((10, 11), 0.0353512316942215), ((1, 11), 0.0353418638308843), ((6, 7), 0.03511542081832886), ((9, 12), 0.034878406673669815), ((2, 7), 0.034852802753448486), ((4, 10), 0.03457201768954595), ((3, 11), 0.03385648379723231), ((0, 5), 0.03372100740671158), ((4, 5), 0.03371018171310425), ((0, 3), 0.033281728625297546), ((7, 10), 0.03271842251221339), ((4, 11), 0.03258614242076874), ((5, 6), 0.03191081061959267), ((3, 7), 0.031542062759399414), ((1, 4), 0.031263258308172226), ((5, 7), 0.031147340312600136), ((3, 9), 0.031103660662968952), ((0, 6), 0.031027354300022125), ((9, 10), 0.030970405787229538), ((1, 2), 0.030333910137414932), ((3, 6), 0.03007221780717373), ((1, 3), 0.02985132671892643), ((0, 7), 0.02941090116898219), ((7, 11), 0.029349001745382946), ((0, 10), 0.028780195116996764), ((5, 9), 0.02842261642217636), ((6, 11), 0.028181634843349457), ((0, 4), 0.028008659680684406), ((2, 6), 0.02770819328725338), ((5, 11), 0.02744759867588679), ((4, 7), 0.026568865403532982), ((1, 7), 0.0260926503688097), ((2, 3), 0.02548830769956112), ((1, 10), 0.025439115862051647), ((2, 10), 0.024846116701761883), ((12, 13), 0.02476460672914982), ((0, 11), 0.02433159351348877), ((9, 13), 0.02415177784860134), ((4, 6), 0.023767560720443726), ((6, 9), 0.023652647932370503), ((7, 9), 0.023164207736651104), ((2, 4), 0.022920940071344376), ((0, 2), 0.022419820229212444), ((9, 11), 0.02232149988412857), ((4, 9), 0.022093976537386577), ((1, 5), 0.02076495997607708), ((0, 1), 0.020760513842105865), ((2, 5), 0.02017775923013687), ((8, 10), 0.019917557016015053), ((7, 8), 0.018588801225026447), ((1, 6), 0.01793494261801243), ((5, 8), 0.017587936172882717), ((8, 9), 0.017364488914608955), ((0, 9), 0.016682153940200804), ((2, 9), 0.016298484057188034), ((10, 12), 0.015195953659713268), ((8, 11), 0.01454565953463316), ((1, 9), 0.014349530140558878), ((5, 12), 0.014346593370040258), ((6, 12), 0.013238787651062012), ((3, 8), 0.012952064474423727), ((7, 12), 0.012883119285106659), ((6, 8), 0.012804122020800909), ((2, 8), 0.012382968018452326), ((8, 12), 0.011593717150390148), ((4, 8), 0.011471190800269445), ((10, 13), 0.010095315985381603), ((3, 12), 0.009443354482452074), ((0, 8), 0.009327442944049835), ((5, 13), 0.00928376242518425), ((1, 8), 0.009214801092942556), ((8, 13), 0.008750323206186295), ((0, 12), 0.008519987016916275), ((11, 12), 0.008376759476959705), ((7, 13), 0.008196044713258743), ((4, 12), 0.007037232319513957), ((3, 13), 0.006723030159870784), ((6, 13), 0.005752875780065854), ((11, 13), 0.005450558383017778), ((4, 13), 0.00531973938147227), ((2, 12), 0.005053346355756124), ((0, 13), 0.004231199249625206), ((2, 13), 0.0036257877945899963), ((1, 13), 0.003578719993432363), ((1, 12), 0.0026812956978877387)]
******* after merging (0.04): [((0,), 128), ((5, 10), 96), ((1,), 64), ((2,), 64), ((3,), 64), ((4,), 64), ((6,), 64), ((7,), 64), ((8,), 32), ((9,), 32), ((11,), 32), ((12,), 32), ((13,), 32)]
{'R_grad_norm': 3.517786684036255, 'training_loss': 18.3634486579895}
{'R_grad_norm': 3.5137146353721618, 'training_loss': 18.334855489730835}
{'R_grad_norm': 3.513412001132965, 'training_loss': 18.372194995880125}
{'R_grad_norm': 3.517353299856186, 'training_loss': 18.342824840545653}
{'R_grad_norm': 3.5113137757778166, 'training_loss': 18.349299182891844}
{'R_grad_norm': 3.50233029961586, 'training_loss': 18.303701696395873}
{'R_grad_norm': 3.499745992422104, 'training_loss': 18.269074087142943}
{'R_grad_norm': 3.504455952644348, 'training_loss': 18.296246404647828}
{'R_grad_norm': 3.5233513474464417, 'training_loss': 18.40083095550537}
{'R_grad_norm': 3.5256381285190583, 'training_loss': 18.4085582447052}
{'R_grad_norm': 3.5419320940971373, 'training_loss': 18.50984357833862}
{'R_grad_norm': 3.547970012426376, 'training_loss': 18.51526759147644}
{'R_grad_norm': 3.56113790512085, 'training_loss': 18.545837955474852}
{'R_grad_norm': 3.5758013355731966, 'training_loss': 18.62266053199768}
{'R_grad_norm': 3.5834726119041442, 'training_loss': 18.69416904449463}
{'R_grad_norm': 3.584737720489502, 'training_loss': 18.703693504333497}
{'R_grad_norm': 3.612849818468094, 'training_loss': 18.82815975189209}
{'R_grad_norm': 3.627044222354889, 'training_loss': 18.972479648590088}
{'R_grad_norm': 3.6407111120224, 'training_loss': 19.016931190490723}
{'R_grad_norm': 3.6638749754428863, 'training_loss': 19.131583251953124}
{'R_grad_norm': 3.6910378527641297, 'training_loss': 19.289056730270385}
{'R_grad_norm': 3.722042590379715, 'training_loss': 19.47800980567932}
{'R_grad_norm': 3.75325798034668, 'training_loss': 19.63263033866882}
{'R_grad_norm': 3.539428960084915, 'training_loss': 18.60159860610962}
{'R_grad_norm': 3.4829480195045472, 'training_loss': 18.298069620132445}
{'R_grad_norm': 3.47678365111351, 'training_loss': 18.34499611854553}
{'R_grad_norm': 3.4722001552581787, 'training_loss': 18.317733192443846}
{'R_grad_norm': 3.4666925847530363, 'training_loss': 18.235846042633057}
{'R_grad_norm': 3.472040721178055, 'training_loss': 18.272006969451905}
{'R_grad_norm': 3.4780359840393067, 'training_loss': 18.343273639678955}
{'R_grad_norm': 3.4707752001285552, 'training_loss': 18.303804893493652}
{'R_grad_norm': 3.464283093214035, 'training_loss': 18.292408180236816}
{'R_grad_norm': 3.466092846393585, 'training_loss': 18.29245909690857}
{'R_grad_norm': 3.4672077775001524, 'training_loss': 18.267959060668947}
{'R_grad_norm': 3.464303028583527, 'training_loss': 18.281053771972655}
{'R_grad_norm': 3.468092796802521, 'training_loss': 18.29283525466919}
{'R_grad_norm': 3.4615255069732664, 'training_loss': 18.243388490676878}
{'R_grad_norm': 3.4566520142555235, 'training_loss': 18.25512903213501}
{'R_grad_norm': 3.467884376049042, 'training_loss': 18.324065427780152}
{'R_grad_norm': 3.456449875831604, 'training_loss': 18.27646592140198}
eval result tensor([40.23788, 25.86152, 18.78228, 22.05696, 14.84177, 17.98004, 21.64277,
        22.37310, 10.93994,  8.79368, 11.48183, 11.16389, 11.17455],
       device='cuda:0')
computing merge metric
normed mi [((4, 5), 0.04026677459478378), ((2, 10), 0.03455674151579539), ((9, 11), 0.03454410657286644), ((3, 10), 0.034067188700040184), ((3, 7), 0.033966001123189926), ((4, 9), 0.03354125966628393), ((6, 7), 0.03330579027533531), ((1, 4), 0.03286363184452057), ((5, 10), 0.03254001587629318), ((0, 4), 0.03249887625376383), ((4, 10), 0.03247536222139994), ((4, 6), 0.03209875896573067), ((2, 5), 0.03174849972128868), ((4, 7), 0.03172862157225609), ((0, 6), 0.030463628470897675), ((0, 1), 0.030439300196511403), ((1, 5), 0.029616725444793702), ((0, 7), 0.029288336634635925), ((2, 4), 0.029286732897162437), ((2, 3), 0.027977511286735535), ((7, 10), 0.02760882427295049), ((0, 5), 0.02749069780111313), ((3, 6), 0.027404364198446274), ((1, 6), 0.026815855503082277), ((5, 7), 0.026404673233628273), ((6, 10), 0.02579036106665929), ((1, 7), 0.02555258572101593), ((2, 7), 0.025433575734496117), ((3, 4), 0.024587256833910942), ((11, 12), 0.02396620251238346), ((5, 6), 0.02387727051973343), ((0, 10), 0.02288062423467636), ((9, 12), 0.022870279848575592), ((6, 9), 0.0223998228708903), ((7, 9), 0.022343464195728302), ((3, 5), 0.02218763343989849), ((0, 3), 0.02207337071498235), ((1, 10), 0.021962780505418777), ((5, 9), 0.021791671713193256), ((9, 10), 0.02045552432537079), ((0, 2), 0.01964687431852023), ((1, 9), 0.018739648163318634), ((1, 2), 0.018679811060428618), ((7, 8), 0.01845753441254298), ((1, 3), 0.01766972094774246), ((8, 9), 0.016931895166635513), ((3, 9), 0.015710995843013126), ((2, 6), 0.015698010101914406), ((0, 9), 0.015235866606235503), ((8, 10), 0.01426863856613636), ((4, 8), 0.014145397891600927), ((2, 9), 0.013722023616234461), ((6, 8), 0.012544962267080942), ((1, 8), 0.012489352375268936), ((7, 11), 0.0123442014058431), ((6, 11), 0.012095189342896143), ((3, 8), 0.011946815997362137), ((8, 11), 0.011705209501087666), ((5, 8), 0.011362690478563309), ((4, 11), 0.010783941795428595), ((1, 11), 0.009634720161557198), ((0, 8), 0.009372583776712417), ((2, 8), 0.008831235269705454), ((8, 12), 0.00861850194633007), ((0, 11), 0.008307685703039169), ((7, 12), 0.007781334842244784), ((10, 11), 0.007715825457125902), ((5, 11), 0.00710988665620486), ((4, 12), 0.007009786864121755), ((1, 12), 0.006084181368350983), ((3, 11), 0.005281394347548485), ((6, 12), 0.005191933053235213), ((5, 12), 0.004987784661352634), ((10, 12), 0.004969651810824871), ((0, 12), 0.003904004395008087), ((2, 12), 0.003430045830706755), ((3, 12), 0.0033516275386015573), ((2, 11), 0.0028474734475215278)]
******* after merging (0.04): [((4, 5), 128), ((0,), 128), ((1,), 96), ((2,), 64), ((3,), 64), ((6,), 64), ((7,), 64), ((8,), 32), ((9,), 32), ((10,), 32), ((11,), 32), ((12,), 32)]
{'R_grad_norm': 3.661722275018692, 'training_loss': 19.187048616409303}
{'R_grad_norm': 3.6464537394046785, 'training_loss': 19.10028956413269}
{'R_grad_norm': 3.6529569208621977, 'training_loss': 19.15465040206909}
{'R_grad_norm': 3.652118270397186, 'training_loss': 19.15901113510132}
{'R_grad_norm': 3.6493940341472624, 'training_loss': 19.107044610977173}
{'R_grad_norm': 3.6530113899707795, 'training_loss': 19.159681520462037}
{'R_grad_norm': 3.6512545120716093, 'training_loss': 19.10995443344116}
{'R_grad_norm': 3.6407342195510863, 'training_loss': 19.06624949455261}
{'R_grad_norm': 3.6500253665447233, 'training_loss': 19.160873413085938}
{'R_grad_norm': 3.647599358558655, 'training_loss': 19.098542356491087}
{'R_grad_norm': 3.636793752908707, 'training_loss': 19.053796911239623}
{'R_grad_norm': 3.633791922330856, 'training_loss': 19.02968276977539}
{'R_grad_norm': 3.6333062636852262, 'training_loss': 19.03408974647522}
{'R_grad_norm': 3.6393584382534026, 'training_loss': 19.062941246032715}
{'R_grad_norm': 3.6322571849822998, 'training_loss': 19.079175815582275}
{'R_grad_norm': 3.6336408376693727, 'training_loss': 19.043709468841552}
{'R_grad_norm': 3.640932848453522, 'training_loss': 19.12079201698303}
{'R_grad_norm': 3.6276033544540405, 'training_loss': 19.05161534309387}
{'R_grad_norm': 3.6328516578674317, 'training_loss': 19.102364530563353}
{'R_grad_norm': 3.617638164758682, 'training_loss': 19.009686059951783}
{'R_grad_norm': 3.622521164417267, 'training_loss': 19.0625905418396}
{'R_grad_norm': 3.6176466262340545, 'training_loss': 19.0215030002594}
{'R_grad_norm': 3.6166856014728546, 'training_loss': 19.03886315345764}
{'R_grad_norm': 3.617048898935318, 'training_loss': 18.99356589317322}
{'R_grad_norm': 3.6273994779586793, 'training_loss': 19.081603288650513}
{'R_grad_norm': 3.6197529911994932, 'training_loss': 19.046039209365844}
{'R_grad_norm': 3.616698035001755, 'training_loss': 19.03330948829651}
{'R_grad_norm': 3.6190903770923613, 'training_loss': 19.026725435256957}
{'R_grad_norm': 3.6254208278656006, 'training_loss': 19.070362195968627}
{'R_grad_norm': 3.6093914532661437, 'training_loss': 18.997968120574953}
{'R_grad_norm': 3.618615118265152, 'training_loss': 19.030835494995117}
{'R_grad_norm': 3.6147724425792696, 'training_loss': 19.020814809799194}
{'R_grad_norm': 3.6143247795104982, 'training_loss': 19.066108922958374}
{'R_grad_norm': 3.6107012021541594, 'training_loss': 19.0106112575531}
{'R_grad_norm': 3.6070225083827974, 'training_loss': 18.98956967353821}
{'R_grad_norm': 3.593123631477356, 'training_loss': 18.96022430419922}
{'R_grad_norm': 3.6126857113838198, 'training_loss': 19.040805101394653}
{'R_grad_norm': 3.611825156211853, 'training_loss': 19.075947160720826}
{'R_grad_norm': 3.608133074045181, 'training_loss': 19.06023808479309}
{'R_grad_norm': 3.6163774847984316, 'training_loss': 19.05899836540222}
eval result tensor([24.96919, 41.48705, 25.61625, 18.23886, 22.19468, 21.04351, 22.06977,
        10.84159,  8.68087, 11.10503, 10.94514, 11.14983], device='cuda:0')
computing merge metric
normed mi [((3, 9), 0.03409758458534876), ((8, 10), 0.033945441246032715), ((4, 6), 0.033505793660879135), ((5, 6), 0.031757570803165436), ((4, 9), 0.03170052170753479), ((1, 2), 0.02985872115407671), ((1, 5), 0.029237784445285797), ((1, 6), 0.028607850273450215), ((2, 5), 0.027084559202194214), ((6, 9), 0.02692689249912898), ((4, 5), 0.02686815895140171), ((3, 4), 0.02643514983355999), ((3, 6), 0.02536867745220661), ((5, 9), 0.025183153649171192), ((0, 1), 0.024964837357401848), ((2, 6), 0.024785065650939943), ((0, 2), 0.023913277047021047), ((0, 3), 0.023809005816777546), ((1, 9), 0.022363848984241486), ((0, 9), 0.022030752897262574), ((10, 11), 0.02200903370976448), ((8, 11), 0.021843409165740013), ((2, 9), 0.021567782387137413), ((1, 4), 0.021383653084437054), ((0, 6), 0.021098668376604717), ((1, 3), 0.01949250449736913), ((6, 8), 0.019358628739913303), ((0, 5), 0.01931564137339592), ((5, 8), 0.01922261839111646), ((2, 3), 0.017938314378261565), ((6, 7), 0.01793011650443077), ((8, 9), 0.017812712118029594), ((2, 4), 0.017128057777881622), ((0, 4), 0.01687932883699735), ((2, 8), 0.016342606395483017), ((3, 5), 0.015348849818110466), ((7, 8), 0.015297754667699337), ((7, 9), 0.013603742234408855), ((4, 8), 0.013491676499446234), ((0, 8), 0.01260838657617569), ((2, 7), 0.012497101910412312), ((5, 7), 0.012156454225381216), ((1, 8), 0.011764347553253174), ((4, 7), 0.011748394618431727), ((3, 8), 0.011740329364935556), ((6, 10), 0.011251905312140783), ((5, 10), 0.011074357976516088), ((7, 10), 0.010195381008088589), ((2, 10), 0.009213864803314209), ((1, 7), 0.008703670650720596), ((3, 7), 0.008572762832045555), ((7, 11), 0.007482812274247408), ((1, 10), 0.0073156081140041355), ((0, 7), 0.007272123545408249), ((9, 10), 0.007243699859827757), ((6, 11), 0.006450034057100614), ((2, 11), 0.005208565853536129), ((4, 10), 0.004906123814483483), ((0, 10), 0.004462819173932075), ((9, 11), 0.004435602109879255), ((5, 11), 0.004244432784616947), ((1, 11), 0.002973021753132343), ((3, 11), 0.0029083658009767532), ((0, 11), 0.0028911421075463297), ((4, 11), 0.0025606881827116013), ((3, 10), 0.002411863145728906)]
finish training (76000)
evaluating (25 steps)...
 ******* eval result *******
mean (weighted) 23.29797871907552
mean (unweighted) 18.9212703704834
tensor([24.75532, 41.32825, 25.41436, 18.11892, 22.10580, 20.87366, 21.91843,
        10.80852,  8.63437, 11.06766, 10.95501, 11.07493], device='cuda:0')
