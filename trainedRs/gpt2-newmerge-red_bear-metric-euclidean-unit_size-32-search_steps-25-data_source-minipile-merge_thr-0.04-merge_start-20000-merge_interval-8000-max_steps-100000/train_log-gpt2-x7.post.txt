{'R_grad_norm': 1.2466533142328262, 'training_loss': 8.438757982254028}
{'R_grad_norm': 1.2556972616910935, 'training_loss': 8.328883364200593}
{'R_grad_norm': 1.2651342195272446, 'training_loss': 8.178872337341309}
{'R_grad_norm': 1.2752659457921982, 'training_loss': 8.094507138729096}
{'R_grad_norm': 1.2826570177078247, 'training_loss': 8.004924826622009}
{'R_grad_norm': 1.2858456379175187, 'training_loss': 7.904928684234619}
{'R_grad_norm': 1.2921159827709199, 'training_loss': 7.850753779411316}
{'R_grad_norm': 1.2928505855798722, 'training_loss': 7.7605585813522335}
{'R_grad_norm': 1.2952880156040192, 'training_loss': 7.698039855957031}
{'R_grad_norm': 1.2968993657827377, 'training_loss': 7.636850905418396}
{'R_grad_norm': 1.294663971066475, 'training_loss': 7.585969452857971}
{'R_grad_norm': 1.2970050919055938, 'training_loss': 7.537321264743805}
{'R_grad_norm': 1.2967849153280258, 'training_loss': 7.494320056438446}
{'R_grad_norm': 1.2955098992586136, 'training_loss': 7.444695448875427}
{'R_grad_norm': 1.2959280860424043, 'training_loss': 7.428549151420594}
{'R_grad_norm': 1.2926194137334823, 'training_loss': 7.36283136844635}
{'R_grad_norm': 1.291255304813385, 'training_loss': 7.325676920413971}
{'R_grad_norm': 1.2943080013990402, 'training_loss': 7.33108690738678}
{'R_grad_norm': 1.2903022766113281, 'training_loss': 7.288294949531555}
{'R_grad_norm': 1.2954205811023711, 'training_loss': 7.302836320400238}
{'R_grad_norm': 1.2932882142066955, 'training_loss': 7.255895850658416}
{'R_grad_norm': 1.2925224500894545, 'training_loss': 7.218208048343659}
{'R_grad_norm': 1.293008301258087, 'training_loss': 7.224921064376831}
{'R_grad_norm': 1.2893109172582626, 'training_loss': 7.176487822532653}
{'R_grad_norm': 1.2887283444404602, 'training_loss': 7.15637033700943}
{'R_grad_norm': 1.2908519756793977, 'training_loss': 7.157193384170532}
{'R_grad_norm': 1.2906265246868134, 'training_loss': 7.130442576408386}
{'R_grad_norm': 1.2900110787153245, 'training_loss': 7.131728961467743}
{'R_grad_norm': 1.2865245831012726, 'training_loss': 7.0972299790382385}
{'R_grad_norm': 1.2882143545150757, 'training_loss': 7.088410177230835}
{'R_grad_norm': 1.2844743233919145, 'training_loss': 7.063807294368744}
{'R_grad_norm': 1.2891402757167816, 'training_loss': 7.078577561378479}
{'R_grad_norm': 1.281984965801239, 'training_loss': 7.026414613723755}
{'R_grad_norm': 1.284160511493683, 'training_loss': 7.037650468349457}
{'R_grad_norm': 1.284960234761238, 'training_loss': 7.043877060413361}
{'R_grad_norm': 1.2831210643053055, 'training_loss': 7.022016704082489}
{'R_grad_norm': 1.2838458979129792, 'training_loss': 7.021216180324554}
{'R_grad_norm': 1.282305535674095, 'training_loss': 6.997870137691498}
{'R_grad_norm': 1.281117240190506, 'training_loss': 6.981143627166748}
{'R_grad_norm': 1.2801151496171952, 'training_loss': 6.9822845458984375}
{'R_grad_norm': 1.2804577881097794, 'training_loss': 6.978603432178497}
{'R_grad_norm': 1.280576124191284, 'training_loss': 6.978261103630066}
{'R_grad_norm': 1.281302039027214, 'training_loss': 6.967698104381562}
{'R_grad_norm': 1.281365560889244, 'training_loss': 6.964545459747314}
{'R_grad_norm': 1.2790293598175049, 'training_loss': 6.953247299194336}
{'R_grad_norm': 1.27934430539608, 'training_loss': 6.948841469287872}
{'R_grad_norm': 1.2780440330505372, 'training_loss': 6.935335326194763}
{'R_grad_norm': 1.2797474056482314, 'training_loss': 6.960296175479889}
{'R_grad_norm': 1.2753162372112274, 'training_loss': 6.9218994235992435}
{'R_grad_norm': 1.275016776919365, 'training_loss': 6.921963531970977}
{'R_grad_norm': 1.278313965201378, 'training_loss': 6.934241914749146}
{'R_grad_norm': 1.2745388102531434, 'training_loss': 6.907407174110412}
{'R_grad_norm': 1.273632138967514, 'training_loss': 6.903570394515992}
{'R_grad_norm': 1.2742056405544282, 'training_loss': 6.903362834453583}
{'R_grad_norm': 1.2760951793193818, 'training_loss': 6.907160966396332}
{'R_grad_norm': 1.2735184782743454, 'training_loss': 6.888077826499939}
{'R_grad_norm': 1.2733122581243514, 'training_loss': 6.884589962959289}
{'R_grad_norm': 1.2739388579130173, 'training_loss': 6.883914587497711}
{'R_grad_norm': 1.2741074657440186, 'training_loss': 6.891856787204742}
{'R_grad_norm': 1.2724956566095351, 'training_loss': 6.879063065052033}
{'R_grad_norm': 1.2734815913438797, 'training_loss': 6.8706218934059144}
{'R_grad_norm': 1.2712103480100632, 'training_loss': 6.862937655448913}
{'R_grad_norm': 1.270527657866478, 'training_loss': 6.864769191741943}
{'R_grad_norm': 1.270823609828949, 'training_loss': 6.863911678791046}
{'R_grad_norm': 1.275857582092285, 'training_loss': 6.8879632878303525}
{'R_grad_norm': 1.2695640575885774, 'training_loss': 6.844529123306274}
{'R_grad_norm': 1.271507400870323, 'training_loss': 6.855126523971558}
{'R_grad_norm': 1.2685958445072174, 'training_loss': 6.853291084766388}
{'R_grad_norm': 1.2706761711835861, 'training_loss': 6.856148803234101}
{'R_grad_norm': 1.2666124659776687, 'training_loss': 6.819136300086975}
{'R_grad_norm': 1.2659511202573777, 'training_loss': 6.824121522903442}
{'R_grad_norm': 1.2669115149974823, 'training_loss': 6.831166274547577}
{'R_grad_norm': 1.2686149060726166, 'training_loss': 6.8293399500846865}
{'R_grad_norm': 1.2695773375034332, 'training_loss': 6.83806515455246}
{'R_grad_norm': 1.2671912705898285, 'training_loss': 6.823938088417053}
{'R_grad_norm': 1.2652968776226043, 'training_loss': 6.820198833942413}
{'R_grad_norm': 1.2678727048635483, 'training_loss': 6.821306698322296}
{'R_grad_norm': 1.2660253608226777, 'training_loss': 6.821239757537842}
{'R_grad_norm': 1.266422929763794, 'training_loss': 6.817778820991516}
{'R_grad_norm': 1.2647617828845978, 'training_loss': 6.80379136800766}
{'R_grad_norm': 1.267349054813385, 'training_loss': 6.829029011726379}
{'R_grad_norm': 1.264086326956749, 'training_loss': 6.803686001300812}
{'R_grad_norm': 1.2611379367113114, 'training_loss': 6.779762752056122}
{'R_grad_norm': 1.2644941681623458, 'training_loss': 6.790474536418915}
{'R_grad_norm': 1.2635801583528519, 'training_loss': 6.790063478946686}
{'R_grad_norm': 1.2640070021152496, 'training_loss': 6.806111052036285}
{'R_grad_norm': 1.2626499652862548, 'training_loss': 6.785588791370392}
{'R_grad_norm': 1.2637230718135835, 'training_loss': 6.809123277664185}
{'R_grad_norm': 1.2576824229955674, 'training_loss': 6.770097391605377}
{'R_grad_norm': 1.2588795399665833, 'training_loss': 6.75760055065155}
{'R_grad_norm': 1.2569690710306167, 'training_loss': 6.76509664773941}
{'R_grad_norm': 1.2624811828136444, 'training_loss': 6.784174299240112}
{'R_grad_norm': 1.2583819538354875, 'training_loss': 6.766544167995453}
{'R_grad_norm': 1.2569076144695281, 'training_loss': 6.770459163188934}
{'R_grad_norm': 1.2567543625831603, 'training_loss': 6.76079115152359}
{'R_grad_norm': 1.2569093739986419, 'training_loss': 6.765146749019623}
{'R_grad_norm': 1.257414938211441, 'training_loss': 6.75742087841034}
{'R_grad_norm': 1.2529760444164275, 'training_loss': 6.740807721614837}
{'R_grad_norm': 1.2537607491016387, 'training_loss': 6.742484254837036}
{'R_grad_norm': 1.2536888718605042, 'training_loss': 6.742418327331543}
eval result tensor([6.01255, 6.66793, 7.41185, 6.86484, 5.47979, 5.79495, 5.42149, 6.68112,
        7.29399, 5.87680, 6.45519, 7.34061, 7.40268, 7.86539, 7.61603, 7.37765,
        6.45385, 6.69708, 7.04972, 5.12278, 5.89358, 8.74303, 5.83422, 7.61791],
       device='cuda:0')
computing merge metric
normed mi [((9, 20), 0.12474535405635834), ((6, 19), 0.11670267581939697), ((9, 19), 0.11648353934288025), ((19, 20), 0.1127525120973587), ((6, 9), 0.11148651689291), ((6, 20), 0.10833326727151871), ((5, 9), 0.10627744346857071), ((9, 22), 0.10550232976675034), ((12, 20), 0.10469549149274826), ((9, 12), 0.10444719344377518), ((5, 22), 0.10310854762792587), ((4, 19), 0.10299725085496902), ((20, 22), 0.10291288048028946), ((5, 20), 0.10278107225894928), ((9, 16), 0.10236888378858566), ((16, 20), 0.10131468623876572), ((0, 9), 0.10001584887504578), ((5, 6), 0.09970108419656754), ((0, 5), 0.09950699657201767), ((0, 6), 0.0986623466014862), ((0, 22), 0.09866147488355637), ((0, 20), 0.09670877456665039), ((6, 22), 0.09543277323246002), ((5, 19), 0.0950583890080452), ((0, 16), 0.09265540540218353), ((16, 22), 0.09246169030666351), ((6, 16), 0.0921478345990181), ((0, 19), 0.09109089523553848), ((5, 16), 0.09105325490236282), ((16, 19), 0.08960582315921783), ((19, 22), 0.0895528793334961), ((12, 16), 0.08661320805549622), ((4, 9), 0.08597831428050995), ((4, 20), 0.08550653606653214), ((12, 22), 0.08524374663829803), ((5, 12), 0.08387447893619537), ((12, 19), 0.08379841595888138), ((0, 7), 0.08288005739450455), ((4, 6), 0.08136971294879913), ((6, 12), 0.08074594289064407), ((7, 22), 0.08073841035366058), ((0, 12), 0.08007233589887619), ((5, 7), 0.07960723340511322), ((7, 16), 0.07739480584859848), ((7, 9), 0.07712390273809433), ((7, 20), 0.07706840336322784), ((10, 20), 0.0754518136382103), ((12, 21), 0.07498724013566971), ((10, 22), 0.07467348128557205), ((9, 10), 0.07457012683153152), ((10, 12), 0.07422672212123871), ((0, 10), 0.07351808995008469), ((5, 10), 0.07266082614660263), ((10, 16), 0.07255949825048447), ((6, 7), 0.0722111314535141), ((1, 22), 0.07153695821762085), ((0, 1), 0.07046017795801163), ((0, 3), 0.06994622945785522), ((7, 10), 0.06992357224225998), ((3, 22), 0.06884097307920456), ((1, 5), 0.06863363087177277), ((7, 12), 0.068508081138134), ((9, 21), 0.06716775894165039), ((3, 16), 0.06675966829061508), ((12, 18), 0.06646953523159027), ((3, 5), 0.0657377764582634), ((20, 21), 0.06558384746313095), ((3, 12), 0.06548416614532471), ((3, 9), 0.0654788687825203), ((1, 7), 0.06503203511238098), ((3, 20), 0.06467040628194809), ((7, 19), 0.06435097008943558), ((18, 22), 0.06332588195800781), ((3, 7), 0.06318499892950058), ((9, 18), 0.062679722905159), ((1, 9), 0.06258098781108856), ((0, 18), 0.062222160398960114), ((18, 20), 0.06209476292133331), ((3, 10), 0.06190680339932442), ((6, 10), 0.06178281083703041), ((1, 10), 0.06149987503886223), ((11, 12), 0.061346687376499176), ((16, 21), 0.060439202934503555), ((10, 18), 0.060355477035045624), ((1, 16), 0.06032124534249306), ((3, 18), 0.06020953133702278), ((1, 20), 0.06004435941576958), ((16, 18), 0.060028281062841415), ((5, 18), 0.059529516845941544), ((4, 16), 0.05943027883768082), ((7, 18), 0.059073708951473236), ((4, 5), 0.058576423674821854), ((4, 12), 0.0583832822740078), ((1, 3), 0.0581541433930397), ((4, 22), 0.05751964822411537), ((1, 12), 0.05709013342857361), ((17, 22), 0.0564667209982872), ((10, 19), 0.05591844394803047), ((9, 11), 0.055646877735853195), ((1, 6), 0.05561302602291107), ((0, 17), 0.05549347773194313), ((5, 17), 0.05518009141087532), ((11, 20), 0.054717618972063065), ((11, 22), 0.05461004003882408), ((19, 21), 0.05455731227993965), ((3, 6), 0.054555200040340424), ((0, 14), 0.05448998883366585), ((1, 14), 0.054428160190582275), ((11, 16), 0.0538782961666584), ((14, 22), 0.05377359315752983), ((0, 11), 0.05366797745227814), ((7, 14), 0.0536261647939682), ((0, 21), 0.05352348834276199), ((1, 18), 0.053496379405260086), ((5, 11), 0.053420308977365494), ((7, 17), 0.05301251634955406), ((21, 22), 0.05299309641122818), ((7, 23), 0.052399344742298126), ((0, 4), 0.052115511149168015), ((14, 16), 0.05205979570746422), ((5, 14), 0.052023060619831085), ((16, 17), 0.05194110423326492), ((1, 17), 0.051582351326942444), ((5, 21), 0.05150340124964714), ((10, 14), 0.051499780267477036), ((10, 11), 0.05109523981809616), ((12, 14), 0.051052674651145935), ((6, 21), 0.05097636952996254), ((3, 19), 0.050856590270996094), ((9, 17), 0.050671253353357315), ((10, 17), 0.050558362156152725), ((1, 23), 0.050464119762182236), ((3, 17), 0.0498514324426651), ((9, 14), 0.04981965944170952), ((3, 14), 0.04979221895337105), ((7, 11), 0.04956087842583656), ((6, 18), 0.049560073763132095), ((8, 23), 0.04918878898024559), ((1, 19), 0.0490947961807251), ((14, 20), 0.049087267369031906), ((3, 11), 0.04902137070894241), ((17, 20), 0.04885100573301315), ((10, 21), 0.04875729978084564), ((3, 23), 0.04871460795402527), ((14, 18), 0.04856498911976814), ((12, 17), 0.04854893684387207), ((14, 23), 0.048497121781110764), ((0, 23), 0.04839230328798294), ((11, 21), 0.047707799822092056), ((3, 21), 0.04741467535495758), ((7, 8), 0.047301653772592545), ((11, 18), 0.047272346913814545), ((10, 23), 0.04722250998020172), ((7, 21), 0.04674355313181877), ((16, 23), 0.04649130627512932), ((1, 11), 0.04640337452292442), ((22, 23), 0.046233415603637695), ((18, 23), 0.04596595838665962), ((3, 8), 0.04549597203731537), ((14, 17), 0.04545079171657562), ((17, 18), 0.04518403857946396), ((18, 19), 0.04513729363679886), ((8, 10), 0.04474758356809616), ((6, 17), 0.04472610354423523), ((5, 23), 0.044613733887672424), ((8, 16), 0.044579584151506424), ((14, 21), 0.04436585307121277), ((6, 11), 0.044305697083473206), ((18, 21), 0.043985046446323395), ((11, 14), 0.04375835135579109), ((1, 8), 0.04339958727359772), ((12, 23), 0.04337242618203163), ((11, 17), 0.043083932250738144), ((0, 8), 0.04288669675588608), ((6, 14), 0.042802564799785614), ((1, 21), 0.042393676936626434), ((17, 23), 0.04206186160445213), ((8, 14), 0.04160507023334503), ((8, 12), 0.041588570922613144), ((8, 22), 0.0413832925260067), ((11, 19), 0.0411461777985096), ((4, 13), 0.04113626852631569), ((9, 23), 0.040641289204359055), ((5, 8), 0.040497101843357086), ((17, 19), 0.040460553020238876), ((20, 23), 0.04003187641501427), ((17, 21), 0.03973805904388428), ((8, 18), 0.03940042480826378), ((11, 23), 0.03910623863339424), ((13, 15), 0.03846103698015213), ((14, 19), 0.03824680298566818), ((8, 17), 0.0380413793027401), ((4, 21), 0.037846703082323074), ((4, 7), 0.03742961958050728), ((8, 20), 0.03719012811779976), ((8, 9), 0.037131648510694504), ((8, 11), 0.036957450211048126), ((6, 23), 0.03690946847200394), ((21, 23), 0.03643388673663139), ((13, 19), 0.03459122031927109), ((4, 10), 0.033457476645708084), ((8, 21), 0.033333469182252884), ((6, 8), 0.03332594409584999), ((4, 15), 0.03326934203505516), ((19, 23), 0.03211295232176781), ((13, 20), 0.030155662447214127), ((3, 4), 0.029597405344247818), ((9, 13), 0.028936194255948067), ((8, 19), 0.028918905183672905), ((12, 13), 0.028425101190805435), ((15, 19), 0.02779017575085163), ((1, 4), 0.027000147849321365), ((4, 11), 0.0261353962123394), ((6, 13), 0.025375599041581154), ((4, 18), 0.025039302185177803), ((4, 17), 0.024853253737092018), ((15, 20), 0.023429343476891518), ((9, 15), 0.02247016690671444), ((4, 14), 0.021202880889177322), ((12, 15), 0.02078874222934246), ((2, 12), 0.02008681744337082), ((6, 15), 0.019812732934951782), ((13, 16), 0.019468095153570175), ((2, 20), 0.019068311899900436), ((2, 9), 0.01844109781086445), ((13, 22), 0.017751941457390785), ((4, 23), 0.017642753198742867), ((5, 13), 0.01728881523013115), ((4, 8), 0.01701013557612896), ((2, 19), 0.016680514439940453), ((13, 21), 0.01663677580654621), ((2, 21), 0.016323458403348923), ((2, 16), 0.016187947243452072), ((2, 15), 0.015998436138033867), ((2, 13), 0.015612004324793816), ((0, 13), 0.015486584976315498), ((15, 16), 0.015001467429101467), ((2, 6), 0.014584102667868137), ((2, 4), 0.013975252397358418), ((2, 22), 0.013643240556120872), ((15, 22), 0.013442516326904297), ((15, 21), 0.013277523219585419), ((2, 5), 0.013270080089569092), ((5, 15), 0.01318107359111309), ((10, 13), 0.013145706616342068), ((0, 2), 0.012842860072851181), ((7, 13), 0.012506290338933468), ((2, 11), 0.01250626053661108), ((0, 15), 0.012076649814844131), ((2, 10), 0.011802882887423038), ((3, 13), 0.011607064865529537), ((2, 17), 0.011407384648919106), ((2, 7), 0.011387084610760212), ((13, 18), 0.011318898759782314), ((11, 13), 0.011060901917517185), ((2, 3), 0.01065583061426878), ((2, 8), 0.010427137836813927), ((10, 15), 0.00965800229460001), ((2, 18), 0.009610123001039028), ((1, 2), 0.009573587216436863), ((1, 13), 0.009467543102800846), ((7, 15), 0.009411686100065708), ((2, 14), 0.00916285440325737), ((2, 23), 0.009110956452786922), ((13, 17), 0.008946015499532223), ((3, 15), 0.00882895477116108), ((15, 18), 0.008223939687013626), ((11, 15), 0.008033975958824158), ((8, 13), 0.007478296756744385), ((13, 14), 0.007384685333818197), ((1, 15), 0.007116497494280338), ((13, 23), 0.00709731737151742), ((15, 17), 0.006928764283657074), ((14, 15), 0.0054665422067046165), ((8, 15), 0.005395182874053717), ((15, 23), 0.005258959252387285)]
******* after merging (0.04): [((9, 20), 64), ((6, 19), 64), ((5, 22), 64), ((0,), 32), ((1,), 32), ((2,), 32), ((3,), 32), ((4,), 32), ((7,), 32), ((8,), 32), ((10,), 32), ((11,), 32), ((12,), 32), ((13,), 32), ((14,), 32), ((15,), 32), ((16,), 32), ((17,), 32), ((18,), 32), ((21,), 32), ((23,), 32)]
{'R_grad_norm': 1.5778153216838837, 'training_loss': 7.310290191173554}
{'R_grad_norm': 1.5791989719867707, 'training_loss': 7.301045839786529}
{'R_grad_norm': 1.5811857324838638, 'training_loss': 7.316427311897278}
{'R_grad_norm': 1.5808917719125748, 'training_loss': 7.306035821437836}
{'R_grad_norm': 1.5815688115358353, 'training_loss': 7.298131844997406}
{'R_grad_norm': 1.5811268597841264, 'training_loss': 7.293694038391113}
{'R_grad_norm': 1.5793911296129226, 'training_loss': 7.286243991851807}
{'R_grad_norm': 1.5795029938220977, 'training_loss': 7.294423315525055}
{'R_grad_norm': 1.5788473296165466, 'training_loss': 7.288998529911042}
{'R_grad_norm': 1.5776020610332488, 'training_loss': 7.273657357692718}
{'R_grad_norm': 1.5758286529779435, 'training_loss': 7.259776074886322}
{'R_grad_norm': 1.5768435603380204, 'training_loss': 7.279338040351868}
{'R_grad_norm': 1.574378969669342, 'training_loss': 7.27102490901947}
{'R_grad_norm': 1.573818246126175, 'training_loss': 7.276423995494842}
{'R_grad_norm': 1.5747652351856232, 'training_loss': 7.26529944896698}
{'R_grad_norm': 1.5728756153583527, 'training_loss': 7.261704466342926}
{'R_grad_norm': 1.5743459212779998, 'training_loss': 7.284454553127289}
{'R_grad_norm': 1.572212491631508, 'training_loss': 7.262008717060089}
{'R_grad_norm': 1.5719214737415315, 'training_loss': 7.265281047821045}
{'R_grad_norm': 1.5725098687410355, 'training_loss': 7.255459969043732}
{'R_grad_norm': 1.5703061616420746, 'training_loss': 7.237322058677673}
{'R_grad_norm': 1.5692316979169845, 'training_loss': 7.258980705738067}
{'R_grad_norm': 1.564123969078064, 'training_loss': 7.226970684528351}
{'R_grad_norm': 1.564358593225479, 'training_loss': 7.232577352523804}
{'R_grad_norm': 1.5649966704845428, 'training_loss': 7.231188848018646}
{'R_grad_norm': 1.5680742865800859, 'training_loss': 7.249660737514496}
{'R_grad_norm': 1.5616348379850387, 'training_loss': 7.225857374668121}
{'R_grad_norm': 1.5648697322607041, 'training_loss': 7.250256087779999}
{'R_grad_norm': 1.5628909069299697, 'training_loss': 7.234790821075439}
{'R_grad_norm': 1.557246652841568, 'training_loss': 7.209532949924469}
{'R_grad_norm': 1.5624743366241456, 'training_loss': 7.222779293060302}
{'R_grad_norm': 1.5571821630001068, 'training_loss': 7.195681624412536}
{'R_grad_norm': 1.559153335094452, 'training_loss': 7.20706964969635}
{'R_grad_norm': 1.5613870245218278, 'training_loss': 7.242373976707459}
{'R_grad_norm': 1.5596284210681914, 'training_loss': 7.225028245449066}
{'R_grad_norm': 1.5587030225992202, 'training_loss': 7.224974954128266}
{'R_grad_norm': 1.5606641805171966, 'training_loss': 7.2436975002288815}
{'R_grad_norm': 1.5528098911046981, 'training_loss': 7.1946614289283755}
{'R_grad_norm': 1.5526785355806352, 'training_loss': 7.213794367313385}
{'R_grad_norm': 1.5529985123872756, 'training_loss': 7.214872205257416}
eval result tensor([9.86354, 8.24573, 9.87633, 5.68766, 6.50578, 7.16147, 6.70201, 5.09017,
        6.55357, 7.24875, 6.22866, 7.11087, 7.23500, 7.77166, 7.35952, 7.34341,
        6.21360, 6.53814, 6.90982, 8.56366, 7.44272], device='cuda:0')
computing merge metric
normed mi [((12, 16), 0.08249276131391525), ((3, 16), 0.08245151489973068), ((3, 8), 0.07327038049697876), ((10, 12), 0.07322482764720917), ((12, 19), 0.07290571928024292), ((0, 12), 0.07221200565497081), ((3, 12), 0.07178786396980286), ((2, 3), 0.0717612902323405), ((0, 16), 0.07163307070732117), ((0, 3), 0.0702101190884908), ((10, 16), 0.06966850161552429), ((3, 10), 0.06877169758081436), ((8, 16), 0.06866426020860672), ((1, 3), 0.067117045323054), ((3, 4), 0.06593804061412811), ((8, 10), 0.06408699601888657), ((3, 6), 0.06364468485116959), ((1, 16), 0.06319705148537953), ((12, 18), 0.06300895661115646), ((0, 1), 0.06296262890100479), ((6, 16), 0.06253623217344284), ((8, 12), 0.061824508011341095), ((6, 12), 0.060890763998031616), ((2, 16), 0.06003732979297638), ((1, 12), 0.05956168472766876), ((4, 8), 0.05923983454704285), ((16, 19), 0.05916902422904968), ((6, 8), 0.05871935188770294), ((6, 10), 0.058625347912311554), ((0, 10), 0.0585999588171641), ((0, 2), 0.05811379849910736), ((4, 10), 0.05789778009057045), ((2, 8), 0.05765956143538157), ((10, 18), 0.05752835050225258), ((16, 18), 0.05668642371892929), ((4, 6), 0.05664728581905365), ((3, 18), 0.056160539388656616), ((4, 16), 0.055810507386922836), ((2, 4), 0.055605217814445496), ((6, 18), 0.05556311085820198), ((3, 14), 0.0552578903734684), ((0, 8), 0.055195887883504234), ((2, 12), 0.05514170229434967), ((2, 10), 0.054293617606163025), ((11, 12), 0.05426168441772461), ((8, 18), 0.05362990126013756), ((4, 12), 0.05359300598502159), ((14, 16), 0.05249691382050514), ((3, 17), 0.0522257536649704), ((4, 14), 0.052201833575963974), ((8, 14), 0.051145970821380615), ((2, 6), 0.05110212663809458), ((9, 20), 0.050901178270578384), ((8, 20), 0.05085550621151924), ((11, 16), 0.05084613710641861), ((1, 7), 0.05075002213319143), ((12, 14), 0.05008552595973015), ((10, 14), 0.050037093460559845), ((16, 17), 0.05001508444547653), ((1, 2), 0.049565188586711884), ((3, 11), 0.049469344317913055), ((8, 9), 0.04926690086722374), ((10, 11), 0.04910406842827797), ((4, 18), 0.0488479919731617), ((10, 17), 0.048777397722005844), ((6, 14), 0.04857468977570534), ((10, 19), 0.048573821783065796), ((0, 6), 0.04854361216227213), ((6, 11), 0.04844336956739426), ((3, 19), 0.04838121309876442), ((4, 20), 0.04831951856613159), ((7, 12), 0.048282820731401443), ((0, 19), 0.04826500018437704), ((9, 16), 0.04813813045620918), ((0, 18), 0.047514895598093666), ((0, 4), 0.04733279347419739), ((7, 16), 0.04718611016869545), ((6, 20), 0.04711523279547691), ((8, 17), 0.047107696533203125), ((6, 9), 0.04640090838074684), ((4, 17), 0.046303004026412964), ((8, 11), 0.046202290803194046), ((6, 19), 0.046182774007320404), ((12, 17), 0.04613291472196579), ((3, 20), 0.0460757277905941), ((14, 19), 0.04602644965052605), ((6, 17), 0.04582355543971062), ((1, 8), 0.045628259579340615), ((9, 10), 0.04559377208352089), ((11, 18), 0.045420944690704346), ((2, 14), 0.04540631671746572), ((2, 18), 0.045089984933535256), ((4, 11), 0.04501550272107124), ((1, 10), 0.044718801975250244), ((14, 18), 0.04468085244297981), ((11, 14), 0.04421341419219971), ((8, 19), 0.043910808861255646), ((10, 20), 0.0437866672873497), ((3, 9), 0.04361981153488159), ((16, 20), 0.043443888425827026), ((11, 19), 0.04332096129655838), ((18, 19), 0.04326405003666878), ((14, 20), 0.04293271154165268), ((4, 9), 0.042884793132543564), ((0, 14), 0.0426950603723526), ((9, 12), 0.04245079308748245), ((14, 17), 0.04237156733870506), ((18, 20), 0.04232723265886307), ((7, 13), 0.04196742922067642), ((2, 17), 0.04153293619553248), ((0, 7), 0.041388275722662606), ((13, 15), 0.041036639362573624), ((3, 7), 0.040791697800159454), ((4, 19), 0.040728695690631866), ((17, 18), 0.04034186899662018), ((1, 19), 0.040232300758361816), ((11, 17), 0.04023201763629913), ((2, 11), 0.040199177960554756), ((0, 11), 0.03990491727987925), ((0, 17), 0.03973867744207382), ((12, 20), 0.0390128530561924), ((9, 14), 0.038984619081020355), ((11, 20), 0.038531795144081116), ((9, 11), 0.038251303136348724), ((1, 6), 0.03818368911743164), ((2, 20), 0.038175744314988456), ((17, 19), 0.0381498858332634), ((9, 18), 0.037416063249111176), ((1, 4), 0.037240090469519295), ((9, 17), 0.03687618672847748), ((17, 20), 0.03661757707595825), ((2, 19), 0.035890584190686546), ((1, 18), 0.0350873072942098), ((9, 19), 0.03507693484425545), ((2, 9), 0.03507194668054581), ((7, 15), 0.03459636867046356), ((1, 14), 0.03341031322876612), ((7, 19), 0.03282459080219269), ((1, 17), 0.032619024316469826), ((0, 9), 0.03224002569913864), ((0, 20), 0.031908221542835236), ((19, 20), 0.03172120079398155), ((1, 11), 0.029572322964668274), ((7, 10), 0.029246734455227852), ((7, 8), 0.02779475785791874), ((12, 13), 0.026689818128943443), ((2, 7), 0.025080755352973938), ((1, 20), 0.0249186505873998), ((1, 9), 0.02472342550754547), ((6, 7), 0.02299671061336994), ((7, 17), 0.0225836131721735), ((4, 7), 0.021305367350578308), ((7, 18), 0.020213600248098373), ((7, 14), 0.020189566537737846), ((5, 12), 0.019590334966778755), ((7, 11), 0.01888204552233219), ((1, 13), 0.018003898362318676), ((12, 15), 0.017474491149187088), ((13, 16), 0.017059314996004105), ((5, 16), 0.016109885647892952), ((5, 19), 0.015442819334566593), ((7, 9), 0.015409424901008606), ((0, 13), 0.014743335545063019), ((5, 13), 0.014564772136509418), ((13, 19), 0.014442965388298035), ((7, 20), 0.013931370340287685), ((1, 15), 0.013193034877379736), ((3, 13), 0.01306194718927145), ((5, 15), 0.012900260277092457), ((10, 13), 0.012465870007872581), ((5, 7), 0.012421397492289543), ((5, 17), 0.012396261096000671), ((3, 5), 0.012362005189061165), ((15, 16), 0.01226174645125866), ((0, 5), 0.012217505524555842), ((5, 10), 0.012053006328642368), ((5, 9), 0.01198159996420145), ((1, 5), 0.01149058093627294), ((5, 8), 0.011085327714681625), ((5, 11), 0.010733239352703094), ((13, 18), 0.010616734623908997), ((8, 13), 0.010560499504208565), ((0, 15), 0.010244982317090034), ((15, 19), 0.009961575269699097), ((5, 6), 0.009935395792126656), ((6, 13), 0.009812395088374615), ((3, 15), 0.009466555900871754), ((13, 17), 0.009439258836209774), ((5, 18), 0.00941162183880806), ((4, 5), 0.009214280173182487), ((5, 14), 0.009160803630948067), ((5, 20), 0.008627435192465782), ((2, 5), 0.00852622278034687), ((4, 13), 0.008489247411489487), ((10, 15), 0.00848802737891674), ((11, 13), 0.008010225370526314), ((2, 13), 0.007964281365275383), ((8, 15), 0.007549337111413479), ((9, 13), 0.007388244848698378), ((15, 18), 0.007026870269328356), ((13, 14), 0.006916589103639126), ((6, 15), 0.006893586367368698), ((15, 17), 0.006606208626180887), ((4, 15), 0.00607104878872633), ((13, 20), 0.006033306010067463), ((2, 15), 0.005593062688906987), ((11, 15), 0.005330067127943039), ((9, 15), 0.005144126247614622), ((14, 15), 0.004831136204302311), ((15, 20), 0.004349899012595415)]
******* after merging (0.04): [((12, 16), 64), ((3, 8), 64), ((0,), 64), ((1,), 64), ((2,), 64), ((4,), 32), ((5,), 32), ((6,), 32), ((7,), 32), ((9,), 32), ((10,), 32), ((11,), 32), ((13,), 32), ((14,), 32), ((15,), 32), ((17,), 32), ((18,), 32), ((19,), 32), ((20,), 32)]
{'R_grad_norm': 1.6784331548213958, 'training_loss': 7.7107775282859805}
{'R_grad_norm': 1.6709949505329131, 'training_loss': 7.681909203529358}
{'R_grad_norm': 1.6780954855680466, 'training_loss': 7.698118326663971}
{'R_grad_norm': 1.6777627593278885, 'training_loss': 7.712939827442169}
{'R_grad_norm': 1.6720025485754013, 'training_loss': 7.679816813468933}
{'R_grad_norm': 1.670630532503128, 'training_loss': 7.666424343585968}
{'R_grad_norm': 1.6736315023899078, 'training_loss': 7.679056808948517}
{'R_grad_norm': 1.6773297971487044, 'training_loss': 7.707623381614685}
{'R_grad_norm': 1.6827312701940536, 'training_loss': 7.722965939044952}
{'R_grad_norm': 1.6848242425918578, 'training_loss': 7.729577662944794}
{'R_grad_norm': 1.6878876090049744, 'training_loss': 7.754331080913544}
{'R_grad_norm': 1.6900725078582763, 'training_loss': 7.753207540512085}
{'R_grad_norm': 1.6981369954347612, 'training_loss': 7.79262839794159}
{'R_grad_norm': 1.6967084896564484, 'training_loss': 7.781139369010925}
{'R_grad_norm': 1.7077119153738023, 'training_loss': 7.8521212339401245}
{'R_grad_norm': 1.7102880251407624, 'training_loss': 7.850435054302215}
{'R_grad_norm': 1.7143912506103516, 'training_loss': 7.872044050693512}
{'R_grad_norm': 1.7180105489492417, 'training_loss': 7.914094350337982}
{'R_grad_norm': 1.729092321395874, 'training_loss': 7.9489796924591065}
{'R_grad_norm': 1.7302723664045334, 'training_loss': 7.971005504131317}
{'R_grad_norm': 1.741675044298172, 'training_loss': 8.026519861221313}
{'R_grad_norm': 1.7536541819572449, 'training_loss': 8.090162401199342}
{'R_grad_norm': 1.698025478720665, 'training_loss': 7.809771902561188}
{'R_grad_norm': 1.664233791232109, 'training_loss': 7.6369456815719605}
{'R_grad_norm': 1.6623293763399125, 'training_loss': 7.635703482627869}
{'R_grad_norm': 1.661284503340721, 'training_loss': 7.614171748161316}
{'R_grad_norm': 1.6556823915243148, 'training_loss': 7.588438255786896}
{'R_grad_norm': 1.6601473599672318, 'training_loss': 7.62685827255249}
{'R_grad_norm': 1.6557493233680725, 'training_loss': 7.593567438125611}
{'R_grad_norm': 1.655072580575943, 'training_loss': 7.596194512844086}
{'R_grad_norm': 1.6577653723955155, 'training_loss': 7.610260925292969}
{'R_grad_norm': 1.6539221715927124, 'training_loss': 7.5880451989173885}
{'R_grad_norm': 1.6508588624000549, 'training_loss': 7.571506559848785}
{'R_grad_norm': 1.6533394038677216, 'training_loss': 7.607113823890686}
{'R_grad_norm': 1.6551623558998108, 'training_loss': 7.6124842166900635}
{'R_grad_norm': 1.657582615017891, 'training_loss': 7.625696926116944}
{'R_grad_norm': 1.6530204063653946, 'training_loss': 7.604660456180572}
{'R_grad_norm': 1.6488064193725587, 'training_loss': 7.579456300735473}
{'R_grad_norm': 1.6478799390792847, 'training_loss': 7.575907280445099}
{'R_grad_norm': 1.651756808757782, 'training_loss': 7.599050335884094}
eval result tensor([11.85971, 10.32098,  9.26438,  7.96882,  9.60122,  6.20255,  6.90820,
         6.40448,  4.81291,  7.06795,  5.98998,  6.85105,  7.56858,  7.01989,
         7.19161,  6.31670,  6.70856,  8.21244,  7.09721], device='cuda:0')
computing merge metric
normed mi [((2, 3), 0.06389406323432922), ((0, 2), 0.060851190239191055), ((2, 10), 0.05719748139381409), ((0, 10), 0.056863819559415184), ((1, 4), 0.056594233959913254), ((2, 4), 0.056232694536447525), ((7, 10), 0.055528998374938965), ((10, 16), 0.05492527782917023), ((5, 7), 0.054694149643182755), ((3, 8), 0.0536845326423645), ((5, 10), 0.053584594279527664), ((4, 5), 0.05342515309651693), ((7, 16), 0.05286965146660805), ((4, 10), 0.05180847148100535), ((0, 17), 0.05107509593168894), ((9, 18), 0.049717772752046585), ((1, 2), 0.049714043736457825), ((0, 4), 0.049420326948165894), ((5, 13), 0.04930524900555611), ((4, 7), 0.04920154313246409), ((3, 4), 0.04905648157000542), ((0, 16), 0.04872554540634155), ((0, 7), 0.048427109917004905), ((10, 13), 0.04799443483352661), ((1, 10), 0.047960047920544945), ((1, 5), 0.047947620352109276), ((0, 3), 0.04791070520877838), ((13, 17), 0.04765962436795235), ((7, 9), 0.04734814167022705), ((7, 13), 0.04715792462229729), ((2, 7), 0.04667712251345316), ((5, 16), 0.046596840023994446), ((2, 17), 0.04646061360836029), ((5, 18), 0.04629264399409294), ((10, 17), 0.04586644098162651), ((2, 16), 0.045659273862838745), ((10, 15), 0.04546637833118439), ((1, 7), 0.04543408751487732), ((4, 13), 0.045253763596216835), ((7, 11), 0.04496007785201073), ((9, 10), 0.0446682870388031), ((1, 3), 0.044530801475048065), ((3, 10), 0.044385155042012535), ((7, 18), 0.04431316256523132), ((2, 8), 0.04430539906024933), ((0, 1), 0.044267646968364716), ((7, 17), 0.04417050629854202), ((2, 5), 0.04413256545861562), ((10, 11), 0.044109296053647995), ((0, 13), 0.04376557966073354), ((5, 11), 0.04353451728820801), ((5, 15), 0.04317585006356239), ((4, 16), 0.04312072197596232), ((2, 13), 0.04308374226093292), ((13, 16), 0.043007031083106995), ((7, 15), 0.04299497604370117), ((11, 13), 0.04287875443696976), ((0, 5), 0.042864784598350525), ((11, 16), 0.04268399253487587), ((8, 12), 0.04260692372918129), ((5, 9), 0.04206054285168648), ((16, 17), 0.04141748696565628), ((1, 13), 0.041306495666503906), ((1, 16), 0.04117538034915924), ((12, 14), 0.04108666628599167), ((0, 11), 0.040468153854211174), ((13, 15), 0.04042264446616173), ((16, 18), 0.03989707678556442), ((3, 17), 0.03962107499440511), ((0, 9), 0.039451894660790764), ((4, 15), 0.039447322487831116), ((10, 18), 0.03929956257343292), ((13, 18), 0.0391070730984211), ((1, 9), 0.03906529893477758), ((11, 17), 0.03902491182088852), ((1, 18), 0.03856151799360911), ((9, 16), 0.038422808051109314), ((9, 13), 0.038327958434820175), ((4, 11), 0.038167715072631836), ((5, 17), 0.03810097277164459), ((15, 16), 0.03802701458334923), ((9, 15), 0.03795427083969116), ((9, 11), 0.03789415583014488), ((9, 17), 0.037886667996644974), ((11, 18), 0.037257906049489975), ((3, 7), 0.037159415582815804), ((0, 15), 0.036831962565581), ((2, 15), 0.03681221355994543), ((11, 15), 0.03662952035665512), ((1, 15), 0.03655273715655009), ((4, 18), 0.03650736312071482), ((4, 9), 0.03586103767156601), ((2, 11), 0.03559585412343343), ((1, 11), 0.035338242848714195), ((3, 13), 0.03532440712054571), ((15, 17), 0.03531907871365547), ((3, 5), 0.035122002164522804), ((8, 14), 0.034888915717601776), ((15, 18), 0.03453536704182625), ((3, 16), 0.03442001839478811), ((4, 17), 0.03423715631167094), ((2, 9), 0.03405583401521047), ((8, 17), 0.03271762654185295), ((0, 18), 0.03213495761156082), ((1, 17), 0.03191884855429331), ((8, 10), 0.03125305101275444), ((3, 15), 0.030394603808720905), ((0, 8), 0.029944380124409992), ((2, 18), 0.029620714485645294), ((17, 18), 0.029590623453259468), ((4, 8), 0.027205740412076313), ((3, 9), 0.02690933148066203), ((3, 11), 0.0263992374142011), ((7, 8), 0.02467690408229828), ((8, 13), 0.023719841614365578), ((3, 18), 0.0237150639295578), ((1, 8), 0.023177300890286762), ((8, 15), 0.0226688664406538), ((5, 8), 0.02222941815853119), ((8, 16), 0.021240826696157455), ((3, 12), 0.02005889266729355), ((8, 9), 0.018503613770008087), ((8, 11), 0.017069347202777863), ((2, 12), 0.016664618005355198), ((6, 12), 0.01551971398293972), ((3, 14), 0.015459245691696802), ((12, 17), 0.015421980060636997), ((6, 17), 0.015360110439360142), ((6, 14), 0.014918433502316475), ((8, 18), 0.014773809351027012), ((10, 12), 0.014339564368128777), ((6, 9), 0.01374299731105566), ((6, 8), 0.013614003546535969), ((0, 12), 0.013596773147583008), ((6, 10), 0.012124103493988514), ((2, 14), 0.012105066329240799), ((2, 6), 0.011889868726332983), ((6, 15), 0.01185870822519064), ((3, 6), 0.01182167480389277), ((14, 17), 0.011657720431685448), ((12, 16), 0.011354907415807247), ((0, 6), 0.011319770167271296), ((7, 12), 0.010636393912136555), ((10, 14), 0.010259549133479595), ((6, 7), 0.009962671436369419), ((6, 11), 0.009959910064935684), ((6, 13), 0.009658360853791237), ((12, 15), 0.009645323269069195), ((5, 6), 0.009482275694608688), ((6, 16), 0.009412207640707493), ((9, 12), 0.00926901213824749), ((5, 12), 0.009156295098364353), ((0, 14), 0.009050149470567703), ((4, 12), 0.008750000347693762), ((4, 6), 0.008612294991811117), ((6, 18), 0.008300896733999252), ((1, 6), 0.00808972492814064), ((7, 14), 0.008020314387977123), ((1, 12), 0.007983373478055), ((12, 13), 0.007908369414508343), ((14, 16), 0.007840706966817379), ((11, 12), 0.0075976005755364895), ((14, 15), 0.0073470463976264), ((5, 14), 0.006647976115345955), ((9, 14), 0.006614344660192728), ((4, 14), 0.006393838052948316), ((12, 18), 0.006308756768703461), ((1, 14), 0.005968447774648666), ((13, 14), 0.005621141754090786), ((11, 14), 0.0053450316190719604), ((14, 18), 0.004718315321952105)]
******* after merging (0.04): [((2, 3), 128), ((0, 10), 96), ((1,), 64), ((4,), 64), ((5,), 32), ((6,), 32), ((7,), 32), ((8,), 32), ((9,), 32), ((11,), 32), ((12,), 32), ((13,), 32), ((14,), 32), ((15,), 32), ((16,), 32), ((17,), 32), ((18,), 32)]
{'R_grad_norm': 1.802260352373123, 'training_loss': 8.027896285057068}
{'R_grad_norm': 1.805030102133751, 'training_loss': 8.023186745643615}
{'R_grad_norm': 1.8037729328870773, 'training_loss': 8.025062005519867}
{'R_grad_norm': 1.8012030243873596, 'training_loss': 7.995210731029511}
{'R_grad_norm': 1.7987524968385697, 'training_loss': 7.999951274394989}
{'R_grad_norm': 1.7991813445091247, 'training_loss': 8.013765358924866}
{'R_grad_norm': 1.7958193910121918, 'training_loss': 7.9847902584075925}
{'R_grad_norm': 1.8054059052467346, 'training_loss': 8.031367235183716}
{'R_grad_norm': 1.800204834342003, 'training_loss': 8.00730320930481}
{'R_grad_norm': 1.7997380584478377, 'training_loss': 8.022108502388}
{'R_grad_norm': 1.7921033221483231, 'training_loss': 7.979820818901062}
{'R_grad_norm': 1.7944133824110031, 'training_loss': 7.976531000137329}
{'R_grad_norm': 1.7958756643533706, 'training_loss': 7.9878637003898625}
{'R_grad_norm': 1.793222235441208, 'training_loss': 7.97840695142746}
{'R_grad_norm': 1.7966001051664353, 'training_loss': 7.997717216014862}
{'R_grad_norm': 1.7944451761245728, 'training_loss': 7.993523368835449}
{'R_grad_norm': 1.7947515398263931, 'training_loss': 7.984288947582245}
{'R_grad_norm': 1.7886170315742493, 'training_loss': 7.957838294506073}
{'R_grad_norm': 1.7870544457435609, 'training_loss': 7.9477778029441835}
{'R_grad_norm': 1.7868567574024201, 'training_loss': 7.95856556892395}
{'R_grad_norm': 1.7900476014614106, 'training_loss': 7.97460940361023}
{'R_grad_norm': 1.787812807559967, 'training_loss': 7.957282786369324}
{'R_grad_norm': 1.7903041017055512, 'training_loss': 7.995185222625732}
{'R_grad_norm': 1.7864075136184692, 'training_loss': 7.95628992319107}
{'R_grad_norm': 1.785497209429741, 'training_loss': 7.968768110275269}
{'R_grad_norm': 1.7854795467853546, 'training_loss': 7.978575103282928}
{'R_grad_norm': 1.7801696342229842, 'training_loss': 7.935404529571533}
{'R_grad_norm': 1.7844012880325317, 'training_loss': 7.957383322715759}
{'R_grad_norm': 1.7780459648370743, 'training_loss': 7.936906812191009}
{'R_grad_norm': 1.7797847455739975, 'training_loss': 7.944324550628662}
{'R_grad_norm': 1.773845300078392, 'training_loss': 7.930729122161865}
{'R_grad_norm': 1.7786712819337844, 'training_loss': 7.963335976600647}
{'R_grad_norm': 1.775977571606636, 'training_loss': 7.951210978031159}
{'R_grad_norm': 1.7783682608604432, 'training_loss': 7.955870990753174}
{'R_grad_norm': 1.7700965279340743, 'training_loss': 7.923580067157745}
{'R_grad_norm': 1.7769247806072235, 'training_loss': 7.956522574424744}
{'R_grad_norm': 1.7704102504253387, 'training_loss': 7.93227769613266}
{'R_grad_norm': 1.770128024816513, 'training_loss': 7.934384651184082}
{'R_grad_norm': 1.7756838923692704, 'training_loss': 7.962937159538269}
{'R_grad_norm': 1.7753408771753312, 'training_loss': 7.946575064659118}
eval result tensor([13.95328, 15.96780,  9.99206,  8.64465,  5.98073,  6.78676,  6.16571,
         4.59825,  7.03187,  6.59845,  7.42093,  6.81983,  7.11131,  6.12907,
         6.52385,  7.92828,  6.89621], device='cuda:0')
computing merge metric
normed mi [((4, 6), 0.05341649800539017), ((2, 3), 0.053344886749982834), ((3, 4), 0.050281802813212075), ((6, 14), 0.050232481211423874), ((8, 16), 0.047784194350242615), ((6, 8), 0.04758688807487488), ((11, 15), 0.046966880559921265), ((2, 4), 0.0469266672929128), ((3, 6), 0.04646603266398112), ((4, 11), 0.04641127586364746), ((4, 14), 0.046381186693906784), ((6, 11), 0.046036235988140106), ((4, 16), 0.04453517496585846), ((2, 6), 0.044281755884488426), ((3, 11), 0.043859208623568215), ((6, 16), 0.043135371059179306), ((0, 3), 0.04296315213044485), ((6, 9), 0.0428110770881176), ((4, 13), 0.04279465228319168), ((7, 10), 0.042210306972265244), ((3, 14), 0.04209310313065847), ((6, 13), 0.0420837476849556), ((11, 14), 0.042061615735292435), ((4, 9), 0.04185085743665695), ((6, 15), 0.04119469225406647), ((9, 11), 0.040535859763622284), ((1, 3), 0.04053298234939575), ((2, 8), 0.0402350922425588), ((4, 8), 0.04018918797373772), ((2, 11), 0.040051743388175964), ((10, 12), 0.03998909518122673), ((2, 14), 0.03985795875390371), ((14, 15), 0.03982524201273918), ((8, 15), 0.03974844515323639), ((9, 14), 0.03956437110900879), ((11, 13), 0.039148032665252686), ((3, 13), 0.039090774953365326), ((8, 14), 0.03849780187010765), ((1, 14), 0.03822370991110802), ((13, 14), 0.037840090692043304), ((14, 16), 0.03739532083272934), ((8, 13), 0.03735443204641342), ((1, 6), 0.03732297942042351), ((9, 16), 0.037180397659540176), ((2, 16), 0.03707131743431091), ((1, 15), 0.03705098479986191), ((8, 11), 0.03669474273920059), ((0, 2), 0.036549992859363556), ((1, 2), 0.0365128368139267), ((2, 13), 0.035943870743115745), ((11, 16), 0.0358581505715847), ((4, 15), 0.03539979085326195), ((3, 8), 0.0349980096022288), ((3, 9), 0.03477294246355692), ((1, 4), 0.03469828516244888), ((9, 13), 0.03454338386654854), ((8, 9), 0.034540507942438126), ((3, 15), 0.03447733074426651), ((1, 11), 0.034221138805150986), ((13, 15), 0.034017398953437805), ((2, 9), 0.03380537529786428), ((7, 12), 0.03379669412970543), ((13, 16), 0.03366610035300255), ((9, 15), 0.03313140198588371), ((0, 1), 0.03271974836077009), ((1, 8), 0.03228619322180748), ((3, 16), 0.03212821980317434), ((3, 7), 0.03070542464653651), ((2, 15), 0.03063678244749705), ((1, 9), 0.030260886996984482), ((7, 15), 0.02912995032966137), ((1, 13), 0.028580917045474052), ((0, 6), 0.027504175901412964), ((0, 4), 0.02737690806388855), ((0, 11), 0.026708504557609557), ((0, 14), 0.0266879141330719), ((0, 15), 0.026111698150634764), ((15, 16), 0.025953566655516624), ((1, 16), 0.025424260646104813), ((0, 7), 0.023596855998039245), ((0, 8), 0.022418460249900816), ((0, 13), 0.022330349683761595), ((2, 7), 0.02198427418867747), ((7, 11), 0.021642785519361496), ((6, 7), 0.021235423162579536), ((4, 7), 0.021120116114616394), ((0, 9), 0.01974480748176575), ((7, 13), 0.01968301832675934), ((7, 14), 0.019641108810901642), ((7, 8), 0.019321635365486145), ((0, 16), 0.018215017020702363), ((1, 7), 0.016204355284571648), ((5, 8), 0.015179464593529701), ((7, 9), 0.01415160484611988), ((5, 15), 0.013602460734546185), ((5, 10), 0.013505072332918644), ((7, 16), 0.013006634078919888), ((10, 15), 0.012054230086505413), ((5, 12), 0.011804440058767796), ((5, 7), 0.011395013891160488), ((5, 13), 0.01067119650542736), ((10, 14), 0.008955770172178745), ((8, 10), 0.008678024634718895), ((3, 10), 0.008453454822301865), ((3, 5), 0.008250157659252485), ((5, 11), 0.008246980607509613), ((4, 5), 0.008053612895309925), ((5, 6), 0.008051320910453796), ((5, 14), 0.007958057336509228), ((6, 10), 0.007583739701658487), ((4, 10), 0.007383838761597872), ((12, 15), 0.007199079263955355), ((10, 13), 0.007195399142801762), ((2, 5), 0.007193877672155698), ((5, 9), 0.007185086607933044), ((5, 16), 0.007120304740965366), ((0, 10), 0.007092109322547913), ((1, 5), 0.0067551713436841965), ((1, 10), 0.006417968310415745), ((0, 5), 0.006351404637098312), ((2, 10), 0.006329225997130076), ((10, 11), 0.005922046024352312), ((8, 12), 0.0054857442155480385), ((3, 12), 0.005413680026928584), ((12, 14), 0.005385722499340773), ((12, 13), 0.004905250854790211), ((6, 12), 0.00485812034457922), ((10, 16), 0.004853322170674801), ((4, 12), 0.004748969338834286), ((9, 10), 0.004723867867141962), ((0, 12), 0.004496312141418457), ((2, 12), 0.004285672679543495), ((11, 12), 0.003816220909357071), ((1, 12), 0.003577215364202857), ((12, 16), 0.0032228564377874136), ((9, 12), 0.002917033853009343)]
******* after merging (0.04): [((2, 3), 128), ((0,), 128), ((1,), 96), ((4, 6), 64), ((5,), 32), ((7,), 32), ((8,), 32), ((9,), 32), ((10,), 32), ((11,), 32), ((12,), 32), ((13,), 32), ((14,), 32), ((15,), 32), ((16,), 32)]
{'R_grad_norm': 1.9236652648448944, 'training_loss': 8.510767140388488}
{'R_grad_norm': 1.9251161068677902, 'training_loss': 8.520288512706756}
{'R_grad_norm': 1.919163755774498, 'training_loss': 8.47777357339859}
{'R_grad_norm': 1.9197709262371063, 'training_loss': 8.470807554721832}
{'R_grad_norm': 1.9215890836715699, 'training_loss': 8.507194397449494}
{'R_grad_norm': 1.918481209874153, 'training_loss': 8.501830904483795}
{'R_grad_norm': 1.9183292752504348, 'training_loss': 8.487014241218567}
{'R_grad_norm': 1.919089611172676, 'training_loss': 8.49686803817749}
{'R_grad_norm': 1.9116032123565674, 'training_loss': 8.44928988456726}
{'R_grad_norm': 1.9178451406955719, 'training_loss': 8.485466947555542}
{'R_grad_norm': 1.9191213327646255, 'training_loss': 8.487922270298004}
{'R_grad_norm': 1.9142281085252761, 'training_loss': 8.488031253814697}
{'R_grad_norm': 1.9169120901823045, 'training_loss': 8.49172737121582}
{'R_grad_norm': 1.911548896431923, 'training_loss': 8.463498423099518}
{'R_grad_norm': 1.9130838578939438, 'training_loss': 8.465593008995056}
{'R_grad_norm': 1.9150392830371856, 'training_loss': 8.472842819690705}
{'R_grad_norm': 1.9111770653724671, 'training_loss': 8.469792048931122}
{'R_grad_norm': 1.9095054519176484, 'training_loss': 8.46574413061142}
{'R_grad_norm': 1.916183267235756, 'training_loss': 8.486659355163575}
{'R_grad_norm': 1.9129261654615402, 'training_loss': 8.497273762226104}
{'R_grad_norm': 1.9110197114944458, 'training_loss': 8.461237397193909}
{'R_grad_norm': 1.9082599180936812, 'training_loss': 8.457076947689057}
{'R_grad_norm': 1.9107902938127517, 'training_loss': 8.473744304180146}
{'R_grad_norm': 1.9104512190818788, 'training_loss': 8.468328137397766}
{'R_grad_norm': 1.9059005457162856, 'training_loss': 8.454662237167359}
{'R_grad_norm': 1.901935338973999, 'training_loss': 8.426553690433503}
{'R_grad_norm': 1.9015521562099458, 'training_loss': 8.432104709148406}
{'R_grad_norm': 1.9056278133392335, 'training_loss': 8.45312578201294}
{'R_grad_norm': 1.9039369142055511, 'training_loss': 8.451820368766784}
{'R_grad_norm': 1.9046937561035155, 'training_loss': 8.452433865070343}
{'R_grad_norm': 1.9034898352622986, 'training_loss': 8.440573651790618}
{'R_grad_norm': 1.9050548750162124, 'training_loss': 8.470917026996613}
{'R_grad_norm': 1.898513495326042, 'training_loss': 8.43515065908432}
{'R_grad_norm': 1.9005468541383743, 'training_loss': 8.451128351688386}
{'R_grad_norm': 1.902325238585472, 'training_loss': 8.44908521413803}
{'R_grad_norm': 1.8994023597240448, 'training_loss': 8.44801970243454}
{'R_grad_norm': 1.9020602560043336, 'training_loss': 8.463683423995972}
{'R_grad_norm': 1.9022598922252656, 'training_loss': 8.469948298931122}
{'R_grad_norm': 1.9011723136901855, 'training_loss': 8.458358821868897}
{'R_grad_norm': 1.894495124220848, 'training_loss': 8.435067486763}
eval result tensor([15.97940, 13.02298, 16.05748,  9.92547,  6.75282,  4.52112,  7.00947,
         6.36240,  7.21865,  6.70932,  7.05800,  5.95480,  6.34843,  7.67585,
         6.69009], device='cuda:0')
computing merge metric
normed mi [((9, 13), 0.04466787353157997), ((6, 14), 0.04458709433674812), ((5, 8), 0.0422111377120018), ((9, 12), 0.042040448635816574), ((6, 13), 0.04068797454237938), ((7, 9), 0.03942327946424484), ((9, 11), 0.03890674561262131), ((8, 10), 0.03879622742533684), ((7, 12), 0.03868419677019119), ((12, 13), 0.03825243562459946), ((6, 12), 0.038162071257829666), ((11, 12), 0.037401217967271805), ((2, 12), 0.037082601338624954), ((3, 12), 0.0370759516954422), ((2, 13), 0.036592885851860046), ((6, 11), 0.03646634891629219), ((12, 14), 0.036337386816740036), ((3, 9), 0.03597933302323023), ((3, 14), 0.03574144343535105), ((7, 14), 0.03562759608030319), ((6, 9), 0.03551449626684189), ((7, 11), 0.03474196046590805), ((3, 7), 0.03459261109431585), ((5, 10), 0.03441886976361275), ((9, 14), 0.03429071605205536), ((11, 14), 0.03386327624320984), ((3, 11), 0.03366522490978241), ((2, 9), 0.033333875238895416), ((6, 7), 0.033161092549562454), ((3, 6), 0.03280943135420481), ((0, 3), 0.03241315484046936), ((2, 3), 0.03177226185798645), ((2, 6), 0.03172546252608299), ((1, 2), 0.03123899017061506), ((11, 13), 0.03077239915728569), ((5, 13), 0.030534032732248306), ((7, 13), 0.030422169715166092), ((2, 7), 0.02868601493537426), ((1, 5), 0.028527316451072694), ((0, 2), 0.028410798736980984), ((0, 1), 0.027431901544332504), ((2, 11), 0.02706771530210972), ((0, 9), 0.026978510618209838), ((0, 12), 0.02654372751712799), ((0, 6), 0.025781896710395814), ((1, 13), 0.025711533427238465), ((1, 9), 0.025602400302886963), ((1, 12), 0.025500965118408204), ((5, 9), 0.02456381544470787), ((1, 3), 0.024211364487806957), ((3, 13), 0.02403516322374344), ((0, 11), 0.02395142912864685), ((0, 14), 0.023935900628566743), ((0, 7), 0.023754476010799407), ((13, 14), 0.023596109822392464), ((2, 14), 0.023578889667987823), ((5, 6), 0.023364990949630737), ((1, 6), 0.02260129153728485), ((5, 12), 0.022071370854973793), ((1, 11), 0.020535020530223845), ((5, 11), 0.0204670038074255), ((0, 13), 0.018760764598846437), ((1, 7), 0.018556666374206544), ((2, 5), 0.017726121470332146), ((4, 6), 0.01666371338069439), ((1, 14), 0.01637914627790451), ((3, 5), 0.016088617344697315), ((5, 7), 0.0156453475356102), ((4, 10), 0.014639955013990402), ((4, 8), 0.014423868618905544), ((0, 5), 0.014084210991859436), ((5, 14), 0.014050151221454144), ((4, 13), 0.013643525540828705), ((8, 13), 0.012894466519355774), ((4, 5), 0.012165607884526253), ((6, 8), 0.010842925868928432), ((4, 11), 0.009937486611306667), ((8, 12), 0.00987372174859047), ((10, 13), 0.009427303448319435), ((1, 8), 0.008940242230892181), ((4, 12), 0.008500955998897552), ((6, 10), 0.007797137834131718), ((4, 9), 0.007667887024581432), ((4, 7), 0.0074813226237893105), ((8, 11), 0.007339651230722666), ((2, 8), 0.007249358110129833), ((4, 14), 0.0068885390646755695), ((8, 9), 0.006771232932806015), ((1, 4), 0.0066485263407230375), ((10, 12), 0.006580331362783909), ((2, 4), 0.00648072874173522), ((1, 10), 0.006399902701377869), ((3, 4), 0.005970182518164317), ((10, 11), 0.005504108965396881), ((8, 14), 0.005407476797699928), ((3, 8), 0.0052826497703790665), ((7, 8), 0.005245712120085955), ((9, 10), 0.004541815258562565), ((2, 10), 0.004311574622988701), ((0, 4), 0.004268770664930343), ((10, 14), 0.003814269555732608), ((0, 8), 0.003781961277127266), ((3, 10), 0.0037029419715205827), ((7, 10), 0.003547615371644497), ((0, 10), 0.002696923352777958)]
******* after merging (0.04): [((0,), 128), ((1,), 128), ((2,), 96), ((9, 13), 64), ((3,), 64), ((4,), 32), ((5,), 32), ((6,), 32), ((7,), 32), ((8,), 32), ((10,), 32), ((11,), 32), ((12,), 32), ((14,), 32)]
{'R_grad_norm': 1.9725420367717743, 'training_loss': 8.844173865318298}
{'R_grad_norm': 1.976364840865135, 'training_loss': 8.875955715179444}
{'R_grad_norm': 1.9758051842451096, 'training_loss': 8.861293182373046}
{'R_grad_norm': 1.9728997069597245, 'training_loss': 8.85908185005188}
{'R_grad_norm': 1.974278174638748, 'training_loss': 8.86216390132904}
{'R_grad_norm': 1.9721525537967681, 'training_loss': 8.848499774932861}
{'R_grad_norm': 1.9657349824905395, 'training_loss': 8.832131328582763}
{'R_grad_norm': 1.9658932077884674, 'training_loss': 8.842202072143555}
{'R_grad_norm': 1.9664469486474991, 'training_loss': 8.851532526016236}
{'R_grad_norm': 1.9657242411375047, 'training_loss': 8.844376754760741}
{'R_grad_norm': 1.9651787793636322, 'training_loss': 8.846695456504822}
{'R_grad_norm': 1.9693846929073333, 'training_loss': 8.868685026168823}
{'R_grad_norm': 1.9621013087034225, 'training_loss': 8.82318651676178}
{'R_grad_norm': 1.9657801330089568, 'training_loss': 8.852998914718627}
{'R_grad_norm': 1.9682589900493621, 'training_loss': 8.847197880744934}
{'R_grad_norm': 1.966601361632347, 'training_loss': 8.85710943222046}
{'R_grad_norm': 1.9635416001081467, 'training_loss': 8.852412028312683}
{'R_grad_norm': 1.9663460284471512, 'training_loss': 8.859644141197204}
{'R_grad_norm': 1.9606954431533814, 'training_loss': 8.833923597335815}
{'R_grad_norm': 1.9572096002101897, 'training_loss': 8.811440038681031}
{'R_grad_norm': 1.9615438067913056, 'training_loss': 8.829233703613282}
{'R_grad_norm': 1.960016763806343, 'training_loss': 8.843357553482056}
{'R_grad_norm': 1.957433003783226, 'training_loss': 8.831533932685852}
{'R_grad_norm': 1.956246337890625, 'training_loss': 8.826806321144105}
{'R_grad_norm': 1.9561859887838364, 'training_loss': 8.810135469436645}
{'R_grad_norm': 1.9577546584606171, 'training_loss': 8.824718527793884}
{'R_grad_norm': 1.9577683645486832, 'training_loss': 8.843581886291505}
{'R_grad_norm': 1.9528696739673614, 'training_loss': 8.813361144065857}
{'R_grad_norm': 1.9518747168779373, 'training_loss': 8.816077208518982}
{'R_grad_norm': 1.9584898126125336, 'training_loss': 8.84676338672638}
{'R_grad_norm': 1.9547285252809525, 'training_loss': 8.850281248092651}
{'R_grad_norm': 1.95436173081398, 'training_loss': 8.826933121681213}
{'R_grad_norm': 1.9497781652212143, 'training_loss': 8.810137724876403}
{'R_grad_norm': 1.955240061879158, 'training_loss': 8.853483529090882}
{'R_grad_norm': 1.954087553024292, 'training_loss': 8.83225562095642}
{'R_grad_norm': 1.9501496106386185, 'training_loss': 8.821050395965576}
{'R_grad_norm': 1.9499435138702392, 'training_loss': 8.835870242118835}
{'R_grad_norm': 1.949825987815857, 'training_loss': 8.821384687423706}
{'R_grad_norm': 1.9470366472005844, 'training_loss': 8.821314234733581}
{'R_grad_norm': 1.946304075717926, 'training_loss': 8.819841003417968}
eval result tensor([16.60220, 12.67386, 15.85441, 12.02897,  9.72314,  6.70951,  4.52650,
         6.98891,  6.18336,  7.09859,  6.95984,  5.87403,  6.18135,  6.59475],
       device='cuda:0')
computing merge metric
normed mi [((7, 13), 0.0440034419298172), ((6, 9), 0.042285285890102386), ((8, 12), 0.03964531794190407), ((9, 10), 0.038778308779001236), ((11, 12), 0.038497425615787506), ((4, 12), 0.03815405319134394), ((7, 12), 0.03808177262544632), ((8, 11), 0.0374065637588501), ((7, 11), 0.036678247153759), ((2, 3), 0.03643395602703094), ((12, 13), 0.03631974384188652), ((2, 12), 0.0359625443816185), ((7, 8), 0.0355653315782547), ((4, 13), 0.03552825252215067), ((4, 8), 0.034376442432403564), ((8, 13), 0.034135423600673676), ((6, 10), 0.03404691442847252), ((4, 11), 0.03392699112494787), ((3, 12), 0.033380123476187386), ((11, 13), 0.033356938511133194), ((4, 7), 0.033039274315039315), ((0, 4), 0.032314750055472054), ((2, 4), 0.03182324469089508), ((2, 7), 0.03128657117486), ((1, 2), 0.030843902911458696), ((3, 7), 0.03054999311765035), ((3, 8), 0.030160183707873028), ((2, 8), 0.029161512851715088), ((3, 11), 0.028669518729050953), ((1, 3), 0.027765649060408275), ((0, 2), 0.02715969298567091), ((2, 11), 0.026598520576953888), ((0, 1), 0.026575829833745956), ((0, 12), 0.026331058144569396), ((0, 7), 0.025926637649536132), ((1, 4), 0.025374082227547962), ((3, 4), 0.025119056925177574), ((1, 12), 0.025112485885620116), ((0, 13), 0.024710924923419954), ((2, 13), 0.02335193194448948), ((1, 6), 0.02318791002035141), ((0, 11), 0.0229748398065567), ((0, 8), 0.022957120835781098), ((1, 7), 0.02260289192199707), ((3, 13), 0.021213603516419727), ((1, 11), 0.02109190672636032), ((1, 8), 0.020359475910663605), ((0, 3), 0.019943442195653915), ((6, 7), 0.019556988030672073), ((3, 6), 0.018926690022150677), ((6, 11), 0.01811010017991066), ((6, 12), 0.0179471205919981), ((5, 7), 0.016832508146762848), ((1, 13), 0.016622549295425414), ((6, 8), 0.015757929533720016), ((2, 6), 0.013977869413793087), ((4, 6), 0.013681825250387192), ((5, 9), 0.012294760905206203), ((5, 6), 0.011480754241347313), ((6, 13), 0.011399887502193451), ((5, 11), 0.010670301504433155), ((5, 10), 0.010185430757701397), ((0, 6), 0.010086876899003982), ((5, 8), 0.008918123319745064), ((5, 12), 0.0087086521089077), ((7, 9), 0.008140221238136292), ((5, 13), 0.007182233035564423), ((9, 12), 0.0070325881242752075), ((1, 5), 0.006902869790792465), ((3, 5), 0.006833162779609363), ((2, 5), 0.006775354500859976), ((1, 9), 0.006645961850881577), ((4, 5), 0.0063138697296381), ((9, 11), 0.00594958895817399), ((2, 9), 0.005145620089024305), ((8, 9), 0.005120888352394104), ((7, 10), 0.005056265275925398), ((3, 9), 0.004410182436307271), ((0, 5), 0.004298849403858185), ((10, 12), 0.004153125919401646), ((4, 9), 0.004130532344182332), ((10, 11), 0.0040297056548297405), ((1, 10), 0.00400182344019413), ((9, 13), 0.003959986846894026), ((8, 10), 0.0031557753682136536), ((10, 13), 0.0027739875949919224), ((4, 10), 0.002719105531771978), ((2, 10), 0.002479249844327569), ((0, 9), 0.002443147823214531), ((3, 10), 0.002206937875598669), ((0, 10), 0.0016550077125430107)]
******* after merging (0.04): [((0,), 128), ((1,), 128), ((2,), 96), ((7, 13), 64), ((3,), 64), ((4,), 64), ((5,), 32), ((6,), 32), ((8,), 32), ((9,), 32), ((10,), 32), ((11,), 32), ((12,), 32)]
{'R_grad_norm': 2.015462204813957, 'training_loss': 9.355096526145935}
{'R_grad_norm': 2.007979318499565, 'training_loss': 9.311159868240356}
{'R_grad_norm': 2.003243206143379, 'training_loss': 9.291735281944275}
{'R_grad_norm': 2.001893340349197, 'training_loss': 9.291969456672668}
{'R_grad_norm': 2.009360461235046, 'training_loss': 9.326432571411132}
{'R_grad_norm': 2.005092911720276, 'training_loss': 9.316718420982362}
{'R_grad_norm': 2.0043031859397886, 'training_loss': 9.321264872550964}
{'R_grad_norm': 2.0063220328092575, 'training_loss': 9.315721807479859}
{'R_grad_norm': 2.0124525380134584, 'training_loss': 9.353162970542908}
{'R_grad_norm': 2.016674434542656, 'training_loss': 9.39411561012268}
{'R_grad_norm': 2.0190132570266726, 'training_loss': 9.383384943008423}
{'R_grad_norm': 2.020289801359177, 'training_loss': 9.404903025627137}
{'R_grad_norm': 2.0261756920814515, 'training_loss': 9.423781390190124}
{'R_grad_norm': 2.032942754626274, 'training_loss': 9.478319101333618}
{'R_grad_norm': 2.0392438346147537, 'training_loss': 9.511732230186462}
{'R_grad_norm': 2.0394171470403673, 'training_loss': 9.509169006347657}
{'R_grad_norm': 2.05080053627491, 'training_loss': 9.587172908782959}
{'R_grad_norm': 2.0583646070957182, 'training_loss': 9.619948954582215}
{'R_grad_norm': 2.058999944329262, 'training_loss': 9.637002892494202}
{'R_grad_norm': 2.070214765071869, 'training_loss': 9.698358941078187}
{'R_grad_norm': 2.0814599108695986, 'training_loss': 9.778888573646546}
{'R_grad_norm': 2.090857692360878, 'training_loss': 9.805846633911132}
{'R_grad_norm': 2.106387152671814, 'training_loss': 9.915911884307862}
{'R_grad_norm': 2.00121597468853, 'training_loss': 9.30725980758667}
{'R_grad_norm': 1.9810847324132919, 'training_loss': 9.201201171875}
{'R_grad_norm': 1.974964024424553, 'training_loss': 9.16704623222351}
{'R_grad_norm': 1.980635758638382, 'training_loss': 9.186832270622254}
{'R_grad_norm': 1.9789683109521865, 'training_loss': 9.195512986183166}
{'R_grad_norm': 1.9756094801425934, 'training_loss': 9.182778582572936}
{'R_grad_norm': 1.980994668006897, 'training_loss': 9.210216088294983}
{'R_grad_norm': 1.9696530556678773, 'training_loss': 9.122498483657838}
{'R_grad_norm': 1.9781043100357056, 'training_loss': 9.200061507225037}
{'R_grad_norm': 1.971785796880722, 'training_loss': 9.157670993804931}
{'R_grad_norm': 1.9803952378034593, 'training_loss': 9.218516006469727}
{'R_grad_norm': 1.973371817469597, 'training_loss': 9.163719267845154}
{'R_grad_norm': 1.9763903027772904, 'training_loss': 9.181694025993346}
{'R_grad_norm': 1.9706567776203157, 'training_loss': 9.176887702941894}
{'R_grad_norm': 1.9755334454774856, 'training_loss': 9.19065050125122}
{'R_grad_norm': 1.9717697566747665, 'training_loss': 9.177319340705871}
{'R_grad_norm': 1.9694634926319123, 'training_loss': 9.168555436134339}
eval result tensor([16.22553, 12.35514, 15.57954, 11.73676, 11.56523,  9.35235,  6.56598,
         4.39058,  5.96065,  6.87345,  6.81900,  5.68578,  6.07780],
       device='cuda:0')
computing merge metric
normed mi [((7, 9), 0.04273896664381027), ((8, 12), 0.04102900251746178), ((11, 12), 0.03958086296916008), ((9, 10), 0.039217691868543625), ((5, 12), 0.038304172456264496), ((8, 11), 0.03824632242321968), ((2, 4), 0.037033256888389585), ((7, 10), 0.03551094979047775), ((2, 12), 0.03537723794579506), ((5, 11), 0.034890949726104736), ((5, 8), 0.03453406939903895), ((4, 12), 0.03406973679860433), ((0, 5), 0.03208701809247335), ((3, 12), 0.031589445968468986), ((2, 5), 0.03155547976493835), ((3, 5), 0.03139607235789299), ((4, 8), 0.031331402560075126), ((1, 2), 0.030295084629740034), ((4, 11), 0.02981570114692052), ((3, 11), 0.029624489446481068), ((1, 4), 0.02935601770877838), ((3, 8), 0.029326893389225006), ((2, 8), 0.02928919903934002), ((2, 3), 0.027909603714942933), ((1, 7), 0.027871927618980406), ((0, 3), 0.026856866975625355), ((0, 2), 0.026469741548810686), ((2, 11), 0.026407387107610703), ((0, 1), 0.02639148198068142), ((0, 12), 0.02620134949684143), ((1, 5), 0.025863366822401684), ((4, 5), 0.02581043355166912), ((1, 12), 0.02548786699771881), ((4, 7), 0.024608721335728962), ((3, 4), 0.024195028468966484), ((0, 11), 0.023797962069511413), ((0, 8), 0.022968587279319764), ((7, 12), 0.022716598585247993), ((7, 11), 0.021679546684026718), ((1, 11), 0.021578346192836762), ((1, 8), 0.020956447720527648), ((0, 4), 0.020198296755552292), ((7, 8), 0.020062221214175224), ((1, 3), 0.01952892045180003), ((5, 7), 0.017471977819999058), ((2, 7), 0.017360089346766472), ((6, 9), 0.01417978759855032), ((6, 10), 0.01413052435964346), ((6, 7), 0.013503286987543106), ((3, 7), 0.012768145650625229), ((0, 7), 0.01254361867904663), ((6, 11), 0.011715115047991276), ((9, 12), 0.010256845504045486), ((3, 6), 0.009847824151317278), ((6, 8), 0.009815926663577557), ((6, 12), 0.00962919369339943), ((1, 9), 0.008828691393136977), ((9, 11), 0.008290546014904976), ((8, 9), 0.007931489497423172), ((4, 6), 0.007677583644787471), ((2, 9), 0.007336700800806284), ((1, 6), 0.007240179181098938), ((2, 6), 0.0070699118077754974), ((10, 12), 0.007069368381053209), ((4, 9), 0.00701154147585233), ((5, 6), 0.006942473351955414), ((10, 11), 0.006377808284014463), ((1, 10), 0.006334473192691803), ((5, 9), 0.006109563633799553), ((8, 10), 0.005852499511092901), ((3, 9), 0.004928589798510075), ((5, 10), 0.004582749369243781), ((4, 10), 0.004544991999864578), ((0, 6), 0.004543250426650047), ((2, 10), 0.004405478946864605), ((3, 10), 0.003734090675910314), ((0, 9), 0.0035864580422639847), ((0, 10), 0.0027391651645302774)]
******* after merging (0.04): [((0,), 128), ((1,), 128), ((2,), 96), ((7, 9), 64), ((3,), 64), ((4,), 64), ((5,), 64), ((6,), 32), ((8,), 32), ((10,), 32), ((11,), 32), ((12,), 32)]
{'R_grad_norm': 2.0547660940885546, 'training_loss': 9.927276902198791}
{'R_grad_norm': 2.0486652565002443, 'training_loss': 9.888429760932922}
{'R_grad_norm': 2.048218309879303, 'training_loss': 9.883940153121948}
{'R_grad_norm': 2.0509202659130095, 'training_loss': 9.897102389335632}
{'R_grad_norm': 2.0520922148227694, 'training_loss': 9.900749187469483}
{'R_grad_norm': 2.047548869252205, 'training_loss': 9.864670395851135}
{'R_grad_norm': 2.0529606485366823, 'training_loss': 9.902453074455261}
{'R_grad_norm': 2.0518943238258363, 'training_loss': 9.910101833343505}
{'R_grad_norm': 2.0453039979934693, 'training_loss': 9.855753293037415}
{'R_grad_norm': 2.049091178178787, 'training_loss': 9.872189965248108}
{'R_grad_norm': 2.0514261817932127, 'training_loss': 9.89779492855072}
{'R_grad_norm': 2.0472957050800322, 'training_loss': 9.880534062385559}
{'R_grad_norm': 2.041111721992493, 'training_loss': 9.865471115112305}
{'R_grad_norm': 2.0455499225854874, 'training_loss': 9.893425884246826}
{'R_grad_norm': 2.042644740343094, 'training_loss': 9.86118266105652}
{'R_grad_norm': 2.0411128467321396, 'training_loss': 9.86137800693512}
{'R_grad_norm': 2.040808608531952, 'training_loss': 9.845445685386657}
{'R_grad_norm': 2.042479683756828, 'training_loss': 9.882729086875916}
{'R_grad_norm': 2.0376830393075944, 'training_loss': 9.856000847816468}
{'R_grad_norm': 2.033320804834366, 'training_loss': 9.830394320487976}
{'R_grad_norm': 2.0371932566165922, 'training_loss': 9.84653582572937}
{'R_grad_norm': 2.0374774795770647, 'training_loss': 9.856305565834045}
{'R_grad_norm': 2.035629647374153, 'training_loss': 9.840941863059998}
{'R_grad_norm': 2.0359718453884126, 'training_loss': 9.8442706823349}
{'R_grad_norm': 2.0391154700517653, 'training_loss': 9.868501152992248}
{'R_grad_norm': 2.0329870545864104, 'training_loss': 9.848301153182984}
{'R_grad_norm': 2.03105720102787, 'training_loss': 9.833177604675292}
{'R_grad_norm': 2.0334533178806304, 'training_loss': 9.854300756454467}
{'R_grad_norm': 2.0334788769483567, 'training_loss': 9.83767927646637}
{'R_grad_norm': 2.0280851572752, 'training_loss': 9.826076593399048}
{'R_grad_norm': 2.024955515265465, 'training_loss': 9.813148069381715}
{'R_grad_norm': 2.026707332730293, 'training_loss': 9.812110481262208}
{'R_grad_norm': 2.0267256700992586, 'training_loss': 9.824291305541992}
{'R_grad_norm': 2.026760339140892, 'training_loss': 9.847873215675355}
{'R_grad_norm': 2.025086928009987, 'training_loss': 9.826590065956117}
{'R_grad_norm': 2.021139127612114, 'training_loss': 9.809079852104187}
{'R_grad_norm': 2.027140409350395, 'training_loss': 9.831926040649414}
{'R_grad_norm': 2.021454735994339, 'training_loss': 9.82071578502655}
{'R_grad_norm': 2.0208141803741455, 'training_loss': 9.800477213859558}
{'R_grad_norm': 2.022347021698952, 'training_loss': 9.81080307006836}
eval result tensor([16.52485, 12.16622, 15.95722,  9.34692, 12.02806, 11.68506,  9.24939,
         6.61900,  5.87022,  6.94989,  5.64124,  6.09967], device='cuda:0')
computing merge metric
normed mi [((8, 11), 0.03957390412688255), ((6, 11), 0.03733506550391515), ((10, 11), 0.0372648686170578), ((8, 10), 0.03626353666186333), ((2, 5), 0.03549773395061493), ((6, 8), 0.03458699584007263), ((2, 11), 0.03406143933534622), ((6, 10), 0.033666941026846565), ((5, 11), 0.03297321250041326), ((0, 6), 0.031123943626880646), ((2, 6), 0.030989620089530944), ((4, 11), 0.03051129976908366), ((4, 6), 0.030186675488948822), ((1, 3), 0.029720594485600788), ((5, 8), 0.029111593961715698), ((4, 8), 0.028981052339076996), ((1, 5), 0.02852827062209447), ((4, 10), 0.02840898682673772), ((5, 10), 0.028394917647043865), ((1, 2), 0.028109942163739885), ((2, 4), 0.027839866280555726), ((2, 8), 0.027236072346568108), ((0, 4), 0.026696900526682537), ((0, 2), 0.02604919033391135), ((5, 6), 0.025916941463947296), ((3, 5), 0.025805354118347168), ((0, 11), 0.025397002696990967), ((0, 1), 0.025017354637384415), ((2, 10), 0.024556027725338936), ((1, 6), 0.024225160479545593), ((4, 5), 0.02373204007744789), ((1, 11), 0.023701512813568117), ((0, 8), 0.02334522157907486), ((3, 11), 0.023052347203095753), ((0, 10), 0.022502507269382476), ((2, 3), 0.022405998408794404), ((3, 10), 0.020852066576480865), ((3, 6), 0.020362718030810356), ((0, 5), 0.01991780350605647), ((1, 10), 0.01936826854944229), ((3, 8), 0.019189103196064632), ((1, 8), 0.01886788159608841), ((1, 4), 0.018134180456399918), ((3, 9), 0.016053784638643265), ((7, 9), 0.01568685844540596), ((0, 3), 0.013583250343799591), ((3, 4), 0.013377074152231216), ((7, 10), 0.011017694137990475), ((3, 7), 0.010869051019350687), ((4, 7), 0.010080929224689802), ((7, 11), 0.009319692850112915), ((7, 8), 0.008437767624855042), ((1, 9), 0.007947638630867004), ((9, 11), 0.007862121798098087), ((5, 7), 0.00777231218914191), ((1, 7), 0.007463239133358002), ((6, 7), 0.007029321665565173), ((2, 7), 0.0069960844703018665), ((9, 10), 0.006809582933783531), ((8, 9), 0.005851253867149353), ((5, 9), 0.00568510964512825), ((2, 9), 0.005026207305490971), ((6, 9), 0.004978467399875323), ((0, 7), 0.004404520988464356), ((4, 9), 0.004259561498959859), ((0, 9), 0.0030410729348659517)]
finish training (76000)
evaluating (25 steps)...
 ******* eval result *******
mean (weighted) 11.591420491536459
mean (unweighted) 9.833026885986328
tensor([16.50987, 12.13370, 15.97599,  9.34276, 12.01276, 11.69127,  9.26830,
         6.58943,  5.85497,  6.92973,  5.63208,  6.05547], device='cuda:0')
