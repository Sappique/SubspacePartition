{'R_grad_norm': 1.4492387115955352, 'training_loss': 10.121423678398132}
{'R_grad_norm': 1.473006807565689, 'training_loss': 9.946148681640626}
{'R_grad_norm': 1.484170169234276, 'training_loss': 9.815779066085815}
{'R_grad_norm': 1.4871453386545181, 'training_loss': 9.645879893302917}
{'R_grad_norm': 1.501729000210762, 'training_loss': 9.584781994819641}
{'R_grad_norm': 1.511262400150299, 'training_loss': 9.51754898071289}
{'R_grad_norm': 1.5141041994094848, 'training_loss': 9.426054463386535}
{'R_grad_norm': 1.5161955630779267, 'training_loss': 9.335938429832458}
{'R_grad_norm': 1.5192844724655152, 'training_loss': 9.280450353622436}
{'R_grad_norm': 1.5216179132461547, 'training_loss': 9.218842787742615}
{'R_grad_norm': 1.5216695827245712, 'training_loss': 9.171974320411682}
{'R_grad_norm': 1.519168689250946, 'training_loss': 9.085740203857421}
{'R_grad_norm': 1.5194016516208648, 'training_loss': 9.042324829101563}
{'R_grad_norm': 1.5182359904050826, 'training_loss': 9.015535621643066}
{'R_grad_norm': 1.518759223818779, 'training_loss': 8.96149001121521}
{'R_grad_norm': 1.5218573850393295, 'training_loss': 8.95115282535553}
{'R_grad_norm': 1.5181755071878433, 'training_loss': 8.910051808357238}
{'R_grad_norm': 1.5201028841733932, 'training_loss': 8.875892009735107}
{'R_grad_norm': 1.5098959958553315, 'training_loss': 8.792868695259095}
{'R_grad_norm': 1.5140328985452651, 'training_loss': 8.794430613517761}
{'R_grad_norm': 1.51574094414711, 'training_loss': 8.767223415374756}
{'R_grad_norm': 1.5150065100193024, 'training_loss': 8.755090789794922}
{'R_grad_norm': 1.5123007345199584, 'training_loss': 8.720164499282838}
{'R_grad_norm': 1.5129127526283264, 'training_loss': 8.698930053710937}
{'R_grad_norm': 1.5076905769109725, 'training_loss': 8.645622701644898}
{'R_grad_norm': 1.5099153476953506, 'training_loss': 8.64788547039032}
{'R_grad_norm': 1.508326923251152, 'training_loss': 8.60863995552063}
{'R_grad_norm': 1.5081214171648025, 'training_loss': 8.606526958942414}
{'R_grad_norm': 1.5079493230581285, 'training_loss': 8.59871277809143}
{'R_grad_norm': 1.507492349743843, 'training_loss': 8.588615479469299}
{'R_grad_norm': 1.5035570859909058, 'training_loss': 8.545861377716065}
{'R_grad_norm': 1.5048231768608094, 'training_loss': 8.541230921745301}
{'R_grad_norm': 1.5045864552259445, 'training_loss': 8.527366471290588}
{'R_grad_norm': 1.5017874878644943, 'training_loss': 8.49726080417633}
{'R_grad_norm': 1.5053190988302232, 'training_loss': 8.515071024894715}
{'R_grad_norm': 1.503980803489685, 'training_loss': 8.507017748355866}
{'R_grad_norm': 1.500520285964012, 'training_loss': 8.479797942638397}
{'R_grad_norm': 1.4963548398017883, 'training_loss': 8.45570347070694}
{'R_grad_norm': 1.4978689229488373, 'training_loss': 8.44933441400528}
{'R_grad_norm': 1.5031180304288865, 'training_loss': 8.469258344173431}
{'R_grad_norm': 1.4939368051290511, 'training_loss': 8.398025197982788}
{'R_grad_norm': 1.495194025039673, 'training_loss': 8.4027792596817}
{'R_grad_norm': 1.4949110871553422, 'training_loss': 8.397044739723206}
{'R_grad_norm': 1.4935889744758606, 'training_loss': 8.396935753822326}
{'R_grad_norm': 1.4945460760593414, 'training_loss': 8.382196390628815}
{'R_grad_norm': 1.4964618682861328, 'training_loss': 8.388775544166565}
{'R_grad_norm': 1.49413933634758, 'training_loss': 8.374382314682007}
{'R_grad_norm': 1.4928350734710694, 'training_loss': 8.369037020206452}
{'R_grad_norm': 1.494722175002098, 'training_loss': 8.381312336921692}
{'R_grad_norm': 1.4894245076179504, 'training_loss': 8.331922674179078}
{'R_grad_norm': 1.4883289694786073, 'training_loss': 8.327973737716675}
{'R_grad_norm': 1.4897391450405122, 'training_loss': 8.328982729911804}
{'R_grad_norm': 1.490977640748024, 'training_loss': 8.3255166554451}
{'R_grad_norm': 1.4896026557683946, 'training_loss': 8.312459318637847}
{'R_grad_norm': 1.488780671954155, 'training_loss': 8.297756316661834}
{'R_grad_norm': 1.4890959769487382, 'training_loss': 8.312324593067169}
{'R_grad_norm': 1.4849243777990342, 'training_loss': 8.28524040222168}
{'R_grad_norm': 1.4878285241127014, 'training_loss': 8.312246706485748}
{'R_grad_norm': 1.4843184834718703, 'training_loss': 8.27599541425705}
{'R_grad_norm': 1.485820381641388, 'training_loss': 8.292605493068695}
{'R_grad_norm': 1.4854008680582047, 'training_loss': 8.277058062553406}
{'R_grad_norm': 1.4815271908044816, 'training_loss': 8.25046685218811}
{'R_grad_norm': 1.4863961726427077, 'training_loss': 8.279021914005279}
{'R_grad_norm': 1.485313127040863, 'training_loss': 8.274004096984862}
{'R_grad_norm': 1.48484257042408, 'training_loss': 8.264410352706909}
{'R_grad_norm': 1.4814899826049805, 'training_loss': 8.248894205093384}
{'R_grad_norm': 1.4813603067398071, 'training_loss': 8.251431245803833}
{'R_grad_norm': 1.4858561718463899, 'training_loss': 8.263290300369263}
{'R_grad_norm': 1.4814324104785919, 'training_loss': 8.240395019054413}
{'R_grad_norm': 1.4846131670475007, 'training_loss': 8.25950054168701}
{'R_grad_norm': 1.481124495267868, 'training_loss': 8.229456055164338}
{'R_grad_norm': 1.4794030421972275, 'training_loss': 8.221734380722046}
{'R_grad_norm': 1.4795397716760634, 'training_loss': 8.212614364624024}
{'R_grad_norm': 1.479735830426216, 'training_loss': 8.231136584281922}
{'R_grad_norm': 1.4820377999544143, 'training_loss': 8.24848301410675}
{'R_grad_norm': 1.4749743676185607, 'training_loss': 8.204615576267242}
{'R_grad_norm': 1.4778754532337188, 'training_loss': 8.201279933452605}
{'R_grad_norm': 1.4791340225934981, 'training_loss': 8.22610116481781}
{'R_grad_norm': 1.4800814074277877, 'training_loss': 8.223713240623475}
{'R_grad_norm': 1.4772952175140381, 'training_loss': 8.205480017662047}
{'R_grad_norm': 1.4775163906812667, 'training_loss': 8.206162240505218}
{'R_grad_norm': 1.4775763845443726, 'training_loss': 8.199887976646423}
{'R_grad_norm': 1.4730134338140488, 'training_loss': 8.171018831729889}
{'R_grad_norm': 1.4775209510326386, 'training_loss': 8.20549967288971}
{'R_grad_norm': 1.475563492178917, 'training_loss': 8.18497243642807}
{'R_grad_norm': 1.4760423576831818, 'training_loss': 8.19315438747406}
{'R_grad_norm': 1.4717347061634063, 'training_loss': 8.169063413143158}
{'R_grad_norm': 1.4732254272699357, 'training_loss': 8.180713758468627}
{'R_grad_norm': 1.4736611795425416, 'training_loss': 8.18359778881073}
{'R_grad_norm': 1.4761183220148086, 'training_loss': 8.182351369857788}
{'R_grad_norm': 1.4695983958244323, 'training_loss': 8.167749471664429}
{'R_grad_norm': 1.4737190133333207, 'training_loss': 8.179162023067475}
{'R_grad_norm': 1.4713693964481354, 'training_loss': 8.17664482831955}
{'R_grad_norm': 1.4694076925516129, 'training_loss': 8.149022295475007}
{'R_grad_norm': 1.4698195165395738, 'training_loss': 8.145799822807312}
{'R_grad_norm': 1.470967566370964, 'training_loss': 8.158759784698486}
{'R_grad_norm': 1.4696660947799682, 'training_loss': 8.142235496044158}
{'R_grad_norm': 1.4683653599023818, 'training_loss': 8.13922472000122}
{'R_grad_norm': 1.4655926090478897, 'training_loss': 8.131520714759827}
{'R_grad_norm': 1.4709377652406692, 'training_loss': 8.164124999046326}
eval result tensor([ 6.21511,  7.86781,  8.55620,  7.89766,  6.72650,  8.86722,  7.74824,
         8.45094,  8.80863,  7.20019,  7.84661,  8.71747,  8.58218,  9.16870,
         9.48525,  8.61054,  7.13082,  7.76069,  8.64758,  6.90976,  6.13990,
        10.36591,  7.92955,  9.11555], device='cuda:0')
computing merge metric
normed mi [((0, 20), 0.12171871215105057), ((9, 20), 0.11788716167211533), ((9, 12), 0.10950072854757309), ((0, 9), 0.10800223797559738), ((0, 19), 0.10348263382911682), ((19, 20), 0.10204589366912842), ((16, 19), 0.10103782266378403), ((9, 19), 0.10066261887550354), ((0, 16), 0.100016288459301), ((16, 20), 0.09991873800754547), ((12, 20), 0.09690127521753311), ((9, 16), 0.09579969942569733), ((3, 9), 0.09151630848646164), ((12, 19), 0.09087368845939636), ((0, 12), 0.08957849442958832), ((4, 20), 0.08796632289886475), ((3, 12), 0.08750656247138977), ((3, 19), 0.08719043433666229), ((5, 12), 0.0847470611333847), ((12, 16), 0.08468206226825714), ((3, 20), 0.08416663110256195), ((9, 22), 0.08383984118700027), ((19, 22), 0.08341269940137863), ((0, 3), 0.08291371911764145), ((12, 22), 0.08227698504924774), ((3, 16), 0.08053595572710037), ((6, 19), 0.08023423701524734), ((5, 9), 0.07623064517974854), ((1, 19), 0.07603834569454193), ((3, 22), 0.07544374465942383), ((4, 9), 0.07466547191143036), ((16, 22), 0.07415396720170975), ((20, 22), 0.07239154726266861), ((6, 16), 0.07235346734523773), ((12, 21), 0.07116436958312988), ((0, 22), 0.07053317129611969), ((5, 22), 0.07028613239526749), ((10, 19), 0.07016801834106445), ((0, 4), 0.0699373409152031), ((7, 16), 0.06800577789545059), ((1, 22), 0.06779754161834717), ((1, 6), 0.06670844554901123), ((0, 6), 0.06663981825113297), ((17, 19), 0.06641529500484467), ((10, 12), 0.06622936576604843), ((7, 19), 0.06616821885108948), ((1, 16), 0.06613384187221527), ((7, 12), 0.066042959690094), ((5, 19), 0.06538727134466171), ((3, 5), 0.06530255824327469), ((10, 22), 0.06529902666807175), ((12, 17), 0.06369848549365997), ((1, 10), 0.06356275081634521), ((1, 9), 0.0632578581571579), ((9, 17), 0.06319230049848557), ((3, 17), 0.06316561996936798), ((1, 3), 0.06312882900238037), ((5, 20), 0.06292615830898285), ((7, 9), 0.06287860125303268), ((6, 22), 0.06285496801137924), ((9, 21), 0.06266510486602783), ((6, 20), 0.0626208633184433), ((9, 10), 0.06248766928911209), ((10, 16), 0.06209111213684082), ((6, 9), 0.06194495037198067), ((1, 12), 0.061596207320690155), ((6, 10), 0.061463091522455215), ((3, 21), 0.061293113976716995), ((0, 7), 0.061119936406612396), ((7, 22), 0.060089852660894394), ((3, 10), 0.060071710497140884), ((5, 16), 0.05997692048549652), ((0, 1), 0.05978037789463997), ((3, 6), 0.05976169556379318), ((3, 7), 0.05926341563463211), ((16, 17), 0.05902571603655815), ((6, 12), 0.0588361881673336), ((17, 22), 0.0587766058743), ((11, 19), 0.0587429478764534), ((7, 20), 0.058453988283872604), ((7, 21), 0.05840756371617317), ((0, 17), 0.05825066938996315), ((5, 21), 0.05802386999130249), ((6, 7), 0.05745520442724228), ((0, 5), 0.05723462998867035), ((1, 20), 0.05717926844954491), ((11, 12), 0.05688641592860222), ((7, 23), 0.056484464555978775), ((7, 10), 0.056218042969703674), ((4, 12), 0.05614197254180908), ((11, 22), 0.05592904984951019), ((19, 21), 0.05588532239198685), ((14, 19), 0.05541202425956726), ((17, 20), 0.055331673473119736), ((1, 18), 0.05512980371713638), ((16, 21), 0.05505160242319107), ((6, 18), 0.05504380911588669), ((3, 11), 0.054933857172727585), ((18, 19), 0.05492270365357399), ((12, 14), 0.05444730818271637), ((5, 10), 0.05440882593393326), ((20, 21), 0.054176606237888336), ((1, 17), 0.05403796210885048), ((0, 10), 0.05399639904499054), ((1, 11), 0.05375925451517105), ((10, 17), 0.05369094759225845), ((21, 22), 0.05353427305817604), ((0, 21), 0.053446438163518906), ((10, 18), 0.053347568958997726), ((1, 7), 0.05322645977139473), ((9, 11), 0.0530463270843029), ((1, 23), 0.05302279442548752), ((7, 18), 0.0525193065404892), ((10, 20), 0.05242175981402397), ((18, 23), 0.05230242758989334), ((11, 16), 0.05230066552758217), ((19, 23), 0.05227167159318924), ((10, 11), 0.05216246843338013), ((1, 14), 0.05193218216300011), ((6, 23), 0.051855720579624176), ((10, 23), 0.051746271550655365), ((14, 22), 0.051680948585271835), ((12, 23), 0.051577772945165634), ((1, 5), 0.051384396851062775), ((14, 16), 0.05131132900714874), ((5, 7), 0.05124123394489288), ((22, 23), 0.051238033920526505), ((9, 14), 0.05118280276656151), ((3, 14), 0.05117817595601082), ((7, 17), 0.051124319434165955), ((6, 17), 0.05109057202935219), ((5, 17), 0.0510551780462265), ((16, 18), 0.0509294718503952), ((6, 11), 0.05068506672978401), ((16, 23), 0.05057387053966522), ((18, 22), 0.05023527517914772), ((14, 23), 0.04995085299015045), ((21, 23), 0.049437254667282104), ((6, 14), 0.048812661319971085), ((14, 21), 0.048739559948444366), ((5, 11), 0.048692796379327774), ((3, 23), 0.04861855506896973), ((10, 14), 0.04813384264707565), ((17, 21), 0.04795551300048828), ((12, 18), 0.04793012514710426), ((4, 16), 0.04772522673010826), ((11, 17), 0.0476781390607357), ((7, 11), 0.047524016350507736), ((3, 18), 0.047074563801288605), ((5, 14), 0.04694652557373047), ((0, 11), 0.0468788668513298), ((5, 6), 0.04683532193303108), ((14, 18), 0.04642555117607117), ((9, 23), 0.04620247334241867), ((1, 21), 0.0461377389729023), ((11, 14), 0.04608729109168053), ((10, 21), 0.04608343169093132), ((3, 4), 0.04591164365410805), ((11, 23), 0.0458756722509861), ((7, 14), 0.0457201786339283), ((11, 18), 0.045413997024297714), ((11, 20), 0.04540889337658882), ((11, 21), 0.045227594673633575), ((1, 8), 0.04502629116177559), ((14, 20), 0.04501185938715935), ((8, 18), 0.04494813457131386), ((5, 23), 0.044945910573005676), ((0, 14), 0.044748373329639435), ((8, 23), 0.04465366154909134), ((4, 19), 0.04443489760160446), ((6, 8), 0.04412516579031944), ((9, 18), 0.04404507204890251), ((6, 21), 0.04395895451307297), ((8, 10), 0.043848633766174316), ((17, 23), 0.04356340691447258), ((14, 17), 0.04340999573469162), ((18, 21), 0.04325568675994873), ((17, 18), 0.04299158602952957), ((0, 18), 0.04247213900089264), ((8, 19), 0.04246902838349342), ((0, 23), 0.04230499640107155), ((5, 18), 0.041704148054122925), ((8, 22), 0.041486967355012894), ((7, 8), 0.04065713286399841), ((20, 23), 0.040497444570064545), ((8, 14), 0.039457812905311584), ((8, 16), 0.03923868387937546), ((18, 20), 0.03904088959097862), ((8, 11), 0.03752239793539047), ((5, 8), 0.03744835406541824), ((8, 12), 0.03736518695950508), ((4, 22), 0.03638223558664322), ((3, 8), 0.03549346327781677), ((8, 21), 0.034956395626068115), ((4, 13), 0.03465523570775986), ((8, 17), 0.034124135971069336), ((8, 9), 0.03335718438029289), ((4, 5), 0.03190312162041664), ((0, 8), 0.031008748337626457), ((13, 15), 0.029803583398461342), ((13, 20), 0.02898179553449154), ((8, 20), 0.02887284941971302), ((4, 15), 0.028493301942944527), ((4, 7), 0.028453925624489784), ((4, 21), 0.02761143445968628), ((4, 17), 0.026966845616698265), ((9, 13), 0.02613360434770584), ((1, 4), 0.024444663897156715), ((12, 13), 0.02388494834303856), ((4, 10), 0.023722123354673386), ((4, 6), 0.023326775059103966), ((0, 13), 0.022737421095371246), ((4, 11), 0.022608423605561256), ((2, 12), 0.0221652053296566), ((2, 9), 0.021486522629857063), ((2, 20), 0.020969120785593987), ((15, 20), 0.019580751657485962), ((4, 14), 0.019277524203062057), ((2, 5), 0.019009722396731377), ((0, 2), 0.01805705577135086), ((2, 16), 0.01794264279305935), ((2, 21), 0.017732927575707436), ((4, 23), 0.017589427530765533), ((2, 7), 0.017423244193196297), ((2, 19), 0.01667877472937107), ((2, 4), 0.01656600646674633), ((2, 22), 0.01640765555202961), ((2, 3), 0.01621653139591217), ((13, 16), 0.01606985740363598), ((4, 18), 0.016005398705601692), ((3, 13), 0.015972942113876343), ((9, 15), 0.015591288916766644), ((13, 19), 0.01525352243334055), ((5, 13), 0.01501538697630167), ((2, 17), 0.014959310181438923), ((0, 15), 0.014362186193466187), ((13, 22), 0.014016230590641499), ((13, 21), 0.01354365423321724), ((7, 13), 0.013307091780006886), ((2, 11), 0.013250410556793213), ((2, 23), 0.013030057772994041), ((12, 15), 0.012991296127438545), ((2, 10), 0.012792392633855343), ((1, 2), 0.01246554497629404), ((2, 14), 0.012115721590816975), ((4, 8), 0.012040878646075726), ((2, 6), 0.011927202343940735), ((13, 17), 0.011526819318532944), ((2, 13), 0.011510662734508514), ((2, 18), 0.011180588975548744), ((2, 8), 0.009824306704103947), ((10, 13), 0.009658755734562874), ((1, 13), 0.009412706829607487), ((2, 15), 0.009102991782128811), ((6, 13), 0.00903446413576603), ((11, 13), 0.009028913453221321), ((15, 16), 0.008805708959698677), ((13, 23), 0.008358948864042759), ((15, 19), 0.008140291087329388), ((3, 15), 0.007583559025079012), ((13, 14), 0.007443486712872982), ((13, 18), 0.007395605091005564), ((5, 15), 0.007175862789154053), ((15, 22), 0.00702297268435359), ((7, 15), 0.006071358919143677), ((8, 13), 0.005966271739453077), ((15, 17), 0.004988518543541431), ((15, 21), 0.00490616075694561), ((10, 15), 0.00458727078512311), ((1, 15), 0.004354155156761408), ((6, 15), 0.004318926017731428), ((11, 15), 0.004205363802611828), ((15, 23), 0.0035071917809545994), ((15, 18), 0.003289035754278302), ((14, 15), 0.0030311057344079018), ((8, 15), 0.002577583072707057)]
******* after merging (0.04): [((0, 20), 64), ((9, 12), 64), ((16, 19), 64), ((1,), 32), ((2,), 32), ((3,), 32), ((4,), 32), ((5,), 32), ((6,), 32), ((7,), 32), ((8,), 32), ((10,), 32), ((11,), 32), ((13,), 32), ((14,), 32), ((15,), 32), ((17,), 32), ((18,), 32), ((21,), 32), ((22,), 32), ((23,), 32)]
{'R_grad_norm': 1.853327335715294, 'training_loss': 8.860613107681274}
{'R_grad_norm': 1.8509729313850403, 'training_loss': 8.842437167167663}
{'R_grad_norm': 1.8509785079956054, 'training_loss': 8.838570585250855}
{'R_grad_norm': 1.8527815055847168, 'training_loss': 8.844404644966126}
{'R_grad_norm': 1.848743000626564, 'training_loss': 8.835147523880005}
{'R_grad_norm': 1.8487799072265625, 'training_loss': 8.810154824256896}
{'R_grad_norm': 1.8500068819522857, 'training_loss': 8.826853404045105}
{'R_grad_norm': 1.8436489218473435, 'training_loss': 8.784271025657654}
{'R_grad_norm': 1.8455031442642211, 'training_loss': 8.794469304084778}
{'R_grad_norm': 1.8513241767883302, 'training_loss': 8.820853929519654}
{'R_grad_norm': 1.8456254136562347, 'training_loss': 8.784926443099975}
{'R_grad_norm': 1.8463494551181794, 'training_loss': 8.788923192024232}
{'R_grad_norm': 1.8445167773962021, 'training_loss': 8.783564767837525}
{'R_grad_norm': 1.8539452707767488, 'training_loss': 8.832151083946227}
{'R_grad_norm': 1.8429608118534089, 'training_loss': 8.779055132865906}
{'R_grad_norm': 1.8424130719900131, 'training_loss': 8.776585297584534}
{'R_grad_norm': 1.8406087559461595, 'training_loss': 8.778682718276977}
{'R_grad_norm': 1.8412916737794875, 'training_loss': 8.766417746543885}
{'R_grad_norm': 1.8413092297315599, 'training_loss': 8.76575466632843}
{'R_grad_norm': 1.8436995154619218, 'training_loss': 8.783036031723022}
{'R_grad_norm': 1.838224954009056, 'training_loss': 8.764064345359802}
{'R_grad_norm': 1.8336197847127915, 'training_loss': 8.744387912750245}
{'R_grad_norm': 1.8340216434001924, 'training_loss': 8.742738723754883}
{'R_grad_norm': 1.8309490305185319, 'training_loss': 8.73944622039795}
{'R_grad_norm': 1.8326992124319077, 'training_loss': 8.744487953186034}
{'R_grad_norm': 1.8313804739713668, 'training_loss': 8.745148186683656}
{'R_grad_norm': 1.831481823325157, 'training_loss': 8.732915134429932}
{'R_grad_norm': 1.832771692276001, 'training_loss': 8.763442425727844}
{'R_grad_norm': 1.8320347917079927, 'training_loss': 8.757287788391114}
{'R_grad_norm': 1.8251536744832992, 'training_loss': 8.71735993862152}
{'R_grad_norm': 1.8217881798744202, 'training_loss': 8.695386781692505}
{'R_grad_norm': 1.8232966566085815, 'training_loss': 8.716928429603577}
{'R_grad_norm': 1.8280338114500045, 'training_loss': 8.74520751953125}
{'R_grad_norm': 1.8239128470420838, 'training_loss': 8.723316044807435}
{'R_grad_norm': 1.8295527082681655, 'training_loss': 8.748008151054382}
{'R_grad_norm': 1.823277803659439, 'training_loss': 8.720673332214355}
{'R_grad_norm': 1.8209699338674545, 'training_loss': 8.70652114868164}
{'R_grad_norm': 1.8217133212089538, 'training_loss': 8.724359827041626}
{'R_grad_norm': 1.8195077735185623, 'training_loss': 8.710338006019592}
{'R_grad_norm': 1.8205267524719237, 'training_loss': 8.730436882972718}
eval result tensor([ 9.39686, 13.81890, 11.30737,  7.65755,  8.29492,  7.46988,  6.14602,
         8.73958,  7.36123,  8.58531,  8.56439,  7.65331,  8.44189,  9.02465,
         9.36644,  8.46917,  7.56830,  8.42532, 10.14992,  7.71404,  8.89949],
       device='cuda:0')
computing merge metric
normed mi [((5, 19), 0.06815081089735031), ((7, 19), 0.06396586447954178), ((1, 5), 0.06260952353477478), ((3, 19), 0.06233392283320427), ((3, 8), 0.06208726763725281), ((11, 19), 0.06044905632734299), ((5, 7), 0.060075923800468445), ((0, 5), 0.0591659148534139), ((1, 19), 0.05905301868915558), ((1, 7), 0.05857463677724203), ((2, 8), 0.05811333656311035), ((8, 19), 0.0581028051674366), ((3, 5), 0.05793653801083565), ((3, 11), 0.057911451905965805), ((2, 5), 0.05730991065502167), ((0, 2), 0.05695819854736328), ((8, 11), 0.05675270035862923), ((5, 18), 0.05674663558602333), ((5, 16), 0.056741487234830856), ((0, 1), 0.05650549381971359), ((5, 8), 0.05638938397169113), ((5, 11), 0.05607221648097038), ((2, 19), 0.05599242945512136), ((9, 18), 0.05592789500951767), ((7, 18), 0.055021174252033234), ((1, 2), 0.05356132984161377), ((9, 20), 0.05350443720817566), ((5, 9), 0.05283592268824577), ((0, 6), 0.05282598237196604), ((16, 19), 0.05272319167852402), ((9, 19), 0.0525338388979435), ((2, 3), 0.051884462436040245), ((8, 17), 0.051542315632104874), ((11, 16), 0.05150885507464409), ((7, 11), 0.05147841200232506), ((0, 19), 0.05052116513252258), ((3, 16), 0.05008688196539879), ((1, 18), 0.04993354777495066), ((3, 17), 0.04974440485239029), ((11, 17), 0.04961293935775757), ((8, 9), 0.04957165569067001), ((8, 16), 0.04952129349112511), ((8, 20), 0.04939917474985123), ((3, 20), 0.049115825444459915), ((1, 11), 0.04907710353533427), ((17, 20), 0.04887883737683296), ((3, 12), 0.04877667501568794), ((5, 14), 0.04867080971598625), ((18, 19), 0.04841535910964012), ((9, 11), 0.04837307706475258), ((2, 11), 0.04834998647371928), ((11, 20), 0.04785175621509552), ((19, 20), 0.04743379354476929), ((8, 12), 0.04737081006169319), ((11, 12), 0.04729665815830231), ((0, 8), 0.046824743350346885), ((14, 18), 0.0467609241604805), ((3, 7), 0.046662960201501846), ((14, 19), 0.0465208999812603), ((3, 14), 0.04623228311538696), ((9, 17), 0.046045899391174316), ((7, 9), 0.04600481316447258), ((2, 9), 0.04592272639274597), ((17, 19), 0.04587911441922188), ((3, 9), 0.04582476615905762), ((7, 16), 0.04567290097475052), ((1, 9), 0.045521289110183716), ((18, 20), 0.04548410698771477), ((12, 19), 0.04534780979156494), ((5, 6), 0.04532264173030853), ((1, 3), 0.04531647761662801), ((1, 16), 0.04522213339805603), ((2, 16), 0.04458871980508169), ((9, 16), 0.04454632103443146), ((12, 17), 0.04438689723610878), ((1, 8), 0.04433387517929077), ((16, 18), 0.044046156108379364), ((2, 7), 0.04396143555641174), ((8, 14), 0.043487705290317535), ((0, 7), 0.04346786439418793), ((12, 20), 0.04344065114855766), ((5, 20), 0.043399546295404434), ((5, 17), 0.04325684905052185), ((14, 20), 0.04318389296531677), ((7, 8), 0.04306546598672867), ((11, 18), 0.04298688843846321), ((3, 18), 0.042831480503082275), ((11, 14), 0.04277604818344116), ((5, 12), 0.04268460348248482), ((10, 20), 0.04242171719670296), ((7, 14), 0.04221644252538681), ((12, 14), 0.04186129570007324), ((10, 17), 0.041817255318164825), ((1, 14), 0.04138820866743723), ((12, 16), 0.04132993519306183), ((7, 20), 0.040967922657728195), ((16, 17), 0.04069339483976364), ((16, 20), 0.04067607969045639), ((0, 9), 0.0406623383363088), ((8, 10), 0.040660515427589417), ((3, 10), 0.040637653321027756), ((0, 3), 0.040615856647491455), ((8, 18), 0.04041028767824173), ((14, 16), 0.04026652127504349), ((14, 17), 0.04006616026163101), ((10, 11), 0.040034569799900055), ((9, 14), 0.03991182520985603), ((2, 17), 0.0397769957780838), ((17, 18), 0.0392586924135685), ((2, 14), 0.03903838743766149), ((2, 18), 0.038975040117899575), ((2, 20), 0.038414277136325836), ((0, 16), 0.038321420550346375), ((7, 12), 0.03823119029402733), ((12, 18), 0.03784368559718132), ((0, 18), 0.037805117666721344), ((10, 12), 0.03778357058763504), ((10, 19), 0.03776438161730766), ((0, 11), 0.037615127861499786), ((7, 17), 0.03740633279085159), ((9, 12), 0.03735164925456047), ((2, 12), 0.03728620707988739), ((1, 20), 0.03716372698545456), ((1, 6), 0.03694770485162735), ((9, 10), 0.035494182258844376), ((6, 19), 0.03519115224480629), ((1, 17), 0.03517314543326696), ((10, 14), 0.034977223724126816), ((6, 13), 0.03479045629501343), ((1, 12), 0.03474444895982742), ((7, 10), 0.034441132098436356), ((0, 14), 0.03388051688671112), ((10, 18), 0.03319650888442993), ((10, 16), 0.0324534997344017), ((5, 10), 0.032160475850105286), ((6, 15), 0.03156372159719467), ((2, 10), 0.030630700290203094), ((6, 7), 0.030578158795833588), ((13, 15), 0.0304527897387743), ((6, 9), 0.03016660548746586), ((0, 20), 0.029166253904501598), ((0, 17), 0.02867959936459859), ((2, 6), 0.027999664346377056), ((1, 10), 0.0273795947432518), ((0, 12), 0.0273188774784406), ((6, 8), 0.02678084559738636), ((6, 18), 0.026549508795142174), ((3, 6), 0.02572309412062168), ((6, 16), 0.025240184739232063), ((6, 11), 0.023677388206124306), ((6, 14), 0.021890906617045403), ((0, 10), 0.021068572998046875), ((7, 13), 0.017619898542761803), ((0, 13), 0.01761532078186671), ((6, 20), 0.017577843740582466), ((5, 13), 0.017118172720074654), ((4, 9), 0.016803337261080742), ((6, 17), 0.016714390367269516), ((4, 7), 0.016694193705916405), ((6, 12), 0.01640349067747593), ((9, 13), 0.016065863892436028), ((1, 13), 0.016010699172814686), ((4, 18), 0.015221504494547844), ((13, 18), 0.01513377670198679), ((13, 19), 0.014332227408885956), ((4, 6), 0.014172973111271858), ((4, 19), 0.01414021011441946), ((4, 5), 0.013414781540632248), ((4, 16), 0.01319238543510437), ((0, 15), 0.012811129291852316), ((6, 10), 0.012700741179287434), ((4, 13), 0.012634329497814178), ((1, 4), 0.01243230327963829), ((0, 4), 0.012177631258964539), ((4, 15), 0.011998020112514496), ((13, 16), 0.01161519717425108), ((4, 20), 0.011415394023060799), ((4, 11), 0.010893828235566616), ((11, 13), 0.010885819792747498), ((2, 13), 0.010598201304674149), ((3, 4), 0.010596847161650658), ((7, 15), 0.010564038529992104), ((4, 14), 0.010511352680623531), ((3, 13), 0.01036550011485815), ((4, 8), 0.010074560530483723), ((5, 15), 0.00998461339622736), ((8, 13), 0.009845924563705921), ((2, 4), 0.009717496111989021), ((1, 15), 0.00970183809598287), ((9, 15), 0.009403407573699951), ((4, 17), 0.009401841089129448), ((15, 19), 0.009300143457949162), ((13, 20), 0.008906582370400429), ((4, 12), 0.008711367845535278), ((13, 14), 0.008697438053786755), ((4, 10), 0.00836235098540783), ((13, 17), 0.007985830307006836), ((12, 13), 0.0074954042211174965), ((15, 18), 0.0071020876057446), ((10, 13), 0.006523674353957176), ((11, 15), 0.006192260887473822), ((2, 15), 0.0061111245304346085), ((15, 16), 0.005885018967092037), ((3, 15), 0.005848964210599661), ((8, 15), 0.005788991693407297), ((15, 20), 0.0042801485396921635), ((14, 15), 0.004174569621682167), ((15, 17), 0.004166648723185062), ((12, 15), 0.0036683152429759502), ((10, 15), 0.0032260550651699305)]
******* after merging (0.04): [((5, 19), 64), ((3, 8), 64), ((0,), 64), ((1,), 64), ((2,), 64), ((4,), 32), ((6,), 32), ((7,), 32), ((9,), 32), ((10,), 32), ((11,), 32), ((12,), 32), ((13,), 32), ((14,), 32), ((15,), 32), ((16,), 32), ((17,), 32), ((18,), 32), ((20,), 32)]
{'R_grad_norm': 1.9451422381401062, 'training_loss': 9.300385637283325}
{'R_grad_norm': 1.9472793358564378, 'training_loss': 9.316016483306885}
{'R_grad_norm': 1.9442614394426345, 'training_loss': 9.285359025001526}
{'R_grad_norm': 1.9430663144588471, 'training_loss': 9.291927585601806}
{'R_grad_norm': 1.9448744767904282, 'training_loss': 9.289356098175048}
{'R_grad_norm': 1.9477388346195221, 'training_loss': 9.313928117752075}
{'R_grad_norm': 1.945483518242836, 'training_loss': 9.289683995246888}
{'R_grad_norm': 1.9491534316539765, 'training_loss': 9.313767375946044}
{'R_grad_norm': 1.9554368776082993, 'training_loss': 9.341804995536805}
{'R_grad_norm': 1.9594608426094056, 'training_loss': 9.35981460094452}
{'R_grad_norm': 1.9604312264919281, 'training_loss': 9.36438596725464}
{'R_grad_norm': 1.9668172758817672, 'training_loss': 9.382602338790894}
{'R_grad_norm': 1.9733861243724824, 'training_loss': 9.428746643066406}
{'R_grad_norm': 1.979063274860382, 'training_loss': 9.44179196357727}
{'R_grad_norm': 1.981332037448883, 'training_loss': 9.466264953613281}
{'R_grad_norm': 1.9894292974472045, 'training_loss': 9.50752872467041}
{'R_grad_norm': 1.9981151509284973, 'training_loss': 9.55590367794037}
{'R_grad_norm': 2.002237660288811, 'training_loss': 9.570513210296632}
{'R_grad_norm': 2.0044826531410216, 'training_loss': 9.561248826980592}
{'R_grad_norm': 2.0126229494810106, 'training_loss': 9.610862474441529}
{'R_grad_norm': 2.02811045229435, 'training_loss': 9.697462363243103}
{'R_grad_norm': 2.043440997004509, 'training_loss': 9.76543749332428}
{'R_grad_norm': 1.9654002964496613, 'training_loss': 9.362846174240111}
{'R_grad_norm': 1.92037974357605, 'training_loss': 9.125412893295287}
{'R_grad_norm': 1.9209792894124984, 'training_loss': 9.150055975914002}
{'R_grad_norm': 1.9155379468202591, 'training_loss': 9.127155485153198}
{'R_grad_norm': 1.9136260586977005, 'training_loss': 9.110592231750488}
{'R_grad_norm': 1.9073363029956818, 'training_loss': 9.071106491088868}
{'R_grad_norm': 1.9098123914003373, 'training_loss': 9.106458349227905}
{'R_grad_norm': 1.9128994607925416, 'training_loss': 9.097979779243468}
{'R_grad_norm': 1.9120200967788696, 'training_loss': 9.109031691551209}
{'R_grad_norm': 1.91288088619709, 'training_loss': 9.127462573051453}
{'R_grad_norm': 1.9136000561714173, 'training_loss': 9.130523705482483}
{'R_grad_norm': 1.9104980075359344, 'training_loss': 9.096408829689025}
{'R_grad_norm': 1.9063974756002426, 'training_loss': 9.07524350643158}
{'R_grad_norm': 1.9083705163002014, 'training_loss': 9.104251132011413}
{'R_grad_norm': 1.9081489223241805, 'training_loss': 9.095078043937683}
{'R_grad_norm': 1.9052689760923385, 'training_loss': 9.096181035041809}
{'R_grad_norm': 1.9065636724233628, 'training_loss': 9.099214553833008}
{'R_grad_norm': 1.9042694419622421, 'training_loss': 9.09667773246765}
eval result tensor([12.67594, 12.64321,  8.95684, 14.10028, 10.86474,  8.08633,  5.65752,
         8.51563,  8.39729,  8.22575,  7.32318,  8.01836,  8.80199,  9.09302,
         8.19543,  7.13186,  8.04858,  9.88186,  8.49820], device='cuda:0')
computing merge metric
normed mi [((2, 6), 0.05817838509877523), ((8, 17), 0.05803520232439041), ((3, 7), 0.057762354612350464), ((2, 4), 0.056578535586595535), ((7, 17), 0.05609039589762688), ((2, 3), 0.05382147803902626), ((8, 18), 0.05374899134039879), ((0, 3), 0.0537235327064991), ((3, 4), 0.05293628200888634), ((0, 4), 0.05290517583489418), ((3, 17), 0.05254527429739634), ((7, 10), 0.05177655071020126), ((10, 15), 0.051404260098934174), ((10, 16), 0.050165317952632904), ((0, 10), 0.04973222812016805), ((3, 10), 0.04938355584939321), ((13, 17), 0.049252256751060486), ((0, 7), 0.04918550451596578), ((4, 10), 0.04827284316221873), ((7, 8), 0.04800672084093094), ((8, 10), 0.04742538928985596), ((10, 18), 0.047415997833013535), ((16, 18), 0.04726187512278557), ((1, 4), 0.046976685523986816), ((10, 11), 0.04671396687626839), ((3, 8), 0.046686788400014244), ((4, 8), 0.04645724594593048), ((17, 18), 0.04616808146238327), ((0, 17), 0.046046435832977295), ((1, 10), 0.045844078063964844), ((0, 2), 0.044840265065431595), ((4, 15), 0.04481534659862518), ((7, 15), 0.044586580246686935), ((8, 16), 0.044556811451911926), ((10, 17), 0.04418138042092323), ((0, 8), 0.04415298501650492), ((11, 15), 0.04407142847776413), ((7, 11), 0.04406098648905754), ((4, 7), 0.04395955801010132), ((0, 15), 0.04394228756427765), ((0, 1), 0.04348134249448776), ((8, 15), 0.04315726086497307), ((8, 11), 0.043120842427015305), ((9, 18), 0.042771074920892715), ((15, 16), 0.04270520433783531), ((0, 11), 0.042518059412638344), ((10, 13), 0.04246702417731285), ((3, 13), 0.042438303430875145), ((11, 17), 0.04242892563343048), ((15, 18), 0.04237639904022217), ((3, 15), 0.04225363830725352), ((7, 13), 0.04202689230442047), ((1, 16), 0.04202111562093099), ((2, 7), 0.04196736713250478), ((7, 18), 0.041866276413202286), ((13, 15), 0.04180970415472984), ((3, 11), 0.041773781180381775), ((9, 16), 0.04150346666574478), ((15, 17), 0.041444625705480576), ((1, 18), 0.04131172349055608), ((13, 18), 0.04129016399383545), ((0, 13), 0.041101910173892975), ((4, 11), 0.04081811259190241), ((2, 8), 0.04043600211540858), ((4, 17), 0.040364389618237816), ((0, 18), 0.040218137204647064), ((9, 10), 0.04006356745958328), ((8, 13), 0.04004480689764023), ((1, 15), 0.03994451214869817), ((16, 17), 0.03962677717208862), ((0, 16), 0.03937991460164388), ((11, 18), 0.03937429189682007), ((11, 13), 0.039373207837343216), ((4, 13), 0.039032074312369026), ((13, 16), 0.03894483298063278), ((4, 16), 0.0389359916249911), ((2, 17), 0.038731190065542855), ((11, 16), 0.03827449306845665), ((3, 18), 0.03805489341417948), ((7, 16), 0.03775807470083237), ((4, 18), 0.03763068467378616), ((1, 3), 0.03735814616084099), ((1, 8), 0.037342265248298645), ((2, 10), 0.03707968940337499), ((6, 12), 0.03705915808677673), ((3, 6), 0.03683613985776901), ((9, 15), 0.03669971972703934), ((3, 16), 0.03615938127040863), ((7, 9), 0.03599735349416733), ((2, 15), 0.03586488962173462), ((6, 14), 0.03556785359978676), ((1, 13), 0.035448397199312844), ((8, 9), 0.03540756180882454), ((1, 9), 0.03540089726448059), ((1, 11), 0.03517594933509827), ((9, 13), 0.03507303074002266), ((1, 7), 0.03471037745475769), ((9, 17), 0.034572914242744446), ((2, 13), 0.034467265009880066), ((2, 11), 0.03441362828016281), ((1, 2), 0.03425809368491173), ((6, 8), 0.033607326447963715), ((4, 6), 0.03316615770260493), ((9, 11), 0.03241778910160065), ((1, 17), 0.032340837021668754), ((0, 9), 0.03201064715782801), ((12, 14), 0.03188319131731987), ((6, 7), 0.03158814460039139), ((4, 9), 0.030597691734631855), ((6, 17), 0.030118001624941826), ((3, 9), 0.02897249162197113), ((2, 16), 0.028787943224112194), ((6, 11), 0.028342198580503464), ((2, 18), 0.028310038149356842), ((0, 6), 0.02827789882818858), ((6, 15), 0.027745041996240616), ((6, 10), 0.026305880397558212), ((6, 13), 0.025601794943213463), ((2, 12), 0.02137102683385213), ((2, 9), 0.02126724272966385), ((7, 12), 0.020626302808523178), ((8, 12), 0.020277587696909904), ((6, 18), 0.01978183723986149), ((12, 17), 0.019452858716249466), ((5, 8), 0.01931392401456833), ((1, 6), 0.01908068483074506), ((3, 12), 0.018838038047154743), ((6, 16), 0.018737835809588432), ((2, 14), 0.01821311314900716), ((5, 7), 0.01732279360294342), ((5, 17), 0.016632171347737312), ((5, 14), 0.016129113733768463), ((5, 12), 0.015369309112429619), ((7, 14), 0.015120173804461956), ((5, 6), 0.01488456316292286), ((6, 9), 0.014424380846321583), ((5, 15), 0.014271527528762817), ((8, 14), 0.014040062204003334), ((11, 12), 0.013756760396063328), ((3, 5), 0.013421950240929922), ((10, 12), 0.013364959508180618), ((4, 12), 0.013295027116934458), ((3, 14), 0.013123534619808197), ((2, 5), 0.01293942704796791), ((0, 12), 0.012721574554840723), ((5, 11), 0.01266317255795002), ((12, 15), 0.01261550560593605), ((5, 10), 0.01189045887440443), ((12, 13), 0.011768784373998642), ((14, 17), 0.011604566127061844), ((5, 18), 0.011448576115071774), ((12, 18), 0.011261590756475925), ((5, 13), 0.010902262292802334), ((4, 5), 0.010665703564882278), ((11, 14), 0.010360910557210445), ((12, 16), 0.010027358308434486), ((0, 5), 0.009847454105814299), ((5, 16), 0.009504558518528938), ((4, 14), 0.009310565888881683), ((5, 9), 0.009234460070729256), ((10, 14), 0.009098605252802372), ((14, 15), 0.0087174903601408), ((9, 12), 0.00807939376682043), ((1, 12), 0.008024876937270164), ((0, 14), 0.00793006643652916), ((1, 5), 0.007877625524997711), ((13, 14), 0.006871150806546211), ((14, 18), 0.006767620798200369), ((14, 16), 0.0061872778460383415), ((1, 14), 0.005107572302222252), ((9, 14), 0.0047910395078361034)]
******* after merging (0.04): [((2, 6), 96), ((8, 17), 64), ((0,), 64), ((1,), 64), ((3,), 64), ((4,), 64), ((5,), 32), ((7,), 32), ((9,), 32), ((10,), 32), ((11,), 32), ((12,), 32), ((13,), 32), ((14,), 32), ((15,), 32), ((16,), 32), ((18,), 32)]
{'R_grad_norm': 2.0481145012378694, 'training_loss': 9.794651036262513}
{'R_grad_norm': 2.04197502553463, 'training_loss': 9.74397897720337}
{'R_grad_norm': 2.047556662559509, 'training_loss': 9.766651062965392}
{'R_grad_norm': 2.0458876353502276, 'training_loss': 9.760891966819763}
{'R_grad_norm': 2.049449878334999, 'training_loss': 9.776796102523804}
{'R_grad_norm': 2.044092762470245, 'training_loss': 9.739872670173645}
{'R_grad_norm': 2.048378050327301, 'training_loss': 9.787196564674378}
{'R_grad_norm': 2.045604879260063, 'training_loss': 9.756538066864014}
{'R_grad_norm': 2.0379813927412034, 'training_loss': 9.73783100605011}
{'R_grad_norm': 2.0413394951820374, 'training_loss': 9.717180519104003}
{'R_grad_norm': 2.045611605644226, 'training_loss': 9.758283967971801}
{'R_grad_norm': 2.0413186502456666, 'training_loss': 9.749669036865235}
{'R_grad_norm': 2.035171319246292, 'training_loss': 9.733412156105041}
{'R_grad_norm': 2.0442203742265703, 'training_loss': 9.771471157073975}
{'R_grad_norm': 2.0381296283006667, 'training_loss': 9.7252006483078}
{'R_grad_norm': 2.0373005121946335, 'training_loss': 9.733760209083558}
{'R_grad_norm': 2.0327912855148313, 'training_loss': 9.710078682899475}
{'R_grad_norm': 2.0353065633773806, 'training_loss': 9.721886224746704}
{'R_grad_norm': 2.0355841583013534, 'training_loss': 9.730098643302917}
{'R_grad_norm': 2.037105619907379, 'training_loss': 9.737454385757447}
{'R_grad_norm': 2.038110713362694, 'training_loss': 9.744740858078003}
{'R_grad_norm': 2.0430155915021895, 'training_loss': 9.780105223655701}
{'R_grad_norm': 2.0371568578481676, 'training_loss': 9.72911663532257}
{'R_grad_norm': 2.03417382478714, 'training_loss': 9.711712412834167}
{'R_grad_norm': 2.030816120505333, 'training_loss': 9.710931649208069}
{'R_grad_norm': 2.0383185547590257, 'training_loss': 9.74399974822998}
{'R_grad_norm': 2.029087693691254, 'training_loss': 9.705181770324707}
{'R_grad_norm': 2.0331036466360093, 'training_loss': 9.738406791687012}
{'R_grad_norm': 2.0334721130132674, 'training_loss': 9.729174809455872}
{'R_grad_norm': 2.026482355594635, 'training_loss': 9.698781728744507}
{'R_grad_norm': 2.028352944254875, 'training_loss': 9.707035427093507}
{'R_grad_norm': 2.0341175490617753, 'training_loss': 9.72838002204895}
{'R_grad_norm': 2.033611287474632, 'training_loss': 9.72380633354187}
{'R_grad_norm': 2.030198467373848, 'training_loss': 9.730693197250366}
{'R_grad_norm': 2.0293005514144897, 'training_loss': 9.723570961952209}
{'R_grad_norm': 2.0206441044807435, 'training_loss': 9.69317831993103}
{'R_grad_norm': 2.028785458803177, 'training_loss': 9.72940598487854}
{'R_grad_norm': 2.022742535471916, 'training_loss': 9.700194697380066}
{'R_grad_norm': 2.0227886247634888, 'training_loss': 9.70514805316925}
{'R_grad_norm': 2.0207834857702256, 'training_loss': 9.681733837127686}
eval result tensor([11.62097, 16.29042, 12.49094, 12.50614, 14.19868, 10.42285,  7.91259,
         8.35587,  7.92806,  7.08206,  7.66906,  8.56189,  8.87865,  7.93731,
         6.91286,  7.70796,  8.12975], device='cuda:0')
computing merge metric
normed mi [((4, 7), 0.057145729660987854), ((2, 4), 0.052608147263526917), ((2, 5), 0.051576096564531326), ((7, 9), 0.05153272673487663), ((4, 5), 0.05126308277249336), ((9, 15), 0.05030326545238495), ((2, 9), 0.04994464417298635), ((9, 14), 0.04973459988832474), ((2, 7), 0.049201841155687966), ((4, 9), 0.04911406338214874), ((5, 9), 0.04743488629659017), ((0, 5), 0.04652003645896911), ((9, 16), 0.0464060977101326), ((7, 14), 0.045229680836200714), ((3, 5), 0.04471595585346222), ((15, 16), 0.04462863504886627), ((5, 14), 0.044451276461283364), ((3, 9), 0.04431969920794169), ((1, 4), 0.04390229284763336), ((2, 3), 0.04373208060860634), ((1, 16), 0.043512905637423195), ((5, 7), 0.043511807918548584), ((0, 4), 0.04304485321044922), ((8, 16), 0.042475298047065735), ((1, 2), 0.04220069944858551), ((4, 14), 0.04209781686464945), ((4, 12), 0.041963612039883934), ((7, 16), 0.04168674722313881), ((2, 14), 0.04163651913404465), ((9, 12), 0.04138883575797081), ((3, 15), 0.04119991262753805), ((3, 16), 0.04103248566389084), ((7, 12), 0.040669068694114685), ((2, 16), 0.04055605580409368), ((2, 15), 0.040470811227957405), ((1, 7), 0.040404719611008964), ((8, 15), 0.04035251587629318), ((2, 12), 0.03979997833569845), ((14, 15), 0.03958619385957718), ((8, 9), 0.03930589184165001), ((14, 16), 0.03913010656833649), ((7, 10), 0.03884157910943031), ((1, 12), 0.038751401007175446), ((12, 16), 0.03852694481611252), ((12, 14), 0.03849092498421669), ((5, 15), 0.03844081858793894), ((1, 9), 0.038219655553499855), ((12, 15), 0.038129858672618866), ((1, 5), 0.037920355796813965), ((7, 15), 0.03773539513349533), ((5, 12), 0.03724536548058192), ((1, 15), 0.03690428535143534), ((4, 16), 0.036752735575040184), ((4, 10), 0.03660136709610621), ((0, 2), 0.03648466169834137), ((5, 16), 0.036469392478466034), ((3, 4), 0.036364443600177765), ((4, 15), 0.03625120719273885), ((3, 8), 0.035685814917087555), ((7, 8), 0.03565816581249237), ((3, 14), 0.03506756822268168), ((10, 14), 0.03488561511039734), ((1, 3), 0.03455476090312004), ((3, 12), 0.03424043208360672), ((8, 12), 0.03391629457473755), ((3, 7), 0.03366089115540186), ((1, 14), 0.033614675203959145), ((2, 8), 0.03353713204463323), ((8, 14), 0.03311853110790253), ((0, 7), 0.03305777907371521), ((1, 8), 0.03186521679162979), ((9, 10), 0.030985793098807335), ((0, 14), 0.030329057946801186), ((11, 13), 0.030274536460638046), ((5, 10), 0.03015679617722829), ((0, 10), 0.030019134283065796), ((5, 8), 0.030002166827519734), ((0, 9), 0.029365625232458115), ((4, 8), 0.029279249409834545), ((0, 3), 0.027480721473693848), ((2, 10), 0.026965821782747906), ((0, 12), 0.026902297511696815), ((0, 1), 0.02659914195537567), ((10, 12), 0.025464408099651337), ((0, 15), 0.02321263775229454), ((10, 13), 0.023176690563559532), ((10, 16), 0.022997373715043068), ((10, 15), 0.022366654127836227), ((1, 10), 0.02234822263320287), ((0, 16), 0.02202240377664566), ((10, 11), 0.02095256932079792), ((7, 11), 0.020013220608234406), ((6, 13), 0.018603354692459106), ((7, 13), 0.017488274723291397), ((3, 10), 0.017186041921377182), ((0, 8), 0.01703324355185032), ((4, 11), 0.01677026351292928), ((8, 10), 0.0167212076485157), ((6, 7), 0.016308635473251343), ((6, 10), 0.016030974686145782), ((6, 11), 0.015332142822444439), ((0, 11), 0.014602121897041798), ((6, 14), 0.01457749493420124), ((0, 13), 0.013806105591356754), ((11, 14), 0.013638992793858051), ((4, 13), 0.013384548326333364), ((9, 11), 0.0127864396199584), ((13, 14), 0.012418045662343502), ((5, 11), 0.012356524666150412), ((4, 6), 0.011987673739592234), ((2, 11), 0.0116112120449543), ((11, 12), 0.011198692955076694), ((6, 9), 0.01088741049170494), ((1, 6), 0.010803793867429098), ((1, 11), 0.01078940803805987), ((11, 16), 0.010718581266701221), ((9, 13), 0.010608496144413948), ((6, 16), 0.01044453214854002), ((5, 13), 0.010352021704117456), ((5, 6), 0.010113964478174845), ((6, 12), 0.01008617877960205), ((0, 6), 0.010049174539744854), ((11, 15), 0.009445794858038425), ((6, 15), 0.00909193605184555), ((2, 6), 0.008960618947943052), ((2, 13), 0.008321288973093033), ((6, 8), 0.00816303864121437), ((12, 13), 0.008097906596958637), ((13, 16), 0.007590278051793575), ((8, 11), 0.007460250519216061), ((3, 11), 0.0074555110186338425), ((13, 15), 0.007281281054019928), ((3, 6), 0.007235636313756307), ((1, 13), 0.006690600266059239), ((3, 13), 0.005642879133423169), ((8, 13), 0.005360262934118509)]
******* after merging (0.04): [((2, 5), 128), ((4, 7), 96), ((0,), 96), ((1,), 64), ((3,), 64), ((6,), 32), ((8,), 32), ((9,), 32), ((10,), 32), ((11,), 32), ((12,), 32), ((13,), 32), ((14,), 32), ((15,), 32), ((16,), 32)]
{'R_grad_norm': 2.2121556615829467, 'training_loss': 10.362378158569335}
{'R_grad_norm': 2.2058314871788025, 'training_loss': 10.319226994514466}
{'R_grad_norm': 2.2018218910694123, 'training_loss': 10.279669861793518}
{'R_grad_norm': 2.205854570865631, 'training_loss': 10.32275200366974}
{'R_grad_norm': 2.2053475093841555, 'training_loss': 10.29414538860321}
{'R_grad_norm': 2.209539020061493, 'training_loss': 10.314638695716859}
{'R_grad_norm': 2.202844421863556, 'training_loss': 10.296970405578612}
{'R_grad_norm': 2.2039664959907532, 'training_loss': 10.2856667470932}
{'R_grad_norm': 2.2004603755474093, 'training_loss': 10.283025822639466}
{'R_grad_norm': 2.201824338436127, 'training_loss': 10.271519565582276}
{'R_grad_norm': 2.204634289741516, 'training_loss': 10.281604671478272}
{'R_grad_norm': 2.202784175872803, 'training_loss': 10.275025601387023}
{'R_grad_norm': 2.196948903799057, 'training_loss': 10.26343454837799}
{'R_grad_norm': 2.1970246195793153, 'training_loss': 10.278595695495605}
{'R_grad_norm': 2.2020191419124604, 'training_loss': 10.302081689834594}
{'R_grad_norm': 2.1973183906078337, 'training_loss': 10.26067368030548}
{'R_grad_norm': 2.1953452122211456, 'training_loss': 10.26371609210968}
{'R_grad_norm': 2.1978661704063414, 'training_loss': 10.299781284332276}
{'R_grad_norm': 2.1999185502529146, 'training_loss': 10.302732939720153}
{'R_grad_norm': 2.195688294172287, 'training_loss': 10.29985520362854}
{'R_grad_norm': 2.1912666392326354, 'training_loss': 10.243992204666137}
{'R_grad_norm': 2.1980654048919677, 'training_loss': 10.281364707946777}
{'R_grad_norm': 2.20045677781105, 'training_loss': 10.305597233772279}
{'R_grad_norm': 2.1941786658763887, 'training_loss': 10.26004852771759}
{'R_grad_norm': 2.1939183974266054, 'training_loss': 10.255882182121276}
{'R_grad_norm': 2.193748062849045, 'training_loss': 10.277801737785339}
{'R_grad_norm': 2.193948419094086, 'training_loss': 10.266588687896729}
{'R_grad_norm': 2.1904903829097746, 'training_loss': 10.275108075141906}
{'R_grad_norm': 2.1885368037223816, 'training_loss': 10.25672224998474}
{'R_grad_norm': 2.185448304414749, 'training_loss': 10.249540710449219}
{'R_grad_norm': 2.1856605505943296, 'training_loss': 10.262465238571167}
{'R_grad_norm': 2.1834844410419465, 'training_loss': 10.253040904998779}
{'R_grad_norm': 2.1822091579437255, 'training_loss': 10.259058237075806}
{'R_grad_norm': 2.1857767474651335, 'training_loss': 10.258309926986694}
{'R_grad_norm': 2.1842995178699494, 'training_loss': 10.266372785568237}
{'R_grad_norm': 2.1792766857147217, 'training_loss': 10.242551312446594}
{'R_grad_norm': 2.1795474421977996, 'training_loss': 10.24150276184082}
{'R_grad_norm': 2.179628163576126, 'training_loss': 10.245036358833312}
{'R_grad_norm': 2.176446223258972, 'training_loss': 10.210459861755371}
{'R_grad_norm': 2.1760425460338593, 'training_loss': 10.248525190353394}
eval result tensor([19.21228, 19.75044, 11.16986, 15.96498, 11.51394,  7.67654,  7.61349,
         6.82871,  7.31665,  8.34683,  8.57978,  7.86685,  6.67867,  7.34575,
         7.85350], device='cuda:0')
computing merge metric
normed mi [((7, 12), 0.05205320194363594), ((7, 13), 0.048223938792943954), ((4, 7), 0.04506265620390574), ((7, 14), 0.0449519082903862), ((13, 14), 0.04231913015246391), ((3, 14), 0.042237902681032814), ((12, 13), 0.04151036590337753), ((12, 14), 0.04114473611116409), ((4, 12), 0.04107805838187536), ((7, 10), 0.04040632024407387), ((4, 13), 0.03974384814500809), ((6, 14), 0.039638321846723557), ((4, 14), 0.039623488982518516), ((10, 12), 0.038596611469984055), ((6, 13), 0.03821732848882675), ((1, 7), 0.03807295858860016), ((3, 7), 0.0372339611252149), ((6, 7), 0.03719272464513779), ((10, 13), 0.036662664264440536), ((0, 4), 0.036189874013264976), ((3, 10), 0.0361588845650355), ((6, 12), 0.03580763190984726), ((10, 14), 0.03564795106649399), ((1, 3), 0.03540968596935272), ((3, 13), 0.034829902152220406), ((4, 6), 0.033651930590470634), ((3, 12), 0.033456976215044655), ((3, 4), 0.033361200243234634), ((6, 10), 0.032753992825746536), ((2, 7), 0.03256738558411598), ((4, 10), 0.03244035691022873), ((0, 7), 0.0324158251285553), ((1, 2), 0.032247357070446014), ((0, 1), 0.03215397255761283), ((0, 2), 0.03162763587066105), ((1, 10), 0.031585320830345154), ((1, 12), 0.03087921254336834), ((0, 3), 0.030843531092007954), ((2, 4), 0.03077738583087921), ((3, 6), 0.030624553561210632), ((1, 4), 0.030534356832504272), ((8, 11), 0.02971971407532692), ((2, 12), 0.029552767053246498), ((0, 12), 0.028473493456840516), ((1, 14), 0.02813579887151718), ((9, 11), 0.028086964040994644), ((1, 13), 0.02803688682615757), ((0, 13), 0.027874824404716492), ((2, 10), 0.027271760627627373), ((0, 14), 0.02722683548927307), ((2, 3), 0.026440027356147765), ((0, 10), 0.025555384159088135), ((8, 9), 0.024297580122947693), ((2, 13), 0.024143166840076447), ((2, 8), 0.02387133240699768), ((1, 6), 0.023567063733935356), ((2, 14), 0.0228817667812109), ((0, 6), 0.0224308118224144), ((7, 8), 0.022265726700425148), ((5, 11), 0.021723298355937004), ((8, 12), 0.0198970977216959), ((8, 10), 0.01740902103483677), ((2, 6), 0.017335206270217896), ((5, 9), 0.01707846112549305), ((5, 8), 0.016514645889401436), ((1, 8), 0.01580158993601799), ((8, 14), 0.014852981083095074), ((8, 13), 0.013142932206392288), ((3, 8), 0.01313545803229014), ((2, 11), 0.013005555607378483), ((2, 9), 0.012592432089149952), ((7, 9), 0.012155764736235142), ((7, 11), 0.011986409313976765), ((4, 8), 0.0115513876080513), ((5, 12), 0.011062822304666042), ((9, 12), 0.010748861357569695), ((11, 12), 0.010477760806679726), ((9, 10), 0.009751356206834316), ((5, 7), 0.009685352444648743), ((3, 9), 0.009667487194140753), ((6, 8), 0.009527033194899559), ((1, 9), 0.009484467096626759), ((9, 14), 0.009460833854973316), ((0, 8), 0.009218237549066543), ((3, 5), 0.00870515468219916), ((2, 5), 0.008550521917641163), ((5, 14), 0.008524737320840359), ((9, 13), 0.008302642963826656), ((5, 10), 0.008283035829663277), ((10, 11), 0.008259030058979988), ((11, 14), 0.00810565147548914), ((1, 11), 0.007951092906296253), ((5, 13), 0.007320326287299395), ((11, 13), 0.0073075732216238976), ((4, 9), 0.007236230497558911), ((3, 11), 0.006711371863881747), ((6, 9), 0.006632027681916952), ((4, 11), 0.006580166518688202), ((5, 6), 0.006301102694123983), ((4, 5), 0.006291229898730914), ((1, 5), 0.006196661852300167), ((0, 9), 0.006040719524025917), ((6, 11), 0.005449553020298481), ((0, 11), 0.004767616093158722), ((0, 5), 0.004484963789582253)]
******* after merging (0.04): [((0,), 128), ((1,), 96), ((2,), 96), ((7, 12), 64), ((3,), 64), ((4,), 64), ((5,), 32), ((6,), 32), ((8,), 32), ((9,), 32), ((10,), 32), ((11,), 32), ((13,), 32), ((14,), 32)]
{'R_grad_norm': 2.270506706237793, 'training_loss': 10.813136429786683}
{'R_grad_norm': 2.2591686344146726, 'training_loss': 10.755982241630555}
{'R_grad_norm': 2.2637217509746552, 'training_loss': 10.77770749092102}
{'R_grad_norm': 2.2618797969818116, 'training_loss': 10.79051191329956}
{'R_grad_norm': 2.263955515623093, 'training_loss': 10.791920547485352}
{'R_grad_norm': 2.260288044214249, 'training_loss': 10.774200930595399}
{'R_grad_norm': 2.2622730576992036, 'training_loss': 10.774066200256348}
{'R_grad_norm': 2.2605168974399565, 'training_loss': 10.767696762084961}
{'R_grad_norm': 2.259625917673111, 'training_loss': 10.79007345676422}
{'R_grad_norm': 2.2618822252750395, 'training_loss': 10.793427791595459}
{'R_grad_norm': 2.2556338787078856, 'training_loss': 10.745504999160767}
{'R_grad_norm': 2.2546182751655577, 'training_loss': 10.758950147628784}
{'R_grad_norm': 2.255595712661743, 'training_loss': 10.7840886592865}
{'R_grad_norm': 2.2508040499687194, 'training_loss': 10.74990400314331}
{'R_grad_norm': 2.246308320760727, 'training_loss': 10.723152403831483}
{'R_grad_norm': 2.2590378391742707, 'training_loss': 10.811026239395142}
{'R_grad_norm': 2.251278591156006, 'training_loss': 10.752228608131409}
{'R_grad_norm': 2.2587201201915743, 'training_loss': 10.783978471755981}
{'R_grad_norm': 2.256092817783356, 'training_loss': 10.795204558372497}
{'R_grad_norm': 2.2503923964500427, 'training_loss': 10.749405417442322}
{'R_grad_norm': 2.244519098997116, 'training_loss': 10.729643149375915}
{'R_grad_norm': 2.247038406133652, 'training_loss': 10.731256680488586}
{'R_grad_norm': 2.2481325709819795, 'training_loss': 10.764010109901427}
{'R_grad_norm': 2.2511493551731108, 'training_loss': 10.771633658409119}
{'R_grad_norm': 2.2458363687992096, 'training_loss': 10.770598187446595}
{'R_grad_norm': 2.2437697184085845, 'training_loss': 10.742986884117126}
{'R_grad_norm': 2.2463624620437623, 'training_loss': 10.766358380317689}
{'R_grad_norm': 2.2469409477710722, 'training_loss': 10.786075077056886}
{'R_grad_norm': 2.2380812895298003, 'training_loss': 10.737178511619568}
{'R_grad_norm': 2.2414676535129545, 'training_loss': 10.741474351882935}
{'R_grad_norm': 2.2454736006259917, 'training_loss': 10.778505086898804}
{'R_grad_norm': 2.2387904751300813, 'training_loss': 10.748668575286866}
{'R_grad_norm': 2.2361254394054413, 'training_loss': 10.733445100784301}
{'R_grad_norm': 2.2360871839523315, 'training_loss': 10.735462007522584}
{'R_grad_norm': 2.2284667241573333, 'training_loss': 10.70652509689331}
{'R_grad_norm': 2.225628207921982, 'training_loss': 10.681046319007873}
{'R_grad_norm': 2.2372242414951327, 'training_loss': 10.77697681903839}
{'R_grad_norm': 2.2323172771930695, 'training_loss': 10.74469066143036}
{'R_grad_norm': 2.22483358502388, 'training_loss': 10.695630888938904}
{'R_grad_norm': 2.225808035135269, 'training_loss': 10.702758889198304}
eval result tensor([20.23136, 20.10354, 11.00891, 10.94174, 15.78548, 10.48565,  7.62843,
         7.39788,  7.02659,  8.19247,  8.50261,  7.72186,  7.13758,  7.58939],
       device='cuda:0')
computing merge metric
normed mi [((3, 5), 0.04521537572145462), ((12, 13), 0.04175099730491638), ((4, 13), 0.04116867979367574), ((5, 12), 0.04066710422436396), ((7, 13), 0.04050769656896591), ((5, 13), 0.039203825096289315), ((0, 5), 0.03877504666646322), ((3, 12), 0.0385783314704895), ((7, 12), 0.03835045173764229), ((10, 12), 0.03737933188676834), ((2, 5), 0.03713640570640564), ((3, 13), 0.036472310622533165), ((1, 4), 0.03504993319511414), ((10, 13), 0.03456767648458481), ((4, 12), 0.03450299302736918), ((4, 10), 0.034419864416122437), ((1, 3), 0.0339083731174469), ((4, 5), 0.03384998068213463), ((8, 11), 0.03367743641138077), ((5, 7), 0.03356349468231201), ((0, 3), 0.033102959394454956), ((7, 10), 0.032806601375341415), ((5, 10), 0.03267829865217209), ((1, 5), 0.03250829875469208), ((3, 4), 0.03249839320778847), ((3, 10), 0.03238183011611303), ((3, 7), 0.032379855712254844), ((4, 7), 0.03220343589782715), ((0, 1), 0.03163569739886692), ((1, 2), 0.03158053755760193), ((1, 10), 0.031326476484537125), ((0, 4), 0.03125541905562083), ((0, 2), 0.030532845429011753), ((2, 3), 0.029938080906867982), ((0, 12), 0.028848534822463988), ((1, 12), 0.028831951320171356), ((0, 13), 0.027318879961967468), ((1, 13), 0.027206189930438995), ((2, 10), 0.027142789214849472), ((8, 9), 0.02599416859447956), ((2, 4), 0.02591068148612976), ((0, 10), 0.025527161359786988), ((9, 11), 0.025466037914156914), ((2, 12), 0.025297347456216812), ((1, 7), 0.024573244154453278), ((2, 8), 0.024097604677081108), ((0, 7), 0.023968884348869325), ((6, 11), 0.022847170010209084), ((2, 13), 0.022400015965104103), ((2, 11), 0.018408462405204773), ((2, 7), 0.018338283523917198), ((6, 9), 0.01796402595937252), ((8, 10), 0.017245853319764137), ((6, 8), 0.015768108889460564), ((1, 8), 0.015307909809052944), ((5, 8), 0.01417205979426702), ((2, 9), 0.01413804106414318), ((8, 12), 0.01404315885156393), ((10, 11), 0.013880361802875996), ((8, 13), 0.013831605203449726), ((3, 8), 0.013533145189285278), ((4, 8), 0.012794867157936096), ((1, 11), 0.012792473658919334), ((11, 13), 0.012762872502207756), ((5, 11), 0.012485407292842865), ((11, 12), 0.01232932973653078), ((3, 11), 0.012075547128915787), ((4, 11), 0.012004364281892776), ((9, 10), 0.01139893475919962), ((4, 9), 0.011252184708913168), ((1, 9), 0.010765833780169487), ((7, 8), 0.010145295411348343), ((4, 6), 0.010112829506397247), ((9, 12), 0.009934789501130581), ((9, 13), 0.009924216195940971), ((5, 9), 0.009853855396310488), ((7, 11), 0.009506551548838615), ((2, 6), 0.008910242468118668), ((3, 9), 0.00856132743259271), ((6, 10), 0.008554339408874512), ((0, 8), 0.008478411287069321), ((6, 13), 0.008414319716393948), ((6, 12), 0.007938339374959469), ((7, 9), 0.007928554899990559), ((5, 6), 0.007375024259090424), ((0, 11), 0.00730997771024704), ((3, 6), 0.007167289033532143), ((6, 7), 0.0071626510471105576), ((1, 6), 0.006707839667797089), ((0, 9), 0.006515688449144364), ((0, 6), 0.004586049914360046)]
******* after merging (0.04): [((3, 5), 128), ((0,), 128), ((1,), 96), ((2,), 96), ((4,), 64), ((6,), 32), ((7,), 32), ((8,), 32), ((9,), 32), ((10,), 32), ((11,), 32), ((12,), 32), ((13,), 32)]
{'R_grad_norm': 2.361641390323639, 'training_loss': 11.150973963737489}
{'R_grad_norm': 2.359869976043701, 'training_loss': 11.12911735534668}
{'R_grad_norm': 2.36078471660614, 'training_loss': 11.131127433776856}
{'R_grad_norm': 2.3526944756507873, 'training_loss': 11.086058626174927}
{'R_grad_norm': 2.3536480367183685, 'training_loss': 11.108848843574524}
{'R_grad_norm': 2.356626065969467, 'training_loss': 11.117237939834595}
{'R_grad_norm': 2.3586677169799803, 'training_loss': 11.132799587249757}
{'R_grad_norm': 2.3587357902526858, 'training_loss': 11.13723394393921}
{'R_grad_norm': 2.360706089735031, 'training_loss': 11.144829545021057}
{'R_grad_norm': 2.367898180484772, 'training_loss': 11.182476754188537}
{'R_grad_norm': 2.375033631324768, 'training_loss': 11.220414729118348}
{'R_grad_norm': 2.3733685278892516, 'training_loss': 11.214547529220582}
{'R_grad_norm': 2.3822963559627532, 'training_loss': 11.26671745300293}
{'R_grad_norm': 2.3875419795513153, 'training_loss': 11.282734870910645}
{'R_grad_norm': 2.3939757335186003, 'training_loss': 11.331268215179444}
{'R_grad_norm': 2.4040281653404234, 'training_loss': 11.391974911689758}
{'R_grad_norm': 2.410281639099121, 'training_loss': 11.438961148262024}
{'R_grad_norm': 2.414070566892624, 'training_loss': 11.465065183639526}
{'R_grad_norm': 2.4339417386054993, 'training_loss': 11.571630182266235}
{'R_grad_norm': 2.4351053869724275, 'training_loss': 11.5707421541214}
{'R_grad_norm': 2.449903950691223, 'training_loss': 11.676463141441346}
{'R_grad_norm': 2.4564988255500793, 'training_loss': 11.73648319721222}
{'R_grad_norm': 2.4885249876976014, 'training_loss': 11.919781036376953}
{'R_grad_norm': 2.3869728791713714, 'training_loss': 11.401869668960572}
{'R_grad_norm': 2.3585316061973574, 'training_loss': 11.253704590797424}
{'R_grad_norm': 2.3636919271945955, 'training_loss': 11.284836187362671}
{'R_grad_norm': 2.365421427488327, 'training_loss': 11.300120782852172}
{'R_grad_norm': 2.359173400402069, 'training_loss': 11.258058009147645}
{'R_grad_norm': 2.355361704826355, 'training_loss': 11.253310751914977}
{'R_grad_norm': 2.3576041615009307, 'training_loss': 11.262935633659362}
{'R_grad_norm': 2.356563594341278, 'training_loss': 11.260531997680664}
{'R_grad_norm': 2.356410058736801, 'training_loss': 11.254339265823365}
{'R_grad_norm': 2.3631899797916414, 'training_loss': 11.305910139083862}
{'R_grad_norm': 2.3564213919639587, 'training_loss': 11.256464276313782}
{'R_grad_norm': 2.3582025110721587, 'training_loss': 11.271449890136719}
{'R_grad_norm': 2.3506862604618073, 'training_loss': 11.235006275177001}
{'R_grad_norm': 2.352941173315048, 'training_loss': 11.25228961467743}
{'R_grad_norm': 2.3500117480754854, 'training_loss': 11.258647937774658}
{'R_grad_norm': 2.3552225959300994, 'training_loss': 11.269484806060792}
{'R_grad_norm': 2.3464197278022767, 'training_loss': 11.215014204978942}
eval result tensor([17.69614, 20.52270, 20.08657, 11.13022, 15.58374,  7.60251,  7.28907,
         6.90312,  8.06507,  8.26558,  7.76678,  6.99145,  7.54810],
       device='cuda:0')
computing merge metric
normed mi [((11, 12), 0.04000938683748245), ((4, 12), 0.039693678418795265), ((6, 12), 0.03946658596396446), ((9, 11), 0.037765756249427795), ((6, 11), 0.03759848326444626), ((9, 12), 0.03341161087155342), ((4, 11), 0.033047897120316826), ((7, 10), 0.032588593661785126), ((6, 9), 0.03235527127981186), ((2, 4), 0.032259076833724976), ((4, 9), 0.03177636116743088), ((4, 6), 0.030991236368815105), ((2, 3), 0.03081754595041275), ((1, 3), 0.030410911355699812), ((1, 2), 0.030283712915011814), ((1, 4), 0.03010843942562739), ((2, 9), 0.029668353497982025), ((1, 11), 0.028980770707130434), ((0, 1), 0.02875412441790104), ((2, 11), 0.028697120025753975), ((7, 8), 0.027657916769385338), ((3, 11), 0.02668892964720726), ((1, 12), 0.02653178870677948), ((3, 9), 0.02640405297279358), ((1, 9), 0.025706440210342407), ((0, 11), 0.025664979219436647), ((2, 12), 0.025175686925649643), ((0, 12), 0.02494804859161377), ((3, 4), 0.024517686665058137), ((8, 10), 0.02398012764751911), ((1, 6), 0.023874932527542116), ((0, 2), 0.023105729903493608), ((2, 6), 0.02297600731253624), ((0, 6), 0.022887995839118956), ((0, 4), 0.0225277841091156), ((0, 3), 0.022469226803098406), ((5, 10), 0.022265827283263206), ((3, 12), 0.02212558686733246), ((0, 9), 0.02004982829093933), ((3, 6), 0.01847665384411812), ((5, 8), 0.016197569668293), ((5, 7), 0.014985397458076477), ((3, 10), 0.014003749005496502), ((3, 7), 0.013994812965393066), ((3, 8), 0.010660573840141296), ((4, 5), 0.009068725630640984), ((10, 11), 0.008803281933069229), ((2, 10), 0.008569563739001751), ((10, 12), 0.008350154384970665), ((9, 10), 0.008209996856749058), ((7, 9), 0.008069179020822048), ((4, 8), 0.00797221933801969), ((7, 11), 0.007854900322854519), ((2, 7), 0.00783727690577507), ((2, 8), 0.007728200871497393), ((3, 5), 0.007712808903306723), ((8, 11), 0.00767475226894021), ((8, 9), 0.007638182491064072), ((4, 10), 0.007389693210522334), ((8, 12), 0.007220415398478508), ((5, 12), 0.007212345022708178), ((7, 12), 0.006907354574650526), ((5, 9), 0.006879768799990416), ((5, 11), 0.006821596994996071), ((6, 10), 0.006267767399549484), ((4, 7), 0.006001754353443782), ((5, 6), 0.005852501839399338), ((6, 8), 0.0056306952610611916), ((2, 5), 0.0055537233129143715), ((6, 7), 0.0051986840553581715), ((1, 10), 0.004683350771665573), ((1, 8), 0.00465988852083683), ((0, 10), 0.004347641766071319), ((1, 7), 0.004121697694063187), ((1, 5), 0.003907625749707222), ((0, 7), 0.0035936471074819567), ((0, 8), 0.003459816798567772), ((0, 5), 0.0034204099327325823)]
******* after merging (0.04): [((0,), 128), ((1,), 128), ((2,), 96), ((3,), 96), ((11, 12), 64), ((4,), 64), ((5,), 32), ((6,), 32), ((7,), 32), ((8,), 32), ((9,), 32), ((10,), 32)]
{'R_grad_norm': 2.4348799669742585, 'training_loss': 11.997063193321228}
{'R_grad_norm': 2.4301132309436797, 'training_loss': 11.980102858543397}
{'R_grad_norm': 2.4310101211071014, 'training_loss': 11.985229392051696}
{'R_grad_norm': 2.4269587779045105, 'training_loss': 11.95955813884735}
{'R_grad_norm': 2.4342019641399384, 'training_loss': 12.009034442901612}
{'R_grad_norm': 2.4310272240638735, 'training_loss': 11.985531506538392}
{'R_grad_norm': 2.4250264286994936, 'training_loss': 11.960469574928284}
{'R_grad_norm': 2.42667729139328, 'training_loss': 11.972262811660766}
{'R_grad_norm': 2.428977423906326, 'training_loss': 11.974709763526917}
{'R_grad_norm': 2.427155251502991, 'training_loss': 11.950947155952454}
{'R_grad_norm': 2.4336377036571504, 'training_loss': 12.014351801872253}
{'R_grad_norm': 2.4241267538070677, 'training_loss': 11.961739382743836}
{'R_grad_norm': 2.429743368625641, 'training_loss': 11.999411025047301}
{'R_grad_norm': 2.4175681793689727, 'training_loss': 11.923240804672242}
{'R_grad_norm': 2.4166390287876127, 'training_loss': 11.941145405769348}
{'R_grad_norm': 2.4167381262779237, 'training_loss': 11.927641792297363}
{'R_grad_norm': 2.419615535736084, 'training_loss': 11.95144190788269}
{'R_grad_norm': 2.4153097426891326, 'training_loss': 11.932964811325073}
{'R_grad_norm': 2.4158285844326017, 'training_loss': 11.923167886734008}
{'R_grad_norm': 2.4130961227416994, 'training_loss': 11.928911023139953}
{'R_grad_norm': 2.419535013437271, 'training_loss': 11.966386075019836}
{'R_grad_norm': 2.4148544204235076, 'training_loss': 11.926269798278808}
{'R_grad_norm': 2.412138521671295, 'training_loss': 11.943391852378845}
{'R_grad_norm': 2.4122381126880645, 'training_loss': 11.938624386787415}
{'R_grad_norm': 2.4148421549797057, 'training_loss': 11.957292723655701}
{'R_grad_norm': 2.4132720363140105, 'training_loss': 11.923381910324096}
{'R_grad_norm': 2.408812059164047, 'training_loss': 11.930790004730225}
{'R_grad_norm': 2.4145098304748536, 'training_loss': 11.933524875640869}
{'R_grad_norm': 2.4154550099372862, 'training_loss': 11.970196175575257}
{'R_grad_norm': 2.4073971009254453, 'training_loss': 11.909811291694641}
{'R_grad_norm': 2.411685063838959, 'training_loss': 11.92674077987671}
{'R_grad_norm': 2.409015146493912, 'training_loss': 11.952529735565186}
{'R_grad_norm': 2.412288259267807, 'training_loss': 11.954619588851928}
{'R_grad_norm': 2.4093262159824373, 'training_loss': 11.963177676200866}
{'R_grad_norm': 2.4022728431224825, 'training_loss': 11.908112106323243}
{'R_grad_norm': 2.4053929352760317, 'training_loss': 11.924403190612793}
{'R_grad_norm': 2.406632078886032, 'training_loss': 11.935860176086425}
{'R_grad_norm': 2.402438300848007, 'training_loss': 11.922588715553283}
{'R_grad_norm': 2.4055570697784425, 'training_loss': 11.924139375686645}
{'R_grad_norm': 2.403063461780548, 'training_loss': 11.93493954181671}
eval result tensor([18.38737, 20.49477, 20.28731, 11.12121, 12.14529, 15.29858,  7.56472,
         7.12875,  6.73138,  7.97537,  8.10902,  7.72037], device='cuda:0')
computing merge metric
normed mi [((4, 7), 0.0329438199599584), ((7, 10), 0.03170697018504143), ((8, 11), 0.031219571828842163), ((2, 3), 0.030871793627738953), ((5, 7), 0.030812280873457592), ((4, 5), 0.030811302363872528), ((1, 3), 0.030720012528555735), ((2, 5), 0.030652350187301634), ((5, 10), 0.029832566777865093), ((1, 2), 0.029818138905933926), ((1, 5), 0.029469209412733715), ((2, 10), 0.0291164368391037), ((0, 1), 0.028101133182644844), ((8, 9), 0.02769952267408371), ((1, 4), 0.027511383096377056), ((0, 4), 0.026842288672924042), ((4, 10), 0.026712531844774883), ((3, 10), 0.026207081973552704), ((1, 10), 0.025751194357872008), ((3, 5), 0.02363668382167816), ((1, 7), 0.02357475608587265), ((0, 7), 0.02319503128528595), ((0, 5), 0.022978566586971283), ((9, 11), 0.022956756874918938), ((0, 2), 0.022807317120688304), ((2, 7), 0.022655479609966278), ((2, 4), 0.022153738141059875), ((6, 11), 0.02165125496685505), ((0, 3), 0.021550961903163364), ((3, 4), 0.02075345814228058), ((0, 10), 0.01990037113428116), ((3, 7), 0.01908639632165432), ((3, 11), 0.016714973375201225), ((6, 9), 0.016148900613188744), ((3, 8), 0.014849185943603516), ((6, 8), 0.014690582640469074), ((2, 11), 0.011731761507689953), ((3, 9), 0.01150537095963955), ((10, 11), 0.011172712780535221), ((5, 11), 0.009938267370065054), ((5, 6), 0.009617552782098452), ((5, 9), 0.008740930507580439), ((2, 9), 0.008681639097630978), ((2, 8), 0.008599921129643917), ((8, 10), 0.008592430502176285), ((9, 10), 0.008500582538545132), ((7, 11), 0.008364846929907799), ((3, 6), 0.007822293788194656), ((6, 10), 0.006890213117003441), ((1, 11), 0.006437972187995911), ((7, 9), 0.006246865727007389), ((6, 7), 0.0062151202000677586), ((5, 8), 0.0061746928840875626), ((4, 11), 0.006083107242981593), ((2, 6), 0.005798674188554287), ((0, 11), 0.005632345005869866), ((7, 8), 0.005364810582250357), ((1, 9), 0.005219219624996186), ((4, 6), 0.004667816994090875), ((1, 8), 0.004495136812329293), ((1, 6), 0.0041729405522346495), ((4, 9), 0.004090659009913604), ((4, 8), 0.003934894688427448), ((0, 8), 0.003696225956082344), ((0, 9), 0.003654380142688751), ((0, 6), 0.0036020498722791673)]
finish training (76000)
evaluating (25 steps)...
 ******* eval result *******
mean (weighted) 14.671785990397135
mean (unweighted) 11.986090660095215
tensor([18.49606, 20.63573, 20.43163, 11.20706, 12.19814, 15.41889,  7.59018,
         7.14504,  6.77882,  8.00624,  8.15770,  7.76757], device='cuda:0')
