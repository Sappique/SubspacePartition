{'R_grad_norm': 0.05054514987394214, 'training_loss': 0.07650374099612237}
{'R_grad_norm': 0.058789190016686914, 'training_loss': 0.054686895925551655}
{'R_grad_norm': 0.0617341017909348, 'training_loss': 0.048249735739082096}
{'R_grad_norm': 0.06308421384543181, 'training_loss': 0.04459203728474677}
{'R_grad_norm': 0.06509283341467381, 'training_loss': 0.04250181189738214}
{'R_grad_norm': 0.06506461098790169, 'training_loss': 0.040560836428776385}
{'R_grad_norm': 0.06564613038673997, 'training_loss': 0.0391876807436347}
{'R_grad_norm': 0.06647512720897794, 'training_loss': 0.03895249865949154}
{'R_grad_norm': 0.06664455283433199, 'training_loss': 0.0376794891897589}
{'R_grad_norm': 0.06727917224168778, 'training_loss': 0.03716574946418404}
{'R_grad_norm': 0.0680593334697187, 'training_loss': 0.037340551940724255}
{'R_grad_norm': 0.06773231359198689, 'training_loss': 0.03608028445392847}
{'R_grad_norm': 0.06826612563803792, 'training_loss': 0.03506688908673823}
{'R_grad_norm': 0.06819938402622938, 'training_loss': 0.03507308385334909}
{'R_grad_norm': 0.06879230033606291, 'training_loss': 0.035130480509251355}
{'R_grad_norm': 0.0691343574784696, 'training_loss': 0.034784365138038995}
{'R_grad_norm': 0.06882567338645458, 'training_loss': 0.03468004963360727}
{'R_grad_norm': 0.06913534041494131, 'training_loss': 0.03375982887111604}
{'R_grad_norm': 0.06960894491523505, 'training_loss': 0.03360441075637936}
{'R_grad_norm': 0.06963465822860598, 'training_loss': 0.03300149676389992}
{'R_grad_norm': 0.06977919019758701, 'training_loss': 0.033859202461317184}
{'R_grad_norm': 0.06970876721665263, 'training_loss': 0.03192370773293078}
{'R_grad_norm': 0.06942507162690163, 'training_loss': 0.032076113112270835}
{'R_grad_norm': 0.07089977813884615, 'training_loss': 0.03331709422171116}
{'R_grad_norm': 0.07065877046436071, 'training_loss': 0.033198569044470785}
{'R_grad_norm': 0.07051275882869959, 'training_loss': 0.03315803406760096}
{'R_grad_norm': 0.07113602813333272, 'training_loss': 0.03351966696791351}
{'R_grad_norm': 0.071161621324718, 'training_loss': 0.03255146524868906}
{'R_grad_norm': 0.07105429569259286, 'training_loss': 0.03177880367264151}
{'R_grad_norm': 0.07081920102238655, 'training_loss': 0.03208770121447742}
{'R_grad_norm': 0.07088220309466124, 'training_loss': 0.03191564598120749}
{'R_grad_norm': 0.07125555215403438, 'training_loss': 0.03208576237782836}
{'R_grad_norm': 0.07067072102800012, 'training_loss': 0.031528392201289536}
{'R_grad_norm': 0.07139516189694405, 'training_loss': 0.0318826337531209}
{'R_grad_norm': 0.07170213030651212, 'training_loss': 0.03294413795694709}
{'R_grad_norm': 0.0717649421468377, 'training_loss': 0.031963084721937776}
{'R_grad_norm': 0.07202370347455143, 'training_loss': 0.03143213680014014}
{'R_grad_norm': 0.07222658421844244, 'training_loss': 0.031958392467349765}
{'R_grad_norm': 0.07125526357442141, 'training_loss': 0.030257430002093313}
{'R_grad_norm': 0.07168643113225698, 'training_loss': 0.03042866937816143}
{'R_grad_norm': 0.07182892240583896, 'training_loss': 0.031185408337041736}
{'R_grad_norm': 0.07218891439959407, 'training_loss': 0.03082036997191608}
{'R_grad_norm': 0.07220821218565106, 'training_loss': 0.030729049034416676}
{'R_grad_norm': 0.07268213903531433, 'training_loss': 0.030748052755370736}
{'R_grad_norm': 0.0717082778736949, 'training_loss': 0.03089599187485874}
{'R_grad_norm': 0.07162939831614494, 'training_loss': 0.030248673148453236}
{'R_grad_norm': 0.07193042054772376, 'training_loss': 0.03140735709108412}
{'R_grad_norm': 0.07148719945922494, 'training_loss': 0.02967215233948082}
{'R_grad_norm': 0.07239560093730688, 'training_loss': 0.030212152721360325}
{'R_grad_norm': 0.0715617986023426, 'training_loss': 0.030323234349489213}
{'R_grad_norm': 0.0723733427003026, 'training_loss': 0.030495501859113573}
{'R_grad_norm': 0.07205131884664297, 'training_loss': 0.030124768018722534}
{'R_grad_norm': 0.07158278342336416, 'training_loss': 0.029630996584892273}
{'R_grad_norm': 0.07150154484435917, 'training_loss': 0.03139616740867496}
{'R_grad_norm': 0.07165259297937154, 'training_loss': 0.029638069001957774}
{'R_grad_norm': 0.07261157099157572, 'training_loss': 0.02998666314408183}
{'R_grad_norm': 0.07185154307633639, 'training_loss': 0.029505940377712248}
{'R_grad_norm': 0.07200298383831978, 'training_loss': 0.029957976033911107}
{'R_grad_norm': 0.07159873936325312, 'training_loss': 0.029688646933063865}
{'R_grad_norm': 0.0720550598949194, 'training_loss': 0.02895809382200241}
{'R_grad_norm': 0.07118547204881906, 'training_loss': 0.028386062672361732}
{'R_grad_norm': 0.07231856420636178, 'training_loss': 0.029909703405573963}
{'R_grad_norm': 0.07197702124714851, 'training_loss': 0.028502887520007788}
{'R_grad_norm': 0.07216070560738444, 'training_loss': 0.02925906422547996}
{'R_grad_norm': 0.07245953043922782, 'training_loss': 0.02907945037819445}
{'R_grad_norm': 0.07276919500902296, 'training_loss': 0.028923405846580864}
{'R_grad_norm': 0.07217574641108512, 'training_loss': 0.028681644750759006}
{'R_grad_norm': 0.0720906331576407, 'training_loss': 0.02904525278136134}
{'R_grad_norm': 0.07154718402773141, 'training_loss': 0.02844157610088587}
{'R_grad_norm': 0.07313972717151046, 'training_loss': 0.028768844744190572}
{'R_grad_norm': 0.0723516440205276, 'training_loss': 0.028917224388569595}
{'R_grad_norm': 0.07214362123981118, 'training_loss': 0.029136247709393503}
{'R_grad_norm': 0.07210997462272645, 'training_loss': 0.029058012911118567}
{'R_grad_norm': 0.07261865412816405, 'training_loss': 0.02911360949743539}
{'R_grad_norm': 0.07107397250831127, 'training_loss': 0.029680728907696904}
{'R_grad_norm': 0.07225234240293503, 'training_loss': 0.029391269916668534}
{'R_grad_norm': 0.07158469635993242, 'training_loss': 0.028945824042893947}
{'R_grad_norm': 0.07143720231950283, 'training_loss': 0.029080431652255358}
{'R_grad_norm': 0.07218776000663638, 'training_loss': 0.029164325543679297}
{'R_grad_norm': 0.07186474669724703, 'training_loss': 0.029186496292240918}
{'R_grad_norm': 0.07155194269493222, 'training_loss': 0.02866608346812427}
{'R_grad_norm': 0.07199110243469477, 'training_loss': 0.028152699917554855}
{'R_grad_norm': 0.07193621650338172, 'training_loss': 0.0290461721457541}
{'R_grad_norm': 0.07154972357675433, 'training_loss': 0.02798481170088053}
{'R_grad_norm': 0.07180454637855291, 'training_loss': 0.028029225980862976}
{'R_grad_norm': 0.07248096581548452, 'training_loss': 0.028386343126185237}
{'R_grad_norm': 0.07169899174943567, 'training_loss': 0.028662258703261615}
{'R_grad_norm': 0.07160938259214163, 'training_loss': 0.028715968900360166}
{'R_grad_norm': 0.07131662169471382, 'training_loss': 0.02835600762628019}
{'R_grad_norm': 0.07214692998677492, 'training_loss': 0.027782984878867864}
{'R_grad_norm': 0.07206164119765163, 'training_loss': 0.02923017465043813}
{'R_grad_norm': 0.07223711693659425, 'training_loss': 0.027714443244040012}
{'R_grad_norm': 0.0712915944494307, 'training_loss': 0.02811853323597461}
{'R_grad_norm': 0.0716391934454441, 'training_loss': 0.027215472171083093}
{'R_grad_norm': 0.07128833960741758, 'training_loss': 0.027540991958230735}
{'R_grad_norm': 0.07192826746031641, 'training_loss': 0.02717183969914913}
{'R_grad_norm': 0.07198685985058546, 'training_loss': 0.028827095944434403}
{'R_grad_norm': 0.07137940941378475, 'training_loss': 0.02756578770466149}
{'R_grad_norm': 0.07126833964139223, 'training_loss': 0.02723876792471856}
{'R_grad_norm': 0.07194188563153148, 'training_loss': 0.027264637271873653}
eval result tensor([0.02352, 0.02714, 0.02630, 0.02423, 0.02467, 0.02399, 0.02352, 0.02341,
        0.02812, 0.02930, 0.02400, 0.10507, 0.02385, 0.02412, 0.02570, 0.02519,
        0.02538, 0.02479, 0.02193, 0.02620, 0.02835, 0.02267, 0.02899, 0.02723],
       device='cuda:0')
computing merge metric
normed mi [((7, 18), 0.13625071942806244), ((6, 18), 0.1362084001302719), ((7, 10), 0.1360376477241516), ((18, 21), 0.1357932686805725), ((0, 7), 0.13577276468276978), ((6, 7), 0.13569214940071106), ((3, 7), 0.13566777110099792), ((7, 12), 0.1354714035987854), ((10, 21), 0.135396346449852), ((7, 21), 0.13532321155071259), ((0, 6), 0.1352640837430954), ((10, 18), 0.13522635400295258), ((6, 21), 0.13521836698055267), ((6, 10), 0.13513043522834778), ((0, 18), 0.13510890305042267), ((12, 18), 0.135087788105011), ((3, 18), 0.13501673936843872), ((3, 6), 0.13482089340686798), ((0, 3), 0.13478496670722961), ((0, 21), 0.1347416192293167), ((12, 21), 0.13474075496196747), ((3, 12), 0.13464711606502533), ((0, 10), 0.1345859169960022), ((3, 21), 0.13442201912403107), ((4, 7), 0.134419247508049), ((0, 12), 0.1343725025653839), ((6, 12), 0.1343485563993454), ((10, 12), 0.13432025909423828), ((3, 10), 0.13431042432785034), ((4, 18), 0.13418394327163696), ((0, 4), 0.13413850963115692), ((3, 14), 0.1340348720550537), ((4, 12), 0.13394682109355927), ((5, 6), 0.1338815689086914), ((5, 7), 0.13380172848701477), ((7, 13), 0.13380074501037598), ((7, 15), 0.1338007152080536), ((10, 14), 0.1337485909461975), ((5, 10), 0.1336914449930191), ((5, 18), 0.13364338874816895), ((12, 14), 0.13362106680870056), ((7, 19), 0.13360384106636047), ((3, 4), 0.13356810808181763), ((0, 16), 0.13353735208511353), ((5, 12), 0.13352173566818237), ((5, 21), 0.1335083693265915), ((7, 14), 0.1335064321756363), ((14, 18), 0.1334983855485916), ((4, 6), 0.1334802359342575), ((8, 10), 0.13346761465072632), ((0, 14), 0.13346335291862488), ((14, 15), 0.1334625780582428), ((10, 13), 0.1334564983844757), ((0, 5), 0.13344745337963104), ((3, 15), 0.13343115150928497), ((6, 14), 0.1334082931280136), ((4, 21), 0.13340792059898376), ((4, 10), 0.13340723514556885), ((6, 13), 0.13337965309619904), ((7, 16), 0.13336478173732758), ((6, 15), 0.1333562582731247), ((12, 13), 0.1333553045988083), ((3, 13), 0.1333412528038025), ((6, 16), 0.13331548869609833), ((14, 21), 0.1333150863647461), ((6, 19), 0.1333058923482895), ((18, 19), 0.13328038156032562), ((5, 14), 0.13327264785766602), ((12, 16), 0.13325700163841248), ((4, 5), 0.13323678076267242), ((15, 21), 0.13322991132736206), ((13, 18), 0.13322341442108154), ((16, 21), 0.13320928812026978), ((17, 18), 0.13320712745189667), ((8, 18), 0.13319484889507294), ((3, 5), 0.13319429755210876), ((6, 8), 0.1331922560930252), ((12, 15), 0.1331920176744461), ((7, 17), 0.1331864297389984), ((10, 15), 0.13318580389022827), ((3, 19), 0.13317905366420746), ((13, 21), 0.13314874470233917), ((0, 17), 0.13314178586006165), ((0, 19), 0.1331372857093811), ((0, 13), 0.1331244260072708), ((19, 21), 0.1330992430448532), ((0, 15), 0.1330656111240387), ((4, 13), 0.13306477665901184), ((15, 18), 0.13305792212486267), ((10, 16), 0.13304877281188965), ((10, 19), 0.13304594159126282), ((7, 8), 0.13302509486675262), ((3, 8), 0.13302461802959442), ((13, 14), 0.13302302360534668), ((8, 12), 0.1329929083585739), ((12, 19), 0.13296964764595032), ((7, 20), 0.1329622119665146), ((10, 17), 0.13291877508163452), ((13, 16), 0.13291817903518677), ((10, 20), 0.13289420306682587), ((16, 18), 0.13289037346839905), ((4, 14), 0.1328618824481964), ((13, 15), 0.13281793892383575), ((18, 20), 0.1327940970659256), ((0, 20), 0.13279078900814056), ((8, 21), 0.13278473913669586), ((3, 16), 0.13278241455554962), ((14, 16), 0.13275903463363647), ((14, 19), 0.13273191452026367), ((0, 8), 0.13271160423755646), ((15, 16), 0.13265743851661682), ((3, 17), 0.13263243436813354), ((20, 21), 0.132628932595253), ((6, 20), 0.13261328637599945), ((15, 19), 0.13261175155639648), ((8, 14), 0.1325986385345459), ((10, 23), 0.13256999850273132), ((6, 17), 0.13256429135799408), ((15, 17), 0.1325632929801941), ((1, 6), 0.13255563378334045), ((8, 13), 0.13250961899757385), ((5, 19), 0.13250790536403656), ((17, 21), 0.13250279426574707), ((4, 19), 0.13250209391117096), ((5, 13), 0.13249562680721283), ((12, 20), 0.13247261941432953), ((5, 20), 0.1324278563261032), ((5, 15), 0.13241539895534515), ((7, 22), 0.1323973685503006), ((2, 4), 0.13239341974258423), ((3, 20), 0.1323871612548828), ((6, 23), 0.1323794424533844), ((5, 16), 0.1323593556880951), ((7, 23), 0.1323588639497757), ((14, 17), 0.13230785727500916), ((2, 7), 0.13230456411838531), ((3, 22), 0.132299542427063), ((15, 20), 0.13228879868984222), ((6, 22), 0.13228480517864227), ((16, 19), 0.13228009641170502), ((18, 22), 0.13227199018001556), ((15, 23), 0.13227148354053497), ((0, 1), 0.13225139677524567), ((4, 16), 0.13225126266479492), ((0, 2), 0.13224846124649048), ((12, 17), 0.13224418461322784), ((14, 23), 0.13223958015441895), ((12, 22), 0.13223083317279816), ((1, 10), 0.1322248876094818), ((16, 17), 0.1322212517261505), ((14, 22), 0.13217778503894806), ((1, 3), 0.13217569887638092), ((18, 23), 0.13216745853424072), ((9, 15), 0.13216274976730347), ((0, 23), 0.13216179609298706), ((13, 20), 0.13215026259422302), ((8, 16), 0.13214975595474243), ((1, 15), 0.13213175535202026), ((1, 21), 0.13212625682353973), ((5, 8), 0.13211460411548615), ((0, 22), 0.13211260735988617), ((2, 12), 0.1320914328098297), ((4, 15), 0.13208970427513123), ((1, 7), 0.13207928836345673), ((3, 23), 0.13207542896270752), ((13, 17), 0.13207249343395233), ((21, 22), 0.13207188248634338), ((19, 20), 0.1320657879114151), ((8, 19), 0.13206353783607483), ((1, 12), 0.1320614069700241), ((4, 17), 0.13206012547016144), ((4, 20), 0.13204826414585114), ((5, 22), 0.1320425122976303), ((13, 19), 0.13202883303165436), ((14, 20), 0.13202108442783356), ((12, 23), 0.132010817527771), ((13, 22), 0.1319972425699234), ((2, 21), 0.13197068870067596), ((15, 22), 0.13193379342556), ((8, 20), 0.1319330334663391), ((9, 14), 0.1319235861301422), ((8, 15), 0.13192249834537506), ((1, 14), 0.13192176818847656), ((7, 9), 0.13190919160842896), ((4, 8), 0.13189463317394257), ((2, 5), 0.13188201189041138), ((2, 18), 0.13185949623584747), ((21, 23), 0.1318395882844925), ((17, 20), 0.13182951509952545), ((9, 13), 0.13182586431503296), ((16, 20), 0.1318080872297287), ((17, 19), 0.13179214298725128), ((1, 16), 0.1317758858203888), ((2, 6), 0.13177183270454407), ((6, 9), 0.1317344456911087), ((5, 17), 0.1317332237958908), ((13, 23), 0.13171236217021942), ((19, 23), 0.13170014321804047), ((10, 22), 0.13169685006141663), ((2, 3), 0.13169638812541962), ((1, 22), 0.13169251382350922), ((1, 18), 0.13167715072631836), ((2, 22), 0.1316743940114975), ((20, 22), 0.1316552758216858), ((1, 5), 0.13164937496185303), ((9, 21), 0.13164256513118744), ((8, 23), 0.13163845241069794), ((4, 22), 0.13161659240722656), ((9, 23), 0.13158689439296722), ((3, 9), 0.1315823644399643), ((16, 22), 0.1315821260213852), ((8, 17), 0.13155820965766907), ((9, 10), 0.13155211508274078), ((2, 14), 0.1315346658229828), ((9, 18), 0.1315019428730011), ((2, 20), 0.1314953863620758), ((1, 8), 0.13147789239883423), ((8, 9), 0.13146930932998657), ((5, 23), 0.1314689666032791), ((2, 8), 0.13145163655281067), ((9, 19), 0.13143610954284668), ((5, 9), 0.1314108669757843), ((2, 10), 0.1314048171043396), ((2, 16), 0.13137993216514587), ((1, 23), 0.1313798427581787), ((8, 22), 0.13137659430503845), ((0, 9), 0.1313619315624237), ((2, 15), 0.13135814666748047), ((9, 12), 0.13134583830833435), ((2, 13), 0.13132771849632263), ((1, 4), 0.1313217133283615), ((22, 23), 0.13132064044475555), ((1, 13), 0.1313166469335556), ((2, 19), 0.13130395114421844), ((16, 23), 0.13130301237106323), ((20, 23), 0.13129226863384247), ((19, 22), 0.13128218054771423), ((17, 22), 0.13127967715263367), ((17, 23), 0.13122661411762238), ((4, 23), 0.13121236860752106), ((1, 20), 0.131210595369339), ((1, 17), 0.13119497895240784), ((9, 16), 0.1311599463224411), ((1, 19), 0.1311100274324417), ((1, 2), 0.1310196816921234), ((1, 9), 0.1310025006532669), ((2, 23), 0.13097716867923737), ((9, 17), 0.13092830777168274), ((2, 17), 0.1309146136045456), ((4, 9), 0.13082793354988098), ((2, 9), 0.13051442801952362), ((9, 22), 0.1304982304573059), ((9, 20), 0.13048923015594482), ((11, 22), 0.07282472401857376), ((11, 23), 0.07261139899492264), ((11, 15), 0.07240107655525208), ((5, 11), 0.07236848771572113), ((11, 14), 0.0721045434474945), ((6, 11), 0.07189948111772537), ((11, 12), 0.07177647203207016), ((0, 11), 0.07164411246776581), ((10, 11), 0.07163920998573303), ((11, 16), 0.07163096964359283), ((11, 20), 0.07142125070095062), ((11, 13), 0.07125750184059143), ((7, 11), 0.07092493772506714), ((11, 21), 0.07088445872068405), ((11, 18), 0.07084590196609497), ((1, 11), 0.07072632014751434), ((9, 11), 0.07054372876882553), ((2, 11), 0.07053735107183456), ((11, 17), 0.07043490558862686), ((3, 11), 0.07041888684034348), ((4, 11), 0.06990354508161545), ((11, 19), 0.06976979970932007), ((8, 11), 0.06956236064434052)]
******* after merging (0.04): [((7, 18), 64), ((10, 21), 64), ((0, 6), 64), ((1,), 32), ((2,), 32), ((3,), 32), ((4,), 32), ((5,), 32), ((8,), 32), ((9,), 32), ((11,), 32), ((12,), 32), ((13,), 32), ((14,), 32), ((15,), 32), ((16,), 32), ((17,), 32), ((19,), 32), ((20,), 32), ((22,), 32), ((23,), 32)]
{'R_grad_norm': 0.08347699616104365, 'training_loss': 0.030130468793213367}
{'R_grad_norm': 0.08246834710240364, 'training_loss': 0.02974982971791178}
{'R_grad_norm': 0.0816411692276597, 'training_loss': 0.029990744604729117}
{'R_grad_norm': 0.08013481751084328, 'training_loss': 0.029963310277089476}
{'R_grad_norm': 0.07915761474519968, 'training_loss': 0.029906816496513784}
{'R_grad_norm': 0.07888565976172686, 'training_loss': 0.029624476293101908}
{'R_grad_norm': 0.07786090172827244, 'training_loss': 0.028979551983065902}
{'R_grad_norm': 0.07778045747429133, 'training_loss': 0.030124938380904496}
{'R_grad_norm': 0.07723022375255822, 'training_loss': 0.029859645748510955}
{'R_grad_norm': 0.07743535231798887, 'training_loss': 0.029397635734640062}
{'R_grad_norm': 0.0767674545198679, 'training_loss': 0.029009233792312444}
{'R_grad_norm': 0.0757200131751597, 'training_loss': 0.02858266929164529}
{'R_grad_norm': 0.07524558637291193, 'training_loss': 0.02879245043732226}
{'R_grad_norm': 0.07503517055884004, 'training_loss': 0.02963269831612706}
{'R_grad_norm': 0.07495166640728712, 'training_loss': 0.028972583622671664}
{'R_grad_norm': 0.07462440591305494, 'training_loss': 0.029326099678874017}
{'R_grad_norm': 0.07476808860898018, 'training_loss': 0.029451827262528242}
{'R_grad_norm': 0.07380283076316119, 'training_loss': 0.029416782995685935}
{'R_grad_norm': 0.07428864926099778, 'training_loss': 0.02820492611732334}
{'R_grad_norm': 0.07417781591415405, 'training_loss': 0.029190782546065747}
{'R_grad_norm': 0.07439849317073823, 'training_loss': 0.02933353797532618}
{'R_grad_norm': 0.07363618237897754, 'training_loss': 0.02899341973476112}
{'R_grad_norm': 0.07386168390512467, 'training_loss': 0.029376743440516294}
{'R_grad_norm': 0.07357901636511087, 'training_loss': 0.02946578204166144}
{'R_grad_norm': 0.07307523081079126, 'training_loss': 0.02929486006963998}
{'R_grad_norm': 0.07281545609235764, 'training_loss': 0.029146568910218777}
{'R_grad_norm': 0.07272950218990445, 'training_loss': 0.02860114521346986}
{'R_grad_norm': 0.07291605573147536, 'training_loss': 0.029250274966470896}
{'R_grad_norm': 0.0728311468847096, 'training_loss': 0.02912817822769284}
{'R_grad_norm': 0.07253185741603374, 'training_loss': 0.028778474107384683}
{'R_grad_norm': 0.0721266433224082, 'training_loss': 0.029028883040882646}
{'R_grad_norm': 0.0721244441717863, 'training_loss': 0.029638786194846035}
{'R_grad_norm': 0.07213905466720462, 'training_loss': 0.028820676882751285}
{'R_grad_norm': 0.07199336420744658, 'training_loss': 0.029248288408853115}
{'R_grad_norm': 0.0719100697338581, 'training_loss': 0.028360774111934006}
{'R_grad_norm': 0.07173873817548156, 'training_loss': 0.027562846927903593}
{'R_grad_norm': 0.07181085851043463, 'training_loss': 0.028434237223118542}
{'R_grad_norm': 0.07189674148336053, 'training_loss': 0.028949823109433056}
{'R_grad_norm': 0.07165197882801294, 'training_loss': 0.028192664473317565}
{'R_grad_norm': 0.07133649950847029, 'training_loss': 0.028274084869772197}
eval result tensor([0.03261, 0.03370, 0.03401, 0.02348, 0.02383, 0.02027, 0.02155, 0.02044,
        0.02352, 0.02497, 0.09354, 0.02006, 0.02007, 0.02175, 0.02133, 0.02152,
        0.02079, 0.02252, 0.02456, 0.02446, 0.02309], device='cuda:0')
computing merge metric
normed mi [((5, 11), 0.13304387032985687), ((7, 13), 0.13289301097393036), ((6, 11), 0.1327867954969406), ((11, 13), 0.13273963332176208), ((5, 13), 0.13268248736858368), ((12, 15), 0.13265959918498993), ((7, 11), 0.13262805342674255), ((12, 13), 0.13262444734573364), ((4, 6), 0.13258197903633118), ((6, 7), 0.13253532350063324), ((13, 14), 0.13247856497764587), ((6, 13), 0.13247644901275635), ((5, 12), 0.132471963763237), ((6, 12), 0.13242894411087036), ((5, 6), 0.13234633207321167), ((11, 15), 0.13234111666679382), ((3, 11), 0.1323159635066986), ((5, 14), 0.13230809569358826), ((13, 17), 0.13229481875896454), ((13, 15), 0.13228408992290497), ((7, 12), 0.1322832554578781), ((11, 17), 0.13223910331726074), ((5, 17), 0.13223400712013245), ((11, 12), 0.13221381604671478), ((5, 15), 0.13213537633419037), ((15, 17), 0.13213180005550385), ((7, 17), 0.13208626210689545), ((11, 14), 0.13202081620693207), ((11, 19), 0.13199719786643982), ((6, 17), 0.13198021054267883), ((6, 16), 0.1319623589515686), ((12, 17), 0.1319258064031601), ((8, 12), 0.13187848031520844), ((5, 7), 0.13186410069465637), ((5, 8), 0.13184349238872528), ((11, 18), 0.1318172663450241), ((12, 18), 0.13181689381599426), ((14, 17), 0.13178279995918274), ((7, 18), 0.13176608085632324), ((13, 20), 0.13175572454929352), ((7, 14), 0.13174302875995636), ((6, 14), 0.1317238062620163), ((4, 19), 0.13171860575675964), ((14, 18), 0.13171598315238953), ((9, 12), 0.1317148059606552), ((13, 18), 0.13169993460178375), ((12, 14), 0.13168896734714508), ((12, 19), 0.13168346881866455), ((4, 18), 0.13167241215705872), ((8, 11), 0.13167087733745575), ((7, 8), 0.1316699981689453), ((14, 20), 0.13165633380413055), ((3, 14), 0.1316363662481308), ((8, 14), 0.13162337243556976), ((6, 8), 0.13162127137184143), ((6, 20), 0.13161294162273407), ((4, 7), 0.13161087036132812), ((3, 12), 0.13159842789173126), ((8, 13), 0.13159841299057007), ((16, 17), 0.13159476220607758), ((4, 15), 0.1315901279449463), ((3, 13), 0.13158540427684784), ((4, 17), 0.13157428801059723), ((4, 13), 0.13157285749912262), ((6, 19), 0.13156960904598236), ((15, 16), 0.13156038522720337), ((5, 16), 0.13155750930309296), ((4, 16), 0.13155727088451385), ((14, 15), 0.13155591487884521), ((3, 4), 0.1315441131591797), ((6, 18), 0.1315438598394394), ((5, 18), 0.13153749704360962), ((13, 16), 0.13153153657913208), ((6, 15), 0.13151679933071136), ((12, 16), 0.1315017193555832), ((4, 8), 0.13148456811904907), ((7, 15), 0.13148191571235657), ((4, 11), 0.1314481794834137), ((3, 5), 0.13144727051258087), ((3, 7), 0.1314411163330078), ((8, 15), 0.13143815100193024), ((4, 12), 0.1314350962638855), ((4, 14), 0.13143250346183777), ((14, 19), 0.13142946362495422), ((11, 16), 0.13142286241054535), ((15, 19), 0.13142263889312744), ((5, 20), 0.13141226768493652), ((13, 19), 0.13138577342033386), ((9, 13), 0.13138547539710999), ((3, 6), 0.13138173520565033), ((17, 18), 0.1313813179731369), ((11, 20), 0.1313764452934265), ((14, 16), 0.13136757910251617), ((17, 19), 0.1313478797674179), ((3, 16), 0.13133756816387177), ((15, 18), 0.13133518397808075), ((5, 9), 0.13132013380527496), ((5, 19), 0.13130947947502136), ((4, 5), 0.13128721714019775), ((8, 17), 0.1312648504972458), ((15, 20), 0.13125118613243103), ((9, 11), 0.13124634325504303), ((8, 9), 0.13122530281543732), ((3, 15), 0.13121743500232697), ((8, 18), 0.1311631053686142), ((4, 9), 0.13111814856529236), ((7, 16), 0.13111811876296997), ((8, 16), 0.13111166656017303), ((7, 19), 0.1310742199420929), ((3, 20), 0.13106703758239746), ((9, 14), 0.13106609880924225), ((17, 20), 0.13106296956539154), ((16, 20), 0.13105300068855286), ((6, 9), 0.13104484975337982), ((9, 17), 0.13104097545146942), ((16, 18), 0.13100776076316833), ((7, 20), 0.13100232183933258), ((8, 19), 0.13096943497657776), ((3, 18), 0.13091783225536346), ((9, 20), 0.13089203834533691), ((3, 17), 0.1308642327785492), ((3, 19), 0.13085752725601196), ((4, 20), 0.13082127273082733), ((18, 20), 0.13079087436199188), ((16, 19), 0.13077011704444885), ((3, 9), 0.13072243332862854), ((3, 8), 0.1307200938463211), ((18, 19), 0.13066710531711578), ((12, 20), 0.13065265119075775), ((7, 9), 0.1306375414133072), ((9, 16), 0.13062888383865356), ((19, 20), 0.1306210607290268), ((9, 18), 0.1304318755865097), ((8, 20), 0.13037864863872528), ((9, 19), 0.13036687672138214), ((9, 15), 0.12997639179229736), ((0, 5), 0.08950547377268474), ((2, 5), 0.08946254849433899), ((0, 11), 0.0894233485062917), ((2, 11), 0.08932973941167195), ((1, 12), 0.08924632271130879), ((1, 15), 0.08924595514933269), ((2, 15), 0.08921595414479573), ((1, 11), 0.08921409646670024), ((2, 13), 0.0890887180964152), ((0, 6), 0.0890720784664154), ((1, 8), 0.08901177843411763), ((2, 12), 0.08900379141171773), ((1, 14), 0.08896724383036296), ((1, 5), 0.08895409107208252), ((0, 13), 0.08894883592923482), ((2, 3), 0.08892370263735454), ((0, 15), 0.08891151348749797), ((0, 14), 0.0889035960038503), ((0, 18), 0.08887988328933716), ((0, 12), 0.0887946089108785), ((2, 14), 0.08879109223683675), ((1, 13), 0.08875993887583415), ((0, 8), 0.08875953157742818), ((0, 17), 0.08875300486882527), ((1, 7), 0.08871660629908244), ((2, 7), 0.08869874477386475), ((0, 16), 0.0886239508787791), ((1, 17), 0.08861187100410461), ((1, 18), 0.0886033574740092), ((2, 8), 0.08857566118240356), ((1, 3), 0.08856975038846333), ((1, 20), 0.08854393164316814), ((2, 17), 0.08852697412172954), ((1, 6), 0.08848517139752705), ((0, 7), 0.08848338325818379), ((0, 19), 0.08840003609657288), ((1, 16), 0.0883881946404775), ((2, 16), 0.0883024533589681), ((2, 6), 0.08828773101170857), ((2, 18), 0.0882478654384613), ((0, 9), 0.08817625045776367), ((2, 9), 0.08817451198895772), ((0, 3), 0.08815647164980571), ((2, 20), 0.08809604247411092), ((1, 9), 0.08804795145988464), ((0, 20), 0.08803219596544902), ((1, 19), 0.08782715598742168), ((2, 19), 0.08776744206746419), ((0, 4), 0.08745611707369487), ((2, 4), 0.0873098373413086), ((1, 4), 0.08697691559791565), ((10, 14), 0.0708770751953125), ((4, 10), 0.06916511803865433), ((10, 11), 0.0686696469783783), ((7, 10), 0.06862185150384903), ((10, 12), 0.06840071082115173), ((10, 13), 0.06836539506912231), ((10, 15), 0.06814827769994736), ((0, 2), 0.06796525418758392), ((1, 2), 0.0679178237915039), ((10, 20), 0.06785186380147934), ((5, 10), 0.06784883141517639), ((0, 1), 0.06772707402706146), ((10, 18), 0.06762442737817764), ((6, 10), 0.06749767065048218), ((10, 19), 0.06711412966251373), ((10, 16), 0.06678219139575958), ((10, 17), 0.06664600968360901), ((3, 10), 0.0665316954255104), ((8, 10), 0.06522084772586823), ((9, 10), 0.06501983851194382), ((1, 10), 0.045933887362480164), ((2, 10), 0.04577141503492991), ((0, 10), 0.04570121566454569)]
******* after merging (0.04): [((5, 11), 64), ((7, 13), 64), ((0,), 64), ((1,), 64), ((2,), 64), ((3,), 32), ((4,), 32), ((6,), 32), ((8,), 32), ((9,), 32), ((10,), 32), ((12,), 32), ((14,), 32), ((15,), 32), ((16,), 32), ((17,), 32), ((18,), 32), ((19,), 32), ((20,), 32)]
{'R_grad_norm': 0.0887492985278368, 'training_loss': 0.03184249186422676}
{'R_grad_norm': 0.08745519939810037, 'training_loss': 0.030519718234427274}
{'R_grad_norm': 0.08636475093662739, 'training_loss': 0.03105120741762221}
{'R_grad_norm': 0.08480500344187021, 'training_loss': 0.03189312668517232}
{'R_grad_norm': 0.08446281231939792, 'training_loss': 0.031726247165352106}
{'R_grad_norm': 0.08280264377593995, 'training_loss': 0.030415167664177716}
{'R_grad_norm': 0.08216200679540635, 'training_loss': 0.031060756454244255}
{'R_grad_norm': 0.08179582685232162, 'training_loss': 0.03104886441025883}
{'R_grad_norm': 0.08168637525290251, 'training_loss': 0.03023002260364592}
{'R_grad_norm': 0.08016269542276859, 'training_loss': 0.03081636522896588}
{'R_grad_norm': 0.08041560642421246, 'training_loss': 0.029581685024313627}
{'R_grad_norm': 0.07950108028948306, 'training_loss': 0.030437108757905663}
{'R_grad_norm': 0.07968278553336859, 'training_loss': 0.030487155136652292}
{'R_grad_norm': 0.07869818937033415, 'training_loss': 0.030743506052531303}
{'R_grad_norm': 0.0785330505296588, 'training_loss': 0.031040149219334127}
{'R_grad_norm': 0.07785317320376635, 'training_loss': 0.03135377404745668}
{'R_grad_norm': 0.07805329445749522, 'training_loss': 0.032849609511904417}
{'R_grad_norm': 0.07830833166837692, 'training_loss': 0.03218639737926424}
{'R_grad_norm': 0.07772405110299588, 'training_loss': 0.033192371018230915}
{'R_grad_norm': 0.0773940685391426, 'training_loss': 0.0315794373350218}
{'R_grad_norm': 0.07696633018553257, 'training_loss': 0.03509834576398134}
{'R_grad_norm': 0.07732159350067377, 'training_loss': 0.03530972470063716}
{'R_grad_norm': 0.07683113232254982, 'training_loss': 0.032317906264215705}
{'R_grad_norm': 0.0770227487757802, 'training_loss': 0.030901719611138107}
{'R_grad_norm': 0.07628175690770149, 'training_loss': 0.030001694266684354}
{'R_grad_norm': 0.07598753301426768, 'training_loss': 0.029696479220874608}
{'R_grad_norm': 0.07666893744841217, 'training_loss': 0.030507655926048757}
{'R_grad_norm': 0.07674976836889982, 'training_loss': 0.03045422782190144}
{'R_grad_norm': 0.07682238269597291, 'training_loss': 0.029962121583521364}
{'R_grad_norm': 0.07557465847581625, 'training_loss': 0.03122915463056415}
{'R_grad_norm': 0.0759242133423686, 'training_loss': 0.029617185015231372}
{'R_grad_norm': 0.07631247736513615, 'training_loss': 0.03012475044466555}
{'R_grad_norm': 0.07669385980814696, 'training_loss': 0.03050197287928313}
{'R_grad_norm': 0.07616794511675834, 'training_loss': 0.029513373468071223}
{'R_grad_norm': 0.07548966743052006, 'training_loss': 0.03023466620594263}
{'R_grad_norm': 0.0759154767729342, 'training_loss': 0.029863119451329113}
{'R_grad_norm': 0.07604962468147278, 'training_loss': 0.030254616029560567}
{'R_grad_norm': 0.07552076857537031, 'training_loss': 0.030895195500925184}
{'R_grad_norm': 0.07593195829540492, 'training_loss': 0.03046644328162074}
{'R_grad_norm': 0.07551624376326799, 'training_loss': 0.030194855644367635}
eval result tensor([0.03839, 0.04146, 0.03850, 0.03859, 0.03977, 0.02540, 0.02620, 0.02370,
        0.02564, 0.02712, 0.09294, 0.02185, 0.02328, 0.02332, 0.02335, 0.02460,
        0.02729, 0.02634, 0.02499], device='cuda:0')
computing merge metric
normed mi [((11, 13), 0.13226842880249023), ((6, 7), 0.13219498097896576), ((7, 11), 0.1321486085653305), ((7, 12), 0.13186322152614594), ((13, 15), 0.13183115422725677), ((12, 15), 0.13177824020385742), ((7, 15), 0.1317289173603058), ((7, 16), 0.13169161975383759), ((7, 14), 0.13164108991622925), ((11, 15), 0.13157111406326294), ((7, 13), 0.13155707716941833), ((15, 16), 0.13155515491962433), ((11, 16), 0.1315421760082245), ((12, 16), 0.13151580095291138), ((12, 14), 0.13150031864643097), ((11, 12), 0.13148629665374756), ((6, 12), 0.13148507475852966), ((7, 17), 0.1314591020345688), ((14, 15), 0.1313621550798416), ((7, 8), 0.13135889172554016), ((6, 16), 0.13134358823299408), ((8, 11), 0.13133849203586578), ((13, 14), 0.13132244348526), ((6, 17), 0.13130661845207214), ((11, 14), 0.13127924501895905), ((6, 14), 0.13127626478672028), ((12, 18), 0.13126996159553528), ((12, 13), 0.1312512755393982), ((6, 8), 0.13124710321426392), ((6, 13), 0.13124291598796844), ((6, 15), 0.13121744990348816), ((8, 12), 0.13120180368423462), ((5, 12), 0.1311456263065338), ((6, 11), 0.13114550709724426), ((5, 6), 0.13108208775520325), ((7, 18), 0.13107998669147491), ((12, 17), 0.13097825646400452), ((13, 16), 0.130976140499115), ((13, 17), 0.13096937537193298), ((8, 14), 0.13092820346355438), ((15, 17), 0.13089719414710999), ((6, 18), 0.1308879405260086), ((11, 17), 0.1308678686618805), ((15, 18), 0.1308506727218628), ((14, 16), 0.13083629310131073), ((8, 13), 0.13080888986587524), ((8, 15), 0.13079304993152618), ((5, 7), 0.13076089322566986), ((6, 9), 0.13073071837425232), ((13, 18), 0.1307290941476822), ((5, 14), 0.1307189017534256), ((14, 17), 0.13070034980773926), ((5, 11), 0.13068562746047974), ((9, 12), 0.13064366579055786), ((9, 11), 0.1305900663137436), ((8, 17), 0.1305864453315735), ((9, 15), 0.13056376576423645), ((11, 18), 0.13055483996868134), ((5, 18), 0.13054248690605164), ((14, 18), 0.13052938878536224), ((16, 17), 0.13052716851234436), ((5, 13), 0.13048386573791504), ((7, 9), 0.1304066926240921), ((8, 16), 0.13039728999137878), ((5, 16), 0.13039669394493103), ((9, 18), 0.13036172091960907), ((16, 18), 0.13033120334148407), ((8, 9), 0.130254328250885), ((5, 15), 0.13023246824741364), ((9, 14), 0.13021458685398102), ((17, 18), 0.13018788397312164), ((5, 17), 0.13005854189395905), ((9, 16), 0.12996919453144073), ((5, 8), 0.12986236810684204), ((8, 18), 0.12985673546791077), ((5, 9), 0.129724383354187), ((9, 17), 0.129704087972641), ((9, 13), 0.12938980758190155), ((3, 11), 0.08926654855410258), ((2, 7), 0.08911759654680888), ((2, 11), 0.08909306923548381), ((2, 12), 0.0890803337097168), ((3, 12), 0.08901311953862508), ((2, 8), 0.08899013201395671), ((3, 8), 0.08887710173924764), ((3, 13), 0.08886489272117615), ((0, 11), 0.08877990643183391), ((2, 14), 0.08877040942509969), ((2, 16), 0.08875943223635356), ((4, 11), 0.08875916401545207), ((2, 13), 0.08875695864359538), ((0, 12), 0.08870903650919597), ((0, 7), 0.08870505293210347), ((4, 13), 0.08863530556360881), ((2, 15), 0.08862781524658203), ((3, 16), 0.08857618769009908), ((3, 14), 0.0885660747687022), ((3, 15), 0.08853067954381307), ((0, 13), 0.08846186598141988), ((0, 15), 0.0884152352809906), ((4, 12), 0.08840382099151611), ((4, 14), 0.08836264411608379), ((3, 7), 0.08832659324010213), ((4, 8), 0.08830753962198894), ((1, 12), 0.08827599883079529), ((4, 7), 0.0882258911927541), ((4, 15), 0.08819682399431865), ((0, 5), 0.08819307883580525), ((2, 17), 0.08816441893577576), ((4, 5), 0.08814739187558492), ((4, 18), 0.08813467621803284), ((3, 5), 0.08812347054481506), ((0, 18), 0.08810737729072571), ((3, 18), 0.08810274799664815), ((2, 5), 0.08806027968724568), ((0, 14), 0.08803364634513855), ((1, 7), 0.08801748355229695), ((3, 9), 0.08796591560045879), ((1, 15), 0.08792831500371297), ((2, 9), 0.08792676528294881), ((2, 18), 0.08791310588518779), ((1, 11), 0.08789421121279399), ((0, 16), 0.08788742621739705), ((4, 16), 0.08786754806836446), ((3, 17), 0.08781622846921285), ((0, 8), 0.08781003952026367), ((1, 13), 0.08773266275723775), ((0, 17), 0.08767760793368022), ((4, 17), 0.08766067028045654), ((4, 9), 0.0876209835211436), ((1, 5), 0.08752007285753886), ((2, 6), 0.08751375476519267), ((0, 9), 0.08749152223269145), ((1, 14), 0.087485005458196), ((1, 16), 0.08746806780497234), ((1, 9), 0.0874279538790385), ((1, 18), 0.08734811345736186), ((1, 8), 0.08727195858955383), ((1, 17), 0.08715048432350159), ((1, 6), 0.08712572852770488), ((0, 6), 0.08694933851559956), ((4, 6), 0.08692005276679993), ((3, 6), 0.08686327934265137), ((10, 12), 0.07091416418552399), ((2, 3), 0.06817741692066193), ((2, 4), 0.06795040518045425), ((6, 10), 0.0679137334227562), ((3, 4), 0.06757862865924835), ((0, 3), 0.0673273578286171), ((0, 2), 0.0673152357339859), ((10, 11), 0.06730454415082932), ((0, 4), 0.0672290250658989), ((10, 16), 0.06679170578718185), ((7, 10), 0.06676746904850006), ((10, 13), 0.06672738492488861), ((10, 18), 0.0665825828909874), ((1, 2), 0.06648414582014084), ((1, 3), 0.06645958870649338), ((0, 1), 0.06620745360851288), ((1, 4), 0.06606552004814148), ((10, 14), 0.06588161736726761), ((10, 15), 0.06538429856300354), ((5, 10), 0.065068818628788), ((10, 17), 0.06500445306301117), ((8, 10), 0.06472664326429367), ((9, 10), 0.06313997507095337), ((2, 10), 0.04509990910689036), ((3, 10), 0.04508050779501597), ((4, 10), 0.044425939520200096), ((0, 10), 0.0443100780248642), ((1, 10), 0.04328848918279012)]
******* after merging (0.04): [((11, 13), 64), ((6, 7), 64), ((0,), 64), ((1,), 64), ((2,), 64), ((3,), 64), ((4,), 64), ((5,), 32), ((8,), 32), ((9,), 32), ((10,), 32), ((12,), 32), ((14,), 32), ((15,), 32), ((16,), 32), ((17,), 32), ((18,), 32)]
{'R_grad_norm': 0.0949122991040349, 'training_loss': 0.03354451605118811}
{'R_grad_norm': 0.0929389937967062, 'training_loss': 0.032678660498932005}
{'R_grad_norm': 0.09205689918249846, 'training_loss': 0.03362059838138521}
{'R_grad_norm': 0.09061043843626976, 'training_loss': 0.032537140008062126}
{'R_grad_norm': 0.08962718807160855, 'training_loss': 0.0327499617729336}
{'R_grad_norm': 0.08870758470147848, 'training_loss': 0.033318106322549286}
{'R_grad_norm': 0.0876368636265397, 'training_loss': 0.03176761158742011}
{'R_grad_norm': 0.08759415283799171, 'training_loss': 0.03368195328861475}
{'R_grad_norm': 0.08661670610308647, 'training_loss': 0.033328146478161215}
{'R_grad_norm': 0.08634057939052582, 'training_loss': 0.033359897802583874}
{'R_grad_norm': 0.08493488915264606, 'training_loss': 0.03266528024338186}
{'R_grad_norm': 0.08490704759955406, 'training_loss': 0.03311575632542372}
{'R_grad_norm': 0.08450646072626114, 'training_loss': 0.03222076640464366}
{'R_grad_norm': 0.08411454383283853, 'training_loss': 0.03422912312671542}
{'R_grad_norm': 0.08376364357769489, 'training_loss': 0.03256702200509608}
{'R_grad_norm': 0.08350567903369666, 'training_loss': 0.032366468920372427}
{'R_grad_norm': 0.0826307500898838, 'training_loss': 0.03242767291143536}
{'R_grad_norm': 0.08241168860346079, 'training_loss': 0.03236523878760636}
{'R_grad_norm': 0.08230343662202358, 'training_loss': 0.033184164599515495}
{'R_grad_norm': 0.08196100696921349, 'training_loss': 0.03260357692837715}
{'R_grad_norm': 0.08189594190567732, 'training_loss': 0.033225331557914614}
{'R_grad_norm': 0.08104527719318867, 'training_loss': 0.033848643098026515}
{'R_grad_norm': 0.079958411231637, 'training_loss': 0.0325689010694623}
{'R_grad_norm': 0.0806807116419077, 'training_loss': 0.031787754017859694}
{'R_grad_norm': 0.08016511280089617, 'training_loss': 0.03272520845755935}
{'R_grad_norm': 0.07989253871142864, 'training_loss': 0.03170873505994678}
{'R_grad_norm': 0.08013492301106453, 'training_loss': 0.03294090757146478}
{'R_grad_norm': 0.07925082154572011, 'training_loss': 0.03231575063429773}
{'R_grad_norm': 0.07986812148243189, 'training_loss': 0.03233522646129131}
{'R_grad_norm': 0.0789550006389618, 'training_loss': 0.03263657621107995}
{'R_grad_norm': 0.07905445504933596, 'training_loss': 0.03286383573897183}
{'R_grad_norm': 0.07828831762075424, 'training_loss': 0.032663653548806904}
{'R_grad_norm': 0.07898516949266195, 'training_loss': 0.03345480089075863}
{'R_grad_norm': 0.07794393066316843, 'training_loss': 0.031423281598836186}
{'R_grad_norm': 0.07785969365388155, 'training_loss': 0.03220579975284636}
{'R_grad_norm': 0.07802029017359019, 'training_loss': 0.03253090069629252}
{'R_grad_norm': 0.07786992743611336, 'training_loss': 0.032950968127697704}
{'R_grad_norm': 0.07763782113790513, 'training_loss': 0.03237992860376835}
{'R_grad_norm': 0.0778415259346366, 'training_loss': 0.032393731460906565}
{'R_grad_norm': 0.07804054893553257, 'training_loss': 0.03296172947622836}
eval result tensor([0.03913, 0.04435, 0.04016, 0.04495, 0.03943, 0.03989, 0.04069, 0.02592,
        0.02571, 0.02773, 0.09243, 0.02252, 0.02298, 0.02412, 0.02714, 0.02609,
        0.02454], device='cuda:0')
computing merge metric
normed mi [((11, 14), 0.13075333833694458), ((11, 13), 0.130715474486351), ((11, 16), 0.13067732751369476), ((8, 11), 0.13065671920776367), ((13, 15), 0.13051700592041016), ((11, 12), 0.13049207627773285), ((13, 14), 0.1304076910018921), ((7, 11), 0.1303904503583908), ((11, 15), 0.1303166002035141), ((8, 13), 0.1301085650920868), ((8, 15), 0.13008235394954681), ((8, 14), 0.13003641366958618), ((12, 13), 0.12999184429645538), ((13, 16), 0.1299874484539032), ((14, 15), 0.129890576004982), ((7, 16), 0.12985308468341827), ((7, 12), 0.12982706725597382), ((12, 15), 0.12982481718063354), ((8, 12), 0.12980636954307556), ((7, 13), 0.12977710366249084), ((12, 14), 0.12975993752479553), ((12, 16), 0.12973324954509735), ((15, 16), 0.12968844175338745), ((9, 11), 0.12968775629997253), ((7, 15), 0.12965860962867737), ((8, 16), 0.12956471741199493), ((14, 16), 0.12952762842178345), ((7, 14), 0.12938617169857025), ((9, 16), 0.12933717668056488), ((7, 8), 0.12925276160240173), ((9, 13), 0.12920348346233368), ((9, 14), 0.12918728590011597), ((8, 9), 0.1290869265794754), ((9, 15), 0.1289670318365097), ((7, 9), 0.12886716425418854), ((9, 12), 0.1288003772497177), ((5, 11), 0.08868613839149475), ((4, 11), 0.0883608063062032), ((4, 8), 0.08823846777280171), ((5, 8), 0.08812446395556132), ((2, 11), 0.08809605240821838), ((4, 14), 0.08805180589358012), ((5, 13), 0.08803339799245198), ((6, 7), 0.0880040427049001), ((6, 11), 0.08800335725148518), ((4, 13), 0.08796170353889465), ((2, 13), 0.08791813254356384), ((5, 12), 0.08791715900103252), ((0, 13), 0.08791333436965942), ((4, 12), 0.08783069252967834), ((2, 7), 0.08781677484512329), ((5, 14), 0.08780244986216228), ((5, 16), 0.08776773015658061), ((3, 11), 0.08774877587954204), ((5, 7), 0.08772729833920796), ((6, 12), 0.08771286408106486), ((0, 11), 0.08766692876815796), ((4, 15), 0.08762319882710774), ((6, 8), 0.08760688702265422), ((3, 13), 0.08759290973345439), ((2, 16), 0.0874787966410319), ((4, 16), 0.08745831251144409), ((5, 15), 0.08745509386062622), ((0, 15), 0.08744362990061443), ((0, 7), 0.08743085463841756), ((6, 13), 0.08742781480153401), ((6, 16), 0.08738869428634644), ((2, 8), 0.08738369743029277), ((4, 7), 0.08738090594609578), ((1, 14), 0.08735241492589314), ((1, 11), 0.08733828862508138), ((0, 16), 0.08733188112576802), ((6, 15), 0.08730395634969075), ((0, 8), 0.08726952473322551), ((1, 15), 0.08725680907567342), ((5, 9), 0.08722821871439616), ((6, 14), 0.08720735708872478), ((1, 13), 0.08718407154083252), ((0, 12), 0.08714631199836731), ((3, 7), 0.08713228503863017), ((2, 12), 0.08712160587310791), ((2, 14), 0.08711332082748413), ((4, 9), 0.08707885940869649), ((3, 16), 0.08707808454831441), ((6, 9), 0.08704614639282227), ((1, 12), 0.08701207240422566), ((2, 15), 0.08699964483579), ((3, 12), 0.08697616060574849), ((3, 14), 0.08697230617205302), ((3, 15), 0.08694536487261455), ((3, 9), 0.08689790964126587), ((0, 14), 0.08686589201291402), ((1, 8), 0.0867426594098409), ((2, 9), 0.08671842018763225), ((3, 8), 0.08671777447064717), ((1, 7), 0.08669605851173401), ((1, 16), 0.08648300170898438), ((0, 9), 0.08630411823590596), ((1, 9), 0.08613669872283936), ((10, 11), 0.07050267606973648), ((4, 5), 0.06778403371572495), ((4, 6), 0.06745787709951401), ((5, 6), 0.06718716770410538), ((10, 14), 0.06704248487949371), ((2, 5), 0.06693083047866821), ((0, 6), 0.06664686650037766), ((2, 6), 0.0665990561246872), ((0, 4), 0.06654831022024155), ((2, 4), 0.06653408706188202), ((0, 5), 0.06651093810796738), ((0, 2), 0.06629761308431625), ((10, 16), 0.06623350828886032), ((3, 4), 0.06620892882347107), ((3, 5), 0.06611192226409912), ((2, 3), 0.06579422950744629), ((1, 4), 0.06569588929414749), ((0, 3), 0.06567426025867462), ((3, 6), 0.06559248268604279), ((1, 2), 0.0652838870882988), ((0, 1), 0.06517058610916138), ((1, 3), 0.06511645764112473), ((10, 13), 0.06506490707397461), ((1, 5), 0.06489918380975723), ((7, 10), 0.06487489491701126), ((1, 6), 0.06483544409275055), ((8, 10), 0.06468075513839722), ((10, 12), 0.06462788581848145), ((10, 15), 0.06440003961324692), ((9, 10), 0.06351187825202942), ((5, 10), 0.04469351967175802), ((4, 10), 0.04460222522417704), ((1, 10), 0.044598797957102455), ((6, 10), 0.04353025555610657), ((2, 10), 0.04337771236896515), ((0, 10), 0.04334651927153269), ((3, 10), 0.04108364631732305)]
******* after merging (0.04): [((11, 14), 64), ((13, 15), 64), ((0,), 64), ((1,), 64), ((2,), 64), ((3,), 64), ((4,), 64), ((5,), 64), ((6,), 64), ((7,), 32), ((8,), 32), ((9,), 32), ((10,), 32), ((12,), 32), ((16,), 32)]
{'R_grad_norm': 0.09981617581099272, 'training_loss': 0.035973167680203914}
{'R_grad_norm': 0.09913849227130413, 'training_loss': 0.03596495494246483}
{'R_grad_norm': 0.09765056565403939, 'training_loss': 0.035776137625798586}
{'R_grad_norm': 0.09589237287640572, 'training_loss': 0.0356547587364912}
{'R_grad_norm': 0.09556396093219519, 'training_loss': 0.03590143989771605}
{'R_grad_norm': 0.09487091746181249, 'training_loss': 0.035009437948465345}
{'R_grad_norm': 0.0933170960098505, 'training_loss': 0.03668026901781559}
{'R_grad_norm': 0.09364284701645374, 'training_loss': 0.035421857219189404}
{'R_grad_norm': 0.09250578224658966, 'training_loss': 0.036190615082159636}
{'R_grad_norm': 0.09208874460309743, 'training_loss': 0.03691905959509313}
{'R_grad_norm': 0.09205259218811988, 'training_loss': 0.03575991053134203}
{'R_grad_norm': 0.09065460488200187, 'training_loss': 0.034952691961079835}
{'R_grad_norm': 0.09108224503695965, 'training_loss': 0.03551553828641772}
{'R_grad_norm': 0.0905821931734681, 'training_loss': 0.03561919007450342}
{'R_grad_norm': 0.08971804238855839, 'training_loss': 0.03547390030696988}
{'R_grad_norm': 0.09018237605690956, 'training_loss': 0.03462752523832023}
{'R_grad_norm': 0.09021921139210462, 'training_loss': 0.03634862577542663}
{'R_grad_norm': 0.0890628681704402, 'training_loss': 0.03565498683601618}
{'R_grad_norm': 0.08868276756256818, 'training_loss': 0.0366530959866941}
{'R_grad_norm': 0.08876012172549963, 'training_loss': 0.03510471076704562}
{'R_grad_norm': 0.0889624972641468, 'training_loss': 0.03541914031840861}
{'R_grad_norm': 0.08850616671144962, 'training_loss': 0.0343919902574271}
{'R_grad_norm': 0.0893074058741331, 'training_loss': 0.035111693376675246}
{'R_grad_norm': 0.08788600515574217, 'training_loss': 0.035204385919496414}
{'R_grad_norm': 0.08750186260789633, 'training_loss': 0.03549916693009436}
{'R_grad_norm': 0.08764473132789136, 'training_loss': 0.03571761842817068}
{'R_grad_norm': 0.08778185576200485, 'training_loss': 0.03541934557259083}
{'R_grad_norm': 0.08758430786430836, 'training_loss': 0.034627496683970097}
{'R_grad_norm': 0.08687981639057397, 'training_loss': 0.03525278695859015}
{'R_grad_norm': 0.08647668421268463, 'training_loss': 0.03466067153029144}
{'R_grad_norm': 0.08677984222769737, 'training_loss': 0.034686293387785554}
{'R_grad_norm': 0.08653488770127296, 'training_loss': 0.03604593250900507}
{'R_grad_norm': 0.08673489060252905, 'training_loss': 0.03458238040097058}
{'R_grad_norm': 0.08580717764794826, 'training_loss': 0.0341213452629745}
{'R_grad_norm': 0.08618448425084352, 'training_loss': 0.03545353967696428}
{'R_grad_norm': 0.08581092335283756, 'training_loss': 0.035783120151609185}
{'R_grad_norm': 0.08497904162853956, 'training_loss': 0.03557436659000814}
{'R_grad_norm': 0.08448479477316141, 'training_loss': 0.034643054259940985}
{'R_grad_norm': 0.08466597985476255, 'training_loss': 0.03589279132895171}
{'R_grad_norm': 0.08446005627512931, 'training_loss': 0.03577939264476299}
eval result tensor([0.03768, 0.03855, 0.03539, 0.04079, 0.03584, 0.04190, 0.03293, 0.03373,
        0.03534, 0.02195, 0.02197, 0.02384, 0.09108, 0.01931, 0.02050],
       device='cuda:0')
computing merge metric
normed mi [((13, 14), 0.13154397904872894), ((9, 14), 0.13133586943149567), ((9, 13), 0.1311611533164978), ((10, 13), 0.13083390891551971), ((11, 14), 0.130525141954422), ((11, 13), 0.13032998144626617), ((10, 14), 0.13022209703922272), ((9, 11), 0.1300794631242752), ((9, 10), 0.12983375787734985), ((10, 11), 0.12968429923057556), ((8, 9), 0.08878713846206665), ((6, 10), 0.08870361248652141), ((8, 13), 0.08864088853200276), ((7, 13), 0.0885562002658844), ((7, 10), 0.08853454391161601), ((6, 13), 0.08846583962440491), ((7, 14), 0.08842090765635173), ((6, 14), 0.08825876315434773), ((8, 10), 0.08824790517489116), ((7, 9), 0.08824536204338074), ((4, 14), 0.08822694420814514), ((4, 9), 0.08822049697240193), ((8, 14), 0.08821948369344075), ((2, 13), 0.08820848663647969), ((2, 9), 0.0881731907526652), ((4, 13), 0.08813880880673726), ((5, 9), 0.08805478612581889), ((6, 9), 0.0880529781182607), ((1, 13), 0.08803972601890564), ((3, 13), 0.08799305558204651), ((5, 13), 0.08793707688649495), ((7, 11), 0.08786835273106892), ((2, 14), 0.08780413866043091), ((5, 14), 0.0877687136332194), ((8, 11), 0.08776137232780457), ((6, 11), 0.08764382203420003), ((2, 10), 0.08757895231246948), ((4, 10), 0.08754620949427287), ((3, 10), 0.08750396966934204), ((1, 14), 0.08746956785519917), ((5, 11), 0.08743821581204732), ((3, 9), 0.08743547399838765), ((0, 10), 0.08742870887120564), ((0, 9), 0.08741023143132527), ((0, 13), 0.08738030989964803), ((4, 11), 0.08729425072669983), ((1, 9), 0.08727806806564331), ((3, 14), 0.08723500370979309), ((5, 10), 0.0871666669845581), ((0, 14), 0.08707311749458313), ((1, 11), 0.08693122863769531), ((1, 10), 0.08692346016565959), ((2, 11), 0.08688847223917644), ((0, 11), 0.08683359622955322), ((3, 11), 0.08678561449050903), ((6, 7), 0.06786627322435379), ((6, 8), 0.06781177222728729), ((12, 14), 0.06776884198188782), ((7, 8), 0.06748832762241364), ((4, 7), 0.06710086017847061), ((4, 6), 0.06707637012004852), ((4, 8), 0.06700889021158218), ((9, 12), 0.06694628298282623), ((2, 8), 0.06686175614595413), ((0, 6), 0.06678690016269684), ((0, 7), 0.06675633788108826), ((2, 7), 0.06674931943416595), ((2, 6), 0.06674407422542572), ((10, 12), 0.06639809906482697), ((1, 7), 0.06637690216302872), ((2, 4), 0.06635571271181107), ((5, 6), 0.06635098159313202), ((5, 7), 0.0663328468799591), ((12, 13), 0.06620334833860397), ((1, 2), 0.06616909056901932), ((5, 8), 0.06611195206642151), ((1, 8), 0.06610594689846039), ((0, 8), 0.06609053164720535), ((3, 6), 0.06606505811214447), ((2, 5), 0.06606322526931763), ((1, 6), 0.06601537764072418), ((1, 4), 0.06588231027126312), ((4, 5), 0.06587909162044525), ((1, 5), 0.06580628454685211), ((0, 4), 0.06575305014848709), ((0, 2), 0.06554118543863297), ((0, 5), 0.06550606340169907), ((3, 8), 0.06547734886407852), ((3, 4), 0.0654137060046196), ((1, 3), 0.06537149846553802), ((3, 7), 0.06531820446252823), ((3, 5), 0.06522571295499802), ((2, 3), 0.06522414088249207), ((0, 1), 0.06508642435073853), ((11, 12), 0.06493930518627167), ((0, 3), 0.06493699550628662), ((0, 12), 0.046578620870908104), ((6, 12), 0.04501822590827942), ((7, 12), 0.04500115911165873), ((3, 12), 0.044768109917640686), ((8, 12), 0.043912301460901894), ((2, 12), 0.04354821642239889), ((4, 12), 0.04342136780420939), ((1, 12), 0.04203718900680542), ((5, 12), 0.04028207312027613)]
******* after merging (0.04): [((13, 14), 64), ((0,), 64), ((1,), 64), ((2,), 64), ((3,), 64), ((4,), 64), ((5,), 64), ((6,), 64), ((7,), 64), ((8,), 64), ((9,), 32), ((10,), 32), ((11,), 32), ((12,), 32)]
{'R_grad_norm': 0.10329198725521564, 'training_loss': 0.038239530650898815}
{'R_grad_norm': 0.1022020298987627, 'training_loss': 0.03702035632915795}
{'R_grad_norm': 0.10052377197891474, 'training_loss': 0.03844086535274983}
{'R_grad_norm': 0.09954636432230472, 'training_loss': 0.03840764763765037}
{'R_grad_norm': 0.09766173746436835, 'training_loss': 0.03763579507358372}
{'R_grad_norm': 0.09736250657588244, 'training_loss': 0.03631107493303716}
{'R_grad_norm': 0.09672852508723735, 'training_loss': 0.036524834875017405}
{'R_grad_norm': 0.09686664268374442, 'training_loss': 0.037860187655314806}
{'R_grad_norm': 0.09433902226388455, 'training_loss': 0.03707305146381259}
{'R_grad_norm': 0.09447843972593546, 'training_loss': 0.0377287076599896}
{'R_grad_norm': 0.09436374556273222, 'training_loss': 0.036542362766340375}
{'R_grad_norm': 0.0939653105288744, 'training_loss': 0.037878702953457834}
{'R_grad_norm': 0.09301248248666524, 'training_loss': 0.03655202200636268}
{'R_grad_norm': 0.09311587873846293, 'training_loss': 0.037306088972836736}
{'R_grad_norm': 0.0925703364983201, 'training_loss': 0.03718095501884818}
{'R_grad_norm': 0.09127794042229652, 'training_loss': 0.036594504229724406}
{'R_grad_norm': 0.0920209126919508, 'training_loss': 0.03682726866565645}
{'R_grad_norm': 0.09191885646432638, 'training_loss': 0.03748734236694872}
{'R_grad_norm': 0.09118630193173885, 'training_loss': 0.036383627327159045}
{'R_grad_norm': 0.09062992636114359, 'training_loss': 0.03695038685575128}
{'R_grad_norm': 0.09125036235898733, 'training_loss': 0.03722943115979433}
{'R_grad_norm': 0.0911732679978013, 'training_loss': 0.03701222875155508}
{'R_grad_norm': 0.09057784017175435, 'training_loss': 0.03922163120470941}
{'R_grad_norm': 0.09036001358181238, 'training_loss': 0.037447419092059134}
{'R_grad_norm': 0.09076766196638346, 'training_loss': 0.037552819121629}
{'R_grad_norm': 0.09039472840726376, 'training_loss': 0.037436661906540394}
{'R_grad_norm': 0.08936715759336948, 'training_loss': 0.03703594909980893}
{'R_grad_norm': 0.08943211924284697, 'training_loss': 0.03739460274577141}
{'R_grad_norm': 0.08977493941783905, 'training_loss': 0.036725723845884205}
{'R_grad_norm': 0.08928152073174715, 'training_loss': 0.03675221166573465}
{'R_grad_norm': 0.0895202899724245, 'training_loss': 0.035703920163214206}
{'R_grad_norm': 0.08941781215369701, 'training_loss': 0.037600368056446315}
{'R_grad_norm': 0.0894601583108306, 'training_loss': 0.03730962075293064}
{'R_grad_norm': 0.08917299449443818, 'training_loss': 0.037568885451182726}
{'R_grad_norm': 0.08888530183583498, 'training_loss': 0.03745599407702684}
{'R_grad_norm': 0.08907431092113256, 'training_loss': 0.037059223148971795}
{'R_grad_norm': 0.08934461627155542, 'training_loss': 0.03736103110015392}
{'R_grad_norm': 0.0893769333511591, 'training_loss': 0.0367833240609616}
{'R_grad_norm': 0.08864714361727238, 'training_loss': 0.0364378644619137}
{'R_grad_norm': 0.08830730404704809, 'training_loss': 0.03717970287427306}
eval result tensor([0.03335, 0.03843, 0.04005, 0.03621, 0.04224, 0.03634, 0.04443, 0.03289,
        0.03357, 0.03535, 0.02074, 0.02150, 0.02400, 0.09285], device='cuda:0')
computing merge metric
normed mi [((10, 11), 0.13125085830688477), ((10, 12), 0.13063478469848633), ((11, 12), 0.1298939287662506), ((9, 10), 0.08864033222198486), ((8, 11), 0.08859320481618245), ((7, 11), 0.08852756023406982), ((3, 10), 0.08848217129707336), ((8, 10), 0.08845349152882893), ((0, 10), 0.08840835094451904), ((9, 11), 0.08833884199460347), ((5, 10), 0.08833035826683044), ((6, 10), 0.08819268147150676), ((7, 10), 0.08815202116966248), ((1, 11), 0.08797515432039897), ((0, 12), 0.08797135949134827), ((2, 10), 0.08786869049072266), ((8, 12), 0.08778869112332661), ((5, 11), 0.0877669354279836), ((1, 10), 0.08773946762084961), ((3, 11), 0.0877247949441274), ((9, 12), 0.08771562576293945), ((0, 11), 0.08770501613616943), ((4, 11), 0.0875696341196696), ((7, 12), 0.08752937118212382), ((6, 11), 0.08750406901041667), ((6, 12), 0.08746082584063213), ((5, 12), 0.08742509285608928), ((4, 10), 0.08741987744967143), ((2, 11), 0.08730112512906392), ((2, 12), 0.0872873564561208), ((1, 12), 0.08716486891110738), ((3, 12), 0.08691459894180298), ((4, 12), 0.08674609661102295), ((11, 13), 0.06815004348754883), ((7, 8), 0.06760809570550919), ((10, 13), 0.06759626418352127), ((7, 9), 0.06749682128429413), ((8, 9), 0.06725183129310608), ((5, 8), 0.06697896122932434), ((5, 7), 0.06691919267177582), ((3, 9), 0.0668017566204071), ((3, 7), 0.06672508269548416), ((3, 8), 0.06662365794181824), ((5, 9), 0.0666130930185318), ((1, 7), 0.06660783290863037), ((0, 8), 0.06656955927610397), ((1, 8), 0.06656892597675323), ((0, 7), 0.0664977952837944), ((0, 2), 0.06642036139965057), ((0, 6), 0.066346175968647), ((0, 9), 0.0663408637046814), ((0, 3), 0.06630564481019974), ((0, 5), 0.06629980355501175), ((6, 7), 0.06623339653015137), ((2, 8), 0.06614699959754944), ((6, 8), 0.06614520400762558), ((1, 9), 0.06612169742584229), ((2, 7), 0.06611593812704086), ((2, 9), 0.06611382216215134), ((3, 5), 0.06611349433660507), ((6, 9), 0.06602673977613449), ((4, 7), 0.06593199819326401), ((2, 3), 0.06590085476636887), ((5, 6), 0.06583993136882782), ((3, 6), 0.06580453366041183), ((12, 13), 0.06573136150836945), ((2, 5), 0.06571893393993378), ((2, 6), 0.06566447764635086), ((1, 5), 0.0656307265162468), ((0, 1), 0.06562097370624542), ((1, 3), 0.06559517234563828), ((1, 6), 0.065529003739357), ((4, 9), 0.0653195008635521), ((4, 8), 0.06528867781162262), ((4, 5), 0.06519891321659088), ((0, 4), 0.06518237292766571), ((1, 2), 0.06515109539031982), ((3, 4), 0.06509298831224442), ((2, 4), 0.0650552436709404), ((4, 6), 0.06500415503978729), ((1, 4), 0.06484945863485336), ((1, 13), 0.04671588043371836), ((7, 13), 0.04518608748912811), ((8, 13), 0.045164555311203), ((0, 13), 0.04516099393367767), ((4, 13), 0.04456209639708201), ((9, 13), 0.044262523452440895), ((5, 13), 0.04358112315336863), ((3, 13), 0.0432220995426178), ((2, 13), 0.041169253488381706), ((6, 13), 0.03992419193188349)]
******* after merging (0.04): [((10, 11), 64), ((0,), 64), ((1,), 64), ((2,), 64), ((3,), 64), ((4,), 64), ((5,), 64), ((6,), 64), ((7,), 64), ((8,), 64), ((9,), 64), ((12,), 32), ((13,), 32)]
{'R_grad_norm': 0.10568302627652884, 'training_loss': 0.03831941342912614}
{'R_grad_norm': 0.10386358927935362, 'training_loss': 0.03920003751292825}
{'R_grad_norm': 0.10280080616474152, 'training_loss': 0.03877863670699298}
{'R_grad_norm': 0.10273733954876661, 'training_loss': 0.03883940316736698}
{'R_grad_norm': 0.10201613515615464, 'training_loss': 0.04071232482790947}
{'R_grad_norm': 0.1005759982764721, 'training_loss': 0.03952989713288844}
{'R_grad_norm': 0.10077445402741432, 'training_loss': 0.0403802727535367}
{'R_grad_norm': 0.09798879437148571, 'training_loss': 0.03812303699553013}
{'R_grad_norm': 0.09878942921757698, 'training_loss': 0.038609812604263424}
{'R_grad_norm': 0.09775862496346235, 'training_loss': 0.03903853257186711}
{'R_grad_norm': 0.09741130266338587, 'training_loss': 0.03729963724501431}
{'R_grad_norm': 0.09675790060311557, 'training_loss': 0.03877752499654889}
{'R_grad_norm': 0.09578805588185788, 'training_loss': 0.04008256008848548}
{'R_grad_norm': 0.09514973539859056, 'training_loss': 0.038049791837111116}
{'R_grad_norm': 0.09530465196818114, 'training_loss': 0.04015107188373804}
{'R_grad_norm': 0.09406370840966702, 'training_loss': 0.03979665114544332}
{'R_grad_norm': 0.09418131794780493, 'training_loss': 0.03974710096605122}
{'R_grad_norm': 0.09357624899595976, 'training_loss': 0.0421389739215374}
{'R_grad_norm': 0.09318459812551737, 'training_loss': 0.04185054244473577}
{'R_grad_norm': 0.09210764460265636, 'training_loss': 0.042795872557908295}
{'R_grad_norm': 0.09161963883787394, 'training_loss': 0.042374322405084965}
{'R_grad_norm': 0.09089218541979789, 'training_loss': 0.04429931679740548}
{'R_grad_norm': 0.09175814628601074, 'training_loss': 0.0444238661415875}
{'R_grad_norm': 0.09033587194979191, 'training_loss': 0.03999978944659233}
{'R_grad_norm': 0.08982455495744944, 'training_loss': 0.03919055837206543}
{'R_grad_norm': 0.0898252772912383, 'training_loss': 0.03891889470629394}
{'R_grad_norm': 0.08985201776027679, 'training_loss': 0.037917419569566846}
{'R_grad_norm': 0.08904901217669249, 'training_loss': 0.03886706415563822}
{'R_grad_norm': 0.08882101718336344, 'training_loss': 0.03790986144915223}
{'R_grad_norm': 0.08874339140951633, 'training_loss': 0.03859140679240227}
{'R_grad_norm': 0.08856075666844845, 'training_loss': 0.03997563431970775}
{'R_grad_norm': 0.08821647267788649, 'training_loss': 0.03924281622283161}
{'R_grad_norm': 0.08794534273445606, 'training_loss': 0.03885285910218954}
{'R_grad_norm': 0.08787226133048534, 'training_loss': 0.039052922492846844}
{'R_grad_norm': 0.08865022696554661, 'training_loss': 0.03831612765789032}
{'R_grad_norm': 0.08779618483036757, 'training_loss': 0.03857050332240761}
{'R_grad_norm': 0.08770667225122451, 'training_loss': 0.03915719503536821}
{'R_grad_norm': 0.08749001145362854, 'training_loss': 0.039803229831159116}
{'R_grad_norm': 0.08838344939053058, 'training_loss': 0.039442374063655736}
{'R_grad_norm': 0.0878979742899537, 'training_loss': 0.04040712656453252}
eval result tensor([0.03482, 0.03284, 0.03761, 0.04036, 0.03538, 0.04224, 0.03531, 0.04407,
        0.03260, 0.03270, 0.03425, 0.02237, 0.09140], device='cuda:0')
computing merge metric
normed mi [((9, 11), 0.08764009674390157), ((8, 11), 0.08758510152498881), ((1, 11), 0.08746095498402913), ((10, 11), 0.08739341298739116), ((6, 11), 0.08723605672518413), ((7, 11), 0.08699667453765869), ((4, 11), 0.08672577142715454), ((3, 11), 0.08657355109850566), ((2, 11), 0.08655787507692973), ((0, 11), 0.08633474508921306), ((5, 11), 0.08632948001225789), ((8, 9), 0.0676785334944725), ((8, 10), 0.06744644790887833), ((9, 10), 0.06713821738958359), ((11, 12), 0.0669742226600647), ((6, 9), 0.06672539561986923), ((6, 8), 0.06671515107154846), ((1, 8), 0.0665656253695488), ((0, 8), 0.06649444252252579), ((0, 10), 0.06641876697540283), ((0, 9), 0.06633657217025757), ((2, 8), 0.06632532179355621), ((4, 9), 0.06625425070524216), ((4, 8), 0.06625188887119293), ((1, 9), 0.0662248507142067), ((4, 10), 0.06621759384870529), ((1, 6), 0.06618677824735641), ((2, 9), 0.06616964936256409), ((0, 1), 0.0661497563123703), ((1, 10), 0.0661332905292511), ((1, 3), 0.06612216681241989), ((1, 7), 0.06610822677612305), ((1, 4), 0.06610613316297531), ((6, 10), 0.06609143316745758), ((7, 8), 0.06595851480960846), ((0, 4), 0.06594059616327286), ((0, 6), 0.06582614034414291), ((7, 10), 0.0658002644777298), ((3, 9), 0.06579332798719406), ((4, 6), 0.06573967635631561), ((7, 9), 0.06573688983917236), ((3, 8), 0.06573616713285446), ((0, 7), 0.06570062041282654), ((0, 2), 0.06566914170980453), ((3, 10), 0.0656595304608345), ((2, 10), 0.06556329876184464), ((6, 7), 0.06554106622934341), ((3, 6), 0.06549280136823654), ((5, 8), 0.06544439494609833), ((3, 4), 0.06542707979679108), ((4, 7), 0.06537521630525589), ((2, 6), 0.06506107747554779), ((5, 9), 0.06502900272607803), ((0, 3), 0.06501677632331848), ((2, 4), 0.06499182432889938), ((3, 7), 0.06492065638303757), ((5, 6), 0.06491929292678833), ((1, 2), 0.06491290777921677), ((2, 7), 0.06488605588674545), ((5, 10), 0.06487622857093811), ((1, 5), 0.06471654772758484), ((4, 5), 0.06470206379890442), ((5, 7), 0.06461731344461441), ((0, 5), 0.06461284309625626), ((3, 5), 0.06457409262657166), ((2, 3), 0.06453770399093628), ((2, 5), 0.06426721066236496), ((2, 12), 0.046432122588157654), ((0, 12), 0.04575350880622864), ((1, 12), 0.045232037703196205), ((9, 12), 0.045151819785436), ((8, 12), 0.04513042171796163), ((5, 12), 0.04455390075842539), ((10, 12), 0.04445375998814901), ((6, 12), 0.043901691834131874), ((4, 12), 0.04329845309257507), ((3, 12), 0.040694658954938255), ((7, 12), 0.03973529736200968)]
******* after merging (0.04): [((9, 11), 96), ((0,), 64), ((1,), 64), ((2,), 64), ((3,), 64), ((4,), 64), ((5,), 64), ((6,), 64), ((7,), 64), ((8,), 64), ((10,), 64), ((12,), 32)]
{'R_grad_norm': 0.10957180369645357, 'training_loss': 0.042601242437958715}
{'R_grad_norm': 0.1079536110535264, 'training_loss': 0.041102530360221864}
{'R_grad_norm': 0.1061086955294013, 'training_loss': 0.03980544344522059}
{'R_grad_norm': 0.10623218819499015, 'training_loss': 0.04001027383841574}
{'R_grad_norm': 0.10472138971090317, 'training_loss': 0.04135197198018432}
{'R_grad_norm': 0.10536940086632968, 'training_loss': 0.04051733882166445}
{'R_grad_norm': 0.10341035924851895, 'training_loss': 0.042106459634378555}
{'R_grad_norm': 0.10437446884810925, 'training_loss': 0.040410717958584426}
{'R_grad_norm': 0.10313679415732623, 'training_loss': 0.0398845727276057}
{'R_grad_norm': 0.10272797431796789, 'training_loss': 0.04078868742100895}
{'R_grad_norm': 0.1022754593193531, 'training_loss': 0.040909791076555846}
{'R_grad_norm': 0.10130092814564705, 'training_loss': 0.0424021212849766}
{'R_grad_norm': 0.10105353340506554, 'training_loss': 0.04124364302493632}
{'R_grad_norm': 0.10069898966699839, 'training_loss': 0.041482209637761114}
{'R_grad_norm': 0.10071814138442278, 'training_loss': 0.04000301226042211}
{'R_grad_norm': 0.10023010641336441, 'training_loss': 0.0406000941619277}
{'R_grad_norm': 0.09966101594269276, 'training_loss': 0.041205636328086256}
{'R_grad_norm': 0.09956766545772552, 'training_loss': 0.03999331209808588}
{'R_grad_norm': 0.09892235767096282, 'training_loss': 0.04238770997151733}
{'R_grad_norm': 0.09769494120031595, 'training_loss': 0.04126770114526153}
{'R_grad_norm': 0.09815387841314077, 'training_loss': 0.041813195133581754}
{'R_grad_norm': 0.09710110291838646, 'training_loss': 0.04023525840602815}
{'R_grad_norm': 0.0966975275427103, 'training_loss': 0.04141073111444712}
{'R_grad_norm': 0.09675686597824097, 'training_loss': 0.042049234956502916}
{'R_grad_norm': 0.0965846161916852, 'training_loss': 0.04098675325512886}
{'R_grad_norm': 0.09571604806929827, 'training_loss': 0.04080870334059}
{'R_grad_norm': 0.09635886427015067, 'training_loss': 0.040491029117256404}
{'R_grad_norm': 0.09508309811353684, 'training_loss': 0.04167942208237946}
{'R_grad_norm': 0.0946516527608037, 'training_loss': 0.04174880157224834}
{'R_grad_norm': 0.09462806217372417, 'training_loss': 0.04207596125081182}
{'R_grad_norm': 0.0949669824168086, 'training_loss': 0.04043024487793446}
{'R_grad_norm': 0.09365164954215288, 'training_loss': 0.04014215983450413}
{'R_grad_norm': 0.09424543529748916, 'training_loss': 0.04183045634999871}
{'R_grad_norm': 0.09340036612004042, 'training_loss': 0.041436323523521425}
{'R_grad_norm': 0.0927745720371604, 'training_loss': 0.040277141174301506}
{'R_grad_norm': 0.09266134846955537, 'training_loss': 0.040653213365003465}
{'R_grad_norm': 0.09238021910190582, 'training_loss': 0.041400532331317665}
{'R_grad_norm': 0.09328817386180162, 'training_loss': 0.041396069647744296}
{'R_grad_norm': 0.09240810357034207, 'training_loss': 0.041368746208027}
{'R_grad_norm': 0.09240662150084972, 'training_loss': 0.04279489847831428}
eval result tensor([0.04296, 0.03140, 0.02897, 0.03471, 0.03813, 0.03252, 0.03868, 0.03149,
        0.04211, 0.02820, 0.02937, 0.09253], device='cuda:0')
computing merge metric
normed mi [((9, 10), 0.06752029061317444), ((2, 9), 0.06694779545068741), ((7, 9), 0.06683001667261124), ((2, 8), 0.06680016219615936), ((2, 10), 0.06677083671092987), ((1, 9), 0.06673609465360641), ((2, 7), 0.06672924011945724), ((1, 10), 0.06669251620769501), ((3, 9), 0.06659019738435745), ((5, 9), 0.06658672541379929), ((2, 5), 0.06651352345943451), ((7, 10), 0.0664588212966919), ((2, 4), 0.06643640249967575), ((5, 10), 0.06641627103090286), ((1, 2), 0.06639621406793594), ((1, 5), 0.06635265052318573), ((8, 9), 0.06625648587942123), ((5, 7), 0.06617741286754608), ((1, 8), 0.06615888327360153), ((1, 7), 0.06615875661373138), ((8, 10), 0.06614465266466141), ((4, 9), 0.06613608449697495), ((3, 10), 0.06602711975574493), ((4, 10), 0.06600616127252579), ((7, 8), 0.0659559890627861), ((1, 3), 0.06593423336744308), ((6, 9), 0.06570880115032196), ((5, 8), 0.0656634122133255), ((4, 7), 0.06556964665651321), ((4, 5), 0.06551582366228104), ((2, 3), 0.06538903713226318), ((1, 4), 0.0653633326292038), ((4, 8), 0.06535416096448898), ((3, 8), 0.06520138680934906), ((6, 10), 0.06517039984464645), ((6, 7), 0.06514724344015121), ((3, 7), 0.06513125449419022), ((3, 5), 0.06505654007196426), ((2, 6), 0.06500493735074997), ((6, 8), 0.06492959707975388), ((3, 4), 0.06488220393657684), ((1, 6), 0.06470361351966858), ((3, 6), 0.06462794542312622), ((4, 6), 0.06462518870830536), ((5, 6), 0.06460034102201462), ((0, 9), 0.054430967569351195), ((0, 10), 0.054002505540847776), ((0, 2), 0.053773194551467896), ((0, 7), 0.053443795442581175), ((0, 5), 0.05339885354042053), ((0, 3), 0.05321939587593079), ((0, 1), 0.05314682126045227), ((0, 8), 0.053090280294418334), ((0, 4), 0.05296869277954101), ((0, 6), 0.05182658433914185), ((3, 11), 0.045723140239715576), ((1, 11), 0.045382559299468994), ((2, 11), 0.04522011677424113), ((9, 11), 0.044978514313697815), ((10, 11), 0.04451033969720205), ((6, 11), 0.044180368383725487), ((7, 11), 0.04371486107508341), ((5, 11), 0.043084800243377686), ((4, 11), 0.04004248728354772), ((8, 11), 0.03906256208817164), ((0, 11), 0.03381756320595741)]
******* after merging (0.04): [((9, 10), 128), ((0,), 96), ((1,), 64), ((2,), 64), ((3,), 64), ((4,), 64), ((5,), 64), ((6,), 64), ((7,), 64), ((8,), 64), ((11,), 32)]
{'R_grad_norm': 0.11327000293880701, 'training_loss': 0.04301259095780551}
{'R_grad_norm': 0.11220664583146572, 'training_loss': 0.0440337108913809}
{'R_grad_norm': 0.11101486522704362, 'training_loss': 0.04297540727071464}
{'R_grad_norm': 0.11066860295832157, 'training_loss': 0.044481752682477234}
{'R_grad_norm': 0.11009128484874964, 'training_loss': 0.043556520473212006}
{'R_grad_norm': 0.11000937134027482, 'training_loss': 0.04390566073358059}
{'R_grad_norm': 0.10914395723491907, 'training_loss': 0.04500969710759819}
{'R_grad_norm': 0.10750557102262974, 'training_loss': 0.04448304271325469}
{'R_grad_norm': 0.10809527222067118, 'training_loss': 0.04279249881394207}
{'R_grad_norm': 0.10688810888677835, 'training_loss': 0.04236427111551166}
{'R_grad_norm': 0.10686236776411534, 'training_loss': 0.04286963848397136}
{'R_grad_norm': 0.10731105942279101, 'training_loss': 0.04454339743591845}
{'R_grad_norm': 0.10602492947131395, 'training_loss': 0.04356512810103595}
{'R_grad_norm': 0.10616473879665136, 'training_loss': 0.04282452789135277}
{'R_grad_norm': 0.10539228655397892, 'training_loss': 0.04330849042162299}
{'R_grad_norm': 0.10498250145465135, 'training_loss': 0.043321167109534146}
{'R_grad_norm': 0.10458380647003651, 'training_loss': 0.04386777888983488}
{'R_grad_norm': 0.10477845497429371, 'training_loss': 0.04361301326192915}
{'R_grad_norm': 0.10389775574207306, 'training_loss': 0.04279751383699477}
{'R_grad_norm': 0.10435701467096806, 'training_loss': 0.04318598215468228}
{'R_grad_norm': 0.10245239235460758, 'training_loss': 0.04266375722363591}
{'R_grad_norm': 0.10311490833759308, 'training_loss': 0.04305266902782023}
{'R_grad_norm': 0.10287604428827762, 'training_loss': 0.043289857218042016}
{'R_grad_norm': 0.10188994150608778, 'training_loss': 0.04271573714911938}
{'R_grad_norm': 0.10188404235988856, 'training_loss': 0.04297823214903474}
{'R_grad_norm': 0.10114288713783026, 'training_loss': 0.04379967594519257}
{'R_grad_norm': 0.1012058611959219, 'training_loss': 0.043388450304046276}
{'R_grad_norm': 0.10069249611347914, 'training_loss': 0.04329656825400889}
{'R_grad_norm': 0.10020694259554147, 'training_loss': 0.043235394274815916}
{'R_grad_norm': 0.09971025064587594, 'training_loss': 0.044133994495496154}
{'R_grad_norm': 0.09951613031327725, 'training_loss': 0.043473384194076065}
{'R_grad_norm': 0.09901303630322218, 'training_loss': 0.043501373138278725}
{'R_grad_norm': 0.09869523324072361, 'training_loss': 0.042802408523857596}
{'R_grad_norm': 0.09804932478815317, 'training_loss': 0.04416946646757424}
{'R_grad_norm': 0.09684253554791213, 'training_loss': 0.04330881778150797}
{'R_grad_norm': 0.09698714174330235, 'training_loss': 0.04265369684435427}
{'R_grad_norm': 0.09650160986930131, 'training_loss': 0.04418368027545512}
{'R_grad_norm': 0.09583739794790745, 'training_loss': 0.04317323215305805}
{'R_grad_norm': 0.09508375637233257, 'training_loss': 0.04273892665281892}
{'R_grad_norm': 0.09477380704134702, 'training_loss': 0.04341804855503142}
eval result tensor([0.05085, 0.04728, 0.03361, 0.03095, 0.03672, 0.04125, 0.03471, 0.04206,
        0.03332, 0.04542, 0.09418], device='cuda:0')
computing merge metric
normed mi [((3, 8), 0.06742917746305466), ((3, 6), 0.0672781765460968), ((3, 9), 0.06725796312093735), ((2, 3), 0.06723194569349289), ((3, 5), 0.06703374534845352), ((2, 6), 0.06694076955318451), ((2, 8), 0.06693954765796661), ((6, 8), 0.06679179519414902), ((2, 9), 0.06678269058465958), ((2, 4), 0.06665003299713135), ((8, 9), 0.0665697529911995), ((5, 8), 0.06644773483276367), ((5, 6), 0.06642494350671768), ((6, 9), 0.06638889014720917), ((2, 5), 0.06625232845544815), ((3, 4), 0.0661110207438469), ((3, 7), 0.06608182936906815), ((7, 8), 0.06607619673013687), ((4, 8), 0.06598930805921555), ((4, 9), 0.06583070009946823), ((4, 6), 0.0658067911863327), ((7, 9), 0.06570126116275787), ((6, 7), 0.06566999107599258), ((4, 5), 0.06564021110534668), ((5, 9), 0.06561876833438873), ((5, 7), 0.06554678082466125), ((2, 7), 0.06554071605205536), ((4, 7), 0.06545650213956833), ((1, 3), 0.05399118065834045), ((1, 8), 0.05376085638999939), ((1, 6), 0.05366782546043396), ((1, 4), 0.05349529385566711), ((1, 2), 0.05345895290374756), ((1, 9), 0.053354793787002565), ((1, 5), 0.05326252579689026), ((1, 7), 0.05233221650123596), ((4, 10), 0.04750417172908783), ((2, 10), 0.04713506996631622), ((3, 10), 0.04683772226174673), ((7, 10), 0.0457381804784139), ((8, 10), 0.0456700474023819), ((0, 3), 0.045189544558525085), ((0, 2), 0.04499890406926473), ((0, 8), 0.04497888684272766), ((0, 6), 0.04492387672265371), ((0, 4), 0.044795443614323936), ((0, 9), 0.04466088612874349), ((6, 10), 0.04459387560685476), ((0, 5), 0.04449095825354258), ((0, 7), 0.043832639853159584), ((5, 10), 0.04136754820744196), ((9, 10), 0.040623292326927185), ((0, 1), 0.038583231823784966), ((1, 10), 0.03482634574174881), ((0, 10), 0.02769429385662079)]
******* after merging (0.04): [((3, 8), 128), ((0,), 128), ((1,), 96), ((2,), 64), ((4,), 64), ((5,), 64), ((6,), 64), ((7,), 64), ((9,), 64), ((10,), 32)]
{'R_grad_norm': 0.11851173870265484, 'training_loss': 0.04583806251175702}
{'R_grad_norm': 0.11745379246771336, 'training_loss': 0.047172028226777914}
{'R_grad_norm': 0.11570889081805945, 'training_loss': 0.046976718939840796}
{'R_grad_norm': 0.1152696456760168, 'training_loss': 0.044865449415519836}
{'R_grad_norm': 0.11451353117823601, 'training_loss': 0.04494996327906847}
{'R_grad_norm': 0.1140082499012351, 'training_loss': 0.046919217212125656}
{'R_grad_norm': 0.11354475941509008, 'training_loss': 0.0450385480094701}
{'R_grad_norm': 0.1126101740449667, 'training_loss': 0.046329014226794245}
{'R_grad_norm': 0.11234412707388401, 'training_loss': 0.04479877506382764}
{'R_grad_norm': 0.11143068812787532, 'training_loss': 0.045683150133118036}
{'R_grad_norm': 0.11067581050097942, 'training_loss': 0.045221848441287876}
{'R_grad_norm': 0.1109714325889945, 'training_loss': 0.047147763967514036}
{'R_grad_norm': 0.10995976250618696, 'training_loss': 0.0461449090950191}
{'R_grad_norm': 0.10905579388141633, 'training_loss': 0.045627159783616665}
{'R_grad_norm': 0.10799921773374081, 'training_loss': 0.045411247462034225}
{'R_grad_norm': 0.1084441166371107, 'training_loss': 0.04779061367735267}
{'R_grad_norm': 0.10809927977621556, 'training_loss': 0.04629825037904084}
{'R_grad_norm': 0.10707929309457541, 'training_loss': 0.045680692968890074}
{'R_grad_norm': 0.10595526743680239, 'training_loss': 0.04532189141958952}
{'R_grad_norm': 0.10627969775348901, 'training_loss': 0.04405458035878837}
{'R_grad_norm': 0.10618336647748947, 'training_loss': 0.046389982709661125}
{'R_grad_norm': 0.10593700733035803, 'training_loss': 0.04631394572556019}
{'R_grad_norm': 0.10456846449524164, 'training_loss': 0.04498496614396572}
{'R_grad_norm': 0.10461013678461313, 'training_loss': 0.04571493991650641}
{'R_grad_norm': 0.10408405758440495, 'training_loss': 0.04546674000099302}
{'R_grad_norm': 0.1039878897741437, 'training_loss': 0.04714421660639346}
{'R_grad_norm': 0.10312003787606955, 'training_loss': 0.04486725562252104}
{'R_grad_norm': 0.10193251069635152, 'training_loss': 0.04516706028021872}
{'R_grad_norm': 0.10282754451036454, 'training_loss': 0.04568422527052462}
{'R_grad_norm': 0.10168228797614574, 'training_loss': 0.046932286592200397}
{'R_grad_norm': 0.10045273292809725, 'training_loss': 0.04569551362656057}
{'R_grad_norm': 0.10166135609149933, 'training_loss': 0.046104213306680325}
{'R_grad_norm': 0.10035528190433979, 'training_loss': 0.04607398774474859}
{'R_grad_norm': 0.09999738771468401, 'training_loss': 0.0471884274482727}
{'R_grad_norm': 0.10003246977925301, 'training_loss': 0.0470418193936348}
{'R_grad_norm': 0.09965977687388658, 'training_loss': 0.046636037854477765}
{'R_grad_norm': 0.0992898291349411, 'training_loss': 0.04393989535048604}
{'R_grad_norm': 0.09809612587094307, 'training_loss': 0.04697024916298687}
{'R_grad_norm': 0.09815929591655731, 'training_loss': 0.0453834022115916}
{'R_grad_norm': 0.09789712030440569, 'training_loss': 0.045846996242180464}
eval result tensor([0.05143, 0.04773, 0.04471, 0.03108, 0.03498, 0.03983, 0.03231, 0.04060,
        0.04480, 0.09193], device='cuda:0')
computing merge metric
normed mi [((3, 6), 0.06637167185544968), ((3, 8), 0.0661514550447464), ((6, 8), 0.06608819216489792), ((3, 4), 0.0659855529665947), ((5, 6), 0.0659104585647583), ((3, 5), 0.06570073962211609), ((4, 8), 0.06533927470445633), ((5, 8), 0.06527123600244522), ((4, 6), 0.0651661604642868), ((6, 7), 0.06512932479381561), ((7, 8), 0.06504371762275696), ((4, 7), 0.06496939808130264), ((3, 7), 0.0648626908659935), ((5, 7), 0.06483927369117737), ((4, 5), 0.06483540683984756), ((2, 6), 0.05336774587631225), ((2, 3), 0.05315401554107666), ((2, 4), 0.05307998061180115), ((2, 8), 0.0530056893825531), ((2, 5), 0.05294317603111267), ((2, 7), 0.05176582932472229), ((4, 9), 0.04672854642073313), ((3, 9), 0.04626428087552389), ((7, 9), 0.044966742396354675), ((1, 6), 0.044617071747779846), ((1, 3), 0.04457630713780721), ((0, 6), 0.044491360584894814), ((0, 3), 0.044374714295069374), ((1, 4), 0.044323280453681946), ((1, 8), 0.04428830246130625), ((0, 5), 0.04419945180416107), ((0, 8), 0.044169411063194275), ((1, 5), 0.04411006470521291), ((6, 9), 0.04408864676952362), ((1, 7), 0.043485706051190696), ((0, 4), 0.04325949649016062), ((0, 7), 0.043189177910486855), ((5, 9), 0.0403788685798645), ((8, 9), 0.039935655891895294), ((1, 2), 0.038249313831329346), ((0, 2), 0.03814577630587986), ((2, 9), 0.03412231430411339), ((0, 1), 0.033390067517757416), ((1, 9), 0.027056488394737243), ((0, 9), 0.02674325406551361)]
******* after merging (0.04): [((3, 6), 128), ((0,), 128), ((1,), 128), ((2,), 96), ((4,), 64), ((5,), 64), ((7,), 64), ((8,), 64), ((9,), 32)]
{'R_grad_norm': 0.12218254562467337, 'training_loss': 0.049032936301082373}
{'R_grad_norm': 0.12082425303757191, 'training_loss': 0.04807267914526164}
{'R_grad_norm': 0.12025941152125597, 'training_loss': 0.04902561587281525}
{'R_grad_norm': 0.12086923070251941, 'training_loss': 0.04946229997090995}
{'R_grad_norm': 0.11984784495085478, 'training_loss': 0.05012979377061129}
{'R_grad_norm': 0.11746413212269545, 'training_loss': 0.048607807895168664}
{'R_grad_norm': 0.11802325628697873, 'training_loss': 0.04937486131675541}
{'R_grad_norm': 0.11712784990668297, 'training_loss': 0.04756404772400856}
{'R_grad_norm': 0.11704116873443127, 'training_loss': 0.049394159391522405}
{'R_grad_norm': 0.11701436046510935, 'training_loss': 0.049479191387072206}
{'R_grad_norm': 0.11670120399445295, 'training_loss': 0.049764511687681076}
{'R_grad_norm': 0.11531488582491875, 'training_loss': 0.050052130175754425}
{'R_grad_norm': 0.11448395263403655, 'training_loss': 0.051062026740983125}
{'R_grad_norm': 0.11330439150333405, 'training_loss': 0.04901064530946314}
{'R_grad_norm': 0.11276798170059919, 'training_loss': 0.04952433951199055}
{'R_grad_norm': 0.11362640116363763, 'training_loss': 0.05095411094836891}
{'R_grad_norm': 0.1113468624278903, 'training_loss': 0.048047964395955205}
{'R_grad_norm': 0.11094263542443514, 'training_loss': 0.05148959572426975}
{'R_grad_norm': 0.10997945636510849, 'training_loss': 0.05148743345402181}
{'R_grad_norm': 0.11022141151130199, 'training_loss': 0.05196704021655023}
{'R_grad_norm': 0.1090473224967718, 'training_loss': 0.05207908854819834}
{'R_grad_norm': 0.10881874263286591, 'training_loss': 0.05340775951743126}
{'R_grad_norm': 0.10987564519047738, 'training_loss': 0.054554018853232265}
{'R_grad_norm': 0.10747243102639914, 'training_loss': 0.0559570371452719}
{'R_grad_norm': 0.10684630233794451, 'training_loss': 0.04804792427457869}
{'R_grad_norm': 0.10583923444151878, 'training_loss': 0.04904086839407682}
{'R_grad_norm': 0.10599964458495378, 'training_loss': 0.04901884482242167}
{'R_grad_norm': 0.10469172175973654, 'training_loss': 0.04862115762196481}
{'R_grad_norm': 0.1061136431992054, 'training_loss': 0.04893795353360474}
{'R_grad_norm': 0.10511225756257772, 'training_loss': 0.04785910187289119}
{'R_grad_norm': 0.10565962083637714, 'training_loss': 0.04929877461865544}
{'R_grad_norm': 0.10524790324270725, 'training_loss': 0.04930084000341594}
{'R_grad_norm': 0.10508216388523578, 'training_loss': 0.04953679913654924}
{'R_grad_norm': 0.10464049078524112, 'training_loss': 0.0496488178987056}
{'R_grad_norm': 0.10475057240575553, 'training_loss': 0.05040542033500969}
{'R_grad_norm': 0.1033820191770792, 'training_loss': 0.048323629768565295}
{'R_grad_norm': 0.10383322402834892, 'training_loss': 0.04892366624437273}
{'R_grad_norm': 0.10329202331602573, 'training_loss': 0.04895828685723245}
{'R_grad_norm': 0.10324369262903929, 'training_loss': 0.04900889021344483}
{'R_grad_norm': 0.10410620704293251, 'training_loss': 0.04904089302755892}
finish training (100000)
evaluating (25 steps)...
 ******* eval result *******
mean (weighted) 0.04646442333857218
mean (unweighted) 0.047975506633520126
tensor([0.05153, 0.05169, 0.04581, 0.04318, 0.03187, 0.03744, 0.03770, 0.04292,
        0.08964], device='cuda:0')
